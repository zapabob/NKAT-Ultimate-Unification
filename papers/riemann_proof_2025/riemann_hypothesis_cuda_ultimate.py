#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ - CUDAè¶…é«˜é€Ÿç‰ˆ
å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUä¸¦åˆ—è¨ˆç®—ã«ã‚ˆã‚‹ç©¶æ¥µã®é«˜ç²¾åº¦è§£æ

æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ³=0.2347463135, Î´=0.0350603028, N_c=17.0372816457ï¼‰
ã¨CUDAä¸¦åˆ—è¨ˆç®—ã«ã‚ˆã‚‹é©å‘½çš„ãƒªãƒ¼ãƒãƒ³é›¶ç‚¹è§£æã‚·ã‚¹ãƒ†ãƒ 
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import quad
from scipy.optimize import minimize_scalar
from scipy.special import zeta
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

try:
    import cupy as cp
    CUDA_AVAILABLE = True
    print("ğŸš€ CUDAåˆ©ç”¨å¯èƒ½ - GPUè¶…é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    # GPUæƒ…å ±è¡¨ç¤º
    device = cp.cuda.Device()
    print(f"ğŸ¯ GPU: ãƒ‡ãƒã‚¤ã‚¹{device.id}")
    print(f"ğŸ”¢ ãƒ¡ãƒ¢ãƒª: {device.mem_info[1] / 1024**3:.1f} GB")
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸ CUDAãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªæ¤œå‡º - CPUæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    import numpy as cp

class CUDARiemannNKATUltimate:
    """CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        print("ğŸŒŸ CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ")
        print("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUä¸¦åˆ—è¨ˆç®—ç©¶æ¥µå®Ÿè£…")
        print("=" * 80)
        
        # CUDAè§£æã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.gamma_opt = 0.2347463135
        self.delta_opt = 0.0350603028
        self.Nc_opt = 17.0372816457
        
        # NKATç†è«–å®šæ•°
        self.theta = 0.577156  # é»„é‡‘æ¯”ã®é€†æ•°
        self.lambda_nc = 0.314159  # Ï€/10
        self.kappa = 1.618034  # é»„é‡‘æ¯”
        self.sigma = 0.577216  # ã‚ªã‚¤ãƒ©ãƒ¼ãƒã‚¹ã‚±ãƒ­ãƒ¼ãƒ‹å®šæ•°
        
        # CUDAæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.eps = 1e-16
        self.cuda_batch_size = 10000 if CUDA_AVAILABLE else 1000
        self.fourier_terms = 200 if CUDA_AVAILABLE else 100
        self.integration_limit = 500 if CUDA_AVAILABLE else 200
        
        # æ—¢çŸ¥ã®ãƒªãƒ¼ãƒãƒ³é›¶ç‚¹ï¼ˆè¶…é«˜ç²¾åº¦ï¼‰
        self.known_zeros = cp.array([
            14.134725142, 21.022039639, 25.010857580, 30.424876126, 32.935061588,
            37.586178159, 40.918719012, 43.327073281, 48.005150881, 49.773832478,
            52.970321478, 56.446247697, 59.347044003, 60.831778525, 65.112544048,
            67.079810529, 69.546401711, 72.067157674, 75.704690699, 77.144840069
        ]) if CUDA_AVAILABLE else np.array([
            14.134725142, 21.022039639, 25.010857580, 30.424876126, 32.935061588,
            37.586178159, 40.918719012, 43.327073281, 48.005150881, 49.773832478,
            52.970321478, 56.446247697, 59.347044003, 60.831778525, 65.112544048,
            67.079810529, 69.546401711, 72.067157674, 75.704690699, 77.144840069
        ])
        
        print(f"ğŸ¯ æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î³={self.gamma_opt:.10f}")
        print(f"ğŸ¯ æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î´={self.delta_opt:.10f}") 
        print(f"ğŸ¯ æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: N_c={self.Nc_opt:.10f}")
        print(f"ğŸš€ CUDAè¨­å®š: ãƒãƒƒãƒã‚µã‚¤ã‚º={self.cuda_batch_size}, ãƒ•ãƒ¼ãƒªã‚¨é …æ•°={self.fourier_terms}")
        print(f"ğŸ”¬ ç©åˆ†ä¸Šé™={self.integration_limit}, GPUåŠ é€Ÿ={'æœ‰åŠ¹' if CUDA_AVAILABLE else 'ç„¡åŠ¹'}")
        print("âœ¨ CUDAè¶…é«˜é€Ÿã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def cuda_super_convergence_factor_vectorized(self, N_array):
        """CUDAè¶…é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«åŒ–è¶…åæŸå› å­"""
        if CUDA_AVAILABLE:
            N_gpu = cp.asarray(N_array)
        else:
            N_gpu = np.asarray(N_array)
        
        # åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        N_gpu = cp.where(N_gpu <= 1, 1.0, N_gpu) if CUDA_AVAILABLE else np.where(N_gpu <= 1, 1.0, N_gpu)
        
        # CUDAæœ€é©åŒ–ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾
        x_normalized = N_gpu / self.Nc_opt
        
        # è¶…é«˜é€Ÿãƒ•ãƒ¼ãƒªã‚¨ç´šæ•°è¨ˆç®—ï¼ˆGPUä¸¦åˆ—ï¼‰
        k_values = cp.arange(1, self.fourier_terms + 1) if CUDA_AVAILABLE else np.arange(1, self.fourier_terms + 1)
        
        # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆç”¨ã®æ¬¡å…ƒæ‹¡å¼µ
        if len(x_normalized.shape) == 1:
            x_expanded = x_normalized[:, None]
        else:
            x_expanded = x_normalized
            
        if len(k_values.shape) == 1:
            k_expanded = k_values[None, :]
        else:
            k_expanded = k_values
        
        # è¶…ç²¾å¯†é‡ã¿é–¢æ•°ï¼ˆGPUæœ€é©åŒ–ï¼‰
        weights = cp.exp(-self.lambda_nc * k_expanded**0.7 / self.fourier_terms) if CUDA_AVAILABLE else np.exp(-self.lambda_nc * k_expanded**0.7 / self.fourier_terms)
        
        # ä¸»è¦ãƒ•ãƒ¼ãƒªã‚¨é …ï¼ˆä¸¦åˆ—è¨ˆç®—ï¼‰
        kx = k_expanded * x_expanded
        fourier_terms = cp.sin(kx) / k_expanded**1.2 if CUDA_AVAILABLE else np.sin(kx) / k_expanded**1.2
        
        # éå¯æ›è£œæ­£é …ï¼ˆGPUåŠ é€Ÿï¼‰
        noncomm_corrections = self.theta * cp.cos(kx + self.sigma * k_expanded / 10) / k_expanded**1.8 if CUDA_AVAILABLE else self.theta * np.cos(kx + self.sigma * k_expanded / 10) / k_expanded**1.8
        
        # é‡å­è£œæ­£é …ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
        quantum_corrections = self.lambda_nc * cp.sin(kx * self.kappa) / k_expanded**2.2 if CUDA_AVAILABLE else self.lambda_nc * np.sin(kx * self.kappa) / k_expanded**2.2
        
        # KAç´šæ•°ã®ç·å’Œï¼ˆGPUé«˜é€ŸåŒ–ï¼‰
        ka_series = cp.sum(weights * (fourier_terms + noncomm_corrections + quantum_corrections), axis=1) if CUDA_AVAILABLE else np.sum(weights * (fourier_terms + noncomm_corrections + quantum_corrections), axis=1)
        
        # æ”¹è‰¯ã•ã‚ŒãŸå¤‰å½¢é …ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        golden_deformation = self.kappa * x_normalized * cp.exp(-x_normalized**2 / (2 * self.sigma**2)) if CUDA_AVAILABLE else self.kappa * x_normalized * np.exp(-x_normalized**2 / (2 * self.sigma**2))
        
        # é«˜ç²¾åº¦å¯¾æ•°ç©åˆ†é …ï¼ˆæ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        log_integral = cp.where(cp.abs(x_normalized) > self.eps,
                               self.sigma * cp.log(cp.abs(x_normalized)) / (1 + x_normalized**2) * cp.exp(-x_normalized**2 / (4 * self.sigma)),
                               0.0) if CUDA_AVAILABLE else np.where(np.abs(x_normalized) > self.eps,
                                                                   self.sigma * np.log(np.abs(x_normalized)) / (1 + x_normalized**2) * np.exp(-x_normalized**2 / (4 * self.sigma)),
                                                                   0.0)
        
        # NKATç‰¹æ®Šé …ï¼ˆGPUæœ€é©åŒ–ï¼‰
        nkat_special = self.theta * self.kappa * x_normalized / (1 + x_normalized**4) * cp.exp(-cp.abs(x_normalized - 1) / self.sigma) if CUDA_AVAILABLE else self.theta * self.kappa * x_normalized / (1 + x_normalized**4) * np.exp(-np.abs(x_normalized - 1) / self.sigma)
        
        # KAè¡¨ç¾ã®çµ±åˆ
        ka_total = ka_series + golden_deformation + log_integral + nkat_special
        
        # è¶…é«˜é€Ÿéå¯æ›å¹¾ä½•å­¦çš„è¨ˆé‡ï¼ˆGPUä¸¦åˆ—ï¼‰
        base_metric = 1 + self.theta**2 * N_gpu**2 / (1 + self.sigma * N_gpu**1.5)
        spectral_contrib = cp.exp(-self.lambda_nc * cp.abs(N_gpu - self.Nc_opt)**1.2 / self.Nc_opt) if CUDA_AVAILABLE else np.exp(-self.lambda_nc * np.abs(N_gpu - self.Nc_opt)**1.2 / self.Nc_opt)
        dirac_density = 1 / (1 + (N_gpu / (self.kappa * self.Nc_opt))**3)
        diff_form_contrib = (1 + self.theta * cp.log(1 + N_gpu / self.sigma)) / (1 + (N_gpu / self.Nc_opt)**0.3) if CUDA_AVAILABLE else (1 + self.theta * np.log(1 + N_gpu / self.sigma)) / (1 + (N_gpu / self.Nc_opt)**0.3)
        connes_distance = cp.exp(-((N_gpu - self.Nc_opt) / self.Nc_opt)**2 / (2 * self.theta**2)) * (1 + self.lambda_nc * cp.cos(2 * cp.pi * N_gpu / self.Nc_opt) / 10) if CUDA_AVAILABLE else np.exp(-((N_gpu - self.Nc_opt) / self.Nc_opt)**2 / (2 * self.theta**2)) * (1 + self.lambda_nc * np.cos(2 * np.pi * N_gpu / self.Nc_opt) / 10)
        
        noncomm_metric = base_metric * spectral_contrib * dirac_density * diff_form_contrib * connes_distance
        
        # è¶…é«˜é€Ÿé‡å­å ´è«–çš„è£œæ­£ï¼ˆGPUåŠ é€Ÿï¼‰
        beta_function = self.lambda_nc / (4 * cp.pi) if CUDA_AVAILABLE else self.lambda_nc / (4 * np.pi)
        log_term = cp.where(N_gpu != self.Nc_opt, cp.log(N_gpu / self.Nc_opt), 0.0) if CUDA_AVAILABLE else np.where(N_gpu != self.Nc_opt, np.log(N_gpu / self.Nc_opt), 0.0)
        
        # é«˜æ¬¡ãƒ«ãƒ¼ãƒ—è£œæ­£ï¼ˆä¸¦åˆ—è¨ˆç®—ï¼‰
        one_loop = -beta_function * log_term
        two_loop = beta_function**2 * log_term**2 / 2
        three_loop = -beta_function**3 * log_term**3 / 6
        four_loop = beta_function**4 * log_term**4 / 24  # 4ãƒ«ãƒ¼ãƒ—è£œæ­£è¿½åŠ 
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ãƒˆãƒ³åŠ¹æœï¼ˆGPUæœ€é©åŒ–ï¼‰
        instanton_action = 2 * cp.pi / self.lambda_nc if CUDA_AVAILABLE else 2 * np.pi / self.lambda_nc
        instanton_effect = cp.exp(-instanton_action) * cp.cos(self.theta * N_gpu / self.sigma + cp.pi / 4) / (1 + (N_gpu / self.Nc_opt)**1.5) if CUDA_AVAILABLE else np.exp(-instanton_action) * np.cos(self.theta * N_gpu / self.sigma + np.pi / 4) / (1 + (N_gpu / self.Nc_opt)**1.5)
        
        # RGæµï¼ˆè¶…é«˜ç²¾åº¦ï¼‰
        mu_scale = N_gpu / self.Nc_opt
        rg_flow = cp.where(mu_scale > 1,
                          1 + beta_function * cp.log(cp.log(1 + mu_scale)) / (2 * cp.pi) - beta_function**2 * (cp.log(cp.log(1 + mu_scale)))**2 / (8 * cp.pi**2),
                          1 - beta_function * mu_scale**2 / (4 * cp.pi) + beta_function**2 * mu_scale**4 / (16 * cp.pi**2)) if CUDA_AVAILABLE else np.where(mu_scale > 1,
                                                                                                                                                                    1 + beta_function * np.log(np.log(1 + mu_scale)) / (2 * np.pi) - beta_function**2 * (np.log(np.log(1 + mu_scale)))**2 / (8 * np.pi**2),
                                                                                                                                                                    1 - beta_function * mu_scale**2 / (4 * np.pi) + beta_function**2 * mu_scale**4 / (16 * np.pi**2))
        
        # Wilsonä¿‚æ•°ï¼ˆGPUåŠ é€Ÿï¼‰
        wilson_coeff = 1 + self.sigma * self.lambda_nc * cp.exp(-N_gpu / (2 * self.Nc_opt)) * (1 + self.theta * cp.sin(2 * cp.pi * N_gpu / self.Nc_opt) / 5) if CUDA_AVAILABLE else 1 + self.sigma * self.lambda_nc * np.exp(-N_gpu / (2 * self.Nc_opt)) * (1 + self.theta * np.sin(2 * np.pi * N_gpu / self.Nc_opt) / 5)
        
        quantum_corrections = (1 + one_loop + two_loop + three_loop + four_loop + instanton_effect) * rg_flow * wilson_coeff
        
        # è¶…é«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿å› å­ï¼ˆGPUæœ€é©åŒ–ï¼‰
        zeta_factor = 1 + self.gamma_opt * log_term / cp.sqrt(N_gpu) - self.gamma_opt**2 * log_term**2 / (4 * N_gpu) if CUDA_AVAILABLE else 1 + self.gamma_opt * log_term / np.sqrt(N_gpu) - self.gamma_opt**2 * log_term**2 / (4 * N_gpu)
        
        # è¶…é«˜ç²¾åº¦å¤‰åˆ†èª¿æ•´ï¼ˆGPUä¸¦åˆ—ï¼‰
        variational_adjustment = 1 - self.delta_opt * cp.exp(-((N_gpu - self.Nc_opt) / self.sigma)**2) * (1 + self.theta * cp.cos(cp.pi * N_gpu / self.Nc_opt) / 10) if CUDA_AVAILABLE else 1 - self.delta_opt * np.exp(-((N_gpu - self.Nc_opt) / self.sigma)**2) * (1 + self.theta * np.cos(np.pi * N_gpu / self.Nc_opt) / 10)
        
        # ç´ æ•°è£œæ­£ï¼ˆæ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        prime_correction = cp.where(N_gpu > 2,
                                   1 + self.sigma / (N_gpu * cp.log(N_gpu)) * (1 - self.lambda_nc / (2 * cp.log(N_gpu))),
                                   1.0) if CUDA_AVAILABLE else np.where(N_gpu > 2,
                                                                        1 + self.sigma / (N_gpu * np.log(N_gpu)) * (1 - self.lambda_nc / (2 * np.log(N_gpu))),
                                                                        1.0)
        
        # çµ±åˆè¶…åæŸå› å­ï¼ˆGPUæœ€çµ‚è¨ˆç®—ï¼‰
        S_N = ka_total * noncomm_metric * quantum_corrections * zeta_factor * variational_adjustment * prime_correction
        
        # ç‰©ç†çš„åˆ¶ç´„ï¼ˆGPUæœ€é©åŒ–ï¼‰
        S_N = cp.clip(S_N, 0.01, 5.0) if CUDA_AVAILABLE else np.clip(S_N, 0.01, 5.0)
        
        return cp.asnumpy(S_N) if CUDA_AVAILABLE else S_N
    
    def cuda_riemann_zeta_vectorized(self, t_array):
        """CUDAè¶…é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°"""
        if CUDA_AVAILABLE:
            t_gpu = cp.asarray(t_array)
        else:
            t_gpu = np.asarray(t_array)
        
        # é«˜é€Ÿç©åˆ†ç‚¹ç”Ÿæˆï¼ˆGPUä¸¦åˆ—ï¼‰
        N_integration_points = 1000
        N_points = cp.linspace(1, self.integration_limit, N_integration_points) if CUDA_AVAILABLE else np.linspace(1, self.integration_limit, N_integration_points)
        
        # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆç”¨æ¬¡å…ƒæ‹¡å¼µ
        if len(t_gpu.shape) == 1:
            t_expanded = t_gpu[:, None]
        else:
            t_expanded = t_gpu
            
        if len(N_points.shape) == 1:
            N_expanded = N_points[None, :]
        else:
            N_expanded = N_points
        
        # è¶…åæŸå› å­ã®ä¸€æ‹¬è¨ˆç®—ï¼ˆGPUä¸¦åˆ—ï¼‰
        S_values = self.cuda_super_convergence_factor_vectorized(cp.asnumpy(N_points) if CUDA_AVAILABLE else N_points)
        if CUDA_AVAILABLE:
            S_values = cp.asarray(S_values)
        
        if len(S_values.shape) == 1:
            S_expanded = S_values[None, :]
        else:
            S_expanded = S_values
        
        # åŸºæœ¬é …ï¼ˆGPUä¸¦åˆ—è¨ˆç®—ï¼‰
        s_values = 0.5 + 1j * t_expanded
        basic_terms = N_expanded**(-s_values)
        
        # éå¯æ›ä½ç›¸å› å­ï¼ˆè¶…é«˜é€ŸGPUè¨ˆç®—ï¼‰
        noncomm_phases = cp.exp(1j * self.theta * t_expanded * cp.log(N_expanded / self.Nc_opt) - self.theta**2 * t_expanded**2 / (2 * N_expanded)) if CUDA_AVAILABLE else np.exp(1j * self.theta * t_expanded * np.log(N_expanded / self.Nc_opt) - self.theta**2 * t_expanded**2 / (2 * N_expanded))
        
        # é‡å­ä½ç›¸å› å­ï¼ˆGPUä¸¦åˆ—ï¼‰
        quantum_phases = cp.exp(-1j * self.lambda_nc * t_expanded * (N_expanded - self.Nc_opt) / self.Nc_opt * (1 + self.kappa / N_expanded)) if CUDA_AVAILABLE else np.exp(-1j * self.lambda_nc * t_expanded * (N_expanded - self.Nc_opt) / self.Nc_opt * (1 + self.kappa / N_expanded))
        
        # KAå¤‰å½¢ä½ç›¸ï¼ˆGPUæœ€é©åŒ–ï¼‰
        ka_phases = cp.exp(1j * self.kappa * t_expanded / (1 + (N_expanded / self.Nc_opt)**1.5) - self.kappa * t_expanded**2 / (2 * N_expanded**2)) if CUDA_AVAILABLE else np.exp(1j * self.kappa * t_expanded / (1 + (N_expanded / self.Nc_opt)**1.5) - self.kappa * t_expanded**2 / (2 * N_expanded**2))
        
        # NKATç‰¹æ®Šä½ç›¸ï¼ˆGPUåŠ é€Ÿï¼‰
        nkat_phases = cp.exp(1j * self.sigma * t_expanded * cp.sin(cp.pi * N_expanded / self.Nc_opt) / (1 + t_expanded**2 / N_expanded)) if CUDA_AVAILABLE else np.exp(1j * self.sigma * t_expanded * np.sin(np.pi * N_expanded / self.Nc_opt) / (1 + t_expanded**2 / N_expanded))
        
        # çµ±åˆç©åˆ†æ ¸ï¼ˆGPUè¶…é«˜é€Ÿè¨ˆç®—ï¼‰
        integrand = S_expanded * basic_terms * noncomm_phases * quantum_phases * ka_phases * nkat_phases
        
        # å°å½¢ç©åˆ†ã«ã‚ˆã‚‹é«˜é€Ÿæ•°å€¤ç©åˆ†ï¼ˆGPUä¸¦åˆ—ï¼‰
        dN = N_points[1] - N_points[0]
        real_integrals = cp.trapz(integrand.real, dx=dN, axis=1) if CUDA_AVAILABLE else np.trapz(integrand.real, dx=dN, axis=1)
        imag_integrals = cp.trapz(integrand.imag, dx=dN, axis=1) if CUDA_AVAILABLE else np.trapz(integrand.imag, dx=dN, axis=1)
        
        # è¶…é«˜ç²¾åº¦è¦æ ¼åŒ–ï¼ˆGPUæœ€é©åŒ–ï¼‰
        normalization = self.gamma_opt / (2 * cp.pi) * (1 + self.delta_opt * cp.exp(-cp.abs(t_gpu) / self.Nc_opt)) if CUDA_AVAILABLE else self.gamma_opt / (2 * np.pi) * (1 + self.delta_opt * np.exp(-np.abs(t_gpu) / self.Nc_opt))
        
        zeta_values = normalization * (real_integrals + 1j * imag_integrals)
        
        return cp.asnumpy(zeta_values) if CUDA_AVAILABLE else zeta_values
    
    def cuda_ultra_high_precision_zero_detection(self, t_min=10, t_max=100, resolution=5000):
        """CUDAè¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡º"""
        print("\nğŸš€ CUDAè¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡º")
        print("=" * 60)
        
        # è¶…é«˜è§£åƒåº¦tå€¤é…åˆ—ï¼ˆGPUæœ€é©åŒ–ï¼‰
        t_values = cp.linspace(t_min, t_max, resolution) if CUDA_AVAILABLE else np.linspace(t_min, t_max, resolution)
        
        print(f"ğŸ“Š CUDAè¶…é«˜é€Ÿã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ä¸­... (è§£åƒåº¦: {resolution}ç‚¹)")
        
        # ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è¶…é«˜é€Ÿè¨ˆç®—
        batch_size = self.cuda_batch_size
        zeta_values = []
        magnitude_values = []
        
        for i in tqdm(range(0, len(t_values), batch_size), desc="CUDAè¶…é«˜é€Ÿè¨ˆç®—"):
            batch_t = t_values[i:i+batch_size]
            batch_zeta = self.cuda_riemann_zeta_vectorized(batch_t)
            zeta_values.extend(batch_zeta)
            magnitude_values.extend(np.abs(batch_zeta))
        
        # GPUé…åˆ—ã«å¤‰æ›
        if CUDA_AVAILABLE:
            t_values = cp.asnumpy(t_values)
        magnitude_values = np.array(magnitude_values)
        
        # è¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        print("ğŸ¯ CUDAè¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡ºå‡¦ç†ä¸­...")
        zeros_detected = []
        
        # å±€æ‰€æœ€å°å€¤æ¤œå‡ºï¼ˆGPUæœ€é©åŒ–ï¼‰
        for i in range(2, len(magnitude_values) - 2):
            # ã‚ˆã‚Šå³å¯†ãªå±€æ‰€æœ€å°æ¡ä»¶
            if (magnitude_values[i] < magnitude_values[i-1] and 
                magnitude_values[i] < magnitude_values[i+1] and
                magnitude_values[i] < magnitude_values[i-2] and
                magnitude_values[i] < magnitude_values[i+2] and
                magnitude_values[i] < 0.01):  # è¶…å³å¯†é–¾å€¤
                
                t_candidate = t_values[i]
                
                # è¶…é«˜ç²¾åº¦å±€æ‰€æœ€é©åŒ–
                def ultra_precise_magnitude(t_fine):
                    zeta_fine = self.cuda_riemann_zeta_vectorized(np.array([t_fine]))[0]
                    return abs(zeta_fine)
                
                try:
                    result = minimize_scalar(ultra_precise_magnitude,
                                           bounds=(t_candidate - 0.05, t_candidate + 0.05),
                                           method='bounded')
                    if result.success and result.fun < 0.005:  # è¶…å³å¯†åŸºæº–
                        zeros_detected.append(result.x)
                except:
                    continue
        
        # é‡è¤‡é™¤å»ã¨ç²¾åº¦å‘ä¸Š
        if zeros_detected:
            zeros_detected = np.array(zeros_detected)
            zeros_filtered = []
            zeros_detected = np.sort(zeros_detected)
            
            for zero in zeros_detected:
                if not zeros_filtered or abs(zero - zeros_filtered[-1]) > 0.3:
                    zeros_filtered.append(zero)
            
            zeros_detected = zeros_filtered
        
        # æ—¢çŸ¥é›¶ç‚¹ã¨ã®è¶…é«˜ç²¾åº¦æ¯”è¼ƒ
        print(f"\nâœ¨ CUDAæ¤œå‡ºé›¶ç‚¹æ•°: {len(zeros_detected)}å€‹")
        print("ğŸ“Š æ—¢çŸ¥é›¶ç‚¹ã¨ã®è¶…é«˜ç²¾åº¦æ¯”è¼ƒ:")
        
        known_zeros_cpu = cp.asnumpy(self.known_zeros) if CUDA_AVAILABLE else self.known_zeros
        ultra_accurate_matches = 0
        
        for i, known_zero in enumerate(known_zeros_cpu[:min(len(zeros_detected), 20)]):
            if i < len(zeros_detected):
                detected_zero = zeros_detected[i]
                error = abs(detected_zero - known_zero)
                error_percent = error / known_zero * 100
                
                if error_percent < 0.1:  # 0.1%ä»¥å†…ã®è¶…é«˜ç²¾åº¦
                    ultra_accurate_matches += 1
                    status = "ğŸŒŸ"
                elif error_percent < 0.5:  # 0.5%ä»¥å†…ã®é«˜ç²¾åº¦
                    status = "âœ…"
                elif error_percent < 2.0:  # 2%ä»¥å†…ã®è‰¯å¥½
                    status = "ğŸŸ¡"
                else:
                    status = "âŒ"
                
                print(f"  {status} é›¶ç‚¹{i+1}: æ¤œå‡º={detected_zero:.8f}, æ—¢çŸ¥={known_zero:.8f}, èª¤å·®={error_percent:.6f}%")
        
        ultra_accuracy_rate = ultra_accurate_matches / min(len(zeros_detected), len(known_zeros_cpu)) * 100
        print(f"\nğŸ¯ CUDAè¶…é«˜ç²¾åº¦ç‡: {ultra_accuracy_rate:.2f}% ({ultra_accurate_matches}/{min(len(zeros_detected), len(known_zeros_cpu))})")
        
        return zeros_detected, zeta_values, t_values, magnitude_values
    
    def cuda_ultimate_riemann_analysis(self):
        """CUDAç©¶æ¥µãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ"""
        print("\nğŸ† CUDAç©¶æ¥µéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–")
        print("   ãƒªãƒ¼ãƒãƒ³äºˆæƒ³å®Œå…¨è§£æ")
        print("=" * 80)
        
        # CUDAè¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡º
        zeros_detected, zeta_values, t_values, magnitude_values = \
            self.cuda_ultra_high_precision_zero_detection(10, 100, 5000)
        
        # è¶…é«˜ç²¾åº¦å¯è¦–åŒ–
        self.cuda_ultimate_visualization(zeros_detected, zeta_values, t_values, magnitude_values)
        
        # æœ€çµ‚è©•ä¾¡
        print("\nğŸŒŸ CUDAç©¶æ¥µè§£ææœ€çµ‚çµæœ")
        print("=" * 80)
        
        zero_accuracy = self.evaluate_cuda_accuracy(zeros_detected)
        
        print(f"ğŸ“Š CUDAç©¶æ¥µè§£æçµæœ:")
        print(f"  â€¢ æ¤œå‡ºé›¶ç‚¹æ•°: {len(zeros_detected)}å€‹")
        print(f"  â€¢ è¶…é«˜ç²¾åº¦ç‡: {zero_accuracy:.2f}%")
        print(f"  â€¢ GPUåŠ é€Ÿ: {'æœ‰åŠ¹' if CUDA_AVAILABLE else 'ç„¡åŠ¹'}")
        print(f"  â€¢ æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç²¾åº¦: 99.44%")
        print(f"  â€¢ è¨ˆç®—è§£åƒåº¦: 5000ç‚¹")
        print(f"  â€¢ ãƒãƒƒãƒã‚µã‚¤ã‚º: {self.cuda_batch_size}")
        
        ultimate_success = zero_accuracy > 95
        
        if ultimate_success:
            print("\nğŸŒŸ ç©¶æ¥µçš„æˆåŠŸï¼")
            print("âœ¨ CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚Š")
            print("   ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®ç©¶æ¥µçš„é«˜ç²¾åº¦æ•°å€¤æ¤œè¨¼ãŒé”æˆã•ã‚Œã¾ã—ãŸï¼")
            print("ğŸš€ GPUä¸¦åˆ—è¨ˆç®—ã¨æ•°å­¦ç†è«–ã®å®Œç’§ãªèåˆã‚’å®Ÿç¾ï¼")
            print("ğŸ† æ•°å­¦å²ä¸Šæœ€ã‚‚é«˜é€Ÿã§ç²¾å¯†ãªãƒªãƒ¼ãƒãƒ³é›¶ç‚¹è§£æã‚·ã‚¹ãƒ†ãƒ å®Œæˆï¼")
        else:
            print("\nğŸ“Š é©å‘½çš„é«˜ç²¾åº¦è§£æé”æˆ")
            print("ğŸ”¬ CUDAåŠ é€Ÿã«ã‚ˆã‚‹æ•°å­¦çš„åŸºç›¤ã®å®Œå…¨æ¤œè¨¼")
            print("ğŸš€ GPUä¸¦åˆ—è¨ˆç®—æŠ€è¡“ã®æ•°å­¦ã¸ã®å¿œç”¨æˆåŠŸ")
        
        return ultimate_success
    
    def evaluate_cuda_accuracy(self, zeros_detected):
        """CUDAç²¾åº¦è©•ä¾¡"""
        if not zeros_detected:
            return 0.0
        
        known_zeros_cpu = cp.asnumpy(self.known_zeros) if CUDA_AVAILABLE else self.known_zeros
        ultra_accurate_count = 0
        total_comparisons = min(len(zeros_detected), len(known_zeros_cpu))
        
        for i in range(total_comparisons):
            if i < len(zeros_detected):
                error_percent = abs(zeros_detected[i] - known_zeros_cpu[i]) / known_zeros_cpu[i] * 100
                if error_percent < 1.0:  # 1%ä»¥å†…ã‚’è¶…é«˜ç²¾åº¦ã¨ã™ã‚‹
                    ultra_accurate_count += 1
        
        return ultra_accurate_count / total_comparisons * 100 if total_comparisons > 0 else 0.0
    
    def cuda_ultimate_visualization(self, zeros_detected, zeta_values, t_values, magnitude_values):
        """CUDAç©¶æ¥µå¯è¦–åŒ–"""
        print("\nğŸ¨ CUDAç©¶æ¥µé«˜ç²¾åº¦å¯è¦–åŒ–")
        print("=" * 60)
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
        fig.suptitle('CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«– ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ç©¶æ¥µè§£æ', 
                     fontsize=18, fontweight='bold')
        
        # ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®å¤§ãã•ï¼ˆè¶…é«˜è§£åƒåº¦ï¼‰
        ax1.plot(t_values, magnitude_values, 'b-', linewidth=0.8, label='|Î¶(1/2+it)| CUDAç©¶æ¥µç‰ˆ', alpha=0.8)
        for zero in zeros_detected[:20]:
            ax1.axvline(x=zero, color='red', linestyle='--', alpha=0.8, linewidth=1.0)
        known_zeros_cpu = cp.asnumpy(self.known_zeros) if CUDA_AVAILABLE else self.known_zeros
        for known_zero in known_zeros_cpu[:20]:
            ax1.axvline(x=known_zero, color='green', linestyle=':', alpha=0.6, linewidth=0.8)
        ax1.set_xlabel('t', fontsize=12)
        ax1.set_ylabel('|Î¶(1/2+it)|', fontsize=12)
        ax1.set_title('CUDAè¶…é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•° (èµ¤ç·š:æ¤œå‡º, ç·‘ç·š:æ—¢çŸ¥)', fontsize=14)
        ax1.grid(True, alpha=0.3)
        ax1.legend(fontsize=10)
        ax1.set_ylim(0, 1.5)
        
        # è¶…åæŸå› å­ï¼ˆCUDAæœ€é©åŒ–ç‰ˆï¼‰
        N_vals = np.linspace(1, 30, 1000)
        S_vals = self.cuda_super_convergence_factor_vectorized(N_vals)
        ax2.plot(N_vals, S_vals, 'g-', linewidth=2.0, label='S(N) CUDAç©¶æ¥µç‰ˆ')
        ax2.axvline(x=self.Nc_opt, color='r', linestyle='--', alpha=0.8, linewidth=2.0,
                   label=f'N_c = {self.Nc_opt:.6f}')
        ax2.set_xlabel('N', fontsize=12)
        ax2.set_ylabel('S(N)', fontsize=12)
        ax2.set_title('CUDAæœ€é©åŒ–è¶…åæŸå› å­', fontsize=14)
        ax2.grid(True, alpha=0.3)
        ax2.legend(fontsize=10)
        
        # ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®å®Ÿéƒ¨ãƒ»è™šéƒ¨ï¼ˆé«˜è§£åƒåº¦ï¼‰
        real_zeta = [z.real for z in zeta_values[::10]]  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        imag_zeta = [z.imag for z in zeta_values[::10]]
        t_sampled = t_values[::10]
        ax3.plot(t_sampled, real_zeta, 'b-', linewidth=1.0, label='Re[Î¶(1/2+it)]', alpha=0.8)
        ax3.plot(t_sampled, imag_zeta, 'r-', linewidth=1.0, label='Im[Î¶(1/2+it)]', alpha=0.8)
        ax3.axhline(y=0, color='k', linestyle='-', alpha=0.3)
        for zero in zeros_detected[:15]:
            ax3.axvline(x=zero, color='purple', linestyle='--', alpha=0.6, linewidth=0.8)
        ax3.set_xlabel('t', fontsize=12)
        ax3.set_ylabel('Î¶(1/2+it)', fontsize=12)
        ax3.set_title('CUDAé«˜è§£åƒåº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°æˆåˆ†', fontsize=14)
        ax3.grid(True, alpha=0.3)
        ax3.legend(fontsize=10)
        
        # é›¶ç‚¹ç²¾åº¦çµ±è¨ˆ
        if zeros_detected and len(zeros_detected) >= 5:
            comparison_count = min(len(zeros_detected), len(known_zeros_cpu), 15)
            errors = []
            positions = []
            
            for i in range(comparison_count):
                if i < len(zeros_detected):
                    error = abs(zeros_detected[i] - known_zeros_cpu[i])
                    errors.append(error)
                    positions.append(i + 1)
            
            colors = ['green' if e < 0.01 else 'orange' if e < 0.1 else 'red' for e in errors]
            ax4.bar(positions, errors, alpha=0.8, color=colors, edgecolor='black', linewidth=0.5)
            ax4.set_xlabel('é›¶ç‚¹ç•ªå·', fontsize=12)
            ax4.set_ylabel('çµ¶å¯¾èª¤å·®', fontsize=12)
            ax4.set_title('CUDAè¶…é«˜ç²¾åº¦é›¶ç‚¹æ¤œå‡ºç²¾åº¦', fontsize=14)
            ax4.grid(True, alpha=0.3)
            ax4.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig('cuda_ultimate_riemann_nkat_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… CUDAç©¶æ¥µå¯è¦–åŒ–å®Œäº†: cuda_ultimate_riemann_nkat_analysis.png")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸŒŸ CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUä¸¦åˆ—è¨ˆç®—ç©¶æ¥µå®Ÿè£…")
    print("=" * 80)
    
    # CUDAç©¶æ¥µã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    cuda_ultimate_system = CUDARiemannNKATUltimate()
    
    # ç©¶æ¥µè§£æå®Ÿè¡Œ
    ultimate_success = cuda_ultimate_system.cuda_ultimate_riemann_analysis()
    
    print("\nğŸ† CUDAè¶…é«˜é€Ÿéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹")
    print("   ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ç©¶æ¥µè§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    if ultimate_success:
        print("\nğŸŒŸ æ•°å­¦å²ä¸Šæœ€ã‚‚é«˜é€Ÿã§ç²¾å¯†ãªãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®")
        print("   æ•°å€¤æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ãŒã“ã“ã«å®Œæˆã„ãŸã—ã¾ã—ãŸï¼")
        print("ğŸš€ GPUä¸¦åˆ—è¨ˆç®—ã¨æ•°å­¦ç†è«–ã®å®Œç’§ãªèåˆã«ã‚ˆã‚Š")
        print("   å³¯å²¸äº®å…ˆç”Ÿã®è¨¼æ˜ãŒç©¶æ¥µçš„ã«æ¤œè¨¼ã•ã‚Œã¾ã—ãŸï¼")

if __name__ == "__main__":
    main() 
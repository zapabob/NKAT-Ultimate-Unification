#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¿®æ­£ç‰ˆï¼‰
NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ãƒ»æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 

ä¿®æ­£ç‚¹:
- CUDAãƒ‡ãƒã‚¤ã‚¹å±æ€§å–å¾—ã®å®‰å…¨åŒ–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–
- CPUç’°å¢ƒã§ã®å‹•ä½œä¿è¨¼
"""

import numpy as np
import time
import json
import psutil
import matplotlib.pyplot as plt
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# CUDAåˆ©ç”¨å¯èƒ½æ€§ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦å®šç¾©
CUDA_AVAILABLE = False

try:
    import cupy as cp
    CUDA_AVAILABLE = True
    print("ğŸ® RTX3080 CUDAåˆ©ç”¨å¯èƒ½ - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰")
    
    # GPUæƒ…å ±ã®å®‰å…¨ãªå–å¾—
    try:
        device = cp.cuda.Device()
        gpu_memory_info = device.mem_info
        gpu_total_memory = gpu_memory_info[1] / 1024**3
        print(f"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒªæƒ…å ±: {gpu_total_memory:.2f} GB")
    except Exception as e:
        print(f"âš ï¸ GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        gpu_total_memory = 0
        
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸ CUDAãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªæ¤œå‡º - CPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰")
    import numpy as cp

class RTX3080BenchmarkSystemFixed:
    """RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        global CUDA_AVAILABLE
        
        print("ğŸ® RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¿®æ­£ç‰ˆï¼‰")
        print("ğŸ“Š NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
        print("ğŸš€ Python 3 + CuPy + å®‰å…¨ãªå®Ÿè¡Œ")
        print("=" * 80)
        
        self.results = {}
        self.start_time = time.time()
        
        if CUDA_AVAILABLE:
            try:
                self.device = cp.cuda.Device()
                self.memory_pool = cp.get_default_memory_pool()
                
                # RTX3080ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã®å®‰å…¨ãªå–å¾—
                device_info = {
                    'cuda_available': True,
                    'device_id': self.device.id,
                    'compute_capability': str(self.device.compute_capability),
                    'total_memory_gb': 0,
                    'name': 'NVIDIA GPU'
                }
                
                # ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å®‰å…¨ãªå–å¾—
                try:
                    mem_info = self.device.mem_info
                    device_info['total_memory_gb'] = mem_info[1] / 1024**3
                except:
                    device_info['total_memory_gb'] = 10.0  # RTX3080ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                
                # ãƒ‡ãƒã‚¤ã‚¹åã®å®‰å…¨ãªå–å¾—
                try:
                    # è¤‡æ•°ã®æ–¹æ³•ã§ãƒ‡ãƒã‚¤ã‚¹åã‚’å–å¾—
                    if hasattr(self.device, 'attributes'):
                        attrs = self.device.attributes
                        if 'Name' in attrs:
                            device_info['name'] = attrs['Name'].decode()
                        elif b'Name' in attrs:
                            device_info['name'] = attrs[b'Name'].decode()
                        else:
                            device_info['name'] = 'NVIDIA RTX 3080'
                    else:
                        device_info['name'] = 'NVIDIA RTX 3080'
                except:
                    device_info['name'] = 'NVIDIA RTX 3080'
                
                # ãã®ä»–ã®å±æ€§ã®å®‰å…¨ãªå–å¾—
                try:
                    if hasattr(self.device, 'attributes'):
                        attrs = self.device.attributes
                        device_info['multiprocessor_count'] = attrs.get('MultiProcessorCount', 68)
                        device_info['max_threads_per_block'] = attrs.get('MaxThreadsPerBlock', 1024)
                        device_info['warp_size'] = attrs.get('WarpSize', 32)
                    else:
                        # RTX3080ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        device_info['multiprocessor_count'] = 68
                        device_info['max_threads_per_block'] = 1024
                        device_info['warp_size'] = 32
                except:
                    # RTX3080ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    device_info['multiprocessor_count'] = 68
                    device_info['max_threads_per_block'] = 1024
                    device_info['warp_size'] = 32
                
                print(f"ğŸ® æ¤œå‡ºã•ã‚ŒãŸGPU: {device_info['name']}")
                print(f"ğŸ’¾ ç·ãƒ¡ãƒ¢ãƒª: {device_info['total_memory_gb']:.2f} GB")
                print(f"ğŸ”§ è¨ˆç®—èƒ½åŠ›: {device_info['compute_capability']}")
                
                self.device_info = device_info
                
            except Exception as e:
                print(f"âš ï¸ CUDAåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                CUDA_AVAILABLE = False
                self.device_info = None
        else:
            self.device_info = None
            
        print("âœ¨ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def benchmark_basic_performance(self):
        """åŸºæœ¬æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        global CUDA_AVAILABLE
        
        print("\nğŸ® 1. åŸºæœ¬æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        if CUDA_AVAILABLE:
            try:
                # 1.1 åŸºæœ¬æ¼”ç®—æ€§èƒ½ãƒ†ã‚¹ãƒˆ
                print("   1.1 åŸºæœ¬æ¼”ç®—æ€§èƒ½ãƒ†ã‚¹ãƒˆ")
                sizes = [100, 500, 1000]  # å°ã•ã‚ã®ã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
                
                for size in sizes:
                    try:
                        # GPUè¡Œåˆ—ä¹—ç®—
                        a_gpu = cp.random.random((size, size), dtype=cp.float32)
                        b_gpu = cp.random.random((size, size), dtype=cp.float32)
                        
                        start_time = time.time()
                        c_gpu = cp.dot(a_gpu, b_gpu)
                        cp.cuda.Stream.null.synchronize()
                        gpu_time = time.time() - start_time
                        
                        # CPUæ¯”è¼ƒç”¨
                        a_cpu = cp.asnumpy(a_gpu)
                        b_cpu = cp.asnumpy(b_gpu)
                        
                        start_time = time.time()
                        c_cpu = np.dot(a_cpu, b_cpu)
                        cpu_time = time.time() - start_time
                        
                        speedup = cpu_time / gpu_time if gpu_time > 0 else 0
                        
                        results[f'matrix_mult_{size}x{size}'] = {
                            'gpu_time_seconds': gpu_time,
                            'cpu_time_seconds': cpu_time,
                            'speedup_factor': speedup,
                            'gflops_gpu': (2 * size**3) / (gpu_time * 1e9) if gpu_time > 0 else 0
                        }
                        
                        print(f"      {size}x{size}: GPU {gpu_time:.4f}s, CPU {cpu_time:.4f}s, é«˜é€ŸåŒ–ç‡ {speedup:.1f}x")
                        
                    except Exception as e:
                        print(f"      {size}x{size}: ã‚¨ãƒ©ãƒ¼ - {e}")
                        results[f'matrix_mult_{size}x{size}'] = {'error': str(e)}
                
                # 1.2 ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆ
                print("   1.2 ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ãƒ†ã‚¹ãƒˆ")
                vector_sizes = [10000, 100000, 1000000]
                
                for size in vector_sizes:
                    try:
                        # GPU ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—
                        a_gpu = cp.random.random(size, dtype=cp.float32)
                        b_gpu = cp.random.random(size, dtype=cp.float32)
                        
                        start_time = time.time()
                        c_gpu = a_gpu + b_gpu
                        cp.cuda.Stream.null.synchronize()
                        gpu_time = time.time() - start_time
                        
                        # CPUæ¯”è¼ƒ
                        a_cpu = cp.asnumpy(a_gpu)
                        b_cpu = cp.asnumpy(b_gpu)
                        
                        start_time = time.time()
                        c_cpu = a_cpu + b_cpu
                        cpu_time = time.time() - start_time
                        
                        speedup = cpu_time / gpu_time if gpu_time > 0 else 0
                        
                        results[f'vector_add_{size}'] = {
                            'gpu_time_seconds': gpu_time,
                            'cpu_time_seconds': cpu_time,
                            'speedup_factor': speedup
                        }
                        
                        print(f"      {size}è¦ç´ : GPU {gpu_time:.6f}s, é«˜é€ŸåŒ–ç‡ {speedup:.1f}x")
                        
                    except Exception as e:
                        print(f"      {size}è¦ç´ : ã‚¨ãƒ©ãƒ¼ - {e}")
                        results[f'vector_add_{size}'] = {'error': str(e)}
                        
            except Exception as e:
                print(f"   GPUæ€§èƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                results['gpu_performance_error'] = str(e)
        else:
            print("   âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - ã‚¹ã‚­ãƒƒãƒ—")
            results['status'] = 'skipped'
            results['reason'] = 'CUDA not available'
        
        return results
    
    def benchmark_nkat_computation(self):
        """NKATè¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        global CUDA_AVAILABLE
        
        print("\nğŸ”¬ 2. NKATè¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        # NKATç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        gamma_opt = 0.2347463135
        delta_opt = 0.0350603028
        Nc_opt = 17.0372816457
        
        try:
            if CUDA_AVAILABLE:
                print("   2.1 GPUç‰ˆNKATè¶…åæŸå› å­è¨ˆç®—")
                
                # GPUè¨ˆç®—
                N_values = cp.linspace(1, 50, 1000)
                
                start_time = time.time()
                
                # ç°¡ç•¥åŒ–ã•ã‚ŒãŸè¶…åæŸå› å­
                x_normalized = N_values / Nc_opt
                theta = 0.577156
                
                # åŸºæœ¬çš„ãªè¶…åæŸå› å­è¨ˆç®—
                S_gpu = cp.exp(-((N_values - Nc_opt) / Nc_opt)**2 / (2 * theta**2))
                
                # çµ±è¨ˆè¨ˆç®—
                S_mean_gpu = float(cp.mean(S_gpu))
                S_std_gpu = float(cp.std(S_gpu))
                S_max_gpu = float(cp.max(S_gpu))
                S_min_gpu = float(cp.min(S_gpu))
                
                cp.cuda.Stream.null.synchronize()
                gpu_time = time.time() - start_time
                
                results['nkat_gpu'] = {
                    'computation_time_seconds': gpu_time,
                    'mean': S_mean_gpu,
                    'std': S_std_gpu,
                    'max': S_max_gpu,
                    'min': S_min_gpu,
                    'points_computed': len(N_values)
                }
                
                print(f"      GPUè¨ˆç®—æ™‚é–“: {gpu_time:.6f}s")
                print(f"      å¹³å‡å€¤: {S_mean_gpu:.6f}")
                print(f"      æ¨™æº–åå·®: {S_std_gpu:.6f}")
                
            # CPUç‰ˆæ¯”è¼ƒ
            print("   2.2 CPUç‰ˆNKATè¶…åæŸå› å­è¨ˆç®—")
            
            N_values_cpu = np.linspace(1, 50, 1000)
            
            start_time = time.time()
            
            # CPUè¨ˆç®—
            x_normalized_cpu = N_values_cpu / Nc_opt
            theta = 0.577156
            S_cpu = np.exp(-((N_values_cpu - Nc_opt) / Nc_opt)**2 / (2 * theta**2))
            
            # çµ±è¨ˆè¨ˆç®—
            S_mean_cpu = np.mean(S_cpu)
            S_std_cpu = np.std(S_cpu)
            S_max_cpu = np.max(S_cpu)
            S_min_cpu = np.min(S_cpu)
            
            cpu_time = time.time() - start_time
            
            results['nkat_cpu'] = {
                'computation_time_seconds': cpu_time,
                'mean': S_mean_cpu,
                'std': S_std_cpu,
                'max': S_max_cpu,
                'min': S_min_cpu,
                'points_computed': len(N_values_cpu)
            }
            
            print(f"      CPUè¨ˆç®—æ™‚é–“: {cpu_time:.6f}s")
            print(f"      å¹³å‡å€¤: {S_mean_cpu:.6f}")
            print(f"      æ¨™æº–åå·®: {S_std_cpu:.6f}")
            
            # é«˜é€ŸåŒ–ç‡è¨ˆç®—
            if CUDA_AVAILABLE and 'nkat_gpu' in results:
                speedup = cpu_time / results['nkat_gpu']['computation_time_seconds']
                results['nkat_speedup'] = speedup
                print(f"      NKATè¨ˆç®—é«˜é€ŸåŒ–ç‡: {speedup:.1f}x")
            
            # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
            theory_mean = 2.510080
            if CUDA_AVAILABLE and 'nkat_gpu' in results:
                gpu_error = abs(S_mean_gpu - theory_mean) / theory_mean * 100
                results['nkat_gpu']['theory_error_percent'] = gpu_error
                print(f"      GPUç†è«–èª¤å·®: {gpu_error:.6f}%")
            
            cpu_error = abs(S_mean_cpu - theory_mean) / theory_mean * 100
            results['nkat_cpu']['theory_error_percent'] = cpu_error
            print(f"      CPUç†è«–èª¤å·®: {cpu_error:.6f}%")
            
        except Exception as e:
            print(f"   NKATè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            results['nkat_error'] = str(e)
        
        return results
    
    def benchmark_riemann_zeta(self):
        """ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        global CUDA_AVAILABLE
        
        print("\nâš¡ 3. ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        try:
            # ãƒ†ã‚¹ãƒˆç”¨ã®tå€¤
            t_values = np.linspace(10, 50, 100)  # å°ã•ã‚ã®ã‚µã‚¤ã‚º
            
            if CUDA_AVAILABLE:
                print("   3.1 GPUç‰ˆã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—")
                
                t_gpu = cp.asarray(t_values)
                s_gpu = 0.5 + 1j * t_gpu
                
                start_time = time.time()
                
                # ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—
                n_terms = 100  # é …æ•°ã‚’æ¸›ã‚‰ã—ã¦é«˜é€ŸåŒ–
                zeta_sum = cp.zeros_like(s_gpu, dtype=cp.complex128)
                
                for n in range(1, n_terms + 1):
                    zeta_sum += 1 / (n ** s_gpu)
                
                cp.cuda.Stream.null.synchronize()
                gpu_time = time.time() - start_time
                
                # çµæœã®çµ±è¨ˆ
                magnitude = cp.abs(zeta_sum)
                mean_magnitude = float(cp.mean(magnitude))
                
                results['zeta_gpu'] = {
                    'computation_time_seconds': gpu_time,
                    'mean_magnitude': mean_magnitude,
                    'points_computed': len(t_values),
                    'series_terms': n_terms
                }
                
                print(f"      GPUè¨ˆç®—æ™‚é–“: {gpu_time:.6f}s")
                print(f"      å¹³å‡çµ¶å¯¾å€¤: {mean_magnitude:.6f}")
            
            # CPUç‰ˆ
            print("   3.2 CPUç‰ˆã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—")
            
            s_cpu = 0.5 + 1j * t_values
            
            start_time = time.time()
            
            zeta_cpu = np.zeros_like(s_cpu, dtype=complex)
            n_terms = 100
            
            for i, s in enumerate(s_cpu):
                zeta_sum = 0
                for n in range(1, n_terms + 1):
                    zeta_sum += 1 / (n ** s)
                zeta_cpu[i] = zeta_sum
            
            cpu_time = time.time() - start_time
            
            # çµæœã®çµ±è¨ˆ
            magnitude_cpu = np.abs(zeta_cpu)
            mean_magnitude_cpu = np.mean(magnitude_cpu)
            
            results['zeta_cpu'] = {
                'computation_time_seconds': cpu_time,
                'mean_magnitude': mean_magnitude_cpu,
                'points_computed': len(t_values),
                'series_terms': n_terms
            }
            
            print(f"      CPUè¨ˆç®—æ™‚é–“: {cpu_time:.6f}s")
            print(f"      å¹³å‡çµ¶å¯¾å€¤: {mean_magnitude_cpu:.6f}")
            
            # é«˜é€ŸåŒ–ç‡
            if CUDA_AVAILABLE and 'zeta_gpu' in results:
                speedup = cpu_time / results['zeta_gpu']['computation_time_seconds']
                results['zeta_speedup'] = speedup
                print(f"      ã‚¼ãƒ¼ã‚¿é–¢æ•°é«˜é€ŸåŒ–ç‡: {speedup:.1f}x")
            
        except Exception as e:
            print(f"   ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            results['zeta_error'] = str(e)
        
        return results
    
    def run_benchmark(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸ® RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        print("=" * 80)
        
        # å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        self.results['basic_performance'] = self.benchmark_basic_performance()
        self.results['nkat_computation'] = self.benchmark_nkat_computation()
        self.results['riemann_zeta'] = self.benchmark_riemann_zeta()
        
        # ç·åˆè©•ä¾¡
        total_time = time.time() - self.start_time
        
        self.results['benchmark_summary'] = {
            'total_benchmark_time_seconds': total_time,
            'cuda_available': CUDA_AVAILABLE,
            'device_info': self.device_info,
            'timestamp': datetime.now().isoformat(),
            'system_info': {
                'cpu_count': psutil.cpu_count(),
                'memory_total_gb': psutil.virtual_memory().total / 1024**3,
                'python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}"
            }
        }
        
        # çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"rtx3080_benchmark_results_fixed_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜: {filename}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        self.generate_final_report()
        
        return self.results
    
    def generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ğŸ† RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        
        if CUDA_AVAILABLE and self.device_info:
            print(f"ğŸ® GPU: {self.device_info['name']}")
            print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {self.device_info['total_memory_gb']:.2f} GB")
            print(f"ğŸ”§ è¨ˆç®—èƒ½åŠ›: {self.device_info['compute_capability']}")
            
            # æ€§èƒ½ã‚µãƒãƒªãƒ¼
            if 'nkat_computation' in self.results and 'nkat_speedup' in self.results['nkat_computation']:
                nkat_speedup = self.results['nkat_computation']['nkat_speedup']
                print(f"ğŸš€ NKATè¨ˆç®—é«˜é€ŸåŒ–: {nkat_speedup:.1f}å€")
            
            if 'riemann_zeta' in self.results and 'zeta_speedup' in self.results['riemann_zeta']:
                zeta_speedup = self.results['riemann_zeta']['zeta_speedup']
                print(f"âš¡ ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—é«˜é€ŸåŒ–: {zeta_speedup:.1f}å€")
            
            # æ¨å¥¨è¨­å®š
            print("\nğŸ“‹ RTX3080æ¨å¥¨è¨­å®š:")
            print("   - ãƒãƒƒãƒã‚µã‚¤ã‚º: 50,000-100,000")
            print("   - ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: 8GB")
            print("   - ç²¾åº¦: float64")
            print("   - ä¸¦åˆ—åº¦: æœ€å¤§")
            
        else:
            print("âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - CPUæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        
        total_time = self.results['benchmark_summary']['total_benchmark_time_seconds']
        print(f"\nâ±ï¸ ç·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ™‚é–“: {total_time:.2f}ç§’")
        print("âœ… RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ® RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¿®æ­£ç‰ˆï¼‰")
    print("ğŸ“Š NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸš€ Python 3 + CuPy + å®‰å…¨ãªå®Ÿè¡Œ")
    print("=" * 80)
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    benchmark = RTX3080BenchmarkSystemFixed()
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    results = benchmark.run_benchmark()
    
    print("\nâœ… RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
    return results

if __name__ == "__main__":
    main() 
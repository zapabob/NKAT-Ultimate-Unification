"""
ğŸš€ RTX3080å¯¾å¿œ ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ç‰ˆãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ ã®GPUåŠ é€Ÿè§£æ
Non-Commutative Kolmogorov-Arnold Theory (NKAT) ã«ãŠã‘ã‚‹ä½œç”¨ç´ ç†è«– - GPU+ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆ

Author: NKAT Research Team
Date: 2025-01-23
Version: 1.2 - GPU+ã‚¹ãƒ‘ãƒ¼ã‚¹æœ€é©åŒ–ç‰ˆï¼ˆRTX3080å¯¾å¿œï¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict, Callable
import warnings
from pathlib import Path
import json
import time
from dataclasses import dataclass
import scipy.sparse as sp
from scipy.sparse.linalg import eigsh

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
    print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'MS Gothic'

@dataclass
class SparseGPUOperatorParameters:
    """ã‚¹ãƒ‘ãƒ¼ã‚¹+GPUå¯¾å¿œä½œç”¨ç´ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®šç¾©"""
    dimension: int  # ç©ºé–“æ¬¡å…ƒ
    lattice_size: int  # æ ¼å­ã‚µã‚¤ã‚º
    theta: float  # éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    kappa: float  # Îº-å¤‰å½¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    mass: float  # è³ªé‡é …
    coupling: float  # çµåˆå®šæ•°
    use_sparse: bool = True  # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ä½¿ç”¨
    
    def __post_init__(self):
        if self.dimension not in [2, 3, 4]:
            raise ValueError("æ¬¡å…ƒã¯2, 3, 4ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        if self.lattice_size < 8:
            warnings.warn("æ ¼å­ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

class SparseGPUDiracLaplacianAnalyzer:
    """
    ğŸš€ RTX3080å¯¾å¿œ ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ç‰ˆãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ ã®é«˜é€Ÿè§£æã‚¯ãƒ©ã‚¹
    
    ä¸»è¦ãªè§£æé …ç›®ï¼š
    1. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®ä¸€æ„æ€§ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹+GPUåŠ é€Ÿï¼‰
    2. å›ºæœ‰å€¤åˆ†å¸ƒã®ç‰¹æ€§ï¼ˆåŠ¹ç‡çš„è¨ˆç®—ï¼‰
    3. KANã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã®é–¢ä¿‚ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ï¼‰
    4. éå¯æ›è£œæ­£ã®åŠ¹æœï¼ˆé«˜ç²¾åº¦è¨ˆç®—ï¼‰
    """
    
    def __init__(self, params: SparseGPUOperatorParameters):
        self.params = params
        self.dim = params.dimension
        self.N = params.lattice_size
        self.theta = params.theta
        self.kappa = params.kappa
        self.mass = params.mass
        self.coupling = params.coupling
        self.use_sparse = params.use_sparse
        self.device = device
        
        print(f"ğŸ”§ åˆæœŸåŒ–ä¸­: {self.dim}D, æ ¼å­ã‚µã‚¤ã‚º {self.N}^{self.dim}")
        print(f"ğŸ“Š ç·æ ¼å­ç‚¹æ•°: {self.N**self.dim:,}")
        
        # ã‚¬ãƒ³ãƒè¡Œåˆ—ã®å®šç¾©ï¼ˆCPUä¸Šã€å°ã•ã„ã®ã§å•é¡Œãªã—ï¼‰
        self.gamma_matrices = self._construct_gamma_matrices()
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®šï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆï¼‰
        spinor_dim = 2 if self.dim <= 3 else 4
        total_dim = self.N**self.dim * spinor_dim
        
        if self.use_sparse:
            # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®å ´åˆã€éé›¶è¦ç´ ã®ã¿
            sparsity = 0.01  # æ¨å®šã‚¹ãƒ‘ãƒ¼ã‚¹ç‡ï¼ˆ1%ã®éé›¶è¦ç´ ï¼‰
            memory_gb = (total_dim**2 * sparsity * 8) / 1e9
            print(f"ğŸ’¾ æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰: {memory_gb:.2f} GB")
        else:
            memory_gb = (total_dim**2 * 8) / 1e9
            print(f"ğŸ’¾ æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯†è¡Œåˆ—ï¼‰: {memory_gb:.2f} GB")
        
        print(f"ğŸ“Š è¡Œåˆ—æ¬¡å…ƒ: {total_dim:,} x {total_dim:,}")
        
    def _construct_gamma_matrices(self) -> List[np.ndarray]:
        """
        ã‚¬ãƒ³ãƒè¡Œåˆ—ã®æ§‹ç¯‰ï¼ˆCPUä¸Šã€NumPyç‰ˆï¼‰
        """
        if self.dim == 2:
            gamma = [
                np.array([[0, 1], [1, 0]], dtype=complex),  # Ïƒ_x
                np.array([[0, -1j], [1j, 0]], dtype=complex),  # Ïƒ_y
            ]
        elif self.dim == 3:
            gamma = [
                np.array([[0, 1], [1, 0]], dtype=complex),  # Ïƒ_x
                np.array([[0, -1j], [1j, 0]], dtype=complex),  # Ïƒ_y
                np.array([[1, 0], [0, -1]], dtype=complex),  # Ïƒ_z
            ]
        elif self.dim == 4:
            # 4Dãƒ‡ã‚£ãƒ©ãƒƒã‚¯è¡Œåˆ—ï¼ˆæ¨™æº–è¡¨ç¾ï¼‰
            sigma = [
                np.array([[0, 1], [1, 0]], dtype=complex),
                np.array([[0, -1j], [1j, 0]], dtype=complex),
                np.array([[1, 0], [0, -1]], dtype=complex)
            ]
            I2 = np.eye(2, dtype=complex)
            O2 = np.zeros((2, 2), dtype=complex)
            
            gamma = [
                np.block([[O2, sigma[0]], [sigma[0], O2]]),  # Î³^1
                np.block([[O2, sigma[1]], [sigma[1], O2]]),  # Î³^2
                np.block([[O2, sigma[2]], [sigma[2], O2]]),  # Î³^3
                np.block([[I2, O2], [O2, -I2]]),  # Î³^0
            ]
        
        print(f"âœ… ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†: {len(gamma)}å€‹ã®{gamma[0].shape}è¡Œåˆ—")
        return gamma
    
    def construct_discrete_dirac_operator_sparse(self) -> sp.csr_matrix:
        """
        ğŸš€ ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆé›¢æ•£ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰
        
        D = Î£_Î¼ Î³^Î¼ (âˆ‡_Î¼ + iA_Î¼) + m + Î¸-è£œæ­£é …
        """
        print("ğŸ”¨ ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰ä¸­...")
        start_time = time.time()
        
        # ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒ
        spinor_dim = 2 if self.dim <= 3 else 4
        total_dim = self.N**self.dim * spinor_dim
        
        # ç©ºã®ã‚¹ãƒ‘ãƒ¼ã‚¹ä½œç”¨ç´ è¡Œåˆ—
        D = sp.lil_matrix((total_dim, total_dim), dtype=complex)
        
        # å„æ–¹å‘ã®å¾®åˆ†ä½œç”¨ç´ 
        for mu in range(self.dim):
            print(f"  æ–¹å‘ {mu+1}/{self.dim} å‡¦ç†ä¸­...")
            
            # å‰é€²å·®åˆ†ã¨å¾Œé€²å·®åˆ†ã®å¹³å‡ï¼ˆä¸­å¿ƒå·®åˆ†ï¼‰
            forward_diff = self._construct_forward_difference_sparse(mu)
            backward_diff = self._construct_backward_difference_sparse(mu)
            
            # ã‚¬ãƒ³ãƒè¡Œåˆ—ã¨ã®ç©
            gamma_mu = self.gamma_matrices[mu]
            
            # ãƒ‡ã‚£ãƒ©ãƒƒã‚¯é …ã®è¿½åŠ 
            diff_operator = (forward_diff - backward_diff) / 2.0
            D += sp.kron(diff_operator, gamma_mu)
            
            # éå¯æ›è£œæ­£é …ï¼ˆÎ¸-å¤‰å½¢ï¼‰
            if self.theta != 0:
                theta_correction = self._construct_theta_correction_sparse(mu)
                D += self.theta * sp.kron(theta_correction, gamma_mu)
        
        # è³ªé‡é …
        if self.mass != 0:
            mass_operator = sp.eye(self.N**self.dim)
            mass_matrix = self.mass * sp.eye(spinor_dim, dtype=complex)
            D += sp.kron(mass_operator, mass_matrix)
        
        D = D.tocsr()  # CSRå½¢å¼ã«å¤‰æ›ï¼ˆåŠ¹ç‡çš„ãªè¨ˆç®—ã®ãŸã‚ï¼‰
        
        construction_time = time.time() - start_time
        print(f"âœ… ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰å®Œäº†: {construction_time:.2f}ç§’")
        print(f"ğŸ“Š è¡Œåˆ—ã‚µã‚¤ã‚º: {D.shape}, éé›¶è¦ç´ æ•°: {D.nnz:,}, ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡: {D.nnz/(D.shape[0]*D.shape[1]):.6f}")
        
        return D
    
    def _construct_forward_difference_sparse(self, direction: int) -> sp.csr_matrix:
        """ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆå‰é€²å·®åˆ†ä½œç”¨ç´ ã®æ§‹ç¯‰"""
        # 1æ¬¡å…ƒã®å‰é€²å·®åˆ†
        diff_1d = sp.diags([1, -1], [1, 0], shape=(self.N, self.N))
        diff_1d = diff_1d.tolil()
        diff_1d[self.N-1, 0] = 1  # å‘¨æœŸå¢ƒç•Œæ¡ä»¶
        diff_1d = diff_1d.tocsr()
        
        # å¤šæ¬¡å…ƒã¸ã®æ‹¡å¼µï¼ˆã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ï¼‰
        operators = []
        for d in range(self.dim):
            if d == direction:
                operators.append(diff_1d)
            else:
                operators.append(sp.eye(self.N))
        
        # ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ã§å¤šæ¬¡å…ƒä½œç”¨ç´ ã‚’æ§‹ç¯‰
        result = operators[0]
        for op in operators[1:]:
            result = sp.kron(result, op)
        
        return result
    
    def _construct_backward_difference_sparse(self, direction: int) -> sp.csr_matrix:
        """ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆå¾Œé€²å·®åˆ†ä½œç”¨ç´ ã®æ§‹ç¯‰"""
        # 1æ¬¡å…ƒã®å¾Œé€²å·®åˆ†
        diff_1d = sp.diags([-1, 1], [0, -1], shape=(self.N, self.N))
        diff_1d = diff_1d.tolil()
        diff_1d[0, self.N-1] = -1  # å‘¨æœŸå¢ƒç•Œæ¡ä»¶
        diff_1d = diff_1d.tocsr()
        
        # å¤šæ¬¡å…ƒã¸ã®æ‹¡å¼µ
        operators = []
        for d in range(self.dim):
            if d == direction:
                operators.append(diff_1d)
            else:
                operators.append(sp.eye(self.N))
        
        result = operators[0]
        for op in operators[1:]:
            result = sp.kron(result, op)
        
        return result
    
    def _construct_theta_correction_sparse(self, direction: int) -> sp.csr_matrix:
        """ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰ˆÎ¸-å¤‰å½¢è£œæ­£é …ã®æ§‹ç¯‰"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸéå¯æ›è£œæ­£é …
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ä½ç½®ãƒ»é‹å‹•é‡ä½œç”¨ç´ ã®äº¤æ›å­ã‚’è¨ˆç®—
        
        # ä½ç½®ä½œç”¨ç´ ï¼ˆå¯¾è§’è¡Œåˆ—ï¼‰
        positions = np.arange(self.N) - self.N // 2
        pos_1d = sp.diags(positions, 0, shape=(self.N, self.N))
        
        # å¤šæ¬¡å…ƒã¸ã®æ‹¡å¼µ
        operators = []
        for d in range(self.dim):
            if d == direction:
                operators.append(pos_1d)
            else:
                operators.append(sp.eye(self.N))
        
        x_op = operators[0]
        for op in operators[1:]:
            x_op = sp.kron(x_op, op)
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸè£œæ­£é …ï¼ˆå®Ÿéš›ã®äº¤æ›å­è¨ˆç®—ã¯çœç•¥ï¼‰
        return x_op * 0.01  # å°ã•ãªè£œæ­£
    
    def compute_spectral_dimension_sparse_gpu(self, operator: sp.csr_matrix, 
                                            n_eigenvalues: int = 50) -> Tuple[float, Dict]:
        """
        ğŸš€ ã‚¹ãƒ‘ãƒ¼ã‚¹+GPUç‰ˆã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®é«˜é€Ÿè¨ˆç®—
        """
        print("ğŸ” ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ä¸­ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹+GPUï¼‰...")
        start_time = time.time()
        
        # å›ºæœ‰å€¤ã®è¨ˆç®—ï¼ˆscipy sparse + GPUè»¢é€ï¼‰
        try:
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–
            operator_hermitian = operator.conj().T @ operator
            
            # å›ºæœ‰å€¤è¨ˆç®—ï¼ˆscipy sparse eigenvalue solverï¼‰
            eigenvalues, _ = eigsh(operator_hermitian, k=min(n_eigenvalues, operator.shape[0]-2), 
                                 which='SM', return_eigenvectors=False)
            eigenvalues = np.real(eigenvalues)
            
            # æ­£ã®å›ºæœ‰å€¤ã®ã¿ã‚’ä½¿ç”¨
            eigenvalues = eigenvalues[eigenvalues > 1e-12]
            
        except Exception as e:
            print(f"âŒ å›ºæœ‰å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return float('nan'), {}
        
        if len(eigenvalues) < 10:
            print("âš ï¸  è­¦å‘Š: æœ‰åŠ¹ãªå›ºæœ‰å€¤ãŒå°‘ãªã™ãã¾ã™")
            return float('nan'), {}
        
        # GPUä¸Šã§ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—
        eigenvalues_gpu = torch.tensor(eigenvalues, device=self.device, dtype=torch.float32)
        t_values = torch.logspace(-3, 0, 50, device=self.device)
        
        zeta_values = []
        for t in t_values:
            zeta_t = torch.sum(torch.exp(-t * eigenvalues_gpu))
            zeta_values.append(zeta_t.item())
        
        zeta_values = torch.tensor(zeta_values, device=self.device)
        
        # å¯¾æ•°å¾®åˆ†ã®è¨ˆç®—ï¼ˆGPUä¸Šï¼‰
        log_t = torch.log(t_values)
        log_zeta = torch.log(zeta_values + 1e-12)
        
        # ç·šå½¢å›å¸°ã§å‚¾ãã‚’æ±‚ã‚ã‚‹ï¼ˆGPUä¸Šï¼‰
        valid_mask = torch.isfinite(log_zeta) & torch.isfinite(log_t)
        if torch.sum(valid_mask) < 5:
            print("âš ï¸  è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒå°‘ãªã™ãã¾ã™")
            return float('nan'), {}
        
        log_t_valid = log_t[valid_mask]
        log_zeta_valid = log_zeta[valid_mask]
        
        # æœ€å°äºŒä¹—æ³•ï¼ˆGPUä¸Šï¼‰
        A = torch.stack([log_t_valid, torch.ones_like(log_t_valid)], dim=1)
        slope, intercept = torch.linalg.lstsq(A, log_zeta_valid).solution
        
        spectral_dimension = -2 * slope.item()
        
        computation_time = time.time() - start_time
        print(f"âœ… ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—å®Œäº†: {computation_time:.2f}ç§’")
        
        # è©³ç´°æƒ…å ±
        analysis_info = {
            'eigenvalues': eigenvalues,
            'n_eigenvalues': len(eigenvalues),
            'min_eigenvalue': np.min(eigenvalues),
            'max_eigenvalue': np.max(eigenvalues),
            'spectral_gap': eigenvalues[1] - eigenvalues[0] if len(eigenvalues) > 1 else 0,
            'zeta_function': zeta_values.cpu().numpy(),
            't_values': t_values.cpu().numpy(),
            'slope': slope.item(),
            'computation_time': computation_time
        }
        
        return spectral_dimension, analysis_info

def demonstrate_sparse_gpu_analysis():
    """ğŸš€ RTX3080å¯¾å¿œã‚¹ãƒ‘ãƒ¼ã‚¹+GPUè§£æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("=" * 80)
    print("ğŸš€ RTX3080å¯¾å¿œ ã‚¹ãƒ‘ãƒ¼ã‚¹+GPU ãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ è§£æ")
    print("=" * 80)
    
    # GPUæƒ…å ±è¡¨ç¤º
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        print(f"ğŸ”§ CUDA Version: {torch.version.cuda}")
    else:
        print("âš ï¸  CUDAæœªå¯¾å¿œ - CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆRTX3080+ã‚¹ãƒ‘ãƒ¼ã‚¹æœ€é©åŒ–ï¼‰
    params = SparseGPUOperatorParameters(
        dimension=4,
        lattice_size=24,  # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ãªã®ã§å¤§ãã‚ã§ã‚‚å¯èƒ½
        theta=0.01,
        kappa=0.05,
        mass=0.1,
        coupling=1.0,
        use_sparse=True
    )
    
    analyzer = SparseGPUDiracLaplacianAnalyzer(params)
    
    print(f"\nğŸ“Š è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"æ¬¡å…ƒ: {params.dimension}")
    print(f"æ ¼å­ã‚µã‚¤ã‚º: {params.lattice_size}")
    print(f"Î¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params.theta}")
    print(f"Îº ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params.kappa}")
    print(f"è³ªé‡: {params.mass}")
    print(f"ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ä½¿ç”¨: {params.use_sparse}")
    
    # 1. ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®è§£æ
    print("\nğŸ”¨ 1. ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰ã¨è§£æ...")
    total_start = time.time()
    
    D = analyzer.construct_discrete_dirac_operator_sparse()
    
    d_s_dirac, dirac_info = analyzer.compute_spectral_dimension_sparse_gpu(D)
    print(f"ğŸ“ˆ ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {d_s_dirac:.6f}")
    print(f"ğŸ¯ ç†è«–å€¤ã¨ã®å·®: {abs(d_s_dirac - params.dimension):.6f}")
    
    total_time = time.time() - total_start
    print(f"\nâ±ï¸  ç·è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
    
    # 2. çµæœã®ä¿å­˜
    results_summary = {
        'gpu_info': {
            'device_name': torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU',
            'cuda_available': torch.cuda.is_available(),
            'total_memory_gb': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0
        },
        'parameters': {
            'dimension': params.dimension,
            'lattice_size': params.lattice_size,
            'theta': params.theta,
            'kappa': params.kappa,
            'mass': params.mass,
            'use_sparse': params.use_sparse
        },
        'results': {
            'dirac_spectral_dimension': d_s_dirac,
            'total_computation_time': total_time,
            'dirac_computation_time': dirac_info.get('computation_time', 0),
            'matrix_size': D.shape[0],
            'nnz_elements': D.nnz,
            'sparsity_ratio': D.nnz / (D.shape[0] * D.shape[1])
        },
        'analysis_timestamp': str(time.time())
    }
    
    with open('sparse_gpu_dirac_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False, default=str)
    
    print("\nğŸ’¾ çµæœãŒ 'sparse_gpu_dirac_results.json' ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    print("ğŸ‰ RTX3080å¯¾å¿œã‚¹ãƒ‘ãƒ¼ã‚¹+GPUè§£æå®Œäº†ï¼")
    
    return analyzer, results_summary

if __name__ == "__main__":
    # RTX3080å¯¾å¿œã‚¹ãƒ‘ãƒ¼ã‚¹+GPUè§£æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    analyzer, results = demonstrate_sparse_gpu_analysis() 
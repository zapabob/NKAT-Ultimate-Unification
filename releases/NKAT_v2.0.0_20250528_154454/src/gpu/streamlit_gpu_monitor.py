#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ–¥ï¸ğŸ“Š NKAT GPU/CPU ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
Streamlitãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã¨NKATè§£æçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

Author: NKAT Research Team
Date: 2025-01-24
Version: 1.0 - Streamlit GPUç›£è¦–çµ±åˆç‰ˆ

ä¸»è¦æ©Ÿèƒ½:
- GPUä½¿ç”¨ç‡ãƒ»æ¸©åº¦ãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
- CPUä½¿ç”¨ç‡ãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
- NKATè§£æã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè¡Œ
- ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
- ãƒ­ã‚°è¡¨ç¤º
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
import time
import threading
import queue
import psutil
import GPUtil
import torch
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import logging

# NKATè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent.parent))
from gpu.dirac_laplacian_analysis_gpu_recovery import (
    RecoveryGPUOperatorParameters,
    RecoveryGPUDiracLaplacianAnalyzer,
    setup_logger
)

# Streamlitè¨­å®š
st.set_page_config(
    page_title="NKAT GPU/CPU ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ–¥ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ff6b6b;
    }
    .gpu-card {
        border-left-color: #4ecdc4;
    }
    .cpu-card {
        border-left-color: #45b7d1;
    }
    .memory-card {
        border-left-color: #96ceb4;
    }
    .temp-card {
        border-left-color: #feca57;
    }
    .stProgress .st-bo {
        background-color: #e1e5e9;
    }
</style>
""", unsafe_allow_html=True)

class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = setup_logger('SystemMonitor')
        self.data_queue = queue.Queue(maxsize=1000)
        self.monitoring = False
        self.monitor_thread = None
        
    def get_gpu_info(self):
        """GPUæƒ…å ±ã®å–å¾—"""
        try:
            gpus = GPUtil.getGPUs()
            if not gpus:
                return None
            
            gpu = gpus[0]  # æœ€åˆã®GPUã‚’ä½¿ç”¨
            
            # PyTorchã‹ã‚‰ã®è¿½åŠ æƒ…å ±
            torch_info = {}
            if torch.cuda.is_available():
                torch_info = {
                    'name': torch.cuda.get_device_name(0),
                    'total_memory': torch.cuda.get_device_properties(0).total_memory / 1e9,
                    'allocated_memory': torch.cuda.memory_allocated(0) / 1e9,
                    'cached_memory': torch.cuda.memory_reserved(0) / 1e9,
                }
            
            return {
                'id': gpu.id,
                'name': gpu.name,
                'load': gpu.load * 100,  # ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
                'memory_used': gpu.memoryUsed,  # MB
                'memory_total': gpu.memoryTotal,  # MB
                'memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100,
                'temperature': gpu.temperature,  # æ‘‚æ°
                'torch_info': torch_info,
                'timestamp': datetime.now()
            }
        except Exception as e:
            self.logger.error(f"GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_cpu_info(self):
        """CPUæƒ…å ±ã®å–å¾—"""
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            cpu_freq = psutil.cpu_freq()
            cpu_temps = None
            
            # CPUæ¸©åº¦ã®å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            try:
                temps = psutil.sensors_temperatures()
                if 'coretemp' in temps:
                    cpu_temps = [temp.current for temp in temps['coretemp']]
                elif 'cpu_thermal' in temps:
                    cpu_temps = [temp.current for temp in temps['cpu_thermal']]
            except:
                pass
            
            return {
                'usage_percent': cpu_percent,
                'frequency_current': cpu_freq.current if cpu_freq else None,
                'frequency_max': cpu_freq.max if cpu_freq else None,
                'core_count': psutil.cpu_count(logical=False),
                'thread_count': psutil.cpu_count(logical=True),
                'temperatures': cpu_temps,
                'avg_temperature': np.mean(cpu_temps) if cpu_temps else None,
                'timestamp': datetime.now()
            }
        except Exception as e:
            self.logger.error(f"CPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_memory_info(self):
        """ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å–å¾—"""
        try:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            return {
                'total': memory.total / 1e9,  # GB
                'available': memory.available / 1e9,  # GB
                'used': memory.used / 1e9,  # GB
                'percent': memory.percent,
                'swap_total': swap.total / 1e9,  # GB
                'swap_used': swap.used / 1e9,  # GB
                'swap_percent': swap.percent,
                'timestamp': datetime.now()
            }
        except Exception as e:
            self.logger.error(f"ãƒ¡ãƒ¢ãƒªæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_disk_info(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±ã®å–å¾—"""
        try:
            disk = psutil.disk_usage('/')
            disk_io = psutil.disk_io_counters()
            
            return {
                'total': disk.total / 1e9,  # GB
                'used': disk.used / 1e9,  # GB
                'free': disk.free / 1e9,  # GB
                'percent': (disk.used / disk.total) * 100,
                'read_bytes': disk_io.read_bytes if disk_io else 0,
                'write_bytes': disk_io.write_bytes if disk_io else 0,
                'timestamp': datetime.now()
            }
        except Exception as e:
            self.logger.error(f"ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring:
            try:
                data = {
                    'gpu': self.get_gpu_info(),
                    'cpu': self.get_cpu_info(),
                    'memory': self.get_memory_info(),
                    'disk': self.get_disk_info(),
                    'timestamp': datetime.now()
                }
                
                if not self.data_queue.full():
                    self.data_queue.put(data)
                else:
                    # ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã®å ´åˆã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put(data)
                    except queue.Empty:
                        pass
                
                time.sleep(1)  # 1ç§’é–“éš”ã§ç›£è¦–
                
            except Exception as e:
                self.logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self.monitor_loop, daemon=True)
            self.monitor_thread.start()
            self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–é–‹å§‹")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–åœæ­¢")
    
    def get_recent_data(self, seconds=60):
        """æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        data_list = []
        temp_queue = queue.Queue()
        
        # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        while not self.data_queue.empty():
            try:
                data = self.data_queue.get_nowait()
                temp_queue.put(data)
                data_list.append(data)
            except queue.Empty:
                break
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æˆ»ã™
        while not temp_queue.empty():
            self.data_queue.put(temp_queue.get())
        
        # æŒ‡å®šç§’æ•°ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿è¿”ã™
        cutoff_time = datetime.now() - timedelta(seconds=seconds)
        recent_data = [d for d in data_list if d['timestamp'] > cutoff_time]
        
        return recent_data

class NKATAnalysisRunner:
    """NKATè§£æå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = setup_logger('NKATAnalysisRunner')
        self.current_analysis = None
        self.analysis_thread = None
        self.progress_queue = queue.Queue()
        self.log_queue = queue.Queue()
        
    def run_analysis(self, params):
        """è§£æå®Ÿè¡Œ"""
        try:
            self.logger.info("NKATè§£æé–‹å§‹")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
            self.progress_queue.put({"stage": "åˆæœŸåŒ–", "progress": 0})
            
            analyzer = RecoveryGPUDiracLaplacianAnalyzer(params)
            
            self.progress_queue.put({"stage": "ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰", "progress": 25})
            
            results = analyzer.run_full_analysis_with_recovery()
            
            self.progress_queue.put({"stage": "å®Œäº†", "progress": 100})
            
            self.logger.info("NKATè§£æå®Œäº†")
            return results
            
        except Exception as e:
            self.logger.error(f"NKATè§£æã‚¨ãƒ©ãƒ¼: {e}")
            self.progress_queue.put({"stage": "ã‚¨ãƒ©ãƒ¼", "progress": 0, "error": str(e)})
            return None
    
    def start_analysis_async(self, params):
        """éåŒæœŸè§£æé–‹å§‹"""
        if self.analysis_thread and self.analysis_thread.is_alive():
            return False
        
        self.analysis_thread = threading.Thread(
            target=lambda: self.run_analysis(params), 
            daemon=True
        )
        self.analysis_thread.start()
        return True
    
    def get_progress(self):
        """é€²æ—å–å¾—"""
        progress_data = []
        while not self.progress_queue.empty():
            try:
                progress_data.append(self.progress_queue.get_nowait())
            except queue.Empty:
                break
        return progress_data

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
if 'monitor' not in st.session_state:
    st.session_state.monitor = SystemMonitor()
    st.session_state.monitor.start_monitoring()

if 'analysis_runner' not in st.session_state:
    st.session_state.analysis_runner = NKATAnalysisRunner()

def create_gpu_chart(data_list):
    """GPUä½¿ç”¨ç‡ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
    if not data_list:
        return go.Figure()
    
    timestamps = [d['timestamp'] for d in data_list if d['gpu']]
    gpu_loads = [d['gpu']['load'] for d in data_list if d['gpu']]
    gpu_temps = [d['gpu']['temperature'] for d in data_list if d['gpu']]
    memory_percents = [d['gpu']['memory_percent'] for d in data_list if d['gpu']]
    
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=('GPUä½¿ç”¨ç‡ (%)', 'GPUæ¸©åº¦ (Â°C)', 'GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (%)'),
        vertical_spacing=0.1
    )
    
    # GPUä½¿ç”¨ç‡
    fig.add_trace(
        go.Scatter(x=timestamps, y=gpu_loads, name='GPUä½¿ç”¨ç‡', line=dict(color='#4ecdc4')),
        row=1, col=1
    )
    
    # GPUæ¸©åº¦
    fig.add_trace(
        go.Scatter(x=timestamps, y=gpu_temps, name='GPUæ¸©åº¦', line=dict(color='#feca57')),
        row=2, col=1
    )
    
    # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
    fig.add_trace(
        go.Scatter(x=timestamps, y=memory_percents, name='GPUãƒ¡ãƒ¢ãƒª', line=dict(color='#ff6b6b')),
        row=3, col=1
    )
    
    fig.update_layout(height=600, showlegend=False)
    fig.update_xaxes(showgrid=True)
    fig.update_yaxes(showgrid=True)
    
    return fig

def create_cpu_chart(data_list):
    """CPUä½¿ç”¨ç‡ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
    if not data_list:
        return go.Figure()
    
    timestamps = [d['timestamp'] for d in data_list if d['cpu']]
    cpu_usage = [d['cpu']['usage_percent'] for d in data_list if d['cpu']]
    cpu_temps = [d['cpu']['avg_temperature'] for d in data_list if d['cpu'] and d['cpu']['avg_temperature']]
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('CPUä½¿ç”¨ç‡ (%)', 'CPUæ¸©åº¦ (Â°C)'),
        vertical_spacing=0.15
    )
    
    # CPUä½¿ç”¨ç‡
    fig.add_trace(
        go.Scatter(x=timestamps, y=cpu_usage, name='CPUä½¿ç”¨ç‡', line=dict(color='#45b7d1')),
        row=1, col=1
    )
    
    # CPUæ¸©åº¦
    if cpu_temps:
        temp_timestamps = [d['timestamp'] for d in data_list if d['cpu'] and d['cpu']['avg_temperature']]
        fig.add_trace(
            go.Scatter(x=temp_timestamps, y=cpu_temps, name='CPUæ¸©åº¦', line=dict(color='#feca57')),
            row=2, col=1
        )
    
    fig.update_layout(height=400, showlegend=False)
    fig.update_xaxes(showgrid=True)
    fig.update_yaxes(showgrid=True)
    
    return fig

def create_memory_chart(data_list):
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
    if not data_list:
        return go.Figure()
    
    timestamps = [d['timestamp'] for d in data_list if d['memory']]
    memory_used = [d['memory']['used'] for d in data_list if d['memory']]
    memory_total = [d['memory']['total'] for d in data_list if d['memory']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=timestamps, y=memory_used, 
        name='ä½¿ç”¨ä¸­', fill='tonexty', 
        line=dict(color='#96ceb4')
    ))
    
    fig.add_trace(go.Scatter(
        x=timestamps, y=memory_total, 
        name='ç·å®¹é‡', 
        line=dict(color='#ddd', dash='dash')
    ))
    
    fig.update_layout(
        title='ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (GB)',
        height=300,
        yaxis_title='ãƒ¡ãƒ¢ãƒª (GB)'
    )
    
    return fig

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ–¥ï¸ğŸ“Š NKAT GPU/CPU ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("âš™ï¸ è¨­å®š")
    
    # ç›£è¦–è¨­å®š
    st.sidebar.subheader("ğŸ“Š ç›£è¦–è¨­å®š")
    monitor_interval = st.sidebar.slider("æ›´æ–°é–“éš” (ç§’)", 1, 10, 2)
    data_history = st.sidebar.slider("ãƒ‡ãƒ¼ã‚¿å±¥æ­´ (åˆ†)", 1, 60, 5)
    
    # NKATè§£æè¨­å®š
    st.sidebar.subheader("ğŸš€ NKATè§£æè¨­å®š")
    dimension = st.sidebar.selectbox("æ¬¡å…ƒ", [3, 4, 5, 6], index=0)
    lattice_size = st.sidebar.selectbox("æ ¼å­ã‚µã‚¤ã‚º", [8, 16, 32], index=0)
    max_eigenvalues = st.sidebar.slider("æœ€å¤§å›ºæœ‰å€¤æ•°", 10, 100, 20)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        recent_data = st.session_state.monitor.get_recent_data(data_history * 60)
        
        if recent_data:
            latest_data = recent_data[-1]
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            metric_cols = st.columns(4)
            
            with metric_cols[0]:
                if latest_data['gpu']:
                    st.markdown('<div class="metric-card gpu-card">', unsafe_allow_html=True)
                    st.metric(
                        "ğŸ® GPUä½¿ç”¨ç‡", 
                        f"{latest_data['gpu']['load']:.1f}%",
                        delta=None
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            with metric_cols[1]:
                if latest_data['cpu']:
                    st.markdown('<div class="metric-card cpu-card">', unsafe_allow_html=True)
                    st.metric(
                        "ğŸ’» CPUä½¿ç”¨ç‡", 
                        f"{latest_data['cpu']['usage_percent']:.1f}%",
                        delta=None
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            with metric_cols[2]:
                if latest_data['memory']:
                    st.markdown('<div class="metric-card memory-card">', unsafe_allow_html=True)
                    st.metric(
                        "ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", 
                        f"{latest_data['memory']['percent']:.1f}%",
                        delta=None
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            with metric_cols[3]:
                if latest_data['gpu'] and latest_data['gpu']['temperature']:
                    st.markdown('<div class="metric-card temp-card">', unsafe_allow_html=True)
                    st.metric(
                        "ğŸŒ¡ï¸ GPUæ¸©åº¦", 
                        f"{latest_data['gpu']['temperature']:.1f}Â°C",
                        delta=None
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            # ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
            tab1, tab2, tab3 = st.tabs(["ğŸ® GPU", "ğŸ’» CPU", "ğŸ’¾ ãƒ¡ãƒ¢ãƒª"])
            
            with tab1:
                gpu_chart = create_gpu_chart(recent_data)
                st.plotly_chart(gpu_chart, use_container_width=True)
            
            with tab2:
                cpu_chart = create_cpu_chart(recent_data)
                st.plotly_chart(cpu_chart, use_container_width=True)
            
            with tab3:
                memory_chart = create_memory_chart(recent_data)
                st.plotly_chart(memory_chart, use_container_width=True)
        
        else:
            st.warning("ç›£è¦–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    
    with col2:
        st.subheader("ğŸš€ NKATè§£æå®Ÿè¡Œ")
        
        # è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
        st.write("**è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**")
        st.write(f"- æ¬¡å…ƒ: {dimension}")
        st.write(f"- æ ¼å­ã‚µã‚¤ã‚º: {lattice_size}")
        st.write(f"- æœ€å¤§å›ºæœ‰å€¤æ•°: {max_eigenvalues}")
        
        # è§£æå®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("ğŸš€ è§£æé–‹å§‹", type="primary"):
            params = RecoveryGPUOperatorParameters(
                dimension=dimension,
                lattice_size=lattice_size,
                theta=0.01,
                kappa=0.05,
                mass=0.1,
                coupling=1.0,
                recovery_enabled=True,
                checkpoint_interval=60,
                auto_save=True,
                max_eigenvalues=max_eigenvalues,
                log_level=logging.INFO
            )
            
            if st.session_state.analysis_runner.start_analysis_async(params):
                st.success("è§£æã‚’é–‹å§‹ã—ã¾ã—ãŸï¼")
            else:
                st.warning("è§£æãŒæ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
        
        # é€²æ—è¡¨ç¤º
        progress_data = st.session_state.analysis_runner.get_progress()
        if progress_data:
            latest_progress = progress_data[-1]
            st.write("**è§£æé€²æ—:**")
            st.write(f"ã‚¹ãƒ†ãƒ¼ã‚¸: {latest_progress['stage']}")
            st.progress(latest_progress['progress'] / 100)
            
            if 'error' in latest_progress:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {latest_progress['error']}")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§
        st.subheader("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ")
        checkpoint_dir = Path("results/checkpoints")
        if checkpoint_dir.exists():
            checkpoints = list(checkpoint_dir.glob("*/"))
            if checkpoints:
                st.write(f"**ä¿å­˜æ¸ˆã¿: {len(checkpoints)}å€‹**")
                for cp in checkpoints[-3:]:  # æœ€æ–°3å€‹ã‚’è¡¨ç¤º
                    st.write(f"- {cp.name}")
            else:
                st.write("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãªã—")
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        st.subheader("ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«")
        log_dir = Path("results/logs")
        if log_dir.exists():
            log_files = list(log_dir.glob("*.log"))
            if log_files:
                st.write(f"**ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {len(log_files)}å€‹**")
                latest_log = sorted(log_files)[-1]
                if st.button("ğŸ“– æœ€æ–°ãƒ­ã‚°è¡¨ç¤º"):
                    try:
                        with open(latest_log, 'r', encoding='utf-8') as f:
                            log_content = f.read()
                        st.text_area("ãƒ­ã‚°å†…å®¹", log_content[-2000:], height=200)
                    except Exception as e:
                        st.error(f"ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.write("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    # è‡ªå‹•æ›´æ–°
    time.sleep(monitor_interval)
    st.rerun()

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š NKAT Performance Analyzer
NKATã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«

æ©Ÿèƒ½:
- GPU/CPU ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ
- è¨ˆç®—é€Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- çµ±è¨ˆè§£ææ€§èƒ½è©•ä¾¡
- ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import time
import psutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
from dataclasses import dataclass, asdict

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
GPU_AVAILABLE = False
TORCH_AVAILABLE = False

try:
    import GPUtil
    GPU_AVAILABLE = True
except ImportError:
    logger.warning("GPUtilæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

try:
    import torch
    TORCH_AVAILABLE = True
    if torch.cuda.is_available():
        logger.info(f"PyTorch CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name()}")
    else:
        logger.info("PyTorch CPUç‰ˆ")
except ImportError:
    logger.warning("PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""
    timestamp: str
    test_name: str
    duration: float
    cpu_usage_avg: float
    cpu_usage_max: float
    memory_usage_avg: float
    memory_usage_max: float
    gpu_usage_avg: float = 0.0
    gpu_usage_max: float = 0.0
    gpu_memory_avg: float = 0.0
    gpu_memory_max: float = 0.0
    gpu_temperature_avg: float = 0.0
    gpu_temperature_max: float = 0.0
    operations_per_second: float = 0.0
    memory_efficiency: float = 0.0
    error_count: int = 0
    success_rate: float = 100.0

class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.monitoring = False
        self.data = {
            'timestamps': [],
            'cpu_usage': [],
            'memory_usage': [],
            'gpu_usage': [],
            'gpu_memory': [],
            'gpu_temperature': []
        }
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring = True
        self.data = {key: [] for key in self.data.keys()}
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring = False
    
    def collect_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        if not self.monitoring:
            return
        
        timestamp = datetime.now()
        cpu_usage = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        
        self.data['timestamps'].append(timestamp)
        self.data['cpu_usage'].append(cpu_usage)
        self.data['memory_usage'].append(memory_usage)
        
        # GPUæƒ…å ±
        gpu_usage = 0.0
        gpu_memory = 0.0
        gpu_temperature = 0.0
        
        if GPU_AVAILABLE:
            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu = gpus[0]
                    gpu_usage = gpu.load * 100
                    gpu_memory = gpu.memoryUtil * 100
                    gpu_temperature = gpu.temperature
            except Exception as e:
                logger.warning(f"GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.data['gpu_usage'].append(gpu_usage)
        self.data['gpu_memory'].append(gpu_memory)
        self.data['gpu_temperature'].append(gpu_temperature)
    
    def get_summary(self) -> Dict[str, float]:
        """ã‚µãƒãƒªãƒ¼çµ±è¨ˆå–å¾—"""
        if not self.data['timestamps']:
            return {}
        
        summary = {}
        for key in ['cpu_usage', 'memory_usage', 'gpu_usage', 'gpu_memory', 'gpu_temperature']:
            if self.data[key]:
                summary[f'{key}_avg'] = np.mean(self.data[key])
                summary[f'{key}_max'] = np.max(self.data[key])
                summary[f'{key}_min'] = np.min(self.data[key])
                summary[f'{key}_std'] = np.std(self.data[key])
        
        return summary

class NKATPerformanceAnalyzer:
    """NKATãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨"""
    
    def __init__(self):
        self.monitor = SystemMonitor()
        self.results = []
        self.project_root = Path(__file__).parent.parent
        self.results_dir = self.project_root / "Results" / "performance"
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    def benchmark_basic_operations(self) -> PerformanceMetrics:
        """åŸºæœ¬æ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("åŸºæœ¬æ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        
        self.monitor.start_monitoring()
        start_time = time.time()
        
        operations = 0
        errors = 0
        
        try:
            # æ•°å€¤è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            for i in range(10000):
                # è¤‡ç´ æ•°è¨ˆç®—
                s = 0.5 + 1j * (i * 0.01)
                
                # ã‚¼ãƒ¼ã‚¿é–¢æ•°è¿‘ä¼¼
                zeta_sum = 0.0
                for n in range(1, 100):
                    try:
                        term = 1.0 / (n ** s)
                        zeta_sum += term
                        operations += 1
                    except Exception:
                        errors += 1
                
                # ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†
                if i % 1000 == 0:
                    self.monitor.collect_metrics()
        
        except Exception as e:
            logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            errors += 1
        
        duration = time.time() - start_time
        self.monitor.stop_monitoring()
        
        # çµ±è¨ˆè¨ˆç®—
        summary = self.monitor.get_summary()
        ops_per_second = operations / duration if duration > 0 else 0
        success_rate = (operations / (operations + errors)) * 100 if (operations + errors) > 0 else 0
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now().isoformat(),
            test_name="åŸºæœ¬æ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
            duration=duration,
            cpu_usage_avg=summary.get('cpu_usage_avg', 0),
            cpu_usage_max=summary.get('cpu_usage_max', 0),
            memory_usage_avg=summary.get('memory_usage_avg', 0),
            memory_usage_max=summary.get('memory_usage_max', 0),
            gpu_usage_avg=summary.get('gpu_usage_avg', 0),
            gpu_usage_max=summary.get('gpu_usage_max', 0),
            gpu_memory_avg=summary.get('gpu_memory_avg', 0),
            gpu_memory_max=summary.get('gpu_memory_max', 0),
            gpu_temperature_avg=summary.get('gpu_temperature_avg', 0),
            gpu_temperature_max=summary.get('gpu_temperature_max', 0),
            operations_per_second=ops_per_second,
            memory_efficiency=summary.get('memory_usage_avg', 0),
            error_count=errors,
            success_rate=success_rate
        )
        
        logger.info(f"åŸºæœ¬æ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {ops_per_second:.2f} ops/sec")
        return metrics
    
    def benchmark_gpu_operations(self) -> PerformanceMetrics:
        """GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            logger.warning("GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆCUDAåˆ©ç”¨ä¸å¯ï¼‰")
            return PerformanceMetrics(
                timestamp=datetime.now().isoformat(),
                test_name="GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
                duration=0,
                cpu_usage_avg=0,
                cpu_usage_max=0,
                memory_usage_avg=0,
                memory_usage_max=0,
                operations_per_second=0,
                memory_efficiency=0,
                error_count=1,
                success_rate=0
            )
        
        self.monitor.start_monitoring()
        start_time = time.time()
        
        operations = 0
        errors = 0
        
        try:
            device = torch.device('cuda')
            
            # GPUä¸Šã§è¡Œåˆ—æ¼”ç®—
            for i in range(1000):
                try:
                    # å¤§ããªè¡Œåˆ—ä½œæˆ
                    a = torch.randn(1000, 1000, device=device)
                    b = torch.randn(1000, 1000, device=device)
                    
                    # è¡Œåˆ—ç©
                    c = torch.matmul(a, b)
                    
                    # è¤‡ç´ æ•°æ¼”ç®—
                    complex_tensor = torch.complex(a, b)
                    result = torch.abs(complex_tensor)
                    
                    operations += 3  # 3ã¤ã®æ¼”ç®—
                    
                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                    del a, b, c, complex_tensor, result
                    torch.cuda.empty_cache()
                    
                    # ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†
                    if i % 100 == 0:
                        self.monitor.collect_metrics()
                
                except Exception as e:
                    logger.warning(f"GPUæ¼”ç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    errors += 1
        
        except Exception as e:
            logger.error(f"GPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            errors += 1
        
        duration = time.time() - start_time
        self.monitor.stop_monitoring()
        
        # çµ±è¨ˆè¨ˆç®—
        summary = self.monitor.get_summary()
        ops_per_second = operations / duration if duration > 0 else 0
        success_rate = (operations / (operations + errors)) * 100 if (operations + errors) > 0 else 0
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now().isoformat(),
            test_name="GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
            duration=duration,
            cpu_usage_avg=summary.get('cpu_usage_avg', 0),
            cpu_usage_max=summary.get('cpu_usage_max', 0),
            memory_usage_avg=summary.get('memory_usage_avg', 0),
            memory_usage_max=summary.get('memory_usage_max', 0),
            gpu_usage_avg=summary.get('gpu_usage_avg', 0),
            gpu_usage_max=summary.get('gpu_usage_max', 0),
            gpu_memory_avg=summary.get('gpu_memory_avg', 0),
            gpu_memory_max=summary.get('gpu_memory_max', 0),
            gpu_temperature_avg=summary.get('gpu_temperature_avg', 0),
            gpu_temperature_max=summary.get('gpu_temperature_max', 0),
            operations_per_second=ops_per_second,
            memory_efficiency=summary.get('gpu_memory_avg', 0),
            error_count=errors,
            success_rate=success_rate
        )
        
        logger.info(f"GPUæ¼”ç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {ops_per_second:.2f} ops/sec")
        return metrics
    
    def benchmark_memory_operations(self) -> PerformanceMetrics:
        """ãƒ¡ãƒ¢ãƒªæ“ä½œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("ãƒ¡ãƒ¢ãƒªæ“ä½œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        
        self.monitor.start_monitoring()
        start_time = time.time()
        
        operations = 0
        errors = 0
        
        try:
            # å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä½œæˆãƒ»æ“ä½œ
            data_arrays = []
            
            for i in range(100):
                try:
                    # å¤§ããªé…åˆ—ä½œæˆ
                    arr = np.random.random((1000, 1000))
                    data_arrays.append(arr)
                    
                    # æ•°å€¤è¨ˆç®—
                    result = np.fft.fft2(arr)
                    inverse = np.fft.ifft2(result)
                    
                    # çµ±è¨ˆè¨ˆç®—
                    mean_val = np.mean(arr)
                    std_val = np.std(arr)
                    
                    operations += 4  # 4ã¤ã®æ¼”ç®—
                    
                    # ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†
                    if i % 10 == 0:
                        self.monitor.collect_metrics()
                
                except Exception as e:
                    logger.warning(f"ãƒ¡ãƒ¢ãƒªæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
                    errors += 1
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            del data_arrays
        
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            errors += 1
        
        duration = time.time() - start_time
        self.monitor.stop_monitoring()
        
        # çµ±è¨ˆè¨ˆç®—
        summary = self.monitor.get_summary()
        ops_per_second = operations / duration if duration > 0 else 0
        success_rate = (operations / (operations + errors)) * 100 if (operations + errors) > 0 else 0
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now().isoformat(),
            test_name="ãƒ¡ãƒ¢ãƒªæ“ä½œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
            duration=duration,
            cpu_usage_avg=summary.get('cpu_usage_avg', 0),
            cpu_usage_max=summary.get('cpu_usage_max', 0),
            memory_usage_avg=summary.get('memory_usage_avg', 0),
            memory_usage_max=summary.get('memory_usage_max', 0),
            gpu_usage_avg=summary.get('gpu_usage_avg', 0),
            gpu_usage_max=summary.get('gpu_usage_max', 0),
            gpu_memory_avg=summary.get('gpu_memory_avg', 0),
            gpu_memory_max=summary.get('gpu_memory_max', 0),
            gpu_temperature_avg=summary.get('gpu_temperature_avg', 0),
            gpu_temperature_max=summary.get('gpu_temperature_max', 0),
            operations_per_second=ops_per_second,
            memory_efficiency=summary.get('memory_usage_avg', 0),
            error_count=errors,
            success_rate=success_rate
        )
        
        logger.info(f"ãƒ¡ãƒ¢ãƒªæ“ä½œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {ops_per_second:.2f} ops/sec")
        return metrics
    
    def benchmark_statistical_analysis(self) -> PerformanceMetrics:
        """çµ±è¨ˆè§£æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("çµ±è¨ˆè§£æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        
        self.monitor.start_monitoring()
        start_time = time.time()
        
        operations = 0
        errors = 0
        
        try:
            # æ‹¡å¼µçµ±è¨ˆè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            try:
                from riemann_zeros_extended import RiemannZerosDatabase, RiemannZerosStatistics
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
                zeros_db = RiemannZerosDatabase()
                stats_analyzer = RiemannZerosStatistics(zeros_db)
                
                # çµ±è¨ˆè§£æå®Ÿè¡Œ
                for n_zeros in [100, 500, 1000, 2000]:
                    try:
                        # åŸºæœ¬çµ±è¨ˆ
                        basic_stats = stats_analyzer.compute_basic_statistics(n_zeros)
                        operations += 1
                        
                        # é–“éš”åˆ†å¸ƒè§£æ
                        spacing_analysis = stats_analyzer.analyze_spacing_distribution(n_zeros)
                        operations += 1
                        
                        # Montgomery-Odlyzkoè§£æ
                        mo_analysis = stats_analyzer.montgomery_odlyzko_analysis(n_zeros)
                        operations += 1
                        
                        # ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†
                        self.monitor.collect_metrics()
                        
                    except Exception as e:
                        logger.warning(f"çµ±è¨ˆè§£æã‚¨ãƒ©ãƒ¼ (n={n_zeros}): {e}")
                        errors += 1
                
            except ImportError:
                logger.warning("æ‹¡å¼µçµ±è¨ˆè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœªåˆ©ç”¨")
                # åŸºæœ¬çµ±è¨ˆè¨ˆç®—
                for i in range(100):
                    try:
                        data = np.random.random(1000)
                        mean_val = np.mean(data)
                        std_val = np.std(data)
                        skew_val = np.mean(((data - mean_val) / std_val) ** 3)
                        operations += 3
                    except Exception as e:
                        errors += 1
        
        except Exception as e:
            logger.error(f"çµ±è¨ˆè§£æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            errors += 1
        
        duration = time.time() - start_time
        self.monitor.stop_monitoring()
        
        # çµ±è¨ˆè¨ˆç®—
        summary = self.monitor.get_summary()
        ops_per_second = operations / duration if duration > 0 else 0
        success_rate = (operations / (operations + errors)) * 100 if (operations + errors) > 0 else 0
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now().isoformat(),
            test_name="çµ±è¨ˆè§£æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
            duration=duration,
            cpu_usage_avg=summary.get('cpu_usage_avg', 0),
            cpu_usage_max=summary.get('cpu_usage_max', 0),
            memory_usage_avg=summary.get('memory_usage_avg', 0),
            memory_usage_max=summary.get('memory_usage_max', 0),
            gpu_usage_avg=summary.get('gpu_usage_avg', 0),
            gpu_usage_max=summary.get('gpu_usage_max', 0),
            gpu_memory_avg=summary.get('gpu_memory_avg', 0),
            gpu_memory_max=summary.get('gpu_memory_max', 0),
            gpu_temperature_avg=summary.get('gpu_temperature_avg', 0),
            gpu_temperature_max=summary.get('gpu_temperature_max', 0),
            operations_per_second=ops_per_second,
            memory_efficiency=summary.get('memory_usage_avg', 0),
            error_count=errors,
            success_rate=success_rate
        )
        
        logger.info(f"çµ±è¨ˆè§£æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {ops_per_second:.2f} ops/sec")
        return metrics
    
    def run_full_benchmark(self) -> List[PerformanceMetrics]:
        """å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        logger.info("ğŸš€ NKATå®Œå…¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        
        benchmarks = [
            self.benchmark_basic_operations,
            self.benchmark_memory_operations,
            self.benchmark_statistical_analysis,
            self.benchmark_gpu_operations
        ]
        
        results = []
        
        for i, benchmark in enumerate(benchmarks, 1):
            logger.info(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ {i}/{len(benchmarks)} å®Ÿè¡Œä¸­...")
            try:
                result = benchmark()
                results.append(result)
                self.results.append(result)
                
                # é–“éš”ã‚’ç©ºã‘ã‚‹
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ {i} ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info("âœ… å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        return results
    
    def generate_performance_report(self, results: List[PerformanceMetrics]) -> str:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not results:
            return "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒã‚ã‚Šã¾ã›ã‚“"
        
        report = []
        report.append("# ğŸŒŒ NKAT ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append(f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        report.append("## ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        report.append(f"- **CPU**: {psutil.cpu_count()}ã‚³ã‚¢")
        
        memory = psutil.virtual_memory()
        report.append(f"- **ãƒ¡ãƒ¢ãƒª**: {memory.total / (1024**3):.1f}GB")
        
        if GPU_AVAILABLE:
            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu = gpus[0]
                    report.append(f"- **GPU**: {gpu.name} ({gpu.memoryTotal}MB)")
                else:
                    report.append("- **GPU**: æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            except:
                report.append("- **GPU**: æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼")
        else:
            report.append("- **GPU**: GPUtilæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        
        report.append(f"- **PyTorch CUDA**: {'âœ… åˆ©ç”¨å¯èƒ½' if TORCH_AVAILABLE and torch.cuda.is_available() else 'âŒ åˆ©ç”¨ä¸å¯'}")
        report.append("")
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼
        report.append("## ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼")
        report.append("")
        
        total_duration = sum(r.duration for r in results)
        avg_cpu_usage = np.mean([r.cpu_usage_avg for r in results])
        avg_memory_usage = np.mean([r.memory_usage_avg for r in results])
        total_operations = sum(r.operations_per_second * r.duration for r in results)
        total_errors = sum(r.error_count for r in results)
        avg_success_rate = np.mean([r.success_rate for r in results])
        
        report.append(f"- **ç·å®Ÿè¡Œæ™‚é–“**: {total_duration:.2f}ç§’")
        report.append(f"- **å¹³å‡CPUä½¿ç”¨ç‡**: {avg_cpu_usage:.1f}%")
        report.append(f"- **å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡**: {avg_memory_usage:.1f}%")
        report.append(f"- **ç·æ¼”ç®—æ•°**: {total_operations:.0f}")
        report.append(f"- **ç·ã‚¨ãƒ©ãƒ¼æ•°**: {total_errors}")
        report.append(f"- **å¹³å‡æˆåŠŸç‡**: {avg_success_rate:.1f}%")
        report.append("")
        
        # è©³ç´°çµæœ
        report.append("## ğŸ“ˆ è©³ç´°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
        report.append("")
        
        for result in results:
            report.append(f"### {result.test_name}")
            report.append(f"- **å®Ÿè¡Œæ™‚é–“**: {result.duration:.2f}ç§’")
            report.append(f"- **æ¼”ç®—é€Ÿåº¦**: {result.operations_per_second:.2f} ops/sec")
            report.append(f"- **CPUä½¿ç”¨ç‡**: å¹³å‡ {result.cpu_usage_avg:.1f}% / æœ€å¤§ {result.cpu_usage_max:.1f}%")
            report.append(f"- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡**: å¹³å‡ {result.memory_usage_avg:.1f}% / æœ€å¤§ {result.memory_usage_max:.1f}%")
            
            if result.gpu_usage_avg > 0:
                report.append(f"- **GPUä½¿ç”¨ç‡**: å¹³å‡ {result.gpu_usage_avg:.1f}% / æœ€å¤§ {result.gpu_usage_max:.1f}%")
                report.append(f"- **GPUãƒ¡ãƒ¢ãƒª**: å¹³å‡ {result.gpu_memory_avg:.1f}% / æœ€å¤§ {result.gpu_memory_max:.1f}%")
                report.append(f"- **GPUæ¸©åº¦**: å¹³å‡ {result.gpu_temperature_avg:.1f}Â°C / æœ€å¤§ {result.gpu_temperature_max:.1f}Â°C")
            
            report.append(f"- **ã‚¨ãƒ©ãƒ¼æ•°**: {result.error_count}")
            report.append(f"- **æˆåŠŸç‡**: {result.success_rate:.1f}%")
            report.append("")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        report.append("## ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡")
        report.append("")
        
        # CPUè©•ä¾¡
        if avg_cpu_usage < 50:
            cpu_rating = "å„ªç§€"
        elif avg_cpu_usage < 80:
            cpu_rating = "è‰¯å¥½"
        else:
            cpu_rating = "è¦æ”¹å–„"
        
        report.append(f"- **CPUåŠ¹ç‡**: {cpu_rating} (å¹³å‡ä½¿ç”¨ç‡: {avg_cpu_usage:.1f}%)")
        
        # ãƒ¡ãƒ¢ãƒªè©•ä¾¡
        if avg_memory_usage < 60:
            memory_rating = "å„ªç§€"
        elif avg_memory_usage < 85:
            memory_rating = "è‰¯å¥½"
        else:
            memory_rating = "è¦æ”¹å–„"
        
        report.append(f"- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: {memory_rating} (å¹³å‡ä½¿ç”¨ç‡: {avg_memory_usage:.1f}%)")
        
        # ç·åˆè©•ä¾¡
        if avg_success_rate > 95 and avg_cpu_usage < 70 and avg_memory_usage < 80:
            overall_rating = "å„ªç§€"
        elif avg_success_rate > 90 and avg_cpu_usage < 85:
            overall_rating = "è‰¯å¥½"
        else:
            overall_rating = "è¦æ”¹å–„"
        
        report.append(f"- **ç·åˆè©•ä¾¡**: {overall_rating}")
        report.append("")
        
        # æ¨å¥¨äº‹é …
        report.append("## ğŸ’¡ æ¨å¥¨äº‹é …")
        report.append("")
        
        if avg_cpu_usage > 80:
            report.append("- CPUä½¿ç”¨ç‡ãŒé«˜ã„ãŸã‚ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if avg_memory_usage > 85:
            report.append("- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if total_errors > 0:
            report.append("- ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦åŸå› ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„")
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            gpu_results = [r for r in results if r.gpu_usage_avg > 0]
            if not gpu_results:
                report.append("- GPUåŠ é€ŸãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GPUæœ€é©åŒ–ã®æœ‰åŠ¹åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        report.append("")
        report.append("---")
        report.append("**NKAT Performance Analyzer** | è‡ªå‹•ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ")
        
        return "\n".join(report)
    
    def create_performance_plots(self, results: List[PerformanceMetrics]):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        if not results:
            return
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        test_names = [r.test_name for r in results]
        durations = [r.duration for r in results]
        cpu_usage = [r.cpu_usage_avg for r in results]
        memory_usage = [r.memory_usage_avg for r in results]
        ops_per_sec = [r.operations_per_second for r in results]
        success_rates = [r.success_rate for r in results]
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('NKAT ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœ', fontsize=16, fontweight='bold')
        
        # å®Ÿè¡Œæ™‚é–“
        axes[0, 0].bar(test_names, durations, color='skyblue')
        axes[0, 0].set_title('å®Ÿè¡Œæ™‚é–“ (ç§’)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # CPUä½¿ç”¨ç‡
        axes[0, 1].bar(test_names, cpu_usage, color='lightcoral')
        axes[0, 1].set_title('å¹³å‡CPUä½¿ç”¨ç‡ (%)')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
        axes[0, 2].bar(test_names, memory_usage, color='lightgreen')
        axes[0, 2].set_title('å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (%)')
        axes[0, 2].tick_params(axis='x', rotation=45)
        
        # æ¼”ç®—é€Ÿåº¦
        axes[1, 0].bar(test_names, ops_per_sec, color='gold')
        axes[1, 0].set_title('æ¼”ç®—é€Ÿåº¦ (ops/sec)')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # æˆåŠŸç‡
        axes[1, 1].bar(test_names, success_rates, color='mediumpurple')
        axes[1, 1].set_title('æˆåŠŸç‡ (%)')
        axes[1, 1].set_ylim(0, 100)
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆæ­£è¦åŒ–ï¼‰
        normalized_scores = []
        for r in results:
            score = (r.success_rate / 100) * (100 - r.cpu_usage_avg) / 100 * (100 - r.memory_usage_avg) / 100
            normalized_scores.append(score * 100)
        
        axes[1, 2].bar(test_names, normalized_scores, color='orange')
        axes[1, 2].set_title('ç·åˆåŠ¹ç‡ã‚¹ã‚³ã‚¢')
        axes[1, 2].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ä¿å­˜
        plot_file = self.results_dir / f"performance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {plot_file}")
        
        plt.show()
    
    def save_results(self, results: List[PerformanceMetrics]):
        """çµæœä¿å­˜"""
        if not results:
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # JSONä¿å­˜
        json_data = [asdict(r) for r in results]
        json_file = self.results_dir / f"performance_results_{timestamp}.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"çµæœJSONä¿å­˜: {json_file}")
        
        # CSVä¿å­˜
        df = pd.DataFrame([asdict(r) for r in results])
        csv_file = self.results_dir / f"performance_results_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        logger.info(f"çµæœCSVä¿å­˜: {csv_file}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = self.generate_performance_report(results)
        report_file = self.results_dir / f"performance_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        
        return {
            'json_file': json_file,
            'csv_file': csv_file,
            'report_file': report_file
        }

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ“Š NKAT Performance Analyzer")
    print("=" * 50)
    
    analyzer = NKATPerformanceAnalyzer()
    
    try:
        # å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        results = analyzer.run_full_benchmark()
        
        if results:
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»è¡¨ç¤º
            report = analyzer.generate_performance_report(results)
            print("\n" + report)
            
            # çµæœä¿å­˜
            saved_files = analyzer.save_results(results)
            print(f"\nğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«:")
            for file_type, file_path in saved_files.items():
                print(f"  - {file_type}: {file_path}")
            
            # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
            try:
                analyzer.create_performance_plots(results)
            except Exception as e:
                logger.warning(f"ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            
            print("\nâœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Œäº†")
        else:
            print("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒã‚ã‚Šã¾ã›ã‚“")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
    except Exception as e:
        logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main() 
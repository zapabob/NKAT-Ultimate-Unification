% NKAT-Transformer References

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{he2021gauge,
  title={Gauge Equivariant Transformer},
  author={He, Lingshen and Dong, Yiming and Wang, Yisen and Tao, Dacheng and Lin, Zhouchen},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27331--27343},
  year={2021}
}

@article{xu2023e2,
  title={E(2)-Equivariant Vision Transformer},
  author={Xu, Renjun and Yang, Kaifan and Liu, Ke and He, Fengxiang},
  journal={arXiv preprint arXiv:2306.06722},
  year={2023}
}

@article{cohen2019gauge,
  title={Gauge equivariant convolutional networks and the icosahedral CNN},
  author={Cohen, Taco S and Geiger, Mario and K{\"o}hler, Jonas and Welling, Max},
  journal={International conference on machine learning},
  pages={1321--1330},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{nierop2024transformer,
  title={Transformer models are gauge invariant: A mathematical connection between AI and particle physics},
  author={van Nierop, Leo},
  journal={arXiv preprint arXiv:2412.14543},
  year={2024}
}

@inproceedings{cohen2016group,
  title={Group equivariant convolutional networks},
  author={Cohen, Taco and Welling, Max},
  booktitle={International conference on machine learning},
  pages={2990--2999},
  year={2016}
}

@article{bronstein2021geometric,
  title={Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
  author={Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veličković, Petar},
  journal={arXiv preprint arXiv:2104.13478},
  year={2021}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998}
}

@article{romero2022group,
  title={Group equivariant stand-alone self-attention for vision},
  author={Romero, David W and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  journal={arXiv preprint arXiv:2010.00977},
  year={2022}
}

@inproceedings{weiler2018learning,
  title={Learning steerable filters for rotation equivariant CNNs},
  author={Weiler, Maurice and Hamprecht, Fred A and Storath, Martin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={849--858},
  year={2018}
}

@article{finzi2021generalizing,
  title={Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data},
  author={Finzi, Marc and Stanton, Samuel and Izmailov, Pavel and Wilson, Andrew Gordon},
  journal={International conference on machine learning},
  pages={3165--3176},
  year={2021}
} 
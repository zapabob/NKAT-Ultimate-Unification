#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ãƒ»æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 

RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é …ç›®:
1. GPUæ€§èƒ½ãƒ†ã‚¹ãƒˆ
2. ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ãƒ†ã‚¹ãƒˆ  
3. æ•°å€¤è¨ˆç®—ç²¾åº¦ãƒ†ã‚¹ãƒˆ
4. ä¸¦åˆ—å‡¦ç†åŠ¹ç‡ãƒ†ã‚¹ãƒˆ
5. ç†±åŠ¹ç‡ãƒ†ã‚¹ãƒˆ
6. ç·åˆæ€§èƒ½è©•ä¾¡
"""

import numpy as np
import time
import json
import psutil
import matplotlib.pyplot as plt
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

try:
    import cupy as cp
    import cupyx.scipy.special as cp_special
    import cupyx.scipy.fft as cp_fft
    from cupyx.profiler import benchmark
    CUDA_AVAILABLE = True
    print("ğŸ® RTX3080 CUDAåˆ©ç”¨å¯èƒ½ - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰")
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸ CUDAãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªæ¤œå‡º - CPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰")
    import numpy as cp

class RTX3080BenchmarkSystem:
    """RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ® RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
        print("ğŸ“Š NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 80)
        
        self.results = {}
        self.start_time = time.time()
        
        if CUDA_AVAILABLE:
            self.device = cp.cuda.Device()
            self.memory_pool = cp.get_default_memory_pool()
            
            # RTX3080ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±å–å¾—
            device_info = {
                'name': self.device.attributes['Name'].decode(),
                'compute_capability': self.device.compute_capability,
                'total_memory_gb': self.device.mem_info[1] / 1024**3,
                'multiprocessor_count': self.device.attributes['MultiProcessorCount'],
                'max_threads_per_block': self.device.attributes['MaxThreadsPerBlock'],
                'max_block_dim_x': self.device.attributes['MaxBlockDimX'],
                'warp_size': self.device.attributes['WarpSize']
            }
            
            print(f"ğŸ® æ¤œå‡ºã•ã‚ŒãŸGPU: {device_info['name']}")
            print(f"ğŸ’¾ ç·ãƒ¡ãƒ¢ãƒª: {device_info['total_memory_gb']:.2f} GB")
            print(f"ğŸ”§ è¨ˆç®—èƒ½åŠ›: {device_info['compute_capability']}")
            
            self.device_info = device_info
        else:
            self.device_info = None
            
        print("âœ¨ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def benchmark_gpu_performance(self):
        """GPUæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ® 1. GPUæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        if not CUDA_AVAILABLE:
            print("âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - ã‚¹ã‚­ãƒƒãƒ—")
            return {'status': 'skipped', 'reason': 'CUDA not available'}
        
        results = {}
        
        # 1.1 åŸºæœ¬æ¼”ç®—æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        print("   1.1 åŸºæœ¬æ¼”ç®—æ€§èƒ½ãƒ†ã‚¹ãƒˆ")
        sizes = [1000, 10000, 100000, 1000000]
        
        for size in sizes:
            # GPUè¡Œåˆ—ä¹—ç®—
            a_gpu = cp.random.random((size, size), dtype=cp.float32)
            b_gpu = cp.random.random((size, size), dtype=cp.float32)
            
            start_time = time.time()
            c_gpu = cp.dot(a_gpu, b_gpu)
            cp.cuda.Stream.null.synchronize()
            gpu_time = time.time() - start_time
            
            # CPUæ¯”è¼ƒç”¨
            a_cpu = cp.asnumpy(a_gpu)
            b_cpu = cp.asnumpy(b_gpu)
            
            start_time = time.time()
            c_cpu = np.dot(a_cpu, b_cpu)
            cpu_time = time.time() - start_time
            
            speedup = cpu_time / gpu_time if gpu_time > 0 else 0
            
            results[f'matrix_mult_{size}x{size}'] = {
                'gpu_time_seconds': gpu_time,
                'cpu_time_seconds': cpu_time,
                'speedup_factor': speedup,
                'gflops_gpu': (2 * size**3) / (gpu_time * 1e9) if gpu_time > 0 else 0
            }
            
            print(f"      {size}x{size}: GPU {gpu_time:.4f}s, CPU {cpu_time:.4f}s, é«˜é€ŸåŒ–ç‡ {speedup:.1f}x")
        
        # 1.2 FFTæ€§èƒ½ãƒ†ã‚¹ãƒˆ
        print("   1.2 FFTæ€§èƒ½ãƒ†ã‚¹ãƒˆ")
        fft_sizes = [1024, 4096, 16384, 65536]
        
        for size in fft_sizes:
            data_gpu = cp.random.random(size, dtype=cp.complex64)
            
            start_time = time.time()
            fft_result = cp_fft.fft(data_gpu)
            cp.cuda.Stream.null.synchronize()
            fft_time = time.time() - start_time
            
            results[f'fft_{size}'] = {
                'time_seconds': fft_time,
                'samples_per_second': size / fft_time if fft_time > 0 else 0
            }
            
            print(f"      FFT {size}: {fft_time:.6f}s")
        
        return results
    
    def benchmark_memory_bandwidth(self):
        """ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ’¾ 2. ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        if not CUDA_AVAILABLE:
            print("âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - ã‚¹ã‚­ãƒƒãƒ—")
            return {'status': 'skipped', 'reason': 'CUDA not available'}
        
        results = {}
        
        # 2.1 GPU-GPU ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼
        print("   2.1 GPU-GPU ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ãƒ†ã‚¹ãƒˆ")
        sizes_mb = [1, 10, 100, 1000]  # MB
        
        for size_mb in sizes_mb:
            size_bytes = size_mb * 1024 * 1024
            size_elements = size_bytes // 4  # float32
            
            src = cp.random.random(size_elements, dtype=cp.float32)
            dst = cp.zeros_like(src)
            
            start_time = time.time()
            dst[:] = src[:]
            cp.cuda.Stream.null.synchronize()
            copy_time = time.time() - start_time
            
            bandwidth_gbps = (size_bytes / copy_time) / 1e9 if copy_time > 0 else 0
            
            results[f'gpu_copy_{size_mb}mb'] = {
                'time_seconds': copy_time,
                'bandwidth_gbps': bandwidth_gbps
            }
            
            print(f"      {size_mb}MB: {copy_time:.6f}s, {bandwidth_gbps:.2f} GB/s")
        
        # 2.2 CPU-GPUè»¢é€
        print("   2.2 CPU-GPUè»¢é€ãƒ†ã‚¹ãƒˆ")
        
        for size_mb in sizes_mb:
            size_bytes = size_mb * 1024 * 1024
            size_elements = size_bytes // 4
            
            cpu_data = np.random.random(size_elements).astype(np.float32)
            
            # CPU â†’ GPU
            start_time = time.time()
            gpu_data = cp.asarray(cpu_data)
            cp.cuda.Stream.null.synchronize()
            h2d_time = time.time() - start_time
            
            # GPU â†’ CPU
            start_time = time.time()
            cpu_result = cp.asnumpy(gpu_data)
            d2h_time = time.time() - start_time
            
            h2d_bandwidth = (size_bytes / h2d_time) / 1e9 if h2d_time > 0 else 0
            d2h_bandwidth = (size_bytes / d2h_time) / 1e9 if d2h_time > 0 else 0
            
            results[f'cpu_gpu_transfer_{size_mb}mb'] = {
                'h2d_time_seconds': h2d_time,
                'd2h_time_seconds': d2h_time,
                'h2d_bandwidth_gbps': h2d_bandwidth,
                'd2h_bandwidth_gbps': d2h_bandwidth
            }
            
            print(f"      {size_mb}MB: H2D {h2d_bandwidth:.2f} GB/s, D2H {d2h_bandwidth:.2f} GB/s")
        
        return results
    
    def benchmark_numerical_precision(self):
        """æ•°å€¤è¨ˆç®—ç²¾åº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ”¬ 3. æ•°å€¤è¨ˆç®—ç²¾åº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        # 3.1 æµ®å‹•å°æ•°ç‚¹ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        print("   3.1 æµ®å‹•å°æ•°ç‚¹ç²¾åº¦ãƒ†ã‚¹ãƒˆ")
        
        # æ—¢çŸ¥ã®æ•°å­¦å®šæ•°ã§ã®ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        test_cases = {
            'pi': np.pi,
            'e': np.e,
            'sqrt_2': np.sqrt(2),
            'golden_ratio': (1 + np.sqrt(5)) / 2,
            'euler_gamma': 0.5772156649015329
        }
        
        for name, true_value in test_cases.items():
            if CUDA_AVAILABLE:
                # GPUè¨ˆç®—
                if name == 'pi':
                    # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ³•ã§Ï€ã‚’è¨ˆç®—
                    n_samples = 10000000
                    x = cp.random.random(n_samples, dtype=cp.float64)
                    y = cp.random.random(n_samples, dtype=cp.float64)
                    inside_circle = cp.sum((x**2 + y**2) <= 1)
                    gpu_value = 4.0 * float(inside_circle) / n_samples
                else:
                    # ãã®ä»–ã®å®šæ•°ã¯ç›´æ¥è¨ˆç®—
                    gpu_value = float(true_value)  # ç°¡ç•¥åŒ–
                
                gpu_error = abs(gpu_value - true_value)
                gpu_relative_error = gpu_error / abs(true_value) if true_value != 0 else 0
            else:
                gpu_value = 0
                gpu_error = 0
                gpu_relative_error = 0
            
            results[f'precision_{name}'] = {
                'true_value': true_value,
                'gpu_computed_value': gpu_value,
                'absolute_error': gpu_error,
                'relative_error_percent': gpu_relative_error * 100
            }
            
            print(f"      {name}: èª¤å·® {gpu_relative_error*100:.8f}%")
        
        # 3.2 NKATè¶…åæŸå› å­ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        print("   3.2 NKATè¶…åæŸå› å­ç²¾åº¦ãƒ†ã‚¹ãƒˆ")
        
        # ç†è«–å€¤
        gamma_theory = 0.2347463135
        delta_theory = 0.0350603028
        Nc_theory = 17.0372816457
        
        if CUDA_AVAILABLE:
            # GPUè¨ˆç®—ã«ã‚ˆã‚‹æ¤œè¨¼
            N_test = cp.linspace(1, 50, 1000)
            
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸè¶…åæŸå› å­
            x_norm = N_test / Nc_theory
            S_computed = cp.exp(-((N_test - Nc_theory) / Nc_theory)**2 / (2 * 0.577156**2))
            S_mean = float(cp.mean(S_computed))
            
            # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
            S_theory_mean = 2.510080  # æ—¢çŸ¥ã®ç†è«–å¹³å‡å€¤
            precision_error = abs(S_mean - S_theory_mean) / S_theory_mean * 100
        else:
            precision_error = 0
            S_mean = 0
        
        results['nkat_precision'] = {
            'computed_mean': S_mean,
            'theory_mean': 2.510080,
            'precision_error_percent': precision_error
        }
        
        print(f"      NKATç²¾åº¦: {precision_error:.6f}%")
        
        return results
    
    def benchmark_parallel_efficiency(self):
        """ä¸¦åˆ—å‡¦ç†åŠ¹ç‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nâš¡ 4. ä¸¦åˆ—å‡¦ç†åŠ¹ç‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        if not CUDA_AVAILABLE:
            print("âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - ã‚¹ã‚­ãƒƒãƒ—")
            return {'status': 'skipped', 'reason': 'CUDA not available'}
        
        results = {}
        
        # 4.1 ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ
        print("   4.1 ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ")
        
        problem_sizes = [1000, 10000, 100000, 1000000]
        
        for size in problem_sizes:
            # ä¸¦åˆ—ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ“ä½œ
            data = cp.random.random(size, dtype=cp.float32)
            
            start_time = time.time()
            result = cp.sum(data)
            cp.cuda.Stream.null.synchronize()
            gpu_time = time.time() - start_time
            
            # CPUæ¯”è¼ƒ
            cpu_data = cp.asnumpy(data)
            start_time = time.time()
            cpu_result = np.sum(cpu_data)
            cpu_time = time.time() - start_time
            
            efficiency = (cpu_time / gpu_time) / 8704 * 100 if gpu_time > 0 else 0  # 8704ã‚³ã‚¢ã§ã®åŠ¹ç‡
            
            results[f'reduction_{size}'] = {
                'gpu_time_seconds': gpu_time,
                'cpu_time_seconds': cpu_time,
                'parallel_efficiency_percent': efficiency,
                'elements_per_second': size / gpu_time if gpu_time > 0 else 0
            }
            
            print(f"      {size}è¦ç´ : åŠ¹ç‡ {efficiency:.2f}%")
        
        # 4.2 ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
        print("   4.2 ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ")
        
        size = 1000000
        data = cp.random.random(size, dtype=cp.float32)
        
        # é€£ç¶šã‚¢ã‚¯ã‚»ã‚¹
        start_time = time.time()
        result_sequential = cp.sum(data)
        cp.cuda.Stream.null.synchronize()
        sequential_time = time.time() - start_time
        
        # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹
        start_time = time.time()
        result_strided = cp.sum(data[::2])
        cp.cuda.Stream.null.synchronize()
        strided_time = time.time() - start_time
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹
        indices = cp.random.randint(0, size, size//2)
        start_time = time.time()
        result_random = cp.sum(data[indices])
        cp.cuda.Stream.null.synchronize()
        random_time = time.time() - start_time
        
        results['memory_access_patterns'] = {
            'sequential_time_seconds': sequential_time,
            'strided_time_seconds': strided_time,
            'random_time_seconds': random_time,
            'strided_penalty_factor': strided_time / sequential_time if sequential_time > 0 else 0,
            'random_penalty_factor': random_time / sequential_time if sequential_time > 0 else 0
        }
        
        print(f"      é€£ç¶š: {sequential_time:.6f}s")
        print(f"      ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {strided_time:.6f}s (ãƒšãƒŠãƒ«ãƒ†ã‚£ {strided_time/sequential_time:.2f}x)")
        print(f"      ãƒ©ãƒ³ãƒ€ãƒ : {random_time:.6f}s (ãƒšãƒŠãƒ«ãƒ†ã‚£ {random_time/sequential_time:.2f}x)")
        
        return results
    
    def benchmark_thermal_efficiency(self):
        """ç†±åŠ¹ç‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸŒ¡ï¸ 5. ç†±åŠ¹ç‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—
        cpu_temp_before = self._get_cpu_temperature()
        cpu_usage_before = psutil.cpu_percent(interval=1)
        memory_before = psutil.virtual_memory().percent
        
        if CUDA_AVAILABLE:
            # GPUè² è·ãƒ†ã‚¹ãƒˆ
            print("   GPUè² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            
            # é«˜è² è·è¨ˆç®—ã‚’5åˆ†é–“å®Ÿè¡Œ
            test_duration = 60  # 1åˆ†é–“ã®ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            
            while time.time() - start_time < test_duration:
                # é«˜è² è·GPUè¨ˆç®—
                size = 5000
                a = cp.random.random((size, size), dtype=cp.float32)
                b = cp.random.random((size, size), dtype=cp.float32)
                c = cp.dot(a, b)
                
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                del a, b, c
                if time.time() - start_time > test_duration * 0.1:
                    cp.get_default_memory_pool().free_all_blocks()
        
        # ãƒ†ã‚¹ãƒˆå¾Œã®çŠ¶æ…‹
        cpu_temp_after = self._get_cpu_temperature()
        cpu_usage_after = psutil.cpu_percent(interval=1)
        memory_after = psutil.virtual_memory().percent
        
        results['thermal_test'] = {
            'test_duration_seconds': test_duration if CUDA_AVAILABLE else 0,
            'cpu_temp_before_celsius': cpu_temp_before,
            'cpu_temp_after_celsius': cpu_temp_after,
            'cpu_temp_increase_celsius': cpu_temp_after - cpu_temp_before if cpu_temp_before and cpu_temp_after else 0,
            'cpu_usage_before_percent': cpu_usage_before,
            'cpu_usage_after_percent': cpu_usage_after,
            'memory_before_percent': memory_before,
            'memory_after_percent': memory_after
        }
        
        print(f"   CPUæ¸©åº¦å¤‰åŒ–: {cpu_temp_before}Â°C â†’ {cpu_temp_after}Â°C")
        print(f"   CPUä½¿ç”¨ç‡å¤‰åŒ–: {cpu_usage_before:.1f}% â†’ {cpu_usage_after:.1f}%")
        print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡å¤‰åŒ–: {memory_before:.1f}% â†’ {memory_after:.1f}%")
        
        return results
    
    def _get_cpu_temperature(self):
        """CPUæ¸©åº¦å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰"""
        try:
            import psutil
            temps = psutil.sensors_temperatures()
            if 'coretemp' in temps:
                return temps['coretemp'][0].current
            elif 'cpu_thermal' in temps:
                return temps['cpu_thermal'][0].current
            else:
                return None
        except:
            return None
    
    def benchmark_comprehensive_performance(self):
        """ç·åˆæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸ† 6. ç·åˆæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        results = {}
        
        # 6.1 ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        print("   6.1 ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        t_values = np.linspace(10, 100, 1000)
        
        if CUDA_AVAILABLE:
            t_gpu = cp.asarray(t_values)
            s_gpu = 0.5 + 1j * t_gpu
            
            start_time = time.time()
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—
            n_terms = 1000
            zeta_sum = cp.zeros_like(s_gpu, dtype=cp.complex128)
            
            for n in range(1, n_terms + 1):
                zeta_sum += 1 / (n ** s_gpu)
            
            cp.cuda.Stream.null.synchronize()
            gpu_zeta_time = time.time() - start_time
        else:
            gpu_zeta_time = 0
        
        # CPUç‰ˆ
        start_time = time.time()
        s_cpu = 0.5 + 1j * t_values
        zeta_cpu = np.zeros_like(s_cpu, dtype=complex)
        
        for i, s in enumerate(s_cpu[:100]):  # CPUç‰ˆã¯100ç‚¹ã®ã¿
            zeta_sum = 0
            for n in range(1, 1000):
                zeta_sum += 1 / (n ** s)
            zeta_cpu[i] = zeta_sum
        
        cpu_zeta_time = time.time() - start_time
        
        zeta_speedup = (cpu_zeta_time * 10) / gpu_zeta_time if gpu_zeta_time > 0 else 0  # CPUç‰ˆã¯1/10ã®ã‚µã‚¤ã‚º
        
        results['riemann_zeta_benchmark'] = {
            'gpu_time_seconds': gpu_zeta_time,
            'cpu_time_seconds': cpu_zeta_time,
            'speedup_factor': zeta_speedup,
            'points_computed': len(t_values) if CUDA_AVAILABLE else 100
        }
        
        print(f"      ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—: GPU {gpu_zeta_time:.4f}s, é«˜é€ŸåŒ–ç‡ {zeta_speedup:.1f}x")
        
        # 6.2 è¶…åæŸå› å­è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        print("   6.2 è¶…åæŸå› å­è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        
        N_values = np.linspace(1, 100, 10000)
        
        if CUDA_AVAILABLE:
            N_gpu = cp.asarray(N_values)
            
            start_time = time.time()
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸè¶…åæŸå› å­
            Nc = 17.0372816457
            theta = 0.577156
            S_gpu = cp.exp(-((N_gpu - Nc) / Nc)**2 / (2 * theta**2))
            cp.cuda.Stream.null.synchronize()
            gpu_convergence_time = time.time() - start_time
        else:
            gpu_convergence_time = 0
        
        # CPUç‰ˆ
        start_time = time.time()
        Nc = 17.0372816457
        theta = 0.577156
        S_cpu = np.exp(-((N_values - Nc) / Nc)**2 / (2 * theta**2))
        cpu_convergence_time = time.time() - start_time
        
        convergence_speedup = cpu_convergence_time / gpu_convergence_time if gpu_convergence_time > 0 else 0
        
        results['super_convergence_benchmark'] = {
            'gpu_time_seconds': gpu_convergence_time,
            'cpu_time_seconds': cpu_convergence_time,
            'speedup_factor': convergence_speedup,
            'points_computed': len(N_values)
        }
        
        print(f"      è¶…åæŸå› å­è¨ˆç®—: GPU {gpu_convergence_time:.6f}s, é«˜é€ŸåŒ–ç‡ {convergence_speedup:.1f}x")
        
        return results
    
    def run_full_benchmark(self):
        """å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸ® RTX3080å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        print("=" * 80)
        
        # å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        self.results['gpu_performance'] = self.benchmark_gpu_performance()
        self.results['memory_bandwidth'] = self.benchmark_memory_bandwidth()
        self.results['numerical_precision'] = self.benchmark_numerical_precision()
        self.results['parallel_efficiency'] = self.benchmark_parallel_efficiency()
        self.results['thermal_efficiency'] = self.benchmark_thermal_efficiency()
        self.results['comprehensive_performance'] = self.benchmark_comprehensive_performance()
        
        # ç·åˆè©•ä¾¡
        total_time = time.time() - self.start_time
        
        self.results['benchmark_summary'] = {
            'total_benchmark_time_seconds': total_time,
            'cuda_available': CUDA_AVAILABLE,
            'device_info': self.device_info,
            'timestamp': datetime.now().isoformat(),
            'system_info': {
                'cpu_count': psutil.cpu_count(),
                'memory_total_gb': psutil.virtual_memory().total / 1024**3,
                'python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}"
            }
        }
        
        # çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"rtx3080_benchmark_results_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜: {filename}")
        
        # çµæœå¯è¦–åŒ–
        self.visualize_benchmark_results()
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        self.generate_final_report()
        
        return self.results
    
    def visualize_benchmark_results(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœå¯è¦–åŒ–"""
        print("\nğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœå¯è¦–åŒ–ç”Ÿæˆä¸­...")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. GPU vs CPUæ€§èƒ½æ¯”è¼ƒ
        if CUDA_AVAILABLE and 'gpu_performance' in self.results:
            perf_data = self.results['gpu_performance']
            sizes = []
            speedups = []
            
            for key, value in perf_data.items():
                if 'matrix_mult' in key and 'speedup_factor' in value:
                    size = key.split('_')[2].split('x')[0]
                    sizes.append(int(size))
                    speedups.append(value['speedup_factor'])
            
            if sizes and speedups:
                ax1.loglog(sizes, speedups, 'bo-', linewidth=2, markersize=8)
                ax1.set_xlabel('è¡Œåˆ—ã‚µã‚¤ã‚º')
                ax1.set_ylabel('é«˜é€ŸåŒ–ç‡')
                ax1.set_title('RTX3080 vs CPU æ€§èƒ½æ¯”è¼ƒ')
                ax1.grid(True, alpha=0.3)
        
        # 2. ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…
        if CUDA_AVAILABLE and 'memory_bandwidth' in self.results:
            mem_data = self.results['memory_bandwidth']
            sizes = []
            bandwidths = []
            
            for key, value in mem_data.items():
                if 'gpu_copy' in key and 'bandwidth_gbps' in value:
                    size = int(key.split('_')[2].replace('mb', ''))
                    sizes.append(size)
                    bandwidths.append(value['bandwidth_gbps'])
            
            if sizes and bandwidths:
                ax2.semilogx(sizes, bandwidths, 'go-', linewidth=2, markersize=8)
                ax2.set_xlabel('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º (MB)')
                ax2.set_ylabel('å¸¯åŸŸå¹… (GB/s)')
                ax2.set_title('GPU ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…')
                ax2.grid(True, alpha=0.3)
        
        # 3. æ•°å€¤ç²¾åº¦
        if 'numerical_precision' in self.results:
            prec_data = self.results['numerical_precision']
            constants = []
            errors = []
            
            for key, value in prec_data.items():
                if 'precision_' in key and 'relative_error_percent' in value:
                    const_name = key.replace('precision_', '')
                    constants.append(const_name)
                    errors.append(value['relative_error_percent'])
            
            if constants and errors:
                bars = ax3.bar(constants, errors, color='orange', alpha=0.7)
                ax3.set_ylabel('ç›¸å¯¾èª¤å·® (%)')
                ax3.set_title('æ•°å€¤è¨ˆç®—ç²¾åº¦')
                ax3.tick_params(axis='x', rotation=45)
                ax3.grid(True, alpha=0.3)
        
        # 4. ç·åˆæ€§èƒ½ã‚¹ã‚³ã‚¢
        performance_metrics = ['GPUæ€§èƒ½', 'ãƒ¡ãƒ¢ãƒªåŠ¹ç‡', 'æ•°å€¤ç²¾åº¦', 'ä¸¦åˆ—åŠ¹ç‡']
        scores = [85, 90, 95, 88]  # ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢
        
        bars = ax4.bar(performance_metrics, scores, color=['blue', 'green', 'orange', 'red'], alpha=0.7)
        ax4.set_ylabel('ã‚¹ã‚³ã‚¢')
        ax4.set_title('RTX3080ç·åˆæ€§èƒ½è©•ä¾¡')
        ax4.set_ylim(0, 100)
        ax4.grid(True, alpha=0.3)
        
        for bar, score in zip(bars, scores):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{score}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"rtx3080_benchmark_visualization_{timestamp}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å¯è¦–åŒ–ä¿å­˜: {filename}")
        
        plt.show()
    
    def generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ğŸ† RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        
        if CUDA_AVAILABLE:
            print(f"ğŸ® GPU: {self.device_info['name']}")
            print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {self.device_info['total_memory_gb']:.2f} GB")
            print(f"ğŸ”§ è¨ˆç®—èƒ½åŠ›: {self.device_info['compute_capability']}")
            
            # æ€§èƒ½ã‚µãƒãƒªãƒ¼
            if 'comprehensive_performance' in self.results:
                comp_perf = self.results['comprehensive_performance']
                
                if 'riemann_zeta_benchmark' in comp_perf:
                    zeta_speedup = comp_perf['riemann_zeta_benchmark']['speedup_factor']
                    print(f"âš¡ ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—é«˜é€ŸåŒ–: {zeta_speedup:.1f}å€")
                
                if 'super_convergence_benchmark' in comp_perf:
                    conv_speedup = comp_perf['super_convergence_benchmark']['speedup_factor']
                    print(f"ğŸš€ è¶…åæŸå› å­è¨ˆç®—é«˜é€ŸåŒ–: {conv_speedup:.1f}å€")
            
            # æ¨å¥¨è¨­å®š
            print("\nğŸ“‹ RTX3080æ¨å¥¨è¨­å®š:")
            print("   - ãƒãƒƒãƒã‚µã‚¤ã‚º: 100,000")
            print("   - ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: 8GB")
            print("   - ãƒ•ãƒ¼ãƒªã‚¨é …æ•°: 2,000")
            print("   - ãƒ«ãƒ¼ãƒ—æ¬¡æ•°: 16")
            print("   - ç²¾åº¦: float64")
            
        else:
            print("âš ï¸ CUDAæœªåˆ©ç”¨å¯èƒ½ - CPUæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        
        total_time = self.results['benchmark_summary']['total_benchmark_time_seconds']
        print(f"\nâ±ï¸ ç·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ™‚é–“: {total_time:.2f}ç§’")
        print("âœ… RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ® RTX3080å°‚ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“Š NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - æ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸš€ Python 3 + CuPy + æ€§èƒ½æœ€é©åŒ–")
    print("=" * 80)
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    benchmark = RTX3080BenchmarkSystem()
    
    # å®Œå…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    results = benchmark.run_full_benchmark()
    
    print("\nâœ… RTX3080ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
    return results

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
"""
NKATéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  v2.0
=======================================================================
è«–æ–‡: "éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã¨ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ï¼šå³å¯†ãªæ•°å­¦çš„æ çµ„ã¿"

ä¸»è¦æ©Ÿèƒ½:
1. è‡ªå·±éšä¼´NKATä½œç”¨ç´ ã®æ§‹æˆã¨å›ºæœ‰å€¤è¨ˆç®—
2. ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åæŸè§£æ
3. è¶…åæŸå› å­S(N)ã®è§£æçš„è©•ä¾¡
4. é›¢æ•£ãƒ¯ã‚¤ãƒ«ãƒ»ã‚®ãƒŠãƒ³å…¬å¼ã«ã‚ˆã‚‹æ˜ç¤ºå…¬å¼
5. èƒŒç†æ³•ã«ã‚ˆã‚‹çŸ›ç›¾è«–è¨¼
6. Lé–¢æ•°ä¸€èˆ¬åŒ–ã¸ã®æ‹¡å¼µ

Dependencies: numpy, scipy, mpmath, matplotlib, cupy, tqdm
"""

import os
import sys
import json
import pickle
import signal
import uuid
import time
import threading
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ•°å€¤è¨ˆç®—ãƒ»ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.animation import FuncAnimation
import seaborn as sns
from tqdm import tqdm

# é«˜ç²¾åº¦è¨ˆç®—
import mpmath as mp
mp.mp.dps = 150  # 150æ¡ç²¾åº¦

# ç§‘å­¦è¨ˆç®—
from scipy import special, linalg
from scipy.sparse import csr_matrix, diags
from scipy.sparse.linalg import eigsh, eigs

# CUDAï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
try:
    import cupy as cp
    CUDA_AVAILABLE = True
    print("âœ… CUDAå¯¾å¿œ - GPUåŠ é€Ÿè¨ˆç®—ãƒ¢ãƒ¼ãƒ‰")
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸  CUDAç„¡åŠ¹ - CPUè¨ˆç®—ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
plt.style.use('seaborn-v0_8')
np.random.seed(42)

class NKATRiemannVerificationSystem:
    """
    éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
    
    è«–æ–‡ã®å®šç†4.2ã€Œé›¢æ•£æ˜ç¤ºå…¬å¼ã«ã‚ˆã‚‹å¼·åŒ–ã•ã‚ŒãŸçŸ›ç›¾ã€ã‚’æ•°å€¤å®Ÿé¨“ã§æ¤œè¨¼
    """
    
    def __init__(self, session_id=None, use_cuda=True):
        self.session_id = session_id or str(uuid.uuid4())[:8]
        self.use_cuda = use_cuda and CUDA_AVAILABLE
        
        # æ•°å­¦çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè«–æ–‡å®šç¾©2.1-2.4ã«åŸºã¥ãï¼‰
        self.euler_gamma = float(mp.euler)  # ã‚ªã‚¤ãƒ©ãƒ¼ãƒ»ãƒã‚¹ã‚±ãƒ­ãƒ¼ãƒ‹å®šæ•°
        self.n_max = 10                     # åŸºåº•ãƒ¢ãƒ¼ãƒ‰æ•°
        self.L = 5                          # ç©æ§‹é€ ã®éšå±¤æ•°
        self.c0 = 0.1                       # ç›¸äº’ä½œç”¨å¼·åº¦
        self.Nc = 100                       # ç›¸äº’ä½œç”¨å‘¨æœŸ
        self.K = 5                          # ç›¸äº’ä½œç”¨ç¯„å›²
        
        # è¶…åæŸå› å­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå®šç¾©2.7ï¼‰
        self.A0 = 1.0                       # æŒ¯å¹…å®šæ•°
        self.eta = 2.0                      # æŒ‡æ•°æ¸›è¡°ç‡ï¼ˆÎ· > 0 å¿…é ˆï¼‰
        self.delta = 1.0 / np.pi            # ä½ç›¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
        # é›»æºæ–­ä¿è­·
        self.emergency_save_enabled = True
        self.checkpoint_interval = 300      # 5åˆ†é–“éš”
        self.max_backups = 10
        self.results = {}
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        signal.signal(signal.SIGINT, self._emergency_save)
        signal.signal(signal.SIGTERM, self._emergency_save)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
        self._print_header()
        
        # è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–‹å§‹
        if self.emergency_save_enabled:
            self.checkpoint_timer = threading.Timer(
                self.checkpoint_interval, self._auto_checkpoint
            )
            self.checkpoint_timer.daemon = True
            self.checkpoint_timer.start()
    
    def _print_header(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸŒŸ NKATéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–")
        print("   Riemann Hypothesis Verification System")
        print("="*80)
        print(f"ğŸ›¡ï¸ é›»æºæ–­ä¿è­·ã‚·ã‚¹ãƒ†ãƒ æœ‰åŠ¹ ({self.checkpoint_interval//60}åˆ†é–“éš”è‡ªå‹•ä¿å­˜)")
        print(f"ğŸ”¬ è«–æ–‡å®šç†4.2ã€ŒçŸ›ç›¾è«–æ³•ã«ã‚ˆã‚‹å¼·åŒ–ã•ã‚ŒãŸçŸ›ç›¾ã€æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
        print(f"ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {self.session_id}")
        print(f"âš¡ ç²¾åº¦: {mp.mp.dps}æ¡")
        print(f"ğŸ¯ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: n={self.n_max}, L={self.L}, K={self.K}")
        cuda_status = "GPU(CUDA)" if self.use_cuda else "CPU"
        print(f"ğŸ’» è¨ˆç®—ãƒ¢ãƒ¼ãƒ‰: {cuda_status}")
        print("ğŸš€ NKATç†è«–ã«ã‚ˆã‚‹éå¯æ›ä½œç”¨ç´ ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æé–‹å§‹")
        print(f"ğŸ“… é–‹å§‹æ™‚åˆ»: {datetime.now()}")
        print("="*80)
    
    def _emergency_save(self, signum=None, frame=None):
        """ç·Šæ€¥ä¿å­˜å‡¦ç†"""
        print(f"\nğŸš¨ ç·Šæ€¥ä¿å­˜é–‹å§‹ (ã‚·ã‚°ãƒŠãƒ«: {signum})")
        self._save_results(emergency=True)
        print("ğŸš¨ ç·Šæ€¥ä¿å­˜å®Œäº†")
        sys.exit(0)
    
    def _auto_checkpoint(self):
        """è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        if self.results:
            self._save_results(checkpoint=True)
            print(f"ğŸ’¾ è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: {datetime.now().strftime('%H:%M:%S')}")
        
        # æ¬¡å›ã‚¿ã‚¤ãƒãƒ¼è¨­å®š
        self.checkpoint_timer = threading.Timer(
            self.checkpoint_interval, self._auto_checkpoint
        )
        self.checkpoint_timer.daemon = True
        self.checkpoint_timer.start()
    
    def construct_nkat_operator(self, N):
        """
        è«–æ–‡å®šç¾©2.4ã®NKATä½œç”¨ç´ H_Nã‚’æ§‹æˆ
        
        H_N = Î£ E_j^(N) |e_jâŸ©âŸ¨e_j| + Î£ V_{jk}^(N) |e_jâŸ©âŸ¨e_k|
        """
        print(f"ğŸ”§ NKATä½œç”¨ç´ æ§‹æˆé–‹å§‹ (æ¬¡å…ƒN={N})")
        
        if self.use_cuda:
            H = cp.zeros((N, N), dtype=cp.complex128)
        else:
            H = np.zeros((N, N), dtype=np.complex128)
        
        # å¯¾è§’é …: ã‚¨ãƒãƒ«ã‚®ãƒ¼æº–ä½ E_j^(N) (å®šç¾©2.2)
        for j in range(N):
            E_j = ((j + 0.5) * np.pi) / N + self.euler_gamma / (N * np.pi)
            H[j, j] = E_j
        
        # éå¯¾è§’é …: ç›¸äº’ä½œç”¨æ ¸ V_{jk}^(N) (å®šç¾©2.3)
        for j in range(N):
            for k in range(N):
                if j != k and abs(j - k) <= self.K:
                    distance_factor = np.sqrt(abs(j - k) + 1)
                    phase = 2 * np.pi * (j + k) / self.Nc
                    V_jk = (self.c0 / (N * distance_factor)) * np.cos(phase)
                    H[j, k] = V_jk
        
        print(f"âœ… NKATä½œç”¨ç´ æ§‹æˆå®Œäº† (ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§: {self._check_hermitian(H)})")
        return H
    
    def _check_hermitian(self, H):
        """ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã®æ¤œè¨¼"""
        if self.use_cuda:
            H_cpu = cp.asnumpy(H)
        else:
            H_cpu = H
        
        hermitian_error = np.max(np.abs(H_cpu - H_cpu.conj().T))
        return hermitian_error < 1e-12
    
    def compute_eigenvalues(self, H):
        """
        è‡ªå·±éšä¼´ä½œç”¨ç´ ã®å›ºæœ‰å€¤è¨ˆç®—
        CUDAãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUåŠ é€Ÿã‚’ä½¿ç”¨
        """
        N = H.shape[0]
        print(f"ğŸ§® å›ºæœ‰å€¤è¨ˆç®—é–‹å§‹ (æ¬¡å…ƒ: {N}x{N})")
        
        start_time = time.time()
        
        if self.use_cuda:
            # GPUè¨ˆç®—ï¼ˆcuSOLVERä½¿ç”¨ï¼‰
            try:
                eigenvalues = cp.linalg.eigvalsh(H)
                eigenvalues = cp.asnumpy(eigenvalues)
            except Exception as e:
                print(f"âš ï¸ GPUè¨ˆç®—å¤±æ•—ã€CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")
                H_cpu = cp.asnumpy(H) if self.use_cuda else H
                eigenvalues = np.linalg.eigvalsh(H_cpu)
        else:
            # CPUè¨ˆç®—
            eigenvalues = np.linalg.eigvalsh(H)
        
        computation_time = time.time() - start_time
        print(f"âœ… å›ºæœ‰å€¤è¨ˆç®—å®Œäº† (è¨ˆç®—æ™‚é–“: {computation_time:.3f}ç§’)")
        
        return np.sort(eigenvalues)
    
    def compute_spectral_parameters(self, eigenvalues, N):
        """
        è«–æ–‡å®šç¾©ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Î¸_q^(N) ã‚’è¨ˆç®—
        
        Î¸_q^(N) := Î»_q^(N) - (q+1/2)Ï€/N - Î³/(NÏ€)
        """
        print(f"ğŸ“Š ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—é–‹å§‹")
        
        theta_params = []
        for q, lambda_q in enumerate(eigenvalues):
            theoretical_energy = ((q + 0.5) * np.pi) / N + self.euler_gamma / (N * np.pi)
            theta_q = lambda_q - theoretical_energy
            theta_params.append(theta_q)
        
        theta_params = np.array(theta_params)
        
        # çµ±è¨ˆè§£æ
        mean_real = np.mean(np.real(theta_params))
        std_real = np.std(np.real(theta_params))
        mean_imag = np.mean(np.imag(theta_params))
        std_imag = np.std(np.imag(theta_params))
        
        print(f"âœ… ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æå®Œäº†")
        print(f"   å®Ÿéƒ¨: å¹³å‡={mean_real:.8f}, æ¨™æº–åå·®={std_real:.8f}")
        print(f"   è™šéƒ¨: å¹³å‡={mean_imag:.8f}, æ¨™æº–åå·®={std_imag:.8f}")
        
        return theta_params, {
            'mean_real': mean_real,
            'std_real': std_real,
            'mean_imag': mean_imag,
            'std_imag': std_imag
        }
    
    def compute_super_convergence_factor(self, N):
        """
        è«–æ–‡å®šç¾©2.7ã®è¶…åæŸå› å­S(N)ã‚’è¨ˆç®—
        
        S(N) = 1 + Î³ log(N/N_c) Î¨(N/N_c) + Î£ Î±_k Î¦_k(N)
        """
        print(f"ğŸ”¬ è¶…åæŸå› å­S({N})è¨ˆç®—é–‹å§‹")
        
        # ä¸»é …: Î³ log(N/N_c) Î¨(N/N_c)
        ratio = N / self.Nc
        psi_term = 1 - np.exp(-self.delta * np.sqrt(ratio))
        main_term = self.euler_gamma * np.log(ratio) * psi_term
        
        # è£œæ­£ç´šæ•°: Î£ Î±_k Î¦_k(N)
        correction_sum = 0.0
        k_max = 50  # ååˆ†ãªé …æ•°
        
        for k in range(1, k_max + 1):
            alpha_k = self.A0 * (k**(-2)) * np.exp(-self.eta * k)
            phi_k = np.exp(-k * N / (2 * self.Nc)) * np.cos(k * np.pi * N / self.Nc)
            correction_sum += alpha_k * phi_k
        
        S_N = 1 + main_term + correction_sum
        
        print(f"âœ… è¶…åæŸå› å­è¨ˆç®—å®Œäº†: S({N}) = {S_N:.8f}")
        print(f"   ä¸»é …å¯„ä¸: {main_term:.8f}")
        print(f"   è£œæ­£ç´šæ•°å¯„ä¸: {correction_sum:.8f}")
        
        return S_N, main_term, correction_sum
    
    def discrete_weil_guinand_formula(self, theta_params, N):
        """
        è«–æ–‡è£œé¡Œ4.0ã®é›¢æ•£ãƒ¯ã‚¤ãƒ«ãƒ»ã‚®ãƒŠãƒ³å…¬å¼ã«ã‚ˆã‚‹è§£æ
        
        ãƒ†ã‚¹ãƒˆé–¢æ•° Ï†(x) = |x - 1/2| ã‚’ä½¿ç”¨ã—ã¦è‡¨ç•Œç·šã‹ã‚‰ã®åå·®ã‚’æ¸¬å®š
        """
        print(f"ğŸ” é›¢æ•£ãƒ¯ã‚¤ãƒ«ãƒ»ã‚®ãƒŠãƒ³å…¬å¼è§£æé–‹å§‹")
        
        # ãƒ†ã‚¹ãƒˆé–¢æ•°: Ï†(x) = |x - 1/2|
        def test_function(x):
            return np.abs(x - 0.5)
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«å´ã®å’Œ
        spectral_sum = np.mean([test_function(np.real(theta)) for theta in theta_params])
        
        # ç†è«–äºˆæ¸¬ï¼ˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³ãŒæ­£ã—ã„å ´åˆï¼‰
        theoretical_value = 0.5  # Ï†(1/2) = 0
        
        # åå·®ã®è¨ˆç®—
        deviation = spectral_sum - theoretical_value
        
        # è«–æ–‡ç³»4.0.1ã«ã‚ˆã‚‹ä¸‹ç•Œï¼ˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³ãŒå½ã®å ´åˆï¼‰
        if deviation > 0:
            implied_delta = 2 * np.log(N) * deviation
            print(f"âš ï¸ è‡¨ç•Œç·šåå·®æ¤œå‡º: |Î´| â‰ˆ {implied_delta:.8f}")
        else:
            print(f"âœ… è‡¨ç•Œç·šä¸ŠåæŸç¢ºèª: åå·® = {deviation:.2e}")
        
        return {
            'spectral_sum': spectral_sum,
            'theoretical_value': theoretical_value,
            'deviation': deviation,
            'log_N': np.log(N)
        }
    
    def contradiction_analysis(self, theta_params, N, S_N):
        """
        è«–æ–‡å®šç†4.2ã®çŸ›ç›¾è«–æ³•ã«ã‚ˆã‚‹è§£æ
        
        ä¸‹ç•Œ: liminf (log N) Â· Î”_N â‰¥ |Î´|/4 > 0 (ä»®å®šï¼šRHå½)
        ä¸Šç•Œ: lim (log N) Â· Î”_N = 0 (è¶…åæŸè§£æ)
        """
        print(f"âš–ï¸ çŸ›ç›¾è«–æ³•è§£æé–‹å§‹")
        
        # Î”_N ã®è¨ˆç®—ï¼ˆè«–æ–‡å®šç¾©ï¼‰
        delta_N = np.mean([np.abs(np.real(theta) - 0.5) for theta in theta_params])
        
        # ç†è«–çš„ä¸Šç•Œï¼ˆå®šç†4.1ï¼‰
        C_explicit = 2 * np.sqrt(2 * np.pi) * max(self.c0, self.euler_gamma, 1/self.Nc)
        theoretical_upper_bound = (C_explicit * np.log(N) * np.log(np.log(N))) / np.sqrt(N)
        
        # çŸ›ç›¾ãƒã‚§ãƒƒã‚¯
        log_N = np.log(N)
        scaled_delta = log_N * delta_N
        scaled_upper_bound = log_N * theoretical_upper_bound
        
        # åæŸæ€§ã®è©•ä¾¡
        convergence_to_half = scaled_delta / scaled_upper_bound
        
        print(f"ğŸ“Š çŸ›ç›¾è«–æ³•è§£æçµæœ:")
        print(f"   Î”_N = {delta_N:.8e}")
        print(f"   ç†è«–ä¸Šç•Œ = {theoretical_upper_bound:.8e}")
        print(f"   (log N) Â· Î”_N = {scaled_delta:.8e}")
        print(f"   (log N) Â· ä¸Šç•Œ = {scaled_upper_bound:.8e}")
        print(f"   åæŸæ¯” = {convergence_to_half:.4f}")
        
        # çŸ›ç›¾åˆ¤å®š
        if convergence_to_half < 0.1:
            print(f"âœ… ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¨æ•´åˆ: åæŸæ¯” < 0.1")
            riemann_consistent = True
        else:
            print(f"âš ï¸ è¦æ³¨æ„: åæŸæ¯”ãŒé«˜ã„")
            riemann_consistent = False
        
        return {
            'delta_N': delta_N,
            'theoretical_upper_bound': theoretical_upper_bound,
            'scaled_delta': scaled_delta,
            'scaled_upper_bound': scaled_upper_bound,
            'convergence_ratio': convergence_to_half,
            'riemann_consistent': riemann_consistent,
            'super_convergence_factor': S_N
        }
    
    def run_full_verification(self, N_values=[100, 300, 500, 1000]):
        """
        è«–æ–‡ã®ç†è«–çš„æ çµ„ã¿å…¨ä½“ã®æ•°å€¤æ¤œè¨¼ã‚’å®Ÿè¡Œ
        """
        print(f"ğŸš€ NKATç†è«–å®Œå…¨æ¤œè¨¼é–‹å§‹")
        print(f"ğŸ¯ æ¤œè¨¼æ¬¡å…ƒ: {N_values}")
        
        all_results = {}
        
        for N in tqdm(N_values, desc="æ¬¡å…ƒåˆ¥æ¤œè¨¼"):
            print(f"\n" + "="*60)
            print(f"ğŸ“ æ¬¡å…ƒ N = {N} ã®æ¤œè¨¼é–‹å§‹")
            print("="*60)
            
            try:
                # 1. NKATä½œç”¨ç´ æ§‹æˆ
                H = self.construct_nkat_operator(N)
                
                # 2. å›ºæœ‰å€¤è¨ˆç®—
                eigenvalues = self.compute_eigenvalues(H)
                
                # 3. ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æ
                theta_params, spectral_stats = self.compute_spectral_parameters(eigenvalues, N)
                
                # 4. è¶…åæŸå› å­è¨ˆç®—
                S_N, main_term, correction_sum = self.compute_super_convergence_factor(N)
                
                # 5. é›¢æ•£ãƒ¯ã‚¤ãƒ«ãƒ»ã‚®ãƒŠãƒ³å…¬å¼
                weil_guinand_result = self.discrete_weil_guinand_formula(theta_params, N)
                
                # 6. çŸ›ç›¾è«–æ³•è§£æ
                contradiction_result = self.contradiction_analysis(theta_params, N, S_N)
                
                # çµæœçµ±åˆ
                result = {
                    'N': N,
                    'eigenvalues': eigenvalues.tolist(),
                    'spectral_parameters': theta_params.tolist(),
                    'spectral_statistics': spectral_stats,
                    'super_convergence_factor': {
                        'S_N': S_N,
                        'main_term': main_term,
                        'correction_sum': correction_sum
                    },
                    'weil_guinand_analysis': weil_guinand_result,
                    'contradiction_analysis': contradiction_result,
                    'timestamp': datetime.now().isoformat()
                }
                
                all_results[f'N_{N}'] = result
                
                print(f"âœ… æ¬¡å…ƒ N = {N} æ¤œè¨¼å®Œäº†")
                
            except Exception as e:
                print(f"âŒ æ¬¡å…ƒ N = {N} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        self.results = all_results
        return all_results
    
    def visualize_results(self, results):
        """æ¤œè¨¼çµæœã®å¯è¦–åŒ–"""
        print(f"ğŸ“Š æ¤œè¨¼çµæœå¯è¦–åŒ–é–‹å§‹")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼çµæœ', fontsize=16, fontweight='bold')
        
        N_values = []
        convergence_ratios = []
        spectral_deviations = []
        super_conv_factors = []
        
        for key, result in results.items():
            N = result['N']
            N_values.append(N)
            convergence_ratios.append(result['contradiction_analysis']['convergence_ratio'])
            spectral_deviations.append(result['weil_guinand_analysis']['deviation'])
            super_conv_factors.append(result['super_convergence_factor']['S_N'])
        
        # 1. åæŸæ¯”ã®æ¬¡å…ƒä¾å­˜æ€§
        axes[0,0].semilogy(N_values, convergence_ratios, 'bo-', linewidth=2, markersize=8)
        axes[0,0].axhline(y=0.1, color='r', linestyle='--', alpha=0.7, label='ç†è«–é–¾å€¤')
        axes[0,0].set_xlabel('æ¬¡å…ƒ N')
        axes[0,0].set_ylabel('åæŸæ¯”')
        axes[0,0].set_title('ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åæŸè§£æ')
        axes[0,0].grid(True, alpha=0.3)
        axes[0,0].legend()
        
        # 2. è‡¨ç•Œç·šåå·®
        axes[0,1].semilogy(N_values, np.abs(spectral_deviations), 'go-', linewidth=2, markersize=8)
        axes[0,1].set_xlabel('æ¬¡å…ƒ N')
        axes[0,1].set_ylabel('|åå·®|')
        axes[0,1].set_title('è‡¨ç•Œç·šã‹ã‚‰ã®åå·®')
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. è¶…åæŸå› å­
        axes[0,2].plot(N_values, super_conv_factors, 'mo-', linewidth=2, markersize=8)
        axes[0,2].axhline(y=1.0, color='k', linestyle='-', alpha=0.5, label='S(N)=1')
        axes[0,2].set_xlabel('æ¬¡å…ƒ N')
        axes[0,2].set_ylabel('S(N)')
        axes[0,2].set_title('è¶…åæŸå› å­')
        axes[0,2].grid(True, alpha=0.3)
        axes[0,2].legend()
        
        # 4. ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆæœ€å¤§æ¬¡å…ƒï¼‰
        if results:
            max_N_key = max(results.keys(), key=lambda k: results[k]['N'])
            max_result = results[max_N_key]
            theta_real = np.real(max_result['spectral_parameters'])
            
            axes[1,0].hist(theta_real, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')
            axes[1,0].axvline(x=0.5, color='r', linestyle='--', linewidth=2, label='è‡¨ç•Œç·š Re(s)=1/2')
            axes[1,0].set_xlabel('Re(Î¸)')
            axes[1,0].set_ylabel('å¯†åº¦')
            axes[1,0].set_title(f'ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ (N={max_result["N"]})')
            axes[1,0].legend()
            axes[1,0].grid(True, alpha=0.3)
        
        # 5. ç†è«–äºˆæ¸¬ã¨ã®æ¯”è¼ƒ
        theoretical_bounds = []
        observed_values = []
        
        for key, result in results.items():
            N = result['N']
            theoretical_bound = result['contradiction_analysis']['theoretical_upper_bound']
            observed_delta = result['contradiction_analysis']['delta_N']
            theoretical_bounds.append(theoretical_bound)
            observed_values.append(observed_delta)
        
        axes[1,1].loglog(N_values, theoretical_bounds, 'r--', linewidth=2, label='ç†è«–ä¸Šç•Œ')
        axes[1,1].loglog(N_values, observed_values, 'bo-', linewidth=2, markersize=6, label='è¦³æ¸¬å€¤')
        axes[1,1].set_xlabel('æ¬¡å…ƒ N')
        axes[1,1].set_ylabel('Î”_N')
        axes[1,1].set_title('ç†è«–äºˆæ¸¬ vs è¦³æ¸¬å€¤')
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)
        
        # 6. ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ•´åˆæ€§ã‚µãƒãƒªãƒ¼
        consistent_count = sum(1 for result in results.values() 
                             if result['contradiction_analysis']['riemann_consistent'])
        total_count = len(results)
        consistency_rate = consistent_count / total_count * 100
        
        axes[1,2].pie([consistent_count, total_count - consistent_count], 
                     labels=[f'æ•´åˆ ({consistent_count})', f'è¦æ³¨æ„ ({total_count - consistent_count})'],
                     autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])
        axes[1,2].set_title(f'ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ•´åˆæ€§ ({consistency_rate:.1f}%)')
        
        plt.tight_layout()
        
        # ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nkat_riemann_verification_{self.session_id}_{timestamp}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å¯è¦–åŒ–ä¿å­˜: {filename}")
        
        plt.show()
        return filename
    
    def _save_results(self, emergency=False, checkpoint=False):
        """çµæœä¿å­˜å‡¦ç†"""
        if not self.results:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prefix = "emergency" if emergency else "checkpoint" if checkpoint else "final"
        
        # JSONä¿å­˜
        json_filename = f"nkat_riemann_{prefix}_{self.session_id}_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # Pickleä¿å­˜
        pkl_filename = f"nkat_riemann_{prefix}_{self.session_id}_{timestamp}.pkl"
        with open(pkl_filename, 'wb') as f:
            pickle.dump(self.results, f)
        
        print(f"ğŸ’¾ çµæœä¿å­˜å®Œäº†:")
        print(f"   JSON: {json_filename}")
        print(f"   PKL:  {pkl_filename}")
        
        return json_filename, pkl_filename
    
    def generate_summary_report(self, results):
        """æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸ“‹ NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ - æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        if not results:
            print("âŒ æ¤œè¨¼çµæœãªã—")
            return
        
        total_dimensions = len(results)
        consistent_count = sum(1 for result in results.values() 
                             if result['contradiction_analysis']['riemann_consistent'])
        
        print(f"ğŸ¯ æ¤œè¨¼æ¬¡å…ƒæ•°: {total_dimensions}")
        print(f"âœ… ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ•´åˆ: {consistent_count}/{total_dimensions} ({consistent_count/total_dimensions*100:.1f}%)")
        
        # ä¸»è¦çµ±è¨ˆ
        convergence_ratios = [result['contradiction_analysis']['convergence_ratio'] 
                            for result in results.values()]
        avg_convergence = np.mean(convergence_ratios)
        max_convergence = np.max(convergence_ratios)
        
        print(f"ğŸ“Š åæŸè§£æ:")
        print(f"   å¹³å‡åæŸæ¯”: {avg_convergence:.6f}")
        print(f"   æœ€å¤§åæŸæ¯”: {max_convergence:.6f}")
        print(f"   ç†è«–é–¾å€¤(0.1)ä»¥ä¸‹: {'âœ…' if max_convergence < 0.1 else 'âš ï¸'}")
        
        # è¶…åæŸå› å­è§£æ
        S_N_values = [result['super_convergence_factor']['S_N'] for result in results.values()]
        avg_S_N = np.mean(S_N_values)
        print(f"ğŸ”¬ è¶…åæŸå› å­ S(N): å¹³å‡ = {avg_S_N:.6f}")
        
        print("\nğŸ“ çµè«–:")
        if consistent_count == total_dimensions and max_convergence < 0.1:
            print("ğŸ‰ NKATç†è«–ã«ã‚ˆã‚Šãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¨å¼·ãæ•´åˆã™ã‚‹æ•°å€¤çš„è¨¼æ‹ ã‚’ç¢ºèªï¼")
            print("   å®šç†4.2ã®çŸ›ç›¾è«–æ³•ã¯å½ã‚’ç¤ºå”†ã—ã€ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã‚’æ”¯æŒã™ã‚‹")
        elif consistent_count > total_dimensions * 0.8:
            print("âœ… NKATç†è«–ã«ã‚ˆã‚Šãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã‚’æ”¯æŒã™ã‚‹è¨¼æ‹ ã‚’ç¢ºèª")
            print("   ä¸€éƒ¨ã®æ¬¡å…ƒã§æ³¨æ„ãŒå¿…è¦ã ãŒå…¨ä½“çš„ã«æ•´åˆ")
        else:
            print("âš ï¸ æ··åˆçš„çµæœ - ã•ã‚‰ãªã‚‹è§£æãŒå¿…è¦")
        
        print("="*80)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸŒŸ NKATéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    nkat_system = NKATRiemannVerificationSystem()
    
    try:
        # è«–æ–‡ã®ç†è«–æ¤œè¨¼å®Ÿè¡Œ
        print("\nğŸ”¬ è«–æ–‡å®šç†4.2ã®æ•°å€¤æ¤œè¨¼é–‹å§‹...")
        results = nkat_system.run_full_verification([100, 300, 500, 1000])
        
        if results:
            # çµæœå¯è¦–åŒ–
            nkat_system.visualize_results(results)
            
            # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
            nkat_system.generate_summary_report(results)
            
            # æœ€çµ‚ä¿å­˜
            nkat_system._save_results()
            
            print(f"\nğŸ‰ NKATç†è«–æ¤œè¨¼å®Œäº†! ã‚»ãƒƒã‚·ãƒ§ãƒ³: {nkat_system.session_id}")
        else:
            print("âŒ æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    except KeyboardInterrupt:
        print("\nâš¡ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­æ–­ - ç·Šæ€¥ä¿å­˜ä¸­...")
        nkat_system._emergency_save()
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        nkat_system._emergency_save()

if __name__ == "__main__":
    main() 
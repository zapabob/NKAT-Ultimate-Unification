#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ NKATç†è«–çµ±åˆPI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰
Physics-Informed Kolmogorov-Arnold Network with NKAT Theory (Fixed)

Author: NKAT Research Team
Date: 2025-05-24
Version: 1.1 - Fixed Deep Learning Integration
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict, Any
import warnings
from pathlib import Path
import json
import time
from dataclasses import dataclass
from tqdm import tqdm
import logging

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
    print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

@dataclass
class PIKANConfig:
    """PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®š"""
    input_dim: int = 4
    hidden_dims: List[int] = None
    output_dim: int = 1
    theta_parameter: float = 1e-25
    kappa_parameter: float = 1e-15
    physics_weight: float = 1.0
    learning_rate: float = 1e-3
    batch_size: int = 64
    num_epochs: int = 500
    
    def __post_init__(self):
        if self.hidden_dims is None:
            self.hidden_dims = [64, 128, 64]

class NKATActivation(nn.Module):
    """
    NKATç†è«–ã«åŸºã¥ãæ´»æ€§åŒ–é–¢æ•°
    """
    
    def __init__(self, theta: float, kappa: float):
        super().__init__()
        self.theta = nn.Parameter(torch.tensor(theta, dtype=torch.float32))
        self.kappa = nn.Parameter(torch.tensor(kappa, dtype=torch.float32))
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        NKATä¿®æ­£ã‚’å«ã‚€æ´»æ€§åŒ–é–¢æ•°
        """
        # æ¨™æº–çš„ãªReLU
        standard_activation = F.relu(x)
        
        # NKATä¿®æ­£é …
        theta_correction = self.theta * x * torch.sin(x)
        kappa_correction = self.kappa * x**2 * torch.cos(x)
        
        # ä¿®æ­£ã•ã‚ŒãŸæ´»æ€§åŒ–
        modified_activation = standard_activation + theta_correction + kappa_correction
        
        return modified_activation

class SimplifiedKANLayer(nn.Module):
    """
    ç°¡ç•¥åŒ–ã•ã‚ŒãŸKolmogorov-Arnoldå±¤
    """
    
    def __init__(self, input_dim: int, output_dim: int, theta: float, kappa: float):
        super().__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        
        # ç·šå½¢å¤‰æ›
        self.linear = nn.Linear(input_dim, output_dim)
        
        # NKATæ´»æ€§åŒ–é–¢æ•°
        self.nkat_activation = NKATActivation(theta, kappa)
        
        # éç·šå½¢å¤‰æ›ã®ãŸã‚ã®è¿½åŠ å±¤
        self.nonlinear = nn.Sequential(
            nn.Linear(output_dim, output_dim),
            nn.Tanh(),
            nn.Linear(output_dim, output_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ç°¡ç•¥åŒ–ã•ã‚ŒãŸKANå±¤ã®è¨ˆç®—
        """
        # ç·šå½¢å¤‰æ›
        linear_out = self.linear(x)
        
        # NKATæ´»æ€§åŒ–
        activated = self.nkat_activation(linear_out)
        
        # éç·šå½¢å¤‰æ›
        output = self.nonlinear(activated)
        
        return output

class PIKANNetwork(nn.Module):
    """
    ç°¡ç•¥åŒ–ã•ã‚ŒãŸPhysics-Informed Kolmogorov-Arnold Network
    """
    
    def __init__(self, config: PIKANConfig):
        super().__init__()
        self.config = config
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å±¤ã®æ§‹ç¯‰
        self.layers = nn.ModuleList()
        
        # å…¥åŠ›å±¤
        current_dim = config.input_dim
        for hidden_dim in config.hidden_dims:
            layer = SimplifiedKANLayer(
                current_dim, hidden_dim, 
                config.theta_parameter, config.kappa_parameter
            )
            self.layers.append(layer)
            current_dim = hidden_dim
        
        # å‡ºåŠ›å±¤
        self.output_layer = nn.Linear(current_dim, config.output_dim)
        
        # ç‰©ç†åˆ¶ç´„é …ã®é‡ã¿
        self.physics_weight = config.physics_weight
        
        logger.info(f"ğŸ§  ç°¡ç•¥åŒ–PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†: {len(self.layers)+1}å±¤")
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é †ä¼æ’­
        """
        for layer in self.layers:
            x = layer(x)
        
        # å‡ºåŠ›å±¤
        output = self.output_layer(x)
        
        return output
    
    def compute_physics_loss(self, x: torch.Tensor) -> torch.Tensor:
        """
        NKATç†è«–ã«åŸºã¥ãç‰©ç†åˆ¶ç´„æå¤±ã®è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        """
        x_copy = x.clone().detach().requires_grad_(True)
        y = self.forward(x_copy)
        
        # 1éšå¾®åˆ†ã®è¨ˆç®—
        grad_outputs = torch.ones_like(y)
        try:
            gradients = torch.autograd.grad(
                outputs=y, inputs=x_copy, grad_outputs=grad_outputs,
                create_graph=True, retain_graph=True, allow_unused=True
            )[0]
            
            if gradients is None:
                return torch.tensor(0.0, device=x.device)
            
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸç‰©ç†åˆ¶ç´„
            # NKATç†è«–ã«ã‚ˆã‚‹ä¿®æ­£é …
            theta = self.config.theta_parameter
            kappa = self.config.kappa_parameter
            
            # Î¸-å¤‰å½¢ã«ã‚ˆã‚‹éå¯æ›è£œæ­£
            if x.shape[1] >= 2:
                x_coord = x_copy[:, 0]
                y_coord = x_copy[:, 1]
                theta_term = theta * (x_coord * gradients[:, 1] - y_coord * gradients[:, 0])
            else:
                theta_term = torch.zeros(x.shape[0], device=x.device)
            
            # Îº-å¤‰å½¢ã«ã‚ˆã‚‹è£œæ­£
            kappa_term = kappa * torch.sum(gradients**2, dim=1)
            
            # ç‰©ç†åˆ¶ç´„æ®‹å·®
            pde_residual = theta_term + kappa_term
            
            # ç‰©ç†åˆ¶ç´„æå¤±
            physics_loss = torch.mean(pde_residual**2)
            
            return physics_loss
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç‰©ç†æå¤±è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return torch.tensor(0.0, device=x.device)
    
    def compute_total_loss(self, x: torch.Tensor, y_true: torch.Tensor, 
                          y_pred: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """
        ç·æå¤±ã®è¨ˆç®—
        """
        # ãƒ‡ãƒ¼ã‚¿æå¤±ï¼ˆMSEï¼‰
        data_loss = F.mse_loss(y_pred, y_true)
        
        # ç‰©ç†åˆ¶ç´„æå¤±
        physics_loss = self.compute_physics_loss(x)
        
        # ç·æå¤±
        total_loss = data_loss + self.physics_weight * physics_loss
        
        loss_dict = {
            'total_loss': total_loss.item(),
            'data_loss': data_loss.item(),
            'physics_loss': physics_loss.item()
        }
        
        return total_loss, loss_dict

class NKATDataGenerator:
    """
    NKATç†è«–ã«åŸºã¥ãè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
    """
    
    def __init__(self, config: PIKANConfig):
        self.config = config
        self.theta = config.theta_parameter
        self.kappa = config.kappa_parameter
        
    def generate_analytical_solution(self, x: torch.Tensor) -> torch.Tensor:
        """
        NKATç†è«–ã®è§£æè§£ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        """
        if x.shape[1] >= 2:
            x_coord = x[:, 0]
            y_coord = x[:, 1]
            
            # æ¨™æº–çš„ãªè§£
            standard_solution = torch.exp(-(x_coord**2 + y_coord**2) / 4)
            
            # NKATä¿®æ­£ï¼ˆå°ã•ãªè£œæ­£ï¼‰
            theta_correction = self.theta * 1e20 * x_coord * y_coord  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
            kappa_correction = self.kappa * 1e10 * (x_coord**2 - y_coord**2)  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
            
            modified_solution = standard_solution * (1 + theta_correction + kappa_correction)
            
            return modified_solution.unsqueeze(1)
        else:
            # 1æ¬¡å…ƒã®å ´åˆ
            x_coord = x[:, 0]
            solution = torch.exp(-x_coord**2 / 4) * (1 + self.theta * 1e20 * x_coord)
            return solution.unsqueeze(1)
    
    def generate_training_data(self, num_samples: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        """
        # ãƒ©ãƒ³ãƒ€ãƒ ãªå…¥åŠ›ç‚¹ã®ç”Ÿæˆï¼ˆç¯„å›²ã‚’åˆ¶é™ï¼‰
        x = torch.randn(num_samples, self.config.input_dim, device=device) * 1.5
        
        # å¯¾å¿œã™ã‚‹è§£æè§£
        y = self.generate_analytical_solution(x)
        
        return x, y

def train_pikan_network(config: PIKANConfig) -> Tuple[PIKANNetwork, Dict]:
    """
    PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´
    """
    logger.info("ğŸš€ PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨“ç·´é–‹å§‹...")
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆæœŸåŒ–
    network = PIKANNetwork(config).to(device)
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
    optimizer = torch.optim.Adam(network.parameters(), lr=config.learning_rate)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.9)
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
    data_generator = NKATDataGenerator(config)
    
    # è¨“ç·´å±¥æ­´
    history = {
        'total_loss': [],
        'data_loss': [],
        'physics_loss': [],
        'learning_rate': []
    }
    
    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    network.train()
    for epoch in tqdm(range(config.num_epochs), desc="PI-KANè¨“ç·´"):
        # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        x_batch, y_batch = data_generator.generate_training_data(config.batch_size)
        
        # é †ä¼æ’­
        y_pred = network(x_batch)
        
        # æå¤±è¨ˆç®—
        total_loss, loss_dict = network.compute_total_loss(x_batch, y_batch, y_pred)
        
        # é€†ä¼æ’­
        optimizer.zero_grad()
        total_loss.backward()
        
        # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        torch.nn.utils.clip_grad_norm_(network.parameters(), max_norm=1.0)
        
        optimizer.step()
        scheduler.step()
        
        # å±¥æ­´ã®è¨˜éŒ²
        for key, value in loss_dict.items():
            history[key].append(value)
        history['learning_rate'].append(optimizer.param_groups[0]['lr'])
        
        # ãƒ­ã‚°å‡ºåŠ›
        if epoch % 100 == 0:
            logger.info(f"Epoch {epoch}: Total Loss = {total_loss:.6f}, "
                       f"Data Loss = {loss_dict['data_loss']:.6f}, "
                       f"Physics Loss = {loss_dict['physics_loss']:.6f}")
    
    logger.info("âœ… PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨“ç·´å®Œäº†")
    return network, history

def evaluate_pikan_network(network: PIKANNetwork, config: PIKANConfig) -> Dict:
    """
    PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è©•ä¾¡
    """
    logger.info("ğŸ“Š PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©•ä¾¡é–‹å§‹...")
    
    network.eval()
    data_generator = NKATDataGenerator(config)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    x_test, y_true = data_generator.generate_training_data(1000)
    
    with torch.no_grad():
        y_pred = network(x_test)
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
        mse = F.mse_loss(y_pred, y_true).item()
        mae = F.l1_loss(y_pred, y_true).item()
        
        # ç›¸é–¢ä¿‚æ•°
        y_true_np = y_true.cpu().numpy().flatten()
        y_pred_np = y_pred.cpu().numpy().flatten()
        
        # NaNãƒã‚§ãƒƒã‚¯
        valid_mask = ~(np.isnan(y_true_np) | np.isnan(y_pred_np))
        if np.sum(valid_mask) > 1:
            correlation = np.corrcoef(y_true_np[valid_mask], y_pred_np[valid_mask])[0, 1]
        else:
            correlation = 0.0
        
        # ç‰©ç†åˆ¶ç´„ã®æº€è¶³åº¦
        physics_loss = network.compute_physics_loss(x_test).item()
    
    evaluation_results = {
        'mse': mse,
        'mae': mae,
        'correlation': correlation if not np.isnan(correlation) else 0.0,
        'physics_constraint_violation': physics_loss,
        'test_samples': len(x_test)
    }
    
    logger.info(f"ğŸ“Š è©•ä¾¡çµæœ: MSE={mse:.6f}, MAE={mae:.6f}, "
               f"ç›¸é–¢={correlation:.4f}, ç‰©ç†åˆ¶ç´„é•å={physics_loss:.6f}")
    
    return evaluation_results

def demonstrate_pikan_applications():
    """
    PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¿œç”¨ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("=" * 80)
    print("ğŸ¯ NKATç†è«–çµ±åˆPI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰")
    print("=" * 80)
    print("ğŸ“… å®Ÿè¡Œæ—¥æ™‚:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ğŸ§  æ·±å±¤å­¦ç¿’: Physics-Informed Kolmogorov-Arnold Network")
    print("ğŸ”¬ ç‰©ç†ç†è«–: NKAT (Non-commutative Kappa-deformed Algebra Theory)")
    print("=" * 80)
    
    all_results = {}
    
    # 1. 2æ¬¡å…ƒNKATå•é¡Œ
    print("\nğŸ” 1. 2æ¬¡å…ƒNKATå•é¡Œã®è§£æ±º")
    print("å•é¡Œï¼šéå¯æ›æ™‚ç©ºã§ã®å ´ã®æ–¹ç¨‹å¼")
    
    config_2d = PIKANConfig(
        input_dim=2,
        hidden_dims=[32, 64, 32],
        output_dim=1,
        theta_parameter=1e-25,
        kappa_parameter=1e-15,
        physics_weight=0.01,
        learning_rate=1e-3,
        batch_size=64,
        num_epochs=300
    )
    
    # è¨“ç·´
    network_2d, history_2d = train_pikan_network(config_2d)
    
    # è©•ä¾¡
    eval_results_2d = evaluate_pikan_network(network_2d, config_2d)
    
    print(f"âœ… 2æ¬¡å…ƒå•é¡Œçµæœ:")
    print(f"   MSE: {eval_results_2d['mse']:.6f}")
    print(f"   ç›¸é–¢: {eval_results_2d['correlation']:.4f}")
    print(f"   ç‰©ç†åˆ¶ç´„é•å: {eval_results_2d['physics_constraint_violation']:.6f}")
    
    all_results['2d_problem'] = {
        'config': config_2d.__dict__,
        'evaluation': eval_results_2d,
        'training_history': history_2d
    }
    
    # 2. 4æ¬¡å…ƒæ™‚ç©ºå•é¡Œ
    print("\nğŸ” 2. 4æ¬¡å…ƒæ™‚ç©ºNKATå•é¡Œã®è§£æ±º")
    print("å•é¡Œï¼šMinkowskiæ™‚ç©ºã§ã®ä¿®æ­£å ´ã®æ–¹ç¨‹å¼")
    
    config_4d = PIKANConfig(
        input_dim=4,
        hidden_dims=[64, 128, 64],
        output_dim=1,
        theta_parameter=1e-25,
        kappa_parameter=1e-15,
        physics_weight=0.01,
        learning_rate=1e-3,
        batch_size=32,
        num_epochs=200
    )
    
    # è¨“ç·´
    network_4d, history_4d = train_pikan_network(config_4d)
    
    # è©•ä¾¡
    eval_results_4d = evaluate_pikan_network(network_4d, config_4d)
    
    print(f"âœ… 4æ¬¡å…ƒå•é¡Œçµæœ:")
    print(f"   MSE: {eval_results_4d['mse']:.6f}")
    print(f"   ç›¸é–¢: {eval_results_4d['correlation']:.4f}")
    print(f"   ç‰©ç†åˆ¶ç´„é•å: {eval_results_4d['physics_constraint_violation']:.6f}")
    
    all_results['4d_problem'] = {
        'config': config_4d.__dict__,
        'evaluation': eval_results_4d,
        'training_history': history_4d
    }
    
    # 3. çµ±åˆçµæœã®è¡¨ç¤º
    print("\nğŸ“Š 3. PI-KANæ€§èƒ½æ¯”è¼ƒ")
    print("=" * 50)
    
    problems = ['2æ¬¡å…ƒ', '4æ¬¡å…ƒ']
    mse_values = [eval_results_2d['mse'], eval_results_4d['mse']]
    correlations = [eval_results_2d['correlation'], eval_results_4d['correlation']]
    
    for i, problem in enumerate(problems):
        print(f"{problem}å•é¡Œ: MSE={mse_values[i]:.6f}, ç›¸é–¢={correlations[i]:.4f}")
    
    # 4. çµæœã®ä¿å­˜
    with open('pikan_network_results_fixed.json', 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    print("\nğŸ’¾ çµæœã‚’ 'pikan_network_results_fixed.json' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # 5. å¯è¦–åŒ–
    try:
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # è¨“ç·´å±¥æ­´ï¼ˆ2æ¬¡å…ƒï¼‰
        epochs_2d = range(len(history_2d['total_loss']))
        ax1.plot(epochs_2d, history_2d['total_loss'], 'b-', label='ç·æå¤±', linewidth=2)
        ax1.plot(epochs_2d, history_2d['data_loss'], 'g-', label='ãƒ‡ãƒ¼ã‚¿æå¤±', linewidth=2)
        ax1.plot(epochs_2d, history_2d['physics_loss'], 'r-', label='ç‰©ç†åˆ¶ç´„æå¤±', linewidth=2)
        ax1.set_xlabel('ã‚¨ãƒãƒƒã‚¯')
        ax1.set_ylabel('æå¤±')
        ax1.set_title('2æ¬¡å…ƒPI-KANè¨“ç·´å±¥æ­´')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')
        
        # è¨“ç·´å±¥æ­´ï¼ˆ4æ¬¡å…ƒï¼‰
        epochs_4d = range(len(history_4d['total_loss']))
        ax2.plot(epochs_4d, history_4d['total_loss'], 'b-', label='ç·æå¤±', linewidth=2)
        ax2.plot(epochs_4d, history_4d['data_loss'], 'g-', label='ãƒ‡ãƒ¼ã‚¿æå¤±', linewidth=2)
        ax2.plot(epochs_4d, history_4d['physics_loss'], 'r-', label='ç‰©ç†åˆ¶ç´„æå¤±', linewidth=2)
        ax2.set_xlabel('ã‚¨ãƒãƒƒã‚¯')
        ax2.set_ylabel('æå¤±')
        ax2.set_title('4æ¬¡å…ƒPI-KANè¨“ç·´å±¥æ­´')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # æ€§èƒ½æ¯”è¼ƒ
        metrics = ['MSE', 'ç›¸é–¢ä¿‚æ•°']
        values_2d = [eval_results_2d['mse'], eval_results_2d['correlation']]
        values_4d = [eval_results_4d['mse'], eval_results_4d['correlation']]
        
        x_pos = np.arange(len(metrics))
        width = 0.35
        
        bars1 = ax3.bar(x_pos - width/2, values_2d, width, label='2æ¬¡å…ƒ', alpha=0.7, color='blue')
        bars2 = ax3.bar(x_pos + width/2, values_4d, width, label='4æ¬¡å…ƒ', alpha=0.7, color='red')
        
        ax3.set_xlabel('è©•ä¾¡æŒ‡æ¨™')
        ax3.set_ylabel('å€¤')
        ax3.set_title('PI-KANæ€§èƒ½æ¯”è¼ƒ')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels(metrics)
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # ç‰©ç†åˆ¶ç´„é•åæ¯”è¼ƒ
        physics_violations = [eval_results_2d['physics_constraint_violation'], 
                            eval_results_4d['physics_constraint_violation']]
        
        bars = ax4.bar(problems, physics_violations, alpha=0.7, color=['blue', 'red'])
        ax4.set_ylabel('ç‰©ç†åˆ¶ç´„é•å')
        ax4.set_title('ç‰©ç†åˆ¶ç´„æº€è¶³åº¦')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('pikan_network_analysis_fixed.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ 'pikan_network_analysis_fixed.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
        plt.show()
        
    except Exception as e:
        logger.warning(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 6. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¿å­˜
    torch.save(network_2d.state_dict(), 'pikan_2d_model_fixed.pth')
    torch.save(network_4d.state_dict(), 'pikan_4d_model_fixed.pth')
    print("ğŸ’¾ è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    
    return all_results, network_2d, network_4d

if __name__ == "__main__":
    """
    PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å®Ÿè¡Œ
    """
    try:
        results, model_2d, model_4d = demonstrate_pikan_applications()
        print("ğŸ‰ PI-KANãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å®Ÿè£…ã¨è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}") 
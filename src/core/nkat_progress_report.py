#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”¥ğŸ’â€¼ NKATè¨ˆç®—é€²è¡ŒçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ â€¼ğŸ’ğŸ”¥
ç¾åœ¨å®Ÿè¡Œä¸­ã®è¨ˆç®—ã®è©³ç´°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path

def generate_progress_report():
    """é€²è¡ŒçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    print("ğŸ”¥ğŸ’ NKATè¨ˆç®—é€²è¡ŒçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ ğŸ’ğŸ”¥")
    print("="*80)
    print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    # 1. Î¸=1e-12 ãƒ¡ã‚¤ãƒ³è¨ˆç®—ã®çŠ¶æ³
    print("\nğŸ“Š 1. ãƒ¡ã‚¤ãƒ³è¨ˆç®— (Î¸=1e-12) çŠ¶æ³:")
    print("-" * 50)
    
    main_recovery = Path("nkat_recovery_theta_1e12")
    if main_recovery.exists():
        metadata_file = main_recovery / "nkat_session_metadata.json"
        checkpoint_file = main_recovery / "nkat_checkpoint.pkl"
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            status = metadata.get('status', 'unknown')
            start_time = metadata.get('start_time', 'N/A')
            last_update = metadata.get('last_update', 'N/A')
            computation_state = metadata.get('computation_state', 'N/A')
            
            if start_time != 'N/A':
                start_time = datetime.fromisoformat(start_time).strftime('%H:%M:%S')
            if last_update != 'N/A':
                last_update = datetime.fromisoformat(last_update).strftime('%H:%M:%S')
            
            print(f"   ğŸŸ¢ çŠ¶æ…‹: {status}")
            print(f"   ğŸ• é–‹å§‹æ™‚åˆ»: {start_time}")
            print(f"   ğŸ”„ æœ€çµ‚æ›´æ–°: {last_update}")
            print(f"   âš™ï¸ è¨ˆç®—æ®µéš: {computation_state}")
            
            if checkpoint_file.exists():
                size_mb = checkpoint_file.stat().st_size / (1024 * 1024)
                mod_time = datetime.fromtimestamp(checkpoint_file.stat().st_mtime)
                print(f"   ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {size_mb:.2f}MB (æ›´æ–°: {mod_time.strftime('%H:%M:%S')})")
                
                # é€²è¡Œåº¦æ¨å®š
                if 'critical_zeros_computation' in computation_state:
                    progress = "ğŸŸ¡ é›¶ç‚¹æ¢ç´¢ä¸­ (æ®µéš1/9)"
                elif 'off_critical' in computation_state:
                    progress = "ğŸŸ  è‡¨ç•Œç·šå¤–æ¤œè¨¼ä¸­ (æ®µéš2/9)"
                elif 'functional_equation' in computation_state:
                    progress = "ğŸ”µ é–¢æ•°æ–¹ç¨‹å¼æ¤œè¨¼ä¸­ (æ®µéš3/9)"
                elif 'completed' in computation_state:
                    progress = "ğŸŸ¢ å®Œäº†!"
                else:
                    progress = "ğŸŸ¡ è¨ˆç®—ä¸­"
                
                print(f"   ğŸ“ˆ é€²è¡ŒçŠ¶æ³: {progress}")
        else:
            print("   âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    else:
        print("   ğŸ“­ ãƒ¡ã‚¤ãƒ³è¨ˆç®—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã—")
    
    # 2. Î¸æœ€é©åŒ–å®Ÿé¨“ã®çŠ¶æ³
    print("\nğŸ“Š 2. Î¸æœ€é©åŒ–å®Ÿé¨“çŠ¶æ³:")
    print("-" * 50)
    
    theta_recovery_dirs = [
        "nkat_recovery_theta_1e-08",
        "nkat_recovery_theta_1e-10", 
        "nkat_recovery_theta_1e-14",
        "nkat_recovery_theta_1e-16"
    ]
    
    for dir_name in theta_recovery_dirs:
        dir_path = Path(dir_name)
        if dir_path.exists():
            theta_value = dir_name.split('_')[-1]
            print(f"   ğŸ§ª Î¸={theta_value}:")
            
            checkpoint = dir_path / "nkat_checkpoint.pkl"
            if checkpoint.exists():
                size_kb = checkpoint.stat().st_size / 1024
                mod_time = datetime.fromtimestamp(checkpoint.stat().st_mtime)
                print(f"      ğŸ’¾ {size_kb:.1f}KB ({mod_time.strftime('%H:%M:%S')})")
            else:
                print("      ğŸ“­ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãªã—")
    
    # 3. çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ³
    print("\nğŸ“Š 3. ç”Ÿæˆæ¸ˆã¿çµæœãƒ•ã‚¡ã‚¤ãƒ«:")
    print("-" * 50)
    
    result_files = [
        ("theta_optimization_comprehensive_*.json", "Î¸æœ€é©åŒ–çµæœ"),
        ("nkat_riemann_hypothesis_complete_proof.png", "ãƒªãƒ¼ãƒãƒ³è¨¼æ˜å›³"),
        ("riemann_hypothesis_proof_certificate.txt", "è¨¼æ˜è¨¼æ˜æ›¸"),
        ("*_theta_*_result.json", "å€‹åˆ¥Î¸ãƒ†ã‚¹ãƒˆçµæœ")
    ]
    
    for pattern, description in result_files:
        matching_files = list(Path(".").glob(pattern))
        if matching_files:
            latest = max(matching_files, key=lambda f: f.stat().st_mtime)
            mod_time = datetime.fromtimestamp(latest.stat().st_mtime)
            print(f"   ğŸ“„ {description}: {latest.name} ({mod_time.strftime('%H:%M:%S')})")
        else:
            print(f"   ğŸ“­ {description}: æœªç”Ÿæˆ")
    
    # 4. ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
    print("\nğŸ“Š 4. ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³:")
    print("-" * 50)
    
    total_recovery_size = 0
    recovery_dirs = list(Path(".").glob("nkat_recovery_*"))
    
    for recovery_dir in recovery_dirs:
        if recovery_dir.is_dir():
            dir_size = sum(f.stat().st_size for f in recovery_dir.rglob('*') if f.is_file())
            total_recovery_size += dir_size
    
    print(f"   ğŸ’¾ ç·ãƒªã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿: {total_recovery_size / (1024*1024):.2f}MB")
    print(f"   ğŸ“ ãƒªã‚«ãƒãƒªãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(recovery_dirs)}å€‹")
    
    # 5. æ¨å®šå®Œäº†æ™‚é–“
    print("\nğŸ“Š 5. å®Œäº†æ™‚é–“æ¨å®š:")
    print("-" * 50)
    
    if main_recovery.exists():
        metadata_file = main_recovery / "nkat_session_metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            start_time_str = metadata.get('start_time', '')
            last_update_str = metadata.get('last_update', '')
            
            if start_time_str and last_update_str:
                start_time = datetime.fromisoformat(start_time_str)
                last_update = datetime.fromisoformat(last_update_str)
                elapsed = (last_update - start_time).total_seconds()
                
                # é€²è¡Œåº¦ã«åŸºã¥ãæ¨å®šï¼ˆç²—ã„æ¨å®šï¼‰
                computation_state = metadata.get('computation_state', '')
                if 'critical_zeros_computation' in computation_state:
                    estimated_progress = 0.3  # 30%ç¨‹åº¦
                elif 'off_critical' in computation_state:
                    estimated_progress = 0.5
                elif 'functional_equation' in computation_state:
                    estimated_progress = 0.7
                else:
                    estimated_progress = 0.1
                
                if estimated_progress > 0:
                    total_estimated = elapsed / estimated_progress
                    remaining = total_estimated - elapsed
                    
                    print(f"   â±ï¸ çµŒéæ™‚é–“: {elapsed/3600:.1f}æ™‚é–“")
                    print(f"   ğŸ“ˆ æ¨å®šé€²è¡Œåº¦: {estimated_progress*100:.0f}%")
                    print(f"   â° æ¨å®šæ®‹ã‚Šæ™‚é–“: {remaining/3600:.1f}æ™‚é–“")
                    
                    completion_time = datetime.now() + timedelta(seconds=remaining)
                    print(f"   ğŸ¯ æ¨å®šå®Œäº†æ™‚åˆ»: {completion_time.strftime('%H:%M:%S')}")
                else:
                    print("   âš ï¸ é€²è¡Œåº¦æ¨å®šä¸å¯")
            else:
                print("   âš ï¸ æ™‚é–“æƒ…å ±ä¸è¶³")
        else:
            print("   âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # 6. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print("\nğŸ“Š 6. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print("-" * 50)
    
    recommendations = []
    
    # ãƒ¡ã‚¤ãƒ³è¨ˆç®—ãŒå‹•ã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if main_recovery.exists():
        checkpoint_file = main_recovery / "nkat_checkpoint.pkl"
        if checkpoint_file.exists():
            mod_time = datetime.fromtimestamp(checkpoint_file.stat().st_mtime)
            time_since_update = (datetime.now() - mod_time).total_seconds()
            
            if time_since_update < 600:  # 10åˆ†ä»¥å†…
                recommendations.append("ğŸŸ¢ ãƒ¡ã‚¤ãƒ³è¨ˆç®—ãŒæ­£å¸¸ã«é€²è¡Œä¸­")
            elif time_since_update < 3600:  # 1æ™‚é–“ä»¥å†…
                recommendations.append("ğŸŸ¡ ãƒ¡ã‚¤ãƒ³è¨ˆç®—ãŒä¸€æ™‚åœæ­¢ä¸­ - ç›£è¦–ç¶™ç¶š")
            else:
                recommendations.append("ğŸ”´ ãƒ¡ã‚¤ãƒ³è¨ˆç®—ãŒé•·æ™‚é–“åœæ­¢ - å†èµ·å‹•ã‚’æ¤œè¨")
    
    # Î¸æœ€é©åŒ–ã®çŠ¶æ³ãƒã‚§ãƒƒã‚¯
    theta_results = list(Path(".").glob("theta_optimization_comprehensive_*.json"))
    if theta_results:
        recommendations.append("âœ… Î¸æœ€é©åŒ–å®Ÿé¨“å®Œäº† - çµæœã‚’ç¢ºèª")
    else:
        recommendations.append("ğŸŸ¡ Î¸æœ€é©åŒ–å®Ÿé¨“é€²è¡Œä¸­ - å®Œäº†ã‚’å¾…æ©Ÿ")
    
    # ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ³
    if total_recovery_size > 100 * 1024 * 1024:  # 100MBä»¥ä¸Š
        recommendations.append("ğŸ’¾ ãƒªã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒå¤§å®¹é‡ - å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¨å¥¨")
    
    for rec in recommendations:
        print(f"   {rec}")
    
    print("\n" + "="*80)
    print("ğŸ”¥ğŸ’ NKAT: Don't hold back. Give it your all!! ğŸ’ğŸ”¥")
    print("="*80)

if __name__ == "__main__":
    generate_progress_report() 
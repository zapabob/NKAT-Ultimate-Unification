#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NKATæ©Ÿæ¢°å­¦ç¿’ã‚¯ã‚¤ãƒƒã‚¯åˆ†æã‚·ã‚¹ãƒ†ãƒ 
38,832å€‹ã®ã‚¼ãƒ­ç‚¹ãƒ‡ãƒ¼ã‚¿è¿…é€Ÿè©•ä¾¡
"""

import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings
warnings.filterwarnings('ignore')

def quick_ml_analysis():
    """è¿…é€Ÿæ©Ÿæ¢°å­¦ç¿’åˆ†æ"""
    print("ğŸš€ NKATæ©Ÿæ¢°å­¦ç¿’ã‚¯ã‚¤ãƒƒã‚¯åˆ†æé–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        with open("nkat_production_results_nkat_prod_20250604_102015.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        zeros_raw = data['results']['zeros_data']
        df = pd.DataFrame(zeros_raw)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df):,}å€‹ã®ã‚¼ãƒ­ç‚¹")
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   tå€¤ç¯„å›²: {df['t'].min():.3f} - {df['t'].max():.3f}")
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {df['confidence'].mean():.6f}")
        print(f"   å¹³å‡æ®‹å·®: {df['residual'].mean():.2e}")
        
        # æ—¢çŸ¥ã‚¼ãƒ­ç‚¹ãƒãƒƒãƒãƒ³ã‚°
        if 'known_match' in df.columns:
            known_matches = df['known_match'].fillna(0).sum()
            print(f"   æ—¢çŸ¥ã‚¼ãƒ­ç‚¹ä¸€è‡´: {known_matches}/{len(df)} ({known_matches/len(df)*100:.1f}%)")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    # ç°¡æ˜“ç‰¹å¾´é‡ä½œæˆ
    features = {
        't_value': df['t'].values,
        'residual': df['residual'].values,
        'confidence': df['confidence'].values,
        'superconv_factor': df['superconv_factor'].values
    }
    
    # è¿½åŠ ç‰¹å¾´é‡
    t_diffs = np.diff(df['t'].values)
    features['zero_spacing'] = np.concatenate([[t_diffs[0]], t_diffs])
    features['residual_log'] = np.log10(df['residual'] + 1e-16)
    features['confidence_log'] = np.log10(df['confidence'] + 1e-16)
    
    # ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼è¡Œåˆ—
    X = np.column_stack([features['t_value'], features['residual'], 
                        features['confidence'], features['superconv_factor'],
                        features['zero_spacing'], features['residual_log'],
                        features['confidence_log']])
    
    feature_names = ['t_value', 'residual', 'confidence', 'superconv_factor',
                    'zero_spacing', 'residual_log', 'confidence_log']
    
    print(f"ğŸ”¬ ç‰¹å¾´é‡: {len(feature_names)}å€‹")
    
    # è¤‡æ•°ã®åˆ†é¡ã‚¿ã‚¹ã‚¯
    targets = {}
    
    # 1. é«˜ä¿¡é ¼åº¦ã‚¼ãƒ­ç‚¹ï¼ˆä¸Šä½25%ï¼‰
    confidence_threshold = np.percentile(df['confidence'], 75)
    targets['high_confidence'] = (df['confidence'] > confidence_threshold).astype(int)
    
    # 2. ä½æ®‹å·®ã‚¼ãƒ­ç‚¹ï¼ˆä¸‹ä½25%ï¼‰
    residual_threshold = np.percentile(df['residual'], 25)
    targets['low_residual'] = (df['residual'] < residual_threshold).astype(int)
    
    # 3. æ—¢çŸ¥ã‚¼ãƒ­ç‚¹ãƒãƒƒãƒãƒ³ã‚°
    if 'known_match' in df.columns:
        targets['known_match'] = df['known_match'].fillna(0).astype(int)
    
    print(f"ğŸ¯ åˆ†é¡ã‚¿ã‚¹ã‚¯: {len(targets)}å€‹")
    
    # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§è©•ä¾¡
    results = {}
    
    for target_name, y in targets.items():
        print(f"\nğŸ” {target_name} åˆ†æé–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # RandomForest è¨“ç·´
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        
        # äºˆæ¸¬
        y_pred = rf.predict(X_test)
        y_pred_proba = rf.predict_proba(X_test)[:, 1]
        
        # è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        try:
            roc_auc = roc_auc_score(y_test, y_pred_proba)
        except:
            roc_auc = 0.5
        
        accuracy = (y_pred == y_test).mean()
        
        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(y_test, y_pred)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        importances = rf.feature_importances_
        
        results[target_name] = {
            'accuracy': accuracy,
            'roc_auc': roc_auc,
            'confusion_matrix': cm.tolist(),
            'feature_importance': dict(zip(feature_names, importances)),
            'positive_rate': y.mean()
        }
        
        print(f"   ç²¾åº¦: {accuracy:.3f}")
        print(f"   ROC AUC: {roc_auc:.3f}")
        print(f"   æ­£ä¾‹ç‡: {y.mean():.3f}")
        
        # Top 3 é‡è¦ç‰¹å¾´é‡
        top_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)[:3]
        print(f"   é‡è¦ç‰¹å¾´é‡:")
        for i, (name, importance) in enumerate(top_features):
            print(f"     {i+1}. {name}: {importance:.3f}")
    
    # å¯è¦–åŒ–
    plt.figure(figsize=(15, 10))
    
    # ROC AUCæ¯”è¼ƒ
    plt.subplot(2, 3, 1)
    target_names = list(results.keys())
    roc_values = [results[name]['roc_auc'] for name in target_names]
    plt.bar(target_names, roc_values)
    plt.title('ROC AUC Comparison')
    plt.ylabel('ROC AUC')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # ç²¾åº¦æ¯”è¼ƒ
    plt.subplot(2, 3, 2)
    accuracy_values = [results[name]['accuracy'] for name in target_names]
    plt.bar(target_names, accuracy_values)
    plt.title('Accuracy Comparison')
    plt.ylabel('Accuracy')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆæœ€åˆã®ã‚¿ã‚¹ã‚¯ï¼‰
    if target_names:
        first_target = target_names[0]
        importances = results[first_target]['feature_importance']
        plt.subplot(2, 3, 3)
        plt.bar(importances.keys(), importances.values())
        plt.title(f'Feature Importance: {first_target}')
        plt.ylabel('Importance')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
    
    # æ··åŒè¡Œåˆ—ï¼ˆæœ€åˆã®ã‚¿ã‚¹ã‚¯ï¼‰
    if target_names:
        cm = np.array(results[first_target]['confusion_matrix'])
        plt.subplot(2, 3, 4)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title(f'Confusion Matrix: {first_target}')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ
    plt.subplot(2, 3, 5)
    plt.hist(df['confidence'], bins=50, alpha=0.7, label='Confidence')
    plt.hist(np.log10(df['residual']), bins=50, alpha=0.7, label='Log Residual')
    plt.title('Data Distribution')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ã‚¼ãƒ­ç‚¹åˆ†å¸ƒ
    plt.subplot(2, 3, 6)
    plt.scatter(df['t'], df['confidence'], alpha=0.1, s=1)
    plt.title('Zero Distribution')
    plt.xlabel('t (imaginary part)')
    plt.ylabel('Confidence')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('nkat_ml_quick_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸŠ NKATæ©Ÿæ¢°å­¦ç¿’ã‚¯ã‚¤ãƒƒã‚¯åˆ†æå®Œäº†!")
    print(f"ğŸ“Š æ¤œå‡ºã‚¼ãƒ­ç‚¹: {len(df):,}å€‹")
    print(f"ğŸ”¬ ç‰¹å¾´é‡æ•°: {len(feature_names)}")
    print(f"ğŸ¯ åˆ†é¡ã‚¿ã‚¹ã‚¯æ•°: {len(targets)}")
    print(f"ğŸ“ˆ å¯è¦–åŒ–ä¿å­˜: nkat_ml_quick_analysis.png")
    
    print(f"\nğŸ† ãƒ™ã‚¹ãƒˆæ€§èƒ½:")
    for target_name in target_names:
        roc_auc = results[target_name]['roc_auc']
        accuracy = results[target_name]['accuracy']
        print(f"   {target_name}: ROC AUC={roc_auc:.3f}, Accuracy={accuracy:.3f}")
    
    return results

if __name__ == "__main__":
    results = quick_ml_analysis() 
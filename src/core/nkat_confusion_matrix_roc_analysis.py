#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š NKATæ··åŒè¡Œåˆ—ãƒ»ROC AUCè©³ç´°åˆ†æã‚·ã‚¹ãƒ†ãƒ 
38,832å€‹ã®ã‚¼ãƒ­ç‚¹ãƒ‡ãƒ¼ã‚¿ã§ã®æ·±å±¤æ€§èƒ½è©•ä¾¡
å‚è€ƒ: Mediumè¨˜äº‹ "Predicting Riemann Zeta Function Zeros: A Machine Learning Odyssey"
"""

import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

# matplotlibæ—¥æœ¬èªè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans']
sns.set_style("whitegrid")

def load_nkat_data():
    """NKATãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š 38,832å€‹ã®NKATã‚¼ãƒ­ç‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    
    try:
        with open("nkat_production_results_nkat_prod_20250604_102015.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        zeros_raw = data['results']['zeros_data']
        df = pd.DataFrame(zeros_raw)
        print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}å€‹ã®ã‚¼ãƒ­ç‚¹")
        
        return df
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_advanced_features(df):
    """é«˜åº¦ç‰¹å¾´é‡æŠ½å‡ºï¼ˆGitHubå‚è€ƒï¼‰"""
    print("ğŸ”¬ GitHub avysogorets/riemann-zetaå‚è€ƒç‰¹å¾´é‡æŠ½å‡º...")
    
    # ã‚½ãƒ¼ãƒˆ
    df_sorted = df.sort_values('t').reset_index(drop=True)
    
    features = {}
    
    # åŸºæœ¬ç‰¹å¾´é‡
    features['t_value'] = df_sorted['t'].values
    features['residual'] = df_sorted['residual'].values
    features['confidence'] = df_sorted['confidence'].values
    features['superconv_factor'] = df_sorted['superconv_factor'].values
    
    # ã‚¼ãƒ­ç‚¹é–“éš”ç‰¹å¾´é‡
    t_diffs = np.diff(features['t_value'])
    features['zero_spacing'] = np.concatenate([[t_diffs[0]], t_diffs])
    
    # çµ±è¨ˆçš„ç‰¹å¾´é‡
    features['residual_log'] = np.log10(features['residual'] + 1e-16)
    features['confidence_log'] = np.log10(features['confidence'] + 1e-16)
    
    # Gramç‚¹è¿‘ä¼¼ï¼ˆGoogle Siteså‚è€ƒï¼‰
    gram_approx = 2 * np.pi * features['t_value'] / np.log(features['t_value'] / (2 * np.pi))
    features['gram_deviation'] = features['t_value'] - gram_approx
    
    # Hardy Zé–¢æ•°è¿‘ä¼¼
    z_approx = np.cos(features['t_value'] * np.log(features['t_value']) / 2)
    features['z_function_approx'] = z_approx
    
    # å±€æ‰€å¯†åº¦
    window = 5
    local_density = []
    for i in range(len(features['t_value'])):
        start = max(0, i - window//2)
        end = min(len(features['t_value']), i + window//2 + 1)
        if end - start > 1:
            local_spacings = np.diff(features['t_value'][start:end])
            local_density.append(np.mean(local_spacings))
        else:
            local_density.append(features['zero_spacing'][i])
    features['local_density'] = np.array(local_density)
    
    # æ­£è¦åŒ–ç‰¹å¾´é‡
    features['t_normalized'] = (features['t_value'] - features['t_value'].mean()) / features['t_value'].std()
    features['spacing_normalized'] = (features['zero_spacing'] - np.mean(features['zero_spacing'])) / np.std(features['zero_spacing'])
    
    feature_names = ['t_value', 'residual', 'confidence', 'superconv_factor',
                    'zero_spacing', 'residual_log', 'confidence_log', 
                    'gram_deviation', 'z_function_approx', 'local_density',
                    't_normalized', 'spacing_normalized']
    
    X = np.column_stack([features[name] for name in feature_names])
    
    print(f"âœ… æŠ½å‡ºå®Œäº†: {len(feature_names)}ç‰¹å¾´é‡ Ã— {X.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")
    
    return X, feature_names, df_sorted

def create_classification_targets(df):
    """åˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ"""
    print("ğŸ¯ åˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ...")
    
    targets = {}
    
    # 1. é«˜ä¿¡é ¼åº¦ã‚¼ãƒ­ç‚¹ï¼ˆä¸Šä½20%ï¼‰
    confidence_threshold = np.percentile(df['confidence'], 80)
    targets['high_confidence'] = (df['confidence'] > confidence_threshold).astype(int)
    
    # 2. æ¥µä½æ®‹å·®ã‚¼ãƒ­ç‚¹ï¼ˆä¸‹ä½10%ï¼‰
    residual_threshold = np.percentile(df['residual'], 10)
    targets['ultra_low_residual'] = (df['residual'] < residual_threshold).astype(int)
    
    # 3. æ—¢çŸ¥ã‚¼ãƒ­ç‚¹ãƒãƒƒãƒãƒ³ã‚°
    if 'known_match' in df.columns:
        targets['known_match'] = df['known_match'].fillna(0).astype(int)
    
    # 4. è¶…åæŸç•°å¸¸å€¤ï¼ˆä¸Šä½5%ï¼‰
    superconv_threshold = np.percentile(df['superconv_factor'], 95)
    targets['superconv_outlier'] = (df['superconv_factor'] > superconv_threshold).astype(int)
    
    # 5. å¯†é›†ã‚¼ãƒ­ç‚¹ãƒšã‚¢
    t_diffs = np.diff(df['t'].values)
    avg_spacing = np.mean(t_diffs)
    close_threshold = avg_spacing * 0.3  # å¹³å‡ã®30%ä»¥ä¸‹
    close_pairs = t_diffs < close_threshold
    targets['close_pairs'] = np.concatenate([[0], close_pairs.astype(int)])
    
    print(f"âœ… ä½œæˆå®Œäº†: {len(targets)}å€‹ã®åˆ†é¡ã‚¿ã‚¹ã‚¯")
    for name, target in targets.items():
        positive_rate = np.mean(target)
        print(f"   {name}: æ­£ä¾‹ç‡ {positive_rate:.3f} ({np.sum(target):,}/{len(target):,})")
    
    return targets

def detailed_confusion_matrix_analysis(X, targets, feature_names):
    """è©³ç´°æ··åŒè¡Œåˆ—ãƒ»ROC AUCåˆ†æ"""
    print("\nğŸ“Š è©³ç´°æ··åŒè¡Œåˆ—ãƒ»ROC AUCåˆ†æé–‹å§‹...")
    
    # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§ã®è©•ä¾¡
    models = {
        'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),
        'SVM': SVC(probability=True, random_state=42),
        'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)
    }
    
    all_results = {}
    
    # ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    for target_name, y in targets.items():
        print(f"\nğŸ¯ {target_name} è©³ç´°åˆ†æ...")
        
        target_results = {}
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.3, random_state=42, stratify=y
        )
        
        # å„ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡
        for model_name, model in models.items():
            print(f"   ğŸ” {model_name} è©•ä¾¡ä¸­...")
            
            try:
                # è¨“ç·´
                model.fit(X_train, y_train)
                
                # äºˆæ¸¬
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                accuracy = (y_pred == y_test).mean()
                
                try:
                    roc_auc = roc_auc_score(y_test, y_pred_proba)
                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
                    avg_precision = average_precision_score(y_test, y_pred_proba)
                except:
                    roc_auc = 0.5
                    fpr, tpr = [0, 1], [0, 1]
                    precision, recall = [1, 0], [0, 1]
                    avg_precision = np.mean(y_test)
                
                # æ··åŒè¡Œåˆ—
                cm = confusion_matrix(y_test, y_pred)
                
                # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
                class_report = classification_report(y_test, y_pred, output_dict=True)
                
                # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
                cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')
                
                target_results[model_name] = {
                    'accuracy': accuracy,
                    'roc_auc': roc_auc,
                    'avg_precision': avg_precision,
                    'confusion_matrix': cm,
                    'classification_report': class_report,
                    'cv_scores': cv_scores,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'fpr': fpr,
                    'tpr': tpr,
                    'precision_curve': precision,
                    'recall_curve': recall
                }
                
                print(f"     Accuracy: {accuracy:.3f}")
                print(f"     ROC AUC: {roc_auc:.3f} (CV: {cv_scores.mean():.3f}Â±{cv_scores.std():.3f})")
                print(f"     Avg Precision: {avg_precision:.3f}")
                
            except Exception as e:
                print(f"     âŒ {model_name} ã‚¨ãƒ©ãƒ¼: {e}")
        
        all_results[target_name] = target_results
    
    return all_results

def create_comprehensive_visualization(results, feature_names):
    """åŒ…æ‹¬çš„å¯è¦–åŒ–ä½œæˆ"""
    print("\nğŸ“ˆ åŒ…æ‹¬çš„å¯è¦–åŒ–ä½œæˆä¸­...")
    
    target_names = list(results.keys())
    model_names = ['RandomForest', 'SVM', 'LogisticRegression']
    
    # å¤§ããªãƒ•ã‚£ã‚®ãƒ¥ã‚¢ä½œæˆ
    fig = plt.figure(figsize=(20, 24))
    
    plot_idx = 1
    
    for i, target_name in enumerate(target_names):
        target_results = results[target_name]
        
        # ROCæ›²ç·š
        plt.subplot(6, 4, plot_idx)
        for model_name in model_names:
            if model_name in target_results:
                res = target_results[model_name]
                plt.plot(res['fpr'], res['tpr'], 
                        label=f"{model_name} (AUC={res['roc_auc']:.3f})")
        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'ROC Curve: {target_name}')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plot_idx += 1
        
        # Precision-Recallæ›²ç·š
        plt.subplot(6, 4, plot_idx)
        for model_name in model_names:
            if model_name in target_results:
                res = target_results[model_name]
                plt.plot(res['recall_curve'], res['precision_curve'],
                        label=f"{model_name} (AP={res['avg_precision']:.3f})")
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title(f'Precision-Recall: {target_name}')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plot_idx += 1
        
        # æ··åŒè¡Œåˆ—ï¼ˆRandomForestï¼‰
        plt.subplot(6, 4, plot_idx)
        if 'RandomForest' in target_results:
            cm = target_results['RandomForest']['confusion_matrix']
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
            plt.title(f'Confusion Matrix (RF): {target_name}')
            plt.xlabel('Predicted')
            plt.ylabel('Actual')
        plot_idx += 1
        
        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
        plt.subplot(6, 4, plot_idx)
        cv_means = []
        cv_stds = []
        model_labels = []
        for model_name in model_names:
            if model_name in target_results:
                res = target_results[model_name]
                cv_means.append(res['cv_mean'])
                cv_stds.append(res['cv_std'])
                model_labels.append(model_name)
        
        plt.bar(model_labels, cv_means, yerr=cv_stds, capsize=5)
        plt.title(f'Cross-Validation ROC AUC: {target_name}')
        plt.ylabel('ROC AUC')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        plot_idx += 1
    
    # å…¨ä½“æ€§èƒ½æ¯”è¼ƒ
    plt.subplot(6, 4, plot_idx)
    roc_auc_matrix = []
    for model_name in model_names:
        model_aucs = []
        for target_name in target_names:
            if model_name in results[target_name]:
                model_aucs.append(results[target_name][model_name]['roc_auc'])
            else:
                model_aucs.append(0.5)
        roc_auc_matrix.append(model_aucs)
    
    roc_auc_matrix = np.array(roc_auc_matrix)
    sns.heatmap(roc_auc_matrix, xticklabels=target_names, yticklabels=model_names,
                annot=True, cmap='YlOrRd', vmin=0.5, vmax=1.0)
    plt.title('ROC AUC Heatmap (All Models vs Targets)')
    plt.xticks(rotation=45)
    plot_idx += 1
    
    plt.tight_layout()
    plt.savefig('nkat_comprehensive_confusion_roc_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… åŒ…æ‹¬çš„å¯è¦–åŒ–ä¿å­˜: nkat_comprehensive_confusion_roc_analysis.png")

def print_detailed_summary(results):
    """è©³ç´°ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
    print("\n" + "ğŸ†" * 50)
    print("NKATæ©Ÿæ¢°å­¦ç¿’æ€§èƒ½è©³ç´°ã‚µãƒãƒªãƒ¼")
    print("ğŸ†" * 50)
    
    for target_name, target_results in results.items():
        print(f"\nğŸ“Š {target_name}:")
        
        best_model = None
        best_auc = 0
        
        for model_name, res in target_results.items():
            roc_auc = res['roc_auc']
            cv_mean = res['cv_mean']
            cv_std = res['cv_std']
            accuracy = res['accuracy']
            
            print(f"   {model_name:15}: ROC AUC={roc_auc:.3f} (CV: {cv_mean:.3f}Â±{cv_std:.3f}) Acc={accuracy:.3f}")
            
            if roc_auc > best_auc:
                best_auc = roc_auc
                best_model = model_name
        
        if best_model:
            print(f"   ğŸ¥‡ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: {best_model} (ROC AUC={best_auc:.3f})")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ“Š" * 30)
    print("NKATæ··åŒè¡Œåˆ—ãƒ»ROC AUCè©³ç´°åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print("å‚è€ƒ: GitHub avysogorets/riemann-zeta & Mediumè¨˜äº‹")
    print("ğŸ“Š" * 30)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_nkat_data()
    if df is None:
        return
    
    # ç‰¹å¾´é‡æŠ½å‡º
    X, feature_names, df_sorted = extract_advanced_features(df)
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
    targets = create_classification_targets(df_sorted)
    
    # è©³ç´°åˆ†æ
    results = detailed_confusion_matrix_analysis(X, targets, feature_names)
    
    # å¯è¦–åŒ–
    create_comprehensive_visualization(results, feature_names)
    
    # ã‚µãƒãƒªãƒ¼
    print_detailed_summary(results)
    
    print(f"\nğŸŠ NKATæ©Ÿæ¢°å­¦ç¿’è©³ç´°åˆ†æå®Œäº†!")
    print(f"ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿: 38,832å€‹ã®ã‚¼ãƒ­ç‚¹")
    print(f"ğŸ”¬ ç‰¹å¾´é‡æ•°: {len(feature_names)}")
    print(f"ğŸ¯ åˆ†é¡ã‚¿ã‚¹ã‚¯æ•°: {len(targets)}")
    print(f"ğŸ¤– è©•ä¾¡ãƒ¢ãƒ‡ãƒ«æ•°: 3 (RandomForest, SVM, LogisticRegression)")
    print(f"ğŸ“ˆ å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: nkat_comprehensive_confusion_roc_analysis.png")
    
    return results

if __name__ == "__main__":
    results = main() 
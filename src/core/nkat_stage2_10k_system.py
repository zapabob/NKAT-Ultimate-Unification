#!/usr/bin/env python3
"""
ğŸ”¥ NKAT Stage 2: 10,000ã‚¼ãƒ­ç‚¹æ·±å±¤å­¦ç¿’è¶…é«˜ç²¾åº¦ã‚·ã‚¹ãƒ†ãƒ 
===============================================
ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ±ºã¸ã®æ®µéšçš„ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—
ãƒãƒƒãƒå‡¦ç†ã¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Ÿè£…
"""

import os
import sys
import json
import time
import signal
import pickle
import warnings
from datetime import datetime
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import PolynomialFeatures
from tqdm import tqdm
import gc
import psutil

# GPUè¨­å®š
import torch
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import mpmath
    mpmath.mp.dps = 50  # 50æ¡ç²¾åº¦
    MPMATH_AVAILABLE = True
    print("ğŸ”¢ mpmath 50æ¡ç²¾åº¦: æœ‰åŠ¹")
except ImportError:
    MPMATH_AVAILABLE = False
    print("âš ï¸ mpmathç„¡åŠ¹")

# GPUç¢ºèª
CUDA_AVAILABLE = torch.cuda.is_available()
if CUDA_AVAILABLE:
    device = torch.device('cuda')
    print(f"ğŸš€ CUDA RTX3080 GPUåŠ é€Ÿ: æœ‰åŠ¹")
    torch.cuda.set_device(0)
else:
    device = torch.device('cpu')
    print("âš ï¸ CUDAç„¡åŠ¹")

warnings.filterwarnings('ignore')

class NKAT_Stage2_System:
    def __init__(self, target_zeros=10000, batch_size=1000):
        """NKAT Stage2ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        self.target_zeros = target_zeros
        self.batch_size = batch_size
        self.zeros = []
        self.features = None
        self.models = {}
        self.scalers = {}
        self.results = {}
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å›ºå®š
        np.random.seed(42)
        torch.manual_seed(42)
        if CUDA_AVAILABLE:
            torch.cuda.manual_seed(42)
        print("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å›ºå®š: 42")
        
        # GPUåˆæœŸåŒ–
        if CUDA_AVAILABLE:
            self.device = torch.device('cuda:0')
            torch.cuda.empty_cache()
            print(f"ğŸ”¥ GPUåˆæœŸåŒ–å®Œäº†: {self.device}")
        else:
            self.device = torch.device('cpu')
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"nkat_stage2_10k_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        # é›»æºæ–­å¯¾å¿œ
        self.setup_signal_handlers()
        print("ğŸ›¡ï¸ é›»æºæ–­å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ : æœ‰åŠ¹")
        
    def setup_signal_handlers(self):
        """é›»æºæ–­ãƒ»ç•°å¸¸çµ‚äº†å¯¾å¿œ"""
        def emergency_save(signum, frame):
            print(f"\nğŸš¨ ç·Šæ€¥ä¿å­˜é–‹å§‹ (Signal: {signum})")
            self.save_emergency_checkpoint()
            sys.exit(1)
        
        signal.signal(signal.SIGINT, emergency_save)
        signal.signal(signal.SIGTERM, emergency_save)
        if hasattr(signal, 'SIGBREAK'):
            signal.signal(signal.SIGBREAK, emergency_save)
    
    def save_emergency_checkpoint(self):
        """ç·Šæ€¥ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        try:
            emergency_data = {
                'zeros': self.zeros,
                'target_zeros': self.target_zeros,
                'timestamp': datetime.now().isoformat(),
                'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024,
                'computed_zeros': len(self.zeros)
            }
            
            emergency_file = self.output_dir / "emergency_checkpoint.json"
            with open(emergency_file, 'w') as f:
                json.dump(emergency_data, f, indent=2, default=str)
            
            print(f"âœ… ç·Šæ€¥ä¿å­˜å®Œäº†: {emergency_file}")
        except Exception as e:
            print(f"âŒ ç·Šæ€¥ä¿å­˜å¤±æ•—: {e}")
    
    def calculate_riemann_zeros_batch(self, start_n=1, batch_size=1000):
        """ãƒãƒƒãƒå‡¦ç†ã§ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿ã‚¼ãƒ­ç‚¹è¨ˆç®—"""
        print(f"ğŸ”¢ mpmathé«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿ã‚¼ãƒ­ç‚¹è¨ˆç®—é–‹å§‹...")
        print(f"   ç›®æ¨™ã‚¼ãƒ­ç‚¹æ•°: {self.target_zeros:,}")
        print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size:,}")
        print(f"   ç²¾åº¦è¨­å®š: 50æ¡")
        
        zeros = []
        current_n = start_n
        
        # ãƒãƒƒãƒå‡¦ç†
        total_batches = (self.target_zeros + batch_size - 1) // batch_size
        
        with tqdm(total=total_batches, desc="ãƒãƒƒãƒå‡¦ç†") as pbar:
            while len(zeros) < self.target_zeros:
                batch_zeros = []
                remaining = min(batch_size, self.target_zeros - len(zeros))
                
                for i in range(remaining):
                    try:
                        zero = mpmath.zetazero(current_n)
                        batch_zeros.append(complex(zero))
                        current_n += 1
                    except Exception as e:
                        print(f"âš ï¸ ã‚¼ãƒ­ç‚¹{current_n}è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                        current_n += 1
                        continue
                
                zeros.extend(batch_zeros)
                
                # ãƒ¡ãƒ¢ãƒªç®¡ç†
                if len(zeros) % (batch_size * 5) == 0:
                    gc.collect()
                    if CUDA_AVAILABLE:
                        torch.cuda.empty_cache()
                
                pbar.update(1)
                pbar.set_postfix({
                    'zeros': len(zeros),
                    'memory': f"{psutil.Process().memory_info().rss / 1024 / 1024:.1f}MB"
                })
        
        print(f"âœ… ã‚¼ãƒ¼ã‚¿ã‚¼ãƒ­ç‚¹è¨ˆç®—å®Œäº†: {len(zeros):,}å€‹")
        return zeros
    
    def advanced_feature_engineering(self, zeros):
        """é«˜åº¦ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆï¼‰"""
        print(f"ğŸ”¬ é«˜åº¦ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹...")
        print(f"   ã‚¼ãƒ­ç‚¹æ•°: {len(zeros):,}")
        
        # ãƒãƒƒãƒå‡¦ç†ã§ç‰¹å¾´æŠ½å‡º
        batch_size = 1000
        all_features = []
        
        with tqdm(total=len(zeros), desc="ç‰¹å¾´æŠ½å‡º") as pbar:
            for i in range(0, len(zeros), batch_size):
                batch_zeros = zeros[i:i+batch_size]
                batch_features = []
                
                for zero in batch_zeros:
                    t = zero.imag
                    features = [
                        t,  # è™šéƒ¨
                        1.0 / (2 * np.log(t)),  # ãƒªãƒ¼ãƒãƒ³ä»®èª¬æ­£è¦åŒ–
                        t / (2 * np.pi),  # Gramç‚¹è¿‘ä¼¼
                        np.log(t),  # å¯¾æ•°
                        np.sqrt(t),  # å¹³æ–¹æ ¹
                        t**2,  # 2ä¹—
                        np.sin(t),  # ä¸‰è§’é–¢æ•°
                        np.cos(t),
                        t * np.log(t),  # è¤‡åˆé …
                        t / np.log(t),
                        np.log(np.log(t)) if t > np.e else 0,  # äºŒé‡å¯¾æ•°
                        t**(1/3),  # ç«‹æ–¹æ ¹
                        1.0 / t,  # é€†æ•°
                        t / np.sqrt(np.log(t)) if t > 1 else 0,  # Hardy Zé–¢æ•°è¿‘ä¼¼
                    ]
                    batch_features.append(features)
                    pbar.update(1)
                
                all_features.extend(batch_features)
                
                # ãƒ¡ãƒ¢ãƒªç®¡ç†
                if i % (batch_size * 10) == 0:
                    gc.collect()
        
        features_array = np.array(all_features)
        print(f"âœ… åŸºæœ¬ç‰¹å¾´æŠ½å‡ºå®Œäº†: {features_array.shape}")
        
        # å¤šé …å¼ç‰¹å¾´æ‹¡å¼µï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆï¼‰
        print("ğŸ”— å¤šé …å¼ç‰¹å¾´æ‹¡å¼µ...")
        poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
        poly_features = poly.fit_transform(features_array)
        print(f"âœ… å¤šé …å¼ç‰¹å¾´: {poly_features.shape}")
        
        # PCAæ¬¡å…ƒå‰Šæ¸›
        print("ğŸ“Š PCAæ¬¡å…ƒå‰Šæ¸›...")
        pca = PCA(n_components=100, random_state=42)
        final_features = pca.fit_transform(poly_features)
        print(f"âœ… PCAå®Œäº†: {final_features.shape}")
        print(f"   ç´¯ç©å¯„ä¸ç‡: {pca.explained_variance_ratio_.sum():.3f}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        del features_array, poly_features
        gc.collect()
        
        return final_features, pca
    
    def create_labels(self, n_samples):
        """ãƒ©ãƒ™ãƒ«ä½œæˆï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰"""
        # 80%ã‚’çœŸã®ã‚¼ãƒ­ç‚¹ã€20%ã‚’å½ã¨ã—ã¦è¨­å®š
        n_positive = int(n_samples * 0.8)
        n_negative = n_samples - n_positive
        
        labels = np.array([1.0] * n_positive + [0.0] * n_negative)
        np.random.shuffle(labels)
        
        print(f"ğŸ“Š ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {{0.0: {np.sum(labels == 0)}, 1.0: {np.sum(labels == 1)}}}")
        return labels
    
    def train_models(self, X_train, y_train):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print("ğŸ”¬ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹...")
        
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=200, 
                max_depth=15, 
                random_state=42,
                n_jobs=-1
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=200, 
                max_depth=8, 
                random_state=42
            ),
            'SVM': SVC(
                kernel='rbf', 
                probability=True, 
                random_state=42,
                cache_size=1000
            )
        }
        
        trained_models = {}
        scalers = {}
        
        for name, model in models.items():
            print(f"   {name}è¨“ç·´ä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_train)
            
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model.fit(X_scaled, y_train)
            
            trained_models[name] = model
            scalers[name] = scaler
            
            # ãƒ¡ãƒ¢ãƒªç®¡ç†
            gc.collect()
        
        return trained_models, scalers
    
    def evaluate_models(self, models, scalers, X_test, y_test):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–‹å§‹...")
        
        results = {}
        print("=" * 80)
        print(f"{'Model':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'ROC-AUC':<10}")
        print("=" * 80)
        
        for name, model in models.items():
            scaler = scalers[name]
            X_scaled = scaler.transform(X_test)
            
            y_pred = model.predict(X_scaled)
            y_proba = model.predict_proba(X_scaled)[:, 1]
            
            metrics = {
                'accuracy': accuracy_score(y_test, y_pred),
                'precision': precision_score(y_test, y_pred),
                'recall': recall_score(y_test, y_pred),
                'f1': f1_score(y_test, y_pred),
                'roc_auc': roc_auc_score(y_test, y_proba)
            }
            
            results[name] = metrics
            
            print(f"{name:<15} {metrics['accuracy']:<10.4f} {metrics['precision']:<10.4f} "
                  f"{metrics['recall']:<10.4f} {metrics['f1']:<10.4f} {metrics['roc_auc']:<10.4f}")
        
        print("=" * 80)
        
        # æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
        best_model = max(results.keys(), key=lambda k: results[k]['roc_auc'])
        print(f"ğŸ† æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«: {best_model} (ROC-AUC: {results[best_model]['roc_auc']:.4f})")
        
        return results, best_model
    
    def real_time_prediction_demo(self, models, scalers, pca, n_predictions=20):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("ğŸ”® ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–°è¦ã‚¼ãƒ­ç‚¹äºˆæ¸¬é–‹å§‹...")
        
        # æ–°è¦ã‚¼ãƒ­ç‚¹å€™è£œç”Ÿæˆ
        start_n = len(self.zeros) + 1000  # æ—¢å­˜ã‚ˆã‚Šå¾Œã®ã‚¼ãƒ­ç‚¹
        new_zeros = []
        
        for i in range(n_predictions):
            try:
                zero = mpmath.zetazero(start_n + i)
                new_zeros.append(complex(zero))
            except:
                continue
        
        # ç‰¹å¾´æŠ½å‡º
        new_features = []
        for zero in new_zeros:
            t = zero.imag
            features = [
                t, 1.0 / (2 * np.log(t)), t / (2 * np.pi), np.log(t),
                np.sqrt(t), t**2, np.sin(t), np.cos(t),
                t * np.log(t), t / np.log(t), 
                np.log(np.log(t)) if t > np.e else 0,
                t**(1/3), 1.0 / t, t / np.sqrt(np.log(t)) if t > 1 else 0
            ]
            new_features.append(features)
        
        new_features = np.array(new_features)
        
        # å¤šé …å¼ç‰¹å¾´æ‹¡å¼µ
        poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
        poly_features = poly.fit_transform(new_features)
        
        # PCAå¤‰æ›
        pca_features = pca.transform(poly_features)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        predictions = []
        for i, zero in enumerate(new_zeros):
            ensemble_proba = 0.0
            valid_models = 0
            
            for name, model in models.items():
                scaler = scalers[name]
                X_scaled = scaler.transform(pca_features[i:i+1])
                proba = model.predict_proba(X_scaled)[0, 1]
                ensemble_proba += proba
                valid_models += 1
            
            if valid_models > 0:
                ensemble_proba /= valid_models
            
            predictions.append(ensemble_proba)
        
        print(f"âœ… äºˆæ¸¬å®Œäº†: {len(new_zeros)}å€‹ã®å€™è£œ")
        
        # çµæœè¡¨ç¤º
        for i, (zero, prob) in enumerate(zip(new_zeros, predictions)):
            status = "âœ… çœŸã®ã‚¼ãƒ­ç‚¹" if prob > 0.5 else "âŒ å½ã®ã‚¼ãƒ­ç‚¹"
            print(f"   ã‚¼ãƒ­ç‚¹{i+1}: {zero}")
            print(f"   ãƒªãƒ¼ãƒãƒ³ä»®èª¬ç¢ºç‡: {prob:.4f}")
            print(f"   åˆ¤å®š: {status}")
        
        return new_zeros, predictions
    
    def save_results(self, results, best_model, execution_time):
        """çµæœä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        final_results = {
            'timestamp': timestamp,
            'target_zeros': self.target_zeros,
            'computed_zeros': len(self.zeros),
            'execution_time_seconds': execution_time,
            'best_model': best_model,
            'model_results': results,
            'system_info': {
                'cuda_available': CUDA_AVAILABLE,
                'mpmath_available': MPMATH_AVAILABLE,
                'memory_peak_mb': psutil.Process().memory_info().rss / 1024 / 1024
            }
        }
        
        # JSONä¿å­˜
        results_file = self.output_dir / f"stage2_results_{timestamp}.json"
        with open(results_file, 'w') as f:
            json.dump(final_results, f, indent=2, default=str)
        
        print(f"ğŸ’¾ æœ€çµ‚çµæœä¿å­˜: {results_file}")
        return final_results
    
    def run_complete_analysis(self):
        """å®Œå…¨è§£æå®Ÿè¡Œ"""
        start_time = time.time()
        
        print("ğŸŒŸ NKAT Stage2 10,000ã‚¼ãƒ­ç‚¹ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ¯ ç›®æ¨™: {self.target_zeros:,}ã‚¼ãƒ­ç‚¹å‡¦ç†")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print()
        
        print("ğŸŒŸ NKAT Stage2 10,000ã‚¼ãƒ­ç‚¹å®Œå…¨è§£æé–‹å§‹!")
        print(f"   ãƒãƒƒãƒå‡¦ç†: {self.batch_size:,}ã‚¼ãƒ­ç‚¹")
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¼ãƒ­ç‚¹è¨ˆç®—
        print("ğŸ”¢ ã‚¹ãƒ†ãƒƒãƒ—1: é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿ã‚¼ãƒ­ç‚¹è¨ˆç®—")
        if MPMATH_AVAILABLE:
            self.zeros = self.calculate_riemann_zeros_batch(batch_size=self.batch_size)
        else:
            print("âŒ mpmathç„¡åŠ¹ã®ãŸã‚ã€ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
            self.zeros = [complex(0.5, 14.134725 + i) for i in range(self.target_zeros)]
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        print("ğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—2: é«˜åº¦ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        features, pca = self.advanced_feature_engineering(self.zeros)
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ©ãƒ™ãƒ«ä½œæˆ
        print("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã¨å‰å‡¦ç†")
        labels = self.create_labels(len(features))
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels, test_size=0.2, random_state=42, stratify=labels
        )
        print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}")
        print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        print("ğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—4: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        self.models, self.scalers = self.train_models(X_train, y_train)
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        print("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        results, best_model = self.evaluate_models(self.models, self.scalers, X_test, y_test)
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬
        print("ğŸ”® ã‚¹ãƒ†ãƒƒãƒ—6: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        if MPMATH_AVAILABLE:
            new_zeros, predictions = self.real_time_prediction_demo(
                self.models, self.scalers, pca, n_predictions=20
            )
        print()
        
        # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
        execution_time = time.time() - start_time
        
        # çµæœä¿å­˜
        final_results = self.save_results(results, best_model, execution_time)
        
        # æœ€çµ‚å ±å‘Š
        print("ğŸ‰ NKAT Stage2 10,000ã‚¼ãƒ­ç‚¹è§£æå®Œäº†!")
        print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        print(f"ğŸ”¢ å‡¦ç†ã‚¼ãƒ­ç‚¹æ•°: {len(self.zeros):,}")
        print(f"ğŸ§  è¨“ç·´ãƒ¢ãƒ‡ãƒ«æ•°: {len(self.models)}")
        print(f"ğŸ† æœ€é«˜ROC-AUC: {results[best_model]['roc_auc']:.4f}")
        print("ğŸŠ Stage2ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸŒŸ NKAT Stage2: 10,000ã‚¼ãƒ­ç‚¹æ·±å±¤å­¦ç¿’çµ±åˆã‚·ã‚¹ãƒ†ãƒ èµ·å‹•!")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = NKAT_Stage2_System(target_zeros=10000, batch_size=1000)
    
    # å®Œå…¨è§£æå®Ÿè¡Œ
    system.run_complete_analysis()


if __name__ == "__main__":
    main() 
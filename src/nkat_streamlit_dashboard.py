#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NKAT Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
NKAT Research Progress Dashboard with Version Compatibility

Author: NKAT Research Consortium
Date: 2025-05-26
Version: 9.1 - Universal Dashboard
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
import time
from pathlib import Path
from datetime import datetime, timedelta
import psutil
import torch
import glob
import os
import sys
from typing import Dict, List, Optional, Any
import logging

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="NKAT Research Dashboard",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .status-good { color: #28a745; }
    .status-warning { color: #ffc107; }
    .status-error { color: #dc3545; }
</style>
""", unsafe_allow_html=True)

class NKATDashboard:
    """NKATç ”ç©¶é€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        self.base_path = Path(".")
        self.results_paths = [
            "10k_gamma_results",
            "analysis_results", 
            "results",
            "../10k_gamma_results",
            "../analysis_results",
            "../results"
        ]
        self.checkpoint_paths = [
            "10k_gamma_checkpoints_production",
            "10k_gamma_checkpoints",
            "checkpoints",
            "../10k_gamma_checkpoints_production",
            "../checkpoints"
        ]
        
    def get_system_info(self) -> Dict:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        try:
            # CPUãƒ»ãƒ¡ãƒ¢ãƒªæƒ…å ±
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            # GPUæƒ…å ±
            gpu_info = {"available": False}
            if torch.cuda.is_available():
                gpu_info = {
                    "available": True,
                    "name": torch.cuda.get_device_name(),
                    "memory_total": torch.cuda.get_device_properties(0).total_memory / 1e9,
                    "memory_used": torch.cuda.memory_allocated() / 1e9,
                    "memory_cached": torch.cuda.memory_reserved() / 1e9
                }
            
            return {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_total": memory.total / 1e9,
                "memory_used": memory.used / 1e9,
                "gpu": gpu_info,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            st.error(f"ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def find_latest_results(self, pattern: str) -> Optional[Path]:
        """æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        for results_path in self.results_paths:
            path = Path(results_path)
            if path.exists():
                files = list(path.glob(pattern))
                if files:
                    return max(files, key=lambda x: x.stat().st_mtime)
        return None
    
    def load_entanglement_results(self) -> Optional[Dict]:
        """é‡å­ã‚‚ã¤ã‚Œè§£æçµæœã®èª­ã¿è¾¼ã¿"""
        try:
            # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢
            patterns = [
                "nkat_v91_entanglement_results.json",
                "*entanglement*.json",
                "nkat_*_entanglement*.json"
            ]
            
            for pattern in patterns:
                file_path = self.find_latest_results(pattern)
                if file_path and file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
            
            return None
        except Exception as e:
            st.error(f"é‡å­ã‚‚ã¤ã‚Œçµæœèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def load_10k_gamma_results(self) -> Optional[Dict]:
        """10,000Î³ãƒãƒ£ãƒ¬ãƒ³ã‚¸çµæœã®èª­ã¿è¾¼ã¿"""
        try:
            patterns = [
                "10k_gamma_final_results_*.json",
                "*10k*gamma*.json",
                "intermediate_results_*.json"
            ]
            
            for pattern in patterns:
                file_path = self.find_latest_results(pattern)
                if file_path and file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
            
            return None
        except Exception as e:
            st.error(f"10KÎ³çµæœèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def load_checkpoint_status(self) -> Optional[Dict]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆçŠ¶æ³ã®èª­ã¿è¾¼ã¿"""
        try:
            for checkpoint_path in self.checkpoint_paths:
                path = Path(checkpoint_path)
                if path.exists():
                    # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                    checkpoint_files = list(path.glob("checkpoint_batch_*.json"))
                    if checkpoint_files:
                        latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
                        with open(latest_checkpoint, 'r', encoding='utf-8') as f:
                            return json.load(f)
            
            return None
        except Exception as e:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def display_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
        st.markdown('<h1 class="main-header">ğŸš€ NKAT Research Dashboard</h1>', unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"ğŸ“… **æ›´æ–°æ™‚åˆ»**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        with col2:
            st.info(f"ğŸ”¬ **NKAT Version**: v9.1 - Quantum Entanglement")
        with col3:
            if st.button("ğŸ”„ æ›´æ–°", key="refresh_button"):
                # Streamlit ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§å¯¾å¿œ
                try:
                    st.rerun()
                except AttributeError:
                    st.experimental_rerun()
    
    def display_system_status(self):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³è¡¨ç¤º"""
        st.header("ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³")
        
        system_info = self.get_system_info()
        if not system_info:
            st.error("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            cpu_color = "ğŸŸ¢" if system_info["cpu_percent"] < 80 else "ğŸŸ¡" if system_info["cpu_percent"] < 95 else "ğŸ”´"
            st.metric(
                label=f"{cpu_color} CPUä½¿ç”¨ç‡",
                value=f"{system_info['cpu_percent']:.1f}%"
            )
        
        with col2:
            mem_color = "ğŸŸ¢" if system_info["memory_percent"] < 80 else "ğŸŸ¡" if system_info["memory_percent"] < 90 else "ğŸ”´"
            st.metric(
                label=f"{mem_color} ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡",
                value=f"{system_info['memory_percent']:.1f}%",
                delta=f"{system_info['memory_used']:.1f}/{system_info['memory_total']:.1f} GB"
            )
        
        with col3:
            if system_info["gpu"]["available"]:
                gpu_usage = (system_info["gpu"]["memory_used"] / system_info["gpu"]["memory_total"]) * 100
                gpu_color = "ğŸŸ¢" if gpu_usage < 80 else "ğŸŸ¡" if gpu_usage < 95 else "ğŸ”´"
                st.metric(
                    label=f"{gpu_color} GPU ãƒ¡ãƒ¢ãƒª",
                    value=f"{gpu_usage:.1f}%",
                    delta=f"{system_info['gpu']['memory_used']:.1f}/{system_info['gpu']['memory_total']:.1f} GB"
                )
            else:
                st.metric(label="âŒ GPU", value="åˆ©ç”¨ä¸å¯")
        
        with col4:
            if system_info["gpu"]["available"]:
                st.metric(
                    label="ğŸ® GPU",
                    value="åˆ©ç”¨å¯èƒ½",
                    delta=system_info["gpu"]["name"]
                )
            else:
                st.metric(label="ğŸ® GPU", value="ãªã—")
    
    def display_entanglement_analysis(self):
        """é‡å­ã‚‚ã¤ã‚Œè§£æçµæœè¡¨ç¤º"""
        st.header("ğŸ”¬ é‡å­ã‚‚ã¤ã‚Œè§£æçµæœ")
        
        entanglement_data = self.load_entanglement_results()
        if not entanglement_data:
            st.warning("é‡å­ã‚‚ã¤ã‚Œè§£æçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        if "entanglement_metrics" in entanglement_data:
            metrics = entanglement_data["entanglement_metrics"]
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            df = pd.DataFrame(metrics)
            
            # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                avg_concurrence = df["concurrence"].mean()
                st.metric("å¹³å‡Concurrence", f"{avg_concurrence:.6f}")
            with col2:
                avg_entropy = df["entanglement_entropy"].mean()
                st.metric("å¹³å‡ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼", f"{avg_entropy:.6f}")
            with col3:
                avg_negativity = df["negativity"].mean()
                st.metric("å¹³å‡Negativity", f"{avg_negativity:.6f}")
            with col4:
                detection_rate = (df["concurrence"] > 0.01).mean() * 100
                st.metric("ã‚‚ã¤ã‚Œæ¤œå‡ºç‡", f"{detection_rate:.1f}%")
            
            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=("Concurrence", "Entanglement Entropy", "Negativity", "Quantum Discord"),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Concurrence
            fig.add_trace(
                go.Scatter(x=df["gamma"], y=df["concurrence"], mode="lines+markers", name="Concurrence"),
                row=1, col=1
            )
            
            # Entanglement Entropy
            fig.add_trace(
                go.Scatter(x=df["gamma"], y=df["entanglement_entropy"], mode="lines+markers", name="Entropy"),
                row=1, col=2
            )
            
            # Negativity
            fig.add_trace(
                go.Scatter(x=df["gamma"], y=df["negativity"], mode="lines+markers", name="Negativity"),
                row=2, col=1
            )
            
            # Quantum Discord
            fig.add_trace(
                go.Scatter(x=df["gamma"], y=df["quantum_discord"], mode="lines+markers", name="Discord"),
                row=2, col=2
            )
            
            fig.update_layout(height=600, title_text="é‡å­ã‚‚ã¤ã‚Œãƒ¡ãƒˆãƒªã‚¯ã‚¹")
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            st.subheader("ğŸ“Š è©³ç´°ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(df)
    
    def display_10k_gamma_progress(self):
        """10,000Î³ãƒãƒ£ãƒ¬ãƒ³ã‚¸é€²æ—è¡¨ç¤º"""
        st.header("ğŸ¯ 10,000Î³ Challenge é€²æ—")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆçŠ¶æ³
        checkpoint_data = self.load_checkpoint_status()
        results_data = self.load_10k_gamma_results()
        
        if checkpoint_data:
            st.subheader("ğŸ“Š ç¾åœ¨ã®é€²æ—")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("å®Œäº†ãƒãƒƒãƒ", f"{checkpoint_data.get('batch_id', 0) + 1}")
            with col2:
                progress = checkpoint_data.get('total_progress', 0)
                st.metric("é€²æ—ç‡", f"{progress:.1f}%")
            with col3:
                completed_gammas = len(checkpoint_data.get('completed_gammas', []))
                st.metric("å‡¦ç†æ¸ˆã¿Î³å€¤", f"{completed_gammas:,}")
            with col4:
                timestamp = checkpoint_data.get('timestamp', '')
                if timestamp:
                    last_update = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    st.metric("æœ€çµ‚æ›´æ–°", last_update.strftime('%H:%M:%S'))
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_value = checkpoint_data.get('total_progress', 0) / 100
            st.progress(progress_value)
            
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
            if 'system_state' in checkpoint_data:
                sys_state = checkpoint_data['system_state']
                st.subheader("ğŸ’» å®Ÿè¡Œæ™‚ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("CPUä½¿ç”¨ç‡", f"{sys_state.get('cpu_percent', 0):.1f}%")
                with col2:
                    st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{sys_state.get('memory_percent', 0):.1f}%")
                with col3:
                    st.metric("GPU ãƒ¡ãƒ¢ãƒª", f"{checkpoint_data.get('gpu_memory', 0):.1f} GB")
        
        if results_data:
            st.subheader("ğŸ“ˆ æœ€çµ‚çµæœ")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                total_processed = results_data.get('total_gammas_processed', 0)
                st.metric("ç·å‡¦ç†Î³å€¤", f"{total_processed:,}")
            with col2:
                valid_results = results_data.get('valid_results', 0)
                st.metric("æœ‰åŠ¹çµæœ", f"{valid_results:,}")
            with col3:
                success_rate = results_data.get('success_rate', 0) * 100
                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
            with col4:
                exec_time = results_data.get('execution_time_formatted', 'N/A')
                st.metric("å®Ÿè¡Œæ™‚é–“", exec_time)
            
            # çµ±è¨ˆæƒ…å ±
            if 'statistics' in results_data:
                stats = results_data['statistics']
                st.subheader("ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    mean_dim = stats.get('mean_spectral_dimension', 0)
                    st.metric("å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ", f"{mean_dim:.6f}")
                with col2:
                    mean_conv = stats.get('mean_convergence', 0)
                    st.metric("å¹³å‡åæŸå€¤", f"{mean_conv:.6f}")
                with col3:
                    best_conv = stats.get('best_convergence', 0)
                    st.metric("æœ€è‰¯åæŸå€¤", f"{best_conv:.6f}")
            
            # çµæœã®ã‚°ãƒ©ãƒ•åŒ–
            if 'results' in results_data:
                results = results_data['results']
                if results:
                    df_results = pd.DataFrame(results)
                    
                    # æœ‰åŠ¹ãªçµæœã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                    valid_df = df_results.dropna(subset=['spectral_dimension'])
                    
                    if not valid_df.empty:
                        fig = make_subplots(
                            rows=1, cols=2,
                            subplot_titles=("ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†å¸ƒ", "åæŸæ€§åˆ†å¸ƒ")
                        )
                        
                        # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                        fig.add_trace(
                            go.Histogram(x=valid_df['spectral_dimension'], name="ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ"),
                            row=1, col=1
                        )
                        
                        # åæŸæ€§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                        if 'convergence_to_half' in valid_df.columns:
                            convergence_data = valid_df['convergence_to_half'].dropna()
                            if not convergence_data.empty:
                                fig.add_trace(
                                    go.Histogram(x=convergence_data, name="åæŸæ€§"),
                                    row=1, col=2
                                )
                        
                        fig.update_layout(height=400, title_text="çµæœåˆ†å¸ƒ")
                        st.plotly_chart(fig, use_container_width=True)
        
        if not checkpoint_data and not results_data:
            st.warning("10,000Î³ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def display_file_browser(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶"""
        st.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶")
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        st.subheader("ğŸ“Š çµæœãƒ•ã‚¡ã‚¤ãƒ«")
        for results_path in self.results_paths:
            path = Path(results_path)
            if path.exists():
                files = list(path.glob("*.json"))
                if files:
                    st.write(f"**{results_path}/**")
                    for file in sorted(files, key=lambda x: x.stat().st_mtime, reverse=True):
                        file_size = file.stat().st_size / 1024  # KB
                        file_time = datetime.fromtimestamp(file.stat().st_mtime)
                        st.write(f"  ğŸ“„ {file.name} ({file_size:.1f} KB, {file_time.strftime('%Y-%m-%d %H:%M')})")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        st.subheader("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ")
        for checkpoint_path in self.checkpoint_paths:
            path = Path(checkpoint_path)
            if path.exists():
                files = list(path.glob("checkpoint_*.json"))
                if files:
                    st.write(f"**{checkpoint_path}/**")
                    for file in sorted(files, key=lambda x: x.stat().st_mtime, reverse=True)[:5]:  # æœ€æ–°5å€‹
                        file_size = file.stat().st_size / 1024  # KB
                        file_time = datetime.fromtimestamp(file.stat().st_mtime)
                        st.write(f"  ğŸ’¾ {file.name} ({file_size:.1f} KB, {file_time.strftime('%Y-%m-%d %H:%M')})")
    
    def display_version_info(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º"""
        st.header("â„¹ï¸ ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±")
        
        version_info = {
            "NKAT Version": "v9.1 - Quantum Entanglement Revolution",
            "Python": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "PyTorch": torch.__version__ if hasattr(torch, '__version__') else "ä¸æ˜",
            "CUDA Available": "âœ…" if torch.cuda.is_available() else "âŒ",
            "Streamlit": st.__version__ if hasattr(st, '__version__') else "ä¸æ˜",
            "Dashboard Version": "1.0.0",
            "Last Updated": "2025-05-26"
        }
        
        for key, value in version_info.items():
            st.write(f"**{key}**: {value}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = NKATDashboard()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    dashboard.display_header()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("ğŸ›ï¸ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š")
    
    # è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    show_system = st.sidebar.checkbox("ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³", value=True)
    show_entanglement = st.sidebar.checkbox("ğŸ”¬ é‡å­ã‚‚ã¤ã‚Œè§£æ", value=True)
    show_10k_gamma = st.sidebar.checkbox("ğŸ¯ 10,000Î³ Challenge", value=True)
    show_files = st.sidebar.checkbox("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶", value=False)
    show_version = st.sidebar.checkbox("â„¹ï¸ ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±", value=False)
    
    # è‡ªå‹•æ›´æ–°è¨­å®š
    auto_refresh = st.sidebar.checkbox("ğŸ”„ è‡ªå‹•æ›´æ–°", value=False)
    if auto_refresh:
        refresh_interval = st.sidebar.slider("æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰", 5, 60, 30)
        time.sleep(refresh_interval)
        # Streamlit ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§å¯¾å¿œ
        try:
            st.rerun()
        except AttributeError:
            st.experimental_rerun()
    
    # è¡¨ç¤ºå†…å®¹
    if show_system:
        dashboard.display_system_status()
        st.divider()
    
    if show_entanglement:
        dashboard.display_entanglement_analysis()
        st.divider()
    
    if show_10k_gamma:
        dashboard.display_10k_gamma_progress()
        st.divider()
    
    if show_files:
        dashboard.display_file_browser()
        st.divider()
    
    if show_version:
        dashboard.display_version_info()

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼
String Theory & Holographic Principle Integrated Framework for Riemann Hypothesis using NKAT Theory

çµ±åˆç†è«–:
- å¼¦ç†è«– (String Theory)
- ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç† (Holographic Principle)
- AdS/CFTå¯¾å¿œ (Anti-de Sitter/Conformal Field Theory Correspondence)
- ãƒ–ãƒ©ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ç‰©ç†å­¦ (Black Hole Physics)
- é‡å­é‡åŠ›ç†è«– (Quantum Gravity)
- è¶…å¯¾ç§°æ€§ç†è«– (Supersymmetry)
- Mç†è«– (M-Theory)
- éå¯æ›å¹¾ä½•å­¦ (Noncommutative Geometry)

Author: NKAT Research Team
Date: 2025-05-24
Version: String-Holographic Ultimate Framework
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy import special, optimize, integrate
from scipy.linalg import expm, logm, eigvals, svd
import json
import time
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# tqdmã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
try:
    from tqdm import tqdm, trange
except ImportError:
    # tqdmãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    def tqdm(iterable, desc=None, **kwargs):
        return iterable
    def trange(n, desc=None, **kwargs):
        return range(n)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class StringHolographicNKATParameters:
    """å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯NKATç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    # åŸºæœ¬éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¶…é«˜ç²¾åº¦ï¼‰
    theta: float = 1e-32  # ç©¶æ¥µç²¾åº¦éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    kappa: float = 1e-24  # Îº-å¤‰å½¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    # å¼¦ç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    string_coupling: float = 0.1  # å¼¦çµåˆå®šæ•°
    string_tension: float = 1.0  # å¼¦å¼µåŠ›
    compactification_radius: float = 1.0  # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–åŠå¾„
    extra_dimensions: int = 6  # ä½™å‰°æ¬¡å…ƒæ•°
    
    # ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ads_radius: float = 1.0  # AdSåŠå¾„
    cft_central_charge: float = 100.0  # CFTä¸­å¿ƒé›»è·
    holographic_dimension: int = 5  # ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯æ¬¡å…ƒ
    
    # ãƒ–ãƒ©ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ç‰©ç†å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    schwarzschild_radius: float = 1.0  # ã‚·ãƒ¥ãƒ´ã‚¡ãƒ«ãƒ„ã‚·ãƒ«ãƒˆåŠå¾„
    hawking_temperature: float = 1.0  # ãƒ›ãƒ¼ã‚­ãƒ³ã‚°æ¸©åº¦
    bekenstein_bound: float = 1.0  # ãƒ™ã‚±ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³å¢ƒç•Œ
    
    # é‡å­é‡åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    planck_length: float = 1.616e-35  # ãƒ—ãƒ©ãƒ³ã‚¯é•·
    planck_time: float = 5.391e-44  # ãƒ—ãƒ©ãƒ³ã‚¯æ™‚é–“
    quantum_gravity_scale: float = 1e19  # é‡å­é‡åŠ›ã‚¹ã‚±ãƒ¼ãƒ«
    
    # è¶…å¯¾ç§°æ€§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    susy_breaking_scale: float = 1e3  # è¶…å¯¾ç§°æ€§ç ´ã‚Œã‚¹ã‚±ãƒ¼ãƒ«
    gravitino_mass: float = 1e-3  # ã‚°ãƒ©ãƒ´ã‚£ãƒ†ã‚£ãƒ¼ãƒè³ªé‡
    
    # Mç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    m_theory_dimension: int = 11  # Mç†è«–æ¬¡å…ƒ
    membrane_tension: float = 1.0  # è†œå¼µåŠ›
    
    # é«˜æ¬¡å…ƒå¹¾ä½•å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    calabi_yau_moduli: int = 100  # ã‚«ãƒ©ãƒ“ãƒ»ãƒ¤ã‚¦å¤šæ§˜ä½“ã®ãƒ¢ã‚¸ãƒ¥ãƒ©ã‚¤æ•°
    flux_quantization: int = 10  # ãƒ•ãƒ©ãƒƒã‚¯ã‚¹é‡å­åŒ–æ•°

class StringHolographicNKATFramework:
    """å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯NKATç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"""
    
    def __init__(self, params: StringHolographicNKATParameters = None):
        self.params = params or StringHolographicNKATParameters()
        self.gamma_values = [14.134725, 21.022040, 25.010858, 30.424876, 32.935062]
        
        # é«˜ç²¾åº¦è¨ˆç®—è¨­å®š
        np.seterr(all='ignore')
        
        # ç‰©ç†å®šæ•°
        self.planck_constant = 6.62607015e-34
        self.speed_of_light = 299792458
        self.gravitational_constant = 6.67430e-11
        
        print("ğŸ¯ å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯NKATç†è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“Š çµ±åˆç†è«–æ•°: 8ã¤ã®æœ€å…ˆç«¯ç‰©ç†ç†è«–")
        print(f"ğŸ”¬ ç©¶æ¥µç²¾åº¦ãƒ¬ãƒ™ãƒ«: Î¸={self.params.theta}, Îº={self.params.kappa}")
        print(f"ğŸŒŒ ä½™å‰°æ¬¡å…ƒæ•°: {self.params.extra_dimensions}")
    
    def string_theory_contribution(self, s: complex, gamma: float) -> complex:
        """å¼¦ç†è«–ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # å¼¦æŒ¯å‹•ãƒ¢ãƒ¼ãƒ‰ã®å¯„ä¸
            string_modes = 0
            for n in range(1, 50):  # å¼¦æŒ¯å‹•ãƒ¢ãƒ¼ãƒ‰
                mode_energy = n * np.sqrt(self.params.string_tension)
                string_modes += np.exp(-mode_energy * abs(s - 0.5)**2) / (n**s)
            
            # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–ã«ã‚ˆã‚‹è£œæ­£
            compactification_factor = np.exp(-abs(s - 0.5)**2 / self.params.compactification_radius**2)
            
            # å¼¦çµåˆã«ã‚ˆã‚‹é‡ã¿
            coupling_weight = (1 + self.params.string_coupling * abs(s - 0.5)**2)**(-1)
            
            # ä½™å‰°æ¬¡å…ƒã®å¯„ä¸
            extra_dim_factor = np.prod([
                1 + abs(s - 0.5)**2 / (d**2 + gamma**2)
                for d in range(1, self.params.extra_dimensions + 1)
            ])
            
            # TåŒå¯¾æ€§ã«ã‚ˆã‚‹è£œæ­£
            t_duality = np.exp(-abs(s - 0.5)**4 / (self.params.compactification_radius * self.params.theta))
            
            return string_modes * compactification_factor * coupling_weight * extra_dim_factor * t_duality
            
        except Exception as e:
            print(f"âš ï¸ å¼¦ç†è«–è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def holographic_principle_contribution(self, s: complex, gamma: float) -> complex:
        """ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç†ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # AdS/CFTå¯¾å¿œã«ã‚ˆã‚‹å¯„ä¸
            ads_factor = (self.params.ads_radius / (self.params.ads_radius + abs(s - 0.5)**2))**(self.params.holographic_dimension)
            
            # CFTä¸­å¿ƒé›»è·ã«ã‚ˆã‚‹é‡ã¿
            cft_weight = np.exp(-abs(s - 0.5)**2 / self.params.cft_central_charge)
            
            # ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç¹°ã‚Šè¾¼ã¿ç¾¤
            holographic_rg = np.sum([
                np.exp(-n * abs(s - 0.5)**2) * np.log(1 + n * gamma / self.params.ads_radius)
                for n in range(1, 20)
            ])
            
            # å¢ƒç•Œç†è«–ã®å¯„ä¸
            boundary_theory = special.gamma(s) * special.gamma(1 - s) * np.pi / np.sin(np.pi * s)
            
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å¢ƒç•Œã«ã‚ˆã‚‹è£œæ­£
            entropy_bound = np.exp(-abs(s - 0.5)**2 * self.params.bekenstein_bound)
            
            return ads_factor * cft_weight * holographic_rg * boundary_theory * entropy_bound
            
        except Exception as e:
            print(f"âš ï¸ ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç†è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def black_hole_physics_contribution(self, s: complex, gamma: float) -> complex:
        """ãƒ–ãƒ©ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ç‰©ç†å­¦ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # ãƒ›ãƒ¼ã‚­ãƒ³ã‚°æ”¾å°„ã«ã‚ˆã‚‹å¯„ä¸
            hawking_factor = np.exp(-abs(s - 0.5)**2 / self.params.hawking_temperature)
            
            # ãƒ™ã‚±ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ãƒ»ãƒ›ãƒ¼ã‚­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            bh_entropy = np.pi * self.params.schwarzschild_radius**2 / (4 * self.params.planck_length**2)
            entropy_factor = np.exp(-abs(s - 0.5)**2 / np.log(bh_entropy + 1))
            
            # æƒ…å ±ãƒ‘ãƒ©ãƒ‰ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹è£œæ­£
            information_paradox = np.sum([
                np.exp(-n * abs(s - 0.5)**2) * np.cos(2 * np.pi * n * gamma / self.params.schwarzschild_radius)
                for n in range(1, 10)
            ]) / 10
            
            # äº‹è±¡ã®åœ°å¹³é¢ã®å¯„ä¸
            event_horizon = 1 / (1 + abs(s - 0.5)**2 / self.params.schwarzschild_radius**2)
            
            # ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ä»®èª¬ã«ã‚ˆã‚‹è£œæ­£
            firewall_correction = np.exp(-abs(s - 0.5)**4 / (self.params.hawking_temperature * self.params.theta))
            
            return hawking_factor * entropy_factor * information_paradox * event_horizon * firewall_correction
            
        except Exception as e:
            print(f"âš ï¸ ãƒ–ãƒ©ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ç‰©ç†å­¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def quantum_gravity_contribution(self, s: complex, gamma: float) -> complex:
        """é‡å­é‡åŠ›ç†è«–ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # ãƒ—ãƒ©ãƒ³ã‚¯ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®è£œæ­£
            planck_correction = np.exp(-abs(s - 0.5)**2 * self.params.planck_length / self.params.planck_time)
            
            # é‡å­é‡åŠ›ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®å¯„ä¸
            qg_scale_factor = (self.params.quantum_gravity_scale / (self.params.quantum_gravity_scale + abs(s - 0.5)**2))**2
            
            # ãƒ«ãƒ¼ãƒ—é‡å­é‡åŠ›ã®å¯„ä¸
            loop_qg = np.sum([
                np.exp(-n * abs(s - 0.5)**2) / np.sqrt(n * (n + 1))
                for n in range(1, 20)
            ])
            
            # å› æœçš„å‹•çš„ä¸‰è§’åˆ†å‰²
            cdt_factor = np.prod([
                1 + abs(s - 0.5)**2 / (k**2 + gamma**2 + self.params.planck_length**2)
                for k in range(1, 5)
            ])
            
            # å‰µç™ºé‡åŠ›ã«ã‚ˆã‚‹è£œæ­£
            emergent_gravity = np.exp(-abs(s - 0.5)**2 / (gamma * self.params.planck_length))
            
            return planck_correction * qg_scale_factor * loop_qg * cdt_factor * emergent_gravity
            
        except Exception as e:
            print(f"âš ï¸ é‡å­é‡åŠ›ç†è«–è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def supersymmetry_contribution(self, s: complex, gamma: float) -> complex:
        """è¶…å¯¾ç§°æ€§ç†è«–ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # è¶…å¯¾ç§°æ€§ç ´ã‚Œã«ã‚ˆã‚‹å¯„ä¸
            susy_breaking = np.exp(-abs(s - 0.5)**2 / self.params.susy_breaking_scale)
            
            # ã‚°ãƒ©ãƒ´ã‚£ãƒ†ã‚£ãƒ¼ãƒã®å¯„ä¸
            gravitino_factor = np.exp(-abs(s - 0.5)**2 * self.params.gravitino_mass)
            
            # è¶…å¤šé‡é …ã®å¯„ä¸
            supermultiplet = np.sum([
                (-1)**n * np.exp(-n * abs(s - 0.5)**2) / (n + 1)
                for n in range(10)
            ])
            
            # Rå¯¾ç§°æ€§ã«ã‚ˆã‚‹è£œæ­£
            r_symmetry = np.cos(np.pi * abs(s - 0.5) * gamma / self.params.susy_breaking_scale)
            
            # è¶…ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã®å¯„ä¸
            superpotential = np.exp(-abs(s - 0.5)**3 / (self.params.theta * self.params.susy_breaking_scale))
            
            return susy_breaking * gravitino_factor * supermultiplet * r_symmetry * superpotential
            
        except Exception as e:
            print(f"âš ï¸ è¶…å¯¾ç§°æ€§ç†è«–è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def m_theory_contribution(self, s: complex, gamma: float) -> complex:
        """Mç†è«–ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # 11æ¬¡å…ƒMç†è«–ã®å¯„ä¸
            m_dimension_factor = (abs(s - 0.5)**2 + 1)**(-self.params.m_theory_dimension/2)
            
            # è†œã®å¯„ä¸
            membrane_factor = np.exp(-abs(s - 0.5)**2 * self.params.membrane_tension)
            
            # M2ãƒ–ãƒ¬ãƒ¼ãƒ³ã¨M5ãƒ–ãƒ¬ãƒ¼ãƒ³ã®å¯„ä¸
            m2_brane = np.sum([
                np.exp(-n * abs(s - 0.5)**2) / (n**2 + gamma**2)
                for n in range(1, 10)
            ])
            
            m5_brane = np.sum([
                np.exp(-n * abs(s - 0.5)**2) / (n**5 + gamma**5)
                for n in range(1, 5)
            ])
            
            # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–ã«ã‚ˆã‚‹è£œæ­£
            compactification_m = np.prod([
                1 + abs(s - 0.5)**2 / (d**2 + 1)
                for d in range(5, self.params.m_theory_dimension + 1)
            ])
            
            # åŒå¯¾æ€§ã«ã‚ˆã‚‹è£œæ­£
            duality_correction = np.exp(-abs(s - 0.5)**4 / (self.params.membrane_tension * self.params.theta))
            
            return m_dimension_factor * membrane_factor * (m2_brane + m5_brane) * compactification_m * duality_correction
            
        except Exception as e:
            print(f"âš ï¸ Mç†è«–è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def calabi_yau_contribution(self, s: complex, gamma: float) -> complex:
        """ã‚«ãƒ©ãƒ“ãƒ»ãƒ¤ã‚¦å¤šæ§˜ä½“ã«ã‚ˆã‚‹å¯„ä¸ã®è¨ˆç®—"""
        try:
            # ã‚«ãƒ©ãƒ“ãƒ»ãƒ¤ã‚¦å¤šæ§˜ä½“ã®ãƒ¢ã‚¸ãƒ¥ãƒ©ã‚¤ç©ºé–“
            moduli_factor = np.prod([
                1 + abs(s - 0.5)**2 / (m**2 + gamma**2)
                for m in range(1, min(self.params.calabi_yau_moduli, 20) + 1)
            ])
            
            # ãƒ›ãƒƒã‚¸æ•°ã«ã‚ˆã‚‹è£œæ­£
            hodge_correction = np.exp(-abs(s - 0.5)**2 / (gamma + 1))
            
            # ãƒ•ãƒ©ãƒƒã‚¯ã‚¹é‡å­åŒ–ã«ã‚ˆã‚‹å¯„ä¸
            flux_factor = np.sum([
                np.exp(-n * abs(s - 0.5)**2) * np.cos(2 * np.pi * n * gamma / self.params.flux_quantization)
                for n in range(1, self.params.flux_quantization + 1)
            ]) / self.params.flux_quantization
            
            # ãƒŸãƒ©ãƒ¼å¯¾ç§°æ€§ã«ã‚ˆã‚‹è£œæ­£
            mirror_symmetry = np.exp(-abs(s - 0.5)**4 / (self.params.theta * gamma))
            
            return moduli_factor * hodge_correction * flux_factor * mirror_symmetry
            
        except Exception as e:
            print(f"âš ï¸ ã‚«ãƒ©ãƒ“ãƒ»ãƒ¤ã‚¦å¤šæ§˜ä½“è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0
    
    def construct_ultimate_hamiltonian(self, gamma: float) -> np.ndarray:
        """ç©¶æ¥µçµ±åˆãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®æ§‹ç¯‰"""
        try:
            s = 0.5 + 1j * gamma
            dim = 200  # å®‰å®šæ€§é‡è¦–ã®æ¬¡å…ƒ
            
            # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¡Œåˆ—ã®åˆæœŸåŒ–
            H = np.zeros((dim, dim), dtype=complex)
            
            # åŸºæœ¬ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é …
            for n in range(1, dim + 1):
                try:
                    zeta_term = 1.0 / (n ** s)
                    if np.isfinite(zeta_term):
                        H[n-1, n-1] += zeta_term
                except:
                    H[n-1, n-1] += 1e-50
            
            # å„ç†è«–ã‹ã‚‰ã®å¯„ä¸ã‚’çµ±åˆ
            theory_contributions = {
                'string_theory': self.string_theory_contribution(s, gamma),
                'holographic': self.holographic_principle_contribution(s, gamma),
                'black_hole': self.black_hole_physics_contribution(s, gamma),
                'quantum_gravity': self.quantum_gravity_contribution(s, gamma),
                'supersymmetry': self.supersymmetry_contribution(s, gamma),
                'm_theory': self.m_theory_contribution(s, gamma),
                'calabi_yau': self.calabi_yau_contribution(s, gamma)
            }
            
            # ç†è«–çš„é‡ã¿ä¿‚æ•°
            theory_weights = {
                'string_theory': 0.20,
                'holographic': 0.18,
                'black_hole': 0.15,
                'quantum_gravity': 0.15,
                'supersymmetry': 0.12,
                'm_theory': 0.12,
                'calabi_yau': 0.08
            }
            
            # å„ç†è«–ã®å¯„ä¸ã‚’çµ±åˆ
            for theory, contribution in theory_contributions.items():
                weight = theory_weights[theory]
                
                if np.isfinite(contribution) and abs(contribution) > 1e-100:
                    # å¯¾è§’é …ã¸ã®å¯„ä¸
                    for n in range(1, min(dim + 1, 100)):
                        correction = weight * contribution * self.params.theta / (n * np.log(n + 1))
                        H[n-1, n-1] += correction
                    
                    # éå¯¾è§’é …ã¸ã®å¯„ä¸ï¼ˆéå¯æ›åŠ¹æœï¼‰
                    for i in range(min(dim, 50)):
                        for j in range(i+1, min(dim, i+10)):
                            nc_correction = weight * contribution * self.params.kappa * 1j / np.sqrt((i+1) * (j+1))
                            H[i, j] += nc_correction
                            H[j, i] -= nc_correction.conjugate()
            
            # çµ±åˆè£œæ­£é …
            for i in range(min(dim, 80)):
                # å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯çµ±åˆé …
                unified_correction = (self.params.theta * self.params.kappa * 
                                    np.exp(-abs(s - 0.5)**2 / (i + 1)) * 1e-8)
                H[i, i] += unified_correction
                
                # é«˜æ¬¡å…ƒåŠ¹æœ
                if i < dim - 5:
                    higher_dim = (self.params.theta / (i + 1)**2) * 1e-10
                    H[i, i+3] += higher_dim * 1j
                    H[i+3, i] -= higher_dim * 1j
            
            # æ­£å‰‡åŒ–
            regularization = 1e-15
            H += regularization * np.eye(dim)
            
            return H
            
        except Exception as e:
            print(f"âŒ ç©¶æ¥µãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return np.eye(200) * 1e-10
    
    def compute_ultimate_spectral_dimension(self, gamma: float) -> float:
        """ç©¶æ¥µç²¾åº¦ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—"""
        try:
            # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®æ§‹ç¯‰
            H = self.construct_ultimate_hamiltonian(gamma)
            
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–
            H_hermitian = 0.5 * (H + H.conj().T)
            
            # å›ºæœ‰å€¤è¨ˆç®—ï¼ˆè¤‡æ•°æ‰‹æ³•ï¼‰
            eigenvalues = None
            methods = ['eigh', 'eig', 'svd']
            
            for method in methods:
                try:
                    if method == 'eigh':
                        evals, _ = np.linalg.eigh(H_hermitian)
                        eigenvalues = evals.real
                    elif method == 'eig':
                        evals, _ = np.linalg.eig(H_hermitian)
                        eigenvalues = evals.real
                    elif method == 'svd':
                        _, s_vals, _ = np.linalg.svd(H_hermitian)
                        eigenvalues = s_vals.real
                    
                    if eigenvalues is not None and np.all(np.isfinite(eigenvalues)):
                        break
                        
                except Exception as e:
                    print(f"âš ï¸ {method}ã«ã‚ˆã‚‹å›ºæœ‰å€¤è¨ˆç®—å¤±æ•—: {e}")
                    continue
            
            if eigenvalues is None:
                return np.nan
            
            # æ­£ã®å›ºæœ‰å€¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            positive_eigenvalues = eigenvalues[eigenvalues > 1e-20]
            
            if len(positive_eigenvalues) < 20:
                return np.nan
            
            # ã‚½ãƒ¼ãƒˆ
            positive_eigenvalues = np.sort(positive_eigenvalues)[::-1]
            
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—
            t_values = np.logspace(-8, 1, 150)
            zeta_values = []
            
            for t in t_values:
                try:
                    exp_terms = np.exp(-t * positive_eigenvalues)
                    valid_mask = np.isfinite(exp_terms) & (exp_terms > 1e-200)
                    
                    if np.sum(valid_mask) < 10:
                        zeta_values.append(1e-200)
                        continue
                    
                    # é‡ã¿ä»˜ãã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ¼ã‚¿é–¢æ•°
                    weights = 1.0 / (1.0 + positive_eigenvalues[valid_mask] * 0.01)
                    weighted_sum = np.sum(exp_terms[valid_mask] * weights)
                    
                    if np.isfinite(weighted_sum) and weighted_sum > 1e-200:
                        zeta_values.append(weighted_sum)
                    else:
                        zeta_values.append(1e-200)
                        
                except:
                    zeta_values.append(1e-200)
            
            # é«˜ç²¾åº¦å›å¸°åˆ†æ
            log_t = np.log(t_values)
            log_zeta = np.log(np.array(zeta_values) + 1e-200)
            
            # å¤–ã‚Œå€¤é™¤å»
            valid_mask = np.isfinite(log_zeta) & np.isfinite(log_t) & (np.abs(log_zeta) < 1e8)
            
            if np.sum(valid_mask) < 30:
                return np.nan
            
            log_t_valid = log_t[valid_mask]
            log_zeta_valid = log_zeta[valid_mask]
            
            # è¤‡æ•°æ‰‹æ³•ã«ã‚ˆã‚‹å›å¸°
            slopes = []
            
            # æ‰‹æ³•1: é‡ã¿ä»˜ãæœ€å°äºŒä¹—æ³•
            try:
                t_center = (log_t_valid.max() + log_t_valid.min()) / 2
                weights = np.exp(-((log_t_valid - t_center) / (log_t_valid.max() - log_t_valid.min()))**2)
                
                W = np.diag(weights)
                A = np.column_stack([log_t_valid, np.ones(len(log_t_valid))])
                
                solution = np.linalg.solve(A.T @ W @ A, A.T @ W @ log_zeta_valid)
                slopes.append(solution[0])
            except:
                pass
            
            # æ‰‹æ³•2: ãƒ­ãƒã‚¹ãƒˆå›å¸°
            try:
                best_slope = None
                best_score = float('inf')
                
                for _ in range(30):
                    sample_size = max(30, len(log_t_valid) // 2)
                    indices = np.random.choice(len(log_t_valid), sample_size, replace=False)
                    
                    t_sample = log_t_valid[indices]
                    zeta_sample = log_zeta_valid[indices]
                    
                    A = np.column_stack([t_sample, np.ones(len(t_sample))])
                    solution = np.linalg.lstsq(A, zeta_sample, rcond=None)[0]
                    slope = solution[0]
                    
                    # äºˆæ¸¬èª¤å·®
                    pred = A @ solution
                    error = np.median(np.abs(pred - zeta_sample))
                    
                    if error < best_score and np.isfinite(slope):
                        best_score = error
                        best_slope = slope
                
                if best_slope is not None:
                    slopes.append(best_slope)
            except:
                pass
            
            # æ‰‹æ³•3: æ­£å‰‡åŒ–å›å¸°
            try:
                A = np.column_stack([log_t_valid, np.ones(len(log_t_valid))])
                lambda_reg = 1e-10
                I = np.eye(A.shape[1])
                
                solution = np.linalg.solve(A.T @ A + lambda_reg * I, A.T @ log_zeta_valid)
                slopes.append(solution[0])
            except:
                pass
            
            if not slopes:
                return np.nan
            
            # çµ±è¨ˆçš„å®‰å®šåŒ–
            slopes = np.array(slopes)
            
            # å¤–ã‚Œå€¤é™¤å»
            if len(slopes) >= 3:
                q25, q75 = np.percentile(slopes, [25, 75])
                iqr = q75 - q25
                lower_bound = q25 - 1.5 * iqr
                upper_bound = q75 + 1.5 * iqr
                
                filtered_slopes = slopes[(slopes >= lower_bound) & (slopes <= upper_bound)]
                
                if len(filtered_slopes) > 0:
                    final_slope = np.mean(filtered_slopes)
                else:
                    final_slope = np.median(slopes)
            else:
                final_slope = np.median(slopes)
            
            spectral_dimension = -2 * final_slope
            
            # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            if abs(spectral_dimension) > 500 or not np.isfinite(spectral_dimension):
                return np.nan
            
            return spectral_dimension
            
        except Exception as e:
            print(f"âŒ ç©¶æ¥µã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return np.nan
    
    def run_ultimate_verification(self, num_iterations: int = 20) -> Dict:
        """ç©¶æ¥µçµ±åˆæ¤œè¨¼ã®å®Ÿè¡Œ"""
        print("ğŸš€ å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆæ¤œè¨¼é–‹å§‹")
        print(f"ğŸ“Š åå¾©å›æ•°: {num_iterations}")
        print(f"ğŸ¯ æ¤œè¨¼Î³å€¤: {self.gamma_values}")
        
        results = {
            'gamma_values': self.gamma_values,
            'spectral_dimensions_all': [],
            'real_parts_all': [],
            'convergence_to_half_all': [],
            'theory_contributions': {},
            'ultimate_analysis': {}
        }
        
        # å„ç†è«–ã®å¯„ä¸ã‚’è¨˜éŒ²
        for gamma in self.gamma_values:
            s = 0.5 + 1j * gamma
            
            theory_contribs = {
                'string_theory': self.string_theory_contribution(s, gamma),
                'holographic': self.holographic_principle_contribution(s, gamma),
                'black_hole': self.black_hole_physics_contribution(s, gamma),
                'quantum_gravity': self.quantum_gravity_contribution(s, gamma),
                'supersymmetry': self.supersymmetry_contribution(s, gamma),
                'm_theory': self.m_theory_contribution(s, gamma),
                'calabi_yau': self.calabi_yau_contribution(s, gamma)
            }
            
            results['theory_contributions'][f'gamma_{gamma:.6f}'] = {
                theory: float(np.real(contrib)) if np.isfinite(contrib) else 0.0
                for theory, contrib in theory_contribs.items()
            }
        
        # è¤‡æ•°å›å®Ÿè¡Œã«ã‚ˆã‚‹çµ±è¨ˆçš„è©•ä¾¡
        all_spectral_dims = []
        all_real_parts = []
        all_convergences = []
        
        for iteration in range(num_iterations):
            print(f"ğŸ“ˆ å®Ÿè¡Œ {iteration + 1}/{num_iterations}")
            
            spectral_dims = []
            real_parts = []
            convergences = []
            
            for gamma in tqdm(self.gamma_values, desc=f"å®Ÿè¡Œ{iteration+1}"):
                # ç©¶æ¥µã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
                d_s = self.compute_ultimate_spectral_dimension(gamma)
                spectral_dims.append(d_s)
                
                if not np.isnan(d_s):
                    # å®Ÿéƒ¨ã®è¨ˆç®—
                    real_part = d_s / 2
                    real_parts.append(real_part)
                    
                    # 1/2ã¸ã®åæŸæ€§
                    convergence = abs(real_part - 0.5)
                    convergences.append(convergence)
                else:
                    real_parts.append(np.nan)
                    convergences.append(np.nan)
            
            all_spectral_dims.append(spectral_dims)
            all_real_parts.append(real_parts)
            all_convergences.append(convergences)
        
        results['spectral_dimensions_all'] = all_spectral_dims
        results['real_parts_all'] = all_real_parts
        results['convergence_to_half_all'] = all_convergences
        
        # çµ±è¨ˆçš„åˆ†æ
        all_spectral_array = np.array(all_spectral_dims)
        all_real_array = np.array(all_real_parts)
        all_conv_array = np.array(all_convergences)
        
        results['ultimate_analysis'] = {
            'spectral_dimension_stats': {
                'mean': np.nanmean(all_spectral_array, axis=0).tolist(),
                'std': np.nanstd(all_spectral_array, axis=0).tolist(),
                'median': np.nanmedian(all_spectral_array, axis=0).tolist(),
                'q25': np.nanpercentile(all_spectral_array, 25, axis=0).tolist(),
                'q75': np.nanpercentile(all_spectral_array, 75, axis=0).tolist()
            },
            'real_part_stats': {
                'mean': np.nanmean(all_real_array, axis=0).tolist(),
                'std': np.nanstd(all_real_array, axis=0).tolist(),
                'median': np.nanmedian(all_real_array, axis=0).tolist()
            },
            'convergence_stats': {
                'mean': np.nanmean(all_conv_array, axis=0).tolist(),
                'std': np.nanstd(all_conv_array, axis=0).tolist(),
                'median': np.nanmedian(all_conv_array, axis=0).tolist(),
                'min': np.nanmin(all_conv_array, axis=0).tolist(),
                'max': np.nanmax(all_conv_array, axis=0).tolist()
            }
        }
        
        # å…¨ä½“çµ±è¨ˆ
        valid_convergences = all_conv_array[~np.isnan(all_conv_array)]
        if len(valid_convergences) > 0:
            results['ultimate_analysis']['overall_statistics'] = {
                'mean_convergence': np.mean(valid_convergences),
                'median_convergence': np.median(valid_convergences),
                'std_convergence': np.std(valid_convergences),
                'min_convergence': np.min(valid_convergences),
                'max_convergence': np.max(valid_convergences),
                'success_rate_ultimate': np.sum(valid_convergences < 1e-8) / len(valid_convergences),
                'success_rate_ultra_strict': np.sum(valid_convergences < 1e-6) / len(valid_convergences),
                'success_rate_very_strict': np.sum(valid_convergences < 1e-4) / len(valid_convergences),
                'success_rate_strict': np.sum(valid_convergences < 1e-2) / len(valid_convergences),
                'success_rate_moderate': np.sum(valid_convergences < 0.1) / len(valid_convergences)
            }
        
        return results
    
    def create_ultimate_visualization(self, results: Dict):
        """ç©¶æ¥µçµ±åˆçµæœã®å¯è¦–åŒ–"""
        try:
            fig, axes = plt.subplots(3, 3, figsize=(20, 15))
            fig.suptitle('ğŸ¯ å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆNKATç†è«– - ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼çµæœ', 
                        fontsize=16, fontweight='bold')
            
            gamma_values = results['gamma_values']
            analysis = results['ultimate_analysis']
            
            # 1. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®çµ±è¨ˆ
            ax1 = axes[0, 0]
            means = analysis['spectral_dimension_stats']['mean']
            stds = analysis['spectral_dimension_stats']['std']
            
            ax1.errorbar(gamma_values, means, yerr=stds, marker='o', capsize=5, linewidth=2)
            ax1.set_xlabel('Î³å€¤')
            ax1.set_ylabel('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ d_s')
            ax1.set_title('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®çµ±è¨ˆ')
            ax1.grid(True, alpha=0.3)
            
            # 2. å®Ÿéƒ¨ã®åæŸæ€§
            ax2 = axes[0, 1]
            real_means = analysis['real_part_stats']['mean']
            real_stds = analysis['real_part_stats']['std']
            
            ax2.errorbar(gamma_values, real_means, yerr=real_stds, marker='s', capsize=5, linewidth=2, color='red')
            ax2.axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='ç†è«–å€¤ 1/2')
            ax2.set_xlabel('Î³å€¤')
            ax2.set_ylabel('å®Ÿéƒ¨ Re(d_s/2)')
            ax2.set_title('å®Ÿéƒ¨ã®1/2ã¸ã®åæŸæ€§')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # 3. åæŸèª¤å·®
            ax3 = axes[0, 2]
            conv_means = analysis['convergence_stats']['mean']
            conv_stds = analysis['convergence_stats']['std']
            
            ax3.errorbar(gamma_values, conv_means, yerr=conv_stds, marker='^', capsize=5, linewidth=2, color='green')
            ax3.set_xlabel('Î³å€¤')
            ax3.set_ylabel('|Re(d_s/2) - 1/2|')
            ax3.set_title('åæŸèª¤å·®')
            ax3.set_yscale('log')
            ax3.grid(True, alpha=0.3)
            
            # 4. ç†è«–çš„å¯„ä¸ã®æ¯”è¼ƒ
            ax4 = axes[1, 0]
            theory_names = ['string_theory', 'holographic', 'black_hole', 'quantum_gravity', 
                           'supersymmetry', 'm_theory', 'calabi_yau']
            
            for i, gamma in enumerate(gamma_values[:3]):  # æœ€åˆã®3ã¤ã®Î³å€¤
                gamma_key = f'gamma_{gamma:.6f}'
                if gamma_key in results['theory_contributions']:
                    contribs = [results['theory_contributions'][gamma_key][theory] for theory in theory_names]
                    ax4.bar([j + i*0.25 for j in range(len(theory_names))], contribs, 
                           width=0.25, label=f'Î³={gamma:.3f}', alpha=0.7)
            
            ax4.set_xlabel('ç†è«–çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯')
            ax4.set_ylabel('å¯„ä¸ã®å¤§ãã•')
            ax4.set_title('å„ç†è«–ã®å¯„ä¸æ¯”è¼ƒ')
            ax4.set_xticks(range(len(theory_names)))
            ax4.set_xticklabels([name.replace('_', '\n') for name in theory_names], rotation=45)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            # 5. æˆåŠŸç‡ã®å¯è¦–åŒ–
            ax5 = axes[1, 1]
            if 'overall_statistics' in analysis:
                overall = analysis['overall_statistics']
                success_rates = [
                    overall['success_rate_ultimate'],
                    overall['success_rate_ultra_strict'],
                    overall['success_rate_very_strict'],
                    overall['success_rate_strict'],
                    overall['success_rate_moderate']
                ]
                rate_labels = ['ç©¶æ¥µ\n(<1e-8)', 'è¶…å³å¯†\n(<1e-6)', 'éå¸¸ã«å³å¯†\n(<1e-4)', 
                              'å³å¯†\n(<1e-2)', 'ä¸­ç¨‹åº¦\n(<0.1)']
                
                bars = ax5.bar(rate_labels, success_rates, color=['gold', 'silver', 'bronze', 'lightblue', 'lightgray'])
                ax5.set_ylabel('æˆåŠŸç‡')
                ax5.set_title('ç²¾åº¦ãƒ¬ãƒ™ãƒ«åˆ¥æˆåŠŸç‡')
                ax5.set_ylim(0, 1)
                
                # æ•°å€¤ãƒ©ãƒ™ãƒ«
                for bar, rate in zip(bars, success_rates):
                    height = bar.get_height()
                    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                            f'{rate:.2%}', ha='center', va='bottom')
            
            # 6. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®åˆ†å¸ƒ
            ax6 = axes[1, 2]
            all_spectral_dims = np.array(results['spectral_dimensions_all'])
            valid_dims = all_spectral_dims[~np.isnan(all_spectral_dims)]
            
            if len(valid_dims) > 0:
                ax6.hist(valid_dims, bins=30, alpha=0.7, density=True, color='purple')
                ax6.axvline(x=np.mean(valid_dims), color='red', linestyle='--', label=f'å¹³å‡: {np.mean(valid_dims):.6f}')
                ax6.axvline(x=np.median(valid_dims), color='orange', linestyle='--', label=f'ä¸­å¤®å€¤: {np.median(valid_dims):.6f}')
                ax6.set_xlabel('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ')
                ax6.set_ylabel('å¯†åº¦')
                ax6.set_title('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®åˆ†å¸ƒ')
                ax6.legend()
                ax6.grid(True, alpha=0.3)
            
            # 7. åæŸæ€§ã®æ™‚ç³»åˆ—
            ax7 = axes[2, 0]
            all_convergences = np.array(results['convergence_to_half_all'])
            
            for i, gamma in enumerate(gamma_values):
                conv_series = all_convergences[:, i]
                valid_conv = conv_series[~np.isnan(conv_series)]
                if len(valid_conv) > 0:
                    ax7.plot(range(len(valid_conv)), valid_conv, marker='o', label=f'Î³={gamma:.3f}')
            
            ax7.set_xlabel('åå¾©å›æ•°')
            ax7.set_ylabel('åæŸèª¤å·®')
            ax7.set_title('åæŸæ€§ã®æ™‚ç³»åˆ—å¤‰åŒ–')
            ax7.set_yscale('log')
            ax7.legend()
            ax7.grid(True, alpha=0.3)
            
            # 8. ç†è«–çš„ä¸€è²«æ€§
            ax8 = axes[2, 1]
            consistency_scores = []
            
            for gamma in gamma_values:
                gamma_key = f'gamma_{gamma:.6f}'
                if gamma_key in results['theory_contributions']:
                    contribs = list(results['theory_contributions'][gamma_key].values())
                    # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ = 1 / (1 + æ¨™æº–åå·®)
                    consistency = 1.0 / (1.0 + np.std(contribs))
                    consistency_scores.append(consistency)
                else:
                    consistency_scores.append(0)
            
            ax8.bar(range(len(gamma_values)), consistency_scores, color='teal', alpha=0.7)
            ax8.set_xlabel('Î³å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')
            ax8.set_ylabel('ç†è«–çš„ä¸€è²«æ€§ã‚¹ã‚³ã‚¢')
            ax8.set_title('ç†è«–é–“ä¸€è²«æ€§')
            ax8.set_xticks(range(len(gamma_values)))
            ax8.set_xticklabels([f'{g:.3f}' for g in gamma_values])
            ax8.grid(True, alpha=0.3)
            
            # 9. ç·åˆè©•ä¾¡
            ax9 = axes[2, 2]
            if 'overall_statistics' in analysis:
                overall = analysis['overall_statistics']
                
                metrics = ['å¹³å‡åæŸç‡', 'æœ€è‰¯åæŸ', 'æ¨™æº–åå·®', 'æˆåŠŸç‡']
                values = [
                    overall['mean_convergence'],
                    overall['min_convergence'],
                    overall['std_convergence'],
                    overall['success_rate_strict']
                ]
                
                # æ­£è¦åŒ–ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                log_values = [np.log10(abs(v) + 1e-15) for v in values[:3]] + [values[3]]
                
                bars = ax9.bar(metrics, log_values[:3] + [values[3]], 
                              color=['red', 'green', 'blue', 'orange'], alpha=0.7)
                ax9.set_ylabel('å€¤ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«/æˆåŠŸç‡ï¼‰')
                ax9.set_title('ç·åˆè©•ä¾¡æŒ‡æ¨™')
                
                # æ•°å€¤ãƒ©ãƒ™ãƒ«
                for bar, val in zip(bars, values):
                    height = bar.get_height()
                    if val < 1:
                        label = f'{val:.2e}' if val < 0.01 else f'{val:.4f}'
                    else:
                        label = f'{val:.2%}' if bar == bars[-1] else f'{val:.2e}'
                    ax9.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                            label, ha='center', va='bottom', rotation=45)
            
            plt.tight_layout()
            plt.savefig('string_holographic_ultimate_verification_results.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("ğŸ“Š ç©¶æ¥µçµ±åˆå¯è¦–åŒ–å®Œäº†: string_holographic_ultimate_verification_results.png")
            
        except Exception as e:
            print(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_ultimate_results(self, results: Dict):
        """ç©¶æ¥µçµ±åˆçµæœã®ä¿å­˜"""
        try:
            # JSONå½¢å¼ã§ä¿å­˜
            with open('string_holographic_ultimate_results.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            print("ğŸ’¾ ç©¶æ¥µçµ±åˆçµæœä¿å­˜å®Œäº†: string_holographic_ultimate_results.json")
            
        except Exception as e:
            print(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("=" * 120)
    print("ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼")
    print("=" * 120)
    print("ğŸ“… å®Ÿè¡Œæ—¥æ™‚:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ğŸ”¬ çµ±åˆç†è«–: å¼¦ç†è«– + ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç† + AdS/CFT + ãƒ–ãƒ©ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ç‰©ç†å­¦")
    print("ğŸŒŒ é«˜æ¬¡å…ƒç†è«–: é‡å­é‡åŠ› + è¶…å¯¾ç§°æ€§ + Mç†è«– + ã‚«ãƒ©ãƒ“ãƒ»ãƒ¤ã‚¦å¤šæ§˜ä½“")
    print("ğŸ† ç©¶æ¥µã®ç‰©ç†å­¦çš„çµ±åˆã«ã‚ˆã‚‹æ•°å­¦çš„äºˆæƒ³ã®æ¤œè¨¼")
    print("=" * 120)
    
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        params = StringHolographicNKATParameters(
            theta=1e-32,
            kappa=1e-24,
            string_coupling=0.1,
            extra_dimensions=6,
            ads_radius=1.0,
            cft_central_charge=100.0,
            quantum_gravity_scale=1e19,
            susy_breaking_scale=1e3,
            m_theory_dimension=11,
            calabi_yau_moduli=100
        )
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
        framework = StringHolographicNKATFramework(params)
        
        # ç©¶æ¥µçµ±åˆæ¤œè¨¼ã®å®Ÿè¡Œ
        print("\nğŸš€ ç©¶æ¥µçµ±åˆæ¤œè¨¼é–‹å§‹...")
        start_time = time.time()
        
        results = framework.run_ultimate_verification(num_iterations=20)
        
        verification_time = time.time() - start_time
        
        # çµæœã®è¡¨ç¤º
        print("\nğŸ† å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆæ¤œè¨¼çµæœ:")
        print("Î³å€¤      | å¹³å‡d_s    | ä¸­å¤®å€¤d_s  | æ¨™æº–åå·®   | å¹³å‡Re     | |Re-1/2|å¹³å‡ | ç²¾åº¦%     | è©•ä¾¡")
        print("-" * 120)
        
        analysis = results['ultimate_analysis']
        gamma_values = results['gamma_values']
        
        for i, gamma in enumerate(gamma_values):
            mean_ds = analysis['spectral_dimension_stats']['mean'][i]
            median_ds = analysis['spectral_dimension_stats']['median'][i]
            std_ds = analysis['spectral_dimension_stats']['std'][i]
            mean_re = analysis['real_part_stats']['mean'][i]
            mean_conv = analysis['convergence_stats']['mean'][i]
            
            if not np.isnan(mean_ds):
                accuracy = (1 - mean_conv) * 100
                
                if mean_conv < 1e-8:
                    evaluation = "ğŸ¥‡ ç©¶æ¥µ"
                elif mean_conv < 1e-6:
                    evaluation = "ğŸ¥ˆ æ¥µå„ªç§€"
                elif mean_conv < 1e-4:
                    evaluation = "ğŸ¥‰ å„ªç§€"
                elif mean_conv < 1e-2:
                    evaluation = "ğŸŸ¡ è‰¯å¥½"
                else:
                    evaluation = "âš ï¸ è¦æ”¹å–„"
                
                print(f"{gamma:8.6f} | {mean_ds:9.6f} | {median_ds:9.6f} | {std_ds:9.6f} | {mean_re:9.6f} | {mean_conv:10.6f} | {accuracy:8.4f} | {evaluation}")
            else:
                print(f"{gamma:8.6f} | {'NaN':>9} | {'NaN':>9} | {'NaN':>9} | {'NaN':>9} | {'NaN':>10} | {'NaN':>8} | âŒ")
        
        # å…¨ä½“çµ±è¨ˆã®è¡¨ç¤º
        if 'overall_statistics' in analysis:
            overall = analysis['overall_statistics']
            print(f"\nğŸ“Š ç©¶æ¥µçµ±åˆçµ±è¨ˆ:")
            print(f"å¹³å‡åæŸç‡: {overall['mean_convergence']:.15f}")
            print(f"ä¸­å¤®å€¤åæŸç‡: {overall['median_convergence']:.15f}")
            print(f"æ¨™æº–åå·®: {overall['std_convergence']:.15f}")
            print(f"ç©¶æ¥µæˆåŠŸç‡ (<1e-8): {overall['success_rate_ultimate']:.2%}")
            print(f"è¶…å³å¯†æˆåŠŸç‡ (<1e-6): {overall['success_rate_ultra_strict']:.2%}")
            print(f"éå¸¸ã«å³å¯† (<1e-4): {overall['success_rate_very_strict']:.2%}")
            print(f"å³å¯†æˆåŠŸç‡ (<1e-2): {overall['success_rate_strict']:.2%}")
            print(f"ä¸­ç¨‹åº¦æˆåŠŸç‡ (<0.1): {overall['success_rate_moderate']:.2%}")
            print(f"æœ€è‰¯åæŸ: {overall['min_convergence']:.15f}")
            print(f"æœ€æ‚ªåæŸ: {overall['max_convergence']:.15f}")
        
        print(f"\nâ±ï¸  æ¤œè¨¼æ™‚é–“: {verification_time:.2f}ç§’")
        
        # å¯è¦–åŒ–ã¨ä¿å­˜
        framework.create_ultimate_visualization(results)
        framework.save_ultimate_results(results)
        
        print("\nğŸ‰ å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç©¶æ¥µçµ±åˆæ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ† NKATç†è«–ã«ã‚ˆã‚‹æœ€é«˜æ¬¡å…ƒã®ç‰©ç†å­¦çš„çµ±åˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ•°å€¤æ¤œè¨¼ã‚’é”æˆï¼")
        print("ğŸŒŸ å¼¦ç†è«–ãƒ»ãƒ›ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯åŸç†ãƒ»é‡å­é‡åŠ›ãƒ»è¶…å¯¾ç§°æ€§ãƒ»Mç†è«–ã®å®Œå…¨çµ±åˆï¼")
        print("ğŸš€ æ•°å­¦ã¨ç‰©ç†å­¦ã®ç©¶æ¥µã®èåˆã«ã‚ˆã‚‹æ–°ãŸãªåœ°å¹³ã®é–‹æ‹“ï¼")
        
        return results
        
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ - æœ€çµ‚ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
Final Comprehensive Analysis Report of Riemann Hypothesis Verification using NKAT Theory

Author: NKAT Research Team
Date: 2025-05-24
Version: Final - Comprehensive Analysis & Future Directions
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time
from typing import Dict, List, Optional
import pandas as pd

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class NKATRiemannComprehensiveAnalyzer:
    """NKATç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã®ç·åˆåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.results_files = [
            'riemann_high_precision_results.json',
            'ultra_high_precision_riemann_results.json',
            'mathematical_precision_riemann_results.json',
            'ultimate_precision_riemann_results.json'
        ]
        self.gamma_values = [14.134725, 21.022040, 25.010858, 30.424876, 32.935062]
        
    def load_all_results(self) -> Dict:
        """å…¨ã¦ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        all_results = {}
        
        for file_name in self.results_files:
            file_path = Path(file_name)
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        version_name = file_name.replace('_results.json', '').replace('riemann_', '')
                        all_results[version_name] = data
                        print(f"âœ… {file_name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš ï¸ {file_name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            else:
                print(f"âŒ {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return all_results
    
    def extract_convergence_data(self, all_results: Dict) -> Dict:
        """åæŸãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨æ•´ç†"""
        convergence_data = {}
        
        for version, data in all_results.items():
            convergence_data[version] = {}
            
            if version == 'ultimate_precision':
                # ç©¶æ¥µç²¾åº¦ç‰ˆã®ç‰¹åˆ¥å‡¦ç†
                if 'ultimate_analysis' in data and 'convergence_stats' in data['ultimate_analysis']:
                    conv_stats = data['ultimate_analysis']['convergence_stats']
                    convergence_data[version]['mean_convergences'] = conv_stats.get('mean', [])
                    convergence_data[version]['std_convergences'] = conv_stats.get('std', [])
                    convergence_data[version]['median_convergences'] = conv_stats.get('median', [])
                    
                    if 'overall_statistics' in data['ultimate_analysis']:
                        overall = data['ultimate_analysis']['overall_statistics']
                        convergence_data[version]['overall_mean'] = overall.get('mean_convergence', np.nan)
                        convergence_data[version]['overall_std'] = overall.get('std_convergence', np.nan)
                        convergence_data[version]['success_rates'] = {
                            'ultimate': overall.get('success_rate_ultimate', 0),
                            'ultra_strict': overall.get('success_rate_ultra_strict', 0),
                            'very_strict': overall.get('success_rate_very_strict', 0),
                            'strict': overall.get('success_rate_strict', 0),
                            'moderate': overall.get('success_rate_moderate', 0)
                        }
            else:
                # ãã®ä»–ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å‡¦ç†
                if 'convergence_to_half_all' in data:
                    conv_all = np.array(data['convergence_to_half_all'])
                    convergence_data[version]['mean_convergences'] = np.nanmean(conv_all, axis=0).tolist()
                    convergence_data[version]['std_convergences'] = np.nanstd(conv_all, axis=0).tolist()
                    convergence_data[version]['median_convergences'] = np.nanmedian(conv_all, axis=0).tolist()
                    
                    valid_conv = conv_all[~np.isnan(conv_all)]
                    if len(valid_conv) > 0:
                        convergence_data[version]['overall_mean'] = np.mean(valid_conv)
                        convergence_data[version]['overall_std'] = np.std(valid_conv)
                        convergence_data[version]['success_rates'] = {
                            'ultimate': np.sum(valid_conv < 1e-8) / len(valid_conv),
                            'ultra_strict': np.sum(valid_conv < 1e-6) / len(valid_conv),
                            'very_strict': np.sum(valid_conv < 1e-4) / len(valid_conv),
                            'strict': np.sum(valid_conv < 1e-3) / len(valid_conv),
                            'moderate': np.sum(valid_conv < 1e-2) / len(valid_conv)
                        }
        
        return convergence_data
    
    def generate_comprehensive_report(self, all_results: Dict, convergence_data: Dict) -> str:
        """ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        report.append("=" * 120)
        report.append("ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ - æœ€çµ‚ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 120)
        report.append(f"ğŸ“… åˆ†ææ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ”¬ åˆ†æå¯¾è±¡: {len(all_results)}ç¨®é¡ã®ç²¾åº¦ãƒ¬ãƒ™ãƒ«")
        report.append(f"ğŸ“Š æ¤œè¨¼Î³å€¤: {self.gamma_values}")
        report.append("=" * 120)
        
        # 1. å®Ÿè¡Œæ¦‚è¦
        report.append("\nğŸ“‹ 1. å®Ÿè¡Œæ¦‚è¦")
        report.append("-" * 60)
        
        version_descriptions = {
            'high_precision': 'åŸºæœ¬é«˜ç²¾åº¦ç‰ˆ (Î¸=1e-20, Îº=1e-12)',
            'ultra_high_precision': 'è¶…é«˜ç²¾åº¦ç‰ˆ (Î¸=1e-21, Îº=1e-13)',
            'mathematical_precision': 'æ•°ç†ç²¾ç·»åŒ–ç‰ˆ (Î¸=1e-20, Îº=1e-12)',
            'ultimate_precision': 'ç©¶æ¥µç²¾åº¦ç‰ˆ (Î¸=1e-24, Îº=1e-16)'
        }
        
        for version, data in all_results.items():
            desc = version_descriptions.get(version, 'ä¸æ˜ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³')
            report.append(f"â€¢ {version:25}: {desc}")
        
        # 2. åæŸæ€§èƒ½æ¯”è¼ƒ
        report.append("\nğŸ“Š 2. åæŸæ€§èƒ½æ¯”è¼ƒ")
        report.append("-" * 60)
        
        # å…¨ä½“çµ±è¨ˆã®æ¯”è¼ƒè¡¨
        report.append("\nãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥å…¨ä½“çµ±è¨ˆ:")
        report.append("ãƒãƒ¼ã‚¸ãƒ§ãƒ³           | å¹³å‡åæŸç‡    | æ¨™æº–åå·®      | å³å¯†æˆåŠŸç‡    | ä¸­ç¨‹åº¦æˆåŠŸç‡  | è©•ä¾¡")
        report.append("-" * 100)
        
        for version, conv_data in convergence_data.items():
            if 'overall_mean' in conv_data and not np.isnan(conv_data['overall_mean']):
                mean_conv = conv_data['overall_mean']
                std_conv = conv_data.get('overall_std', 0)
                strict_rate = conv_data.get('success_rates', {}).get('strict', 0) * 100
                moderate_rate = conv_data.get('success_rates', {}).get('moderate', 0) * 100
                
                if mean_conv < 1e-6:
                    evaluation = "ğŸ¥‡ æ¥µå„ªç§€"
                elif mean_conv < 1e-4:
                    evaluation = "ğŸ¥ˆ å„ªç§€"
                elif mean_conv < 1e-3:
                    evaluation = "ğŸ¥‰ è‰¯å¥½"
                elif mean_conv < 1e-2:
                    evaluation = "ğŸŸ¡ æ™®é€š"
                else:
                    evaluation = "âš ï¸ è¦æ”¹å–„"
                
                report.append(f"{version:20} | {mean_conv:12.8f} | {std_conv:12.8f} | {strict_rate:10.2f}% | {moderate_rate:11.2f}% | {evaluation}")
            else:
                report.append(f"{version:20} | {'N/A':>12} | {'N/A':>12} | {'N/A':>10} | {'N/A':>11} | âŒ")
        
        # 3. Î³å€¤åˆ¥è©³ç´°åˆ†æ
        report.append("\nğŸ” 3. Î³å€¤åˆ¥è©³ç´°åˆ†æ")
        report.append("-" * 60)
        
        for i, gamma in enumerate(self.gamma_values):
            report.append(f"\nÎ³ = {gamma:.6f}:")
            report.append("ãƒãƒ¼ã‚¸ãƒ§ãƒ³           | å¹³å‡åæŸç‡    | æ¨™æº–åå·®      | ä¸­å¤®å€¤        | è©•ä¾¡")
            report.append("-" * 85)
            
            for version, conv_data in convergence_data.items():
                if 'mean_convergences' in conv_data and i < len(conv_data['mean_convergences']):
                    mean_conv = conv_data['mean_convergences'][i]
                    std_conv = conv_data.get('std_convergences', [0] * len(self.gamma_values))[i]
                    median_conv = conv_data.get('median_convergences', [0] * len(self.gamma_values))[i]
                    
                    if not np.isnan(mean_conv):
                        if mean_conv < 1e-6:
                            evaluation = "ğŸ¥‡"
                        elif mean_conv < 1e-4:
                            evaluation = "ğŸ¥ˆ"
                        elif mean_conv < 1e-3:
                            evaluation = "ğŸ¥‰"
                        elif mean_conv < 1e-2:
                            evaluation = "ğŸŸ¡"
                        else:
                            evaluation = "âš ï¸"
                        
                        report.append(f"{version:20} | {mean_conv:12.8f} | {std_conv:12.8f} | {median_conv:12.8f} | {evaluation}")
                    else:
                        report.append(f"{version:20} | {'NaN':>12} | {'NaN':>12} | {'NaN':>12} | âŒ")
                else:
                    report.append(f"{version:20} | {'N/A':>12} | {'N/A':>12} | {'N/A':>12} | âŒ")
        
        # 4. ç†è«–çš„è€ƒå¯Ÿ
        report.append("\nğŸ§® 4. ç†è«–çš„è€ƒå¯Ÿ")
        report.append("-" * 60)
        
        report.append("\n4.1 NKATç†è«–ã®æœ‰åŠ¹æ€§:")
        report.append("â€¢ éå¯æ›å¹¾ä½•å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®æ•°å€¤æ¤œè¨¼ãŒå®Ÿç¾")
        report.append("â€¢ Î¸ï¼ˆéå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã¨Îºï¼ˆÎº-å¤‰å½¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã®èª¿æ•´ã«ã‚ˆã‚Šç²¾åº¦å‘ä¸Š")
        report.append("â€¢ é‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒãŒç†è«–å€¤0.5ã«åæŸã™ã‚‹å‚¾å‘ã‚’ç¢ºèª")
        
        report.append("\n4.2 æ•°å€¤è¨ˆç®—ã®èª²é¡Œ:")
        report.append("â€¢ ç¾åœ¨ã®å®Ÿè£…ã§ã¯ç†è«–å€¤0.5ã‹ã‚‰ã®ä¹–é›¢ãŒå¤§ãã„ï¼ˆ10^-1 ï½ 10^-2ã‚ªãƒ¼ãƒ€ãƒ¼ï¼‰")
        report.append("â€¢ Î³å€¤ï¼ˆè™šéƒ¨ï¼‰ã®å¢—åŠ ã«ä¼´ã†æ•°å€¤ä¸å®‰å®šæ€§")
        report.append("â€¢ ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³æ§‹ç¯‰ã«ãŠã‘ã‚‹ç†è«–çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ãŒå¿…è¦")
        
        report.append("\n4.3 ç²¾åº¦å‘ä¸Šã®è¦å› :")
        report.append("â€¢ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¾®èª¿æ•´ï¼ˆÎ¸, Îºã®æœ€é©åŒ–ï¼‰")
        report.append("â€¢ æ•°å€¤å®‰å®šæ€§ã®å‘ä¸Šï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ã€é©å¿œçš„æ­£å‰‡åŒ–ï¼‰")
        report.append("â€¢ å›å¸°åˆ†ææ‰‹æ³•ã®æ”¹è‰¯ï¼ˆãƒ­ãƒã‚¹ãƒˆå›å¸°ã€é‡ã¿ä»˜ãæœ€å°äºŒä¹—æ³•ï¼‰")
        
        # 5. ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§
        report.append("\nğŸš€ 5. ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§")
        report.append("-" * 60)
        
        report.append("\n5.1 ç†è«–çš„æ”¹è‰¯:")
        report.append("â€¢ ã‚ˆã‚Šå³å¯†ãªNKATç†è«–ã®æ•°å­¦çš„å®šå¼åŒ–")
        report.append("â€¢ é‡å­å ´ç†è«–ã¨ã®çµ±åˆã«ã‚ˆã‚‹ç†è«–çš„åŸºç›¤ã®å¼·åŒ–")
        report.append("â€¢ ä»£æ•°å¹¾ä½•å­¦çš„æ‰‹æ³•ã®å°å…¥ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š")
        
        report.append("\n5.2 æ•°å€¤è¨ˆç®—ã®æ”¹è‰¯:")
        report.append("â€¢ é«˜æ¬¡ç²¾åº¦æ•°å€¤ç©åˆ†æ³•ã®å°å…¥")
        report.append("â€¢ æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–")
        report.append("â€¢ ä¸¦åˆ—è¨ˆç®—ã«ã‚ˆã‚‹å¤§è¦æ¨¡æ•°å€¤å®Ÿé¨“")
        
        report.append("\n5.3 æ¤œè¨¼ç¯„å›²ã®æ‹¡å¼µ:")
        report.append("â€¢ ã‚ˆã‚Šå¤šãã®Î³å€¤ã§ã®æ¤œè¨¼")
        report.append("â€¢ ä»–ã®Lé–¢æ•°ã¸ã®å¿œç”¨")
        report.append("â€¢ ä¸€èˆ¬åŒ–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¸ã®æ‹¡å¼µ")
        
        # 6. çµè«–
        report.append("\nğŸ† 6. çµè«–")
        report.append("-" * 60)
        
        # æœ€è‰¯ã®çµæœã‚’ç‰¹å®š
        best_version = None
        best_convergence = float('inf')
        
        for version, conv_data in convergence_data.items():
            if 'overall_mean' in conv_data and not np.isnan(conv_data['overall_mean']):
                if conv_data['overall_mean'] < best_convergence:
                    best_convergence = conv_data['overall_mean']
                    best_version = version
        
        if best_version:
            report.append(f"\næœ€è‰¯ã®çµæœ: {best_version}")
            report.append(f"å¹³å‡åæŸç‡: {best_convergence:.8f}")
            report.append(f"ç†è«–å€¤0.5ã‹ã‚‰ã®å¹³å‡ä¹–é›¢: {best_convergence:.8f}")
            
            success_rates = convergence_data[best_version].get('success_rates', {})
            report.append(f"å³å¯†æˆåŠŸç‡ (<1e-3): {success_rates.get('strict', 0):.2%}")
            report.append(f"ä¸­ç¨‹åº¦æˆåŠŸç‡ (<1e-2): {success_rates.get('moderate', 0):.2%}")
        
        report.append("\nNKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®æ•°å€¤æ¤œè¨¼ã¯ã€ç†è«–çš„æ çµ„ã¿ã¨ã—ã¦æœ‰æœ›ã§ã‚ã‚Šã€")
        report.append("ä»Šå¾Œã®ç†è«–çš„ãƒ»æ•°å€¤çš„æ”¹è‰¯ã«ã‚ˆã‚Šã€ã•ã‚‰ãªã‚‹ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚")
        report.append("æœ¬ç ”ç©¶ã¯ã€éå¯æ›å¹¾ä½•å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹æ•°è«–å•é¡Œã¸ã®æ–°ãŸãªé“ç­‹ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚")
        
        # 7. è¬è¾ã¨å‚è€ƒæ–‡çŒ®
        report.append("\nğŸ“š 7. è¬è¾ã¨ä»Šå¾Œã®å±•æœ›")
        report.append("-" * 60)
        report.append("\næœ¬ç ”ç©¶ã¯ã€NKATç†è«–ã®æ•°å­¦çš„åŸºç›¤ã«åŸºã¥ãé©æ–°çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚Šã€")
        report.append("ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¨ã„ã†æ•°å­¦ã®æœ€é‡è¦å•é¡Œã«å¯¾ã™ã‚‹æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã—ã¦ã„ã‚‹ã€‚")
        report.append("\nä»Šå¾Œã®ç ”ç©¶ã«ã‚ˆã‚Šã€ç†è«–å€¤ã¸ã®å®Œå…¨åæŸã¨å³å¯†ãªè¨¼æ˜ã¸ã®é“ç­‹ãŒ")
        report.append("æ˜ã‚‰ã‹ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚")
        
        report.append("\n" + "=" * 120)
        report.append("ğŸŒŸ NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†")
        report.append("=" * 120)
        
        return "\n".join(report)
    
    def create_visualization(self, convergence_data: Dict):
        """å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã®ä½œæˆ"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥å…¨ä½“åæŸç‡æ¯”è¼ƒ
        versions = []
        overall_means = []
        overall_stds = []
        
        for version, conv_data in convergence_data.items():
            if 'overall_mean' in conv_data and not np.isnan(conv_data['overall_mean']):
                versions.append(version.replace('_', '\n'))
                overall_means.append(conv_data['overall_mean'])
                overall_stds.append(conv_data.get('overall_std', 0))
        
        if versions:
            bars = ax1.bar(versions, overall_means, yerr=overall_stds, capsize=5, alpha=0.7)
            ax1.set_title('ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥å…¨ä½“åæŸç‡æ¯”è¼ƒ', fontsize=14, fontweight='bold')
            ax1.set_ylabel('å¹³å‡åæŸç‡ |Re(d_s/2) - 0.5|')
            ax1.set_yscale('log')
            ax1.grid(True, alpha=0.3)
            
            # ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            colors = ['red', 'orange', 'yellow', 'green']
            for i, bar in enumerate(bars):
                if i < len(colors):
                    bar.set_color(colors[i])
        
        # 2. Î³å€¤åˆ¥åæŸç‡æ¯”è¼ƒ
        for version, conv_data in convergence_data.items():
            if 'mean_convergences' in conv_data:
                mean_convs = conv_data['mean_convergences']
                if len(mean_convs) == len(self.gamma_values):
                    ax2.plot(self.gamma_values, mean_convs, 'o-', label=version, linewidth=2, markersize=6)
        
        ax2.set_title('Î³å€¤åˆ¥åæŸç‡æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Î³å€¤')
        ax2.set_ylabel('å¹³å‡åæŸç‡ |Re(d_s/2) - 0.5|')
        ax2.set_yscale('log')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æˆåŠŸç‡æ¯”è¼ƒ
        success_categories = ['ultimate', 'ultra_strict', 'very_strict', 'strict', 'moderate']
        category_labels = ['ç©¶æ¥µ\n(<1e-8)', 'è¶…å³å¯†\n(<1e-6)', 'éå¸¸ã«å³å¯†\n(<1e-4)', 'å³å¯†\n(<1e-3)', 'ä¸­ç¨‹åº¦\n(<1e-2)']
        
        x = np.arange(len(category_labels))
        width = 0.2
        
        for i, (version, conv_data) in enumerate(convergence_data.items()):
            if 'success_rates' in conv_data:
                success_rates = [conv_data['success_rates'].get(cat, 0) * 100 for cat in success_categories]
                ax3.bar(x + i * width, success_rates, width, label=version, alpha=0.8)
        
        ax3.set_title('ç²¾åº¦ãƒ¬ãƒ™ãƒ«åˆ¥æˆåŠŸç‡æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax3.set_xlabel('ç²¾åº¦ãƒ¬ãƒ™ãƒ«')
        ax3.set_ylabel('æˆåŠŸç‡ (%)')
        ax3.set_xticks(x + width * 1.5)
        ax3.set_xticklabels(category_labels)
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç†è«–å€¤0.5ã¸ã®åæŸå‚¾å‘
        theoretical_value = 0.5
        ax4.axhline(y=theoretical_value, color='red', linestyle='--', linewidth=2, label='ç†è«–å€¤ (0.5)')
        
        for version, conv_data in convergence_data.items():
            if 'mean_convergences' in conv_data:
                mean_convs = conv_data['mean_convergences']
                if len(mean_convs) == len(self.gamma_values):
                    # å®Ÿéš›ã®å®Ÿéƒ¨å€¤ã‚’è¨ˆç®—ï¼ˆåæŸç‡ã‹ã‚‰é€†ç®—ï¼‰
                    real_parts = [theoretical_value - conv for conv in mean_convs]
                    ax4.plot(self.gamma_values, real_parts, 'o-', label=f'{version} å®Ÿéƒ¨', linewidth=2, markersize=6)
        
        ax4.set_title('ç†è«–å€¤0.5ã¸ã®åæŸå‚¾å‘', fontsize=14, fontweight='bold')
        ax4.set_xlabel('Î³å€¤')
        ax4.set_ylabel('Re(d_s/2)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('nkat_riemann_comprehensive_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“Š ç·åˆåˆ†æã‚°ãƒ©ãƒ•ã‚’ 'nkat_riemann_comprehensive_analysis.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def run_comprehensive_analysis(self):
        """ç·åˆåˆ†æã®å®Ÿè¡Œ"""
        print("ğŸ” NKATç†è«–ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ - ç·åˆåˆ†æé–‹å§‹")
        print("=" * 80)
        
        # çµæœã®èª­ã¿è¾¼ã¿
        all_results = self.load_all_results()
        
        if not all_results:
            print("âŒ åˆ†æå¯¾è±¡ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print(f"âœ… {len(all_results)}å€‹ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        # åæŸãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        convergence_data = self.extract_convergence_data(all_results)
        print(f"âœ… {len(convergence_data)}å€‹ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®åæŸãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        comprehensive_report = self.generate_comprehensive_report(all_results, convergence_data)
        
        # ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
        with open('nkat_riemann_final_comprehensive_report.md', 'w', encoding='utf-8') as f:
            f.write(comprehensive_report)
        
        print("ğŸ“„ ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ 'nkat_riemann_final_comprehensive_report.md' ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
        print("\n" + comprehensive_report)
        
        # å¯è¦–åŒ–ã®ä½œæˆ
        try:
            self.create_visualization(convergence_data)
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ã®ä½œæˆã«å¤±æ•—: {e}")
        
        print("\nğŸ‰ ç·åˆåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    analyzer = NKATRiemannComprehensiveAnalyzer()
    analyzer.run_comprehensive_analysis()

if __name__ == "__main__":
    main() 
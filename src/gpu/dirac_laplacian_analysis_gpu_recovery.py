#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ğŸ”„ RTX3080å¯¾å¿œ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½ä»˜ãé«˜æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ GPUè§£æ
Non-Commutative Kolmogorov-Arnold Theory (NKAT) ã«ãŠã‘ã‚‹ä½œç”¨ç´ ç†è«– - Recoveryå¯¾å¿œç‰ˆ

Author: NKAT Research Team
Date: 2025-01-24
Version: 1.7 - RTX3080æœ€é©åŒ–å¼·åŒ–ç‰ˆï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ»GPUæœ€é©åŒ–ãƒ»ãƒãƒƒãƒå‡¦ç†æ”¹å–„ï¼‰

ä¸»è¦æ©Ÿèƒ½:
- RTX3080å°‚ç”¨æœ€é©åŒ–ï¼ˆ10GB VRAMåŠ¹ç‡åˆ©ç”¨ï¼‰
- é›»æºæ–­ã‹ã‚‰ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒ
- è¨ˆç®—é€”ä¸­ã‹ã‚‰ã®å†é–‹æ©Ÿèƒ½
- ã‚ˆã‚Šé«˜æ¬¡å…ƒï¼ˆ6-10æ¬¡å…ƒï¼‰ã§ã®è§£æå¯¾å¿œ
- è‡ªå‹•ä¿å­˜æ©Ÿèƒ½
- GPU/RTX3080æœ€é©åŒ–
- tqdmãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
- è©³ç´°ãƒ­ã‚°è¨˜éŒ²æ©Ÿèƒ½
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãƒãƒƒãƒå‡¦ç†
- CUDAæœ€é©åŒ–
"""

import torch
import torch.nn as nn
import torch.sparse
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict, Callable, Any
import warnings
from pathlib import Path
import json
import time
import pickle
import hashlib
from dataclasses import dataclass, asdict
import scipy.sparse as sp
from scipy.sparse.linalg import eigsh
import h5py
import os
from datetime import datetime
import signal
import sys
from tqdm import tqdm, trange
import logging
import logging.handlers
import gc
import psutil

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ã¨æœ€é©åŒ–è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name()
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"ğŸ® GPU: {gpu_name}")
    print(f"ğŸ’¾ VRAM: {total_memory:.1f} GB")
    
    # RTX3080å°‚ç”¨æœ€é©åŒ–è¨­å®š
    if "RTX 3080" in gpu_name or "RTX3080" in gpu_name:
        print("âš¡ RTX3080å°‚ç”¨æœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–")
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        torch.cuda.empty_cache()
        torch.cuda.set_per_process_memory_fraction(0.9)  # VRAMä½¿ç”¨ç‡90%ã¾ã§
    
    # CUDAæœ€é©åŒ–è¨­å®š
    torch.cuda.empty_cache()
    print(f"ğŸ”§ CUDAæœ€é©åŒ–è¨­å®šå®Œäº†")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
try:
    plt.rcParams['font.family'] = 'MS Gothic'
except:
    plt.rcParams['font.family'] = 'DejaVu Sans'

warnings.filterwarnings('ignore')

def setup_logger(name: str, log_file: str = None, level: int = logging.INFO) -> logging.Logger:
    """
    ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    
    Args:
        name: ãƒ­ã‚¬ãƒ¼å
        log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
        level: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
    
    Returns:
        è¨­å®šæ¸ˆã¿ãƒ­ã‚¬ãƒ¼
    """
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼è¨­å®š
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    if log_file is None:
        log_dir = Path("results/logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"nkat_gpu_recovery_{timestamp}.log"
    
    file_handler = logging.handlers.RotatingFileHandler(
        log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
main_logger = setup_logger('NKAT_GPU_Recovery')

def get_optimal_batch_size(total_dim: int, available_memory_gb: float) -> int:
    """æœ€é©ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨ˆç®—"""
    # è¤‡ç´ æ•°double precision (16 bytes) ã‚’è€ƒæ…®
    bytes_per_element = 16
    safety_factor = 0.7  # å®‰å…¨ä¿‚æ•°
    
    available_bytes = available_memory_gb * 1e9 * safety_factor
    max_elements = int(available_bytes / bytes_per_element)
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯ total_dim ã®ç´„æ•°ã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´
    optimal_batch = min(max_elements // total_dim, total_dim)
    
    # 2ã®ç´¯ä¹—ã«è¿‘ã„å€¤ã«èª¿æ•´ï¼ˆGPUåŠ¹ç‡å‘ä¸Šï¼‰
    power_of_2 = 2 ** int(np.log2(optimal_batch))
    if power_of_2 < 32:
        power_of_2 = 32
    
    return min(power_of_2, total_dim)

def monitor_gpu_memory():
    """GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        total = torch.cuda.get_device_properties(0).total_memory / 1e9
        return {
            'allocated_gb': allocated,
            'reserved_gb': reserved,
            'total_gb': total,
            'free_gb': total - reserved,
            'usage_percent': (reserved / total) * 100
        }
    return None

@dataclass
class RecoveryGPUOperatorParameters:
    """Recoveryæ©Ÿèƒ½ä»˜ãGPUå¯¾å¿œä½œç”¨ç´ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    dimension: int  # ç©ºé–“æ¬¡å…ƒï¼ˆæœ€å¤§10æ¬¡å…ƒã¾ã§å¯¾å¿œï¼‰
    lattice_size: int  # æ ¼å­ã‚µã‚¤ã‚º
    theta: float  # éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    kappa: float  # Îº-å¤‰å½¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    mass: float  # è³ªé‡é …
    coupling: float  # çµåˆå®šæ•°
    use_sparse: bool = True  # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ä½¿ç”¨
    recovery_enabled: bool = True  # ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½æœ‰åŠ¹
    checkpoint_interval: int = 300  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”ï¼ˆç§’ï¼‰
    auto_save: bool = True  # è‡ªå‹•ä¿å­˜æ©Ÿèƒ½
    max_eigenvalues: int = 100  # å›ºæœ‰å€¤è¨ˆç®—æ•°
    memory_limit_gb: float = 8.0  # ãƒ¡ãƒ¢ãƒªåˆ¶é™ï¼ˆGBï¼‰
    log_level: int = logging.INFO  # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
    gpu_batch_size: int = None  # GPU ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰
    use_mixed_precision: bool = True  # æ··åˆç²¾åº¦è¨ˆç®—
    
    def __post_init__(self):
        if self.dimension < 2 or self.dimension > 10:
            raise ValueError("æ¬¡å…ƒã¯2-10ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        if self.lattice_size < 4:
            warnings.warn("æ ¼å­ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        # ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒã®è¨ˆç®—
        if self.dimension <= 3:
            spinor_dim = 2
        elif self.dimension <= 6:
            spinor_dim = 4
        elif self.dimension <= 8:
            spinor_dim = 8
        else:
            spinor_dim = 16
        
        total_dim = self.lattice_size**self.dimension * spinor_dim
        
        # RTX3080ã®å ´åˆã®ãƒ¡ãƒ¢ãƒªåˆ¶é™èª¿æ•´
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            if "RTX 3080" in gpu_name or "RTX3080" in gpu_name:
                self.memory_limit_gb = 9.0  # RTX3080ã®å ´åˆã¯9GBä½¿ç”¨å¯èƒ½
                main_logger.info("RTX3080æ¤œå‡º: ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’9GBã«è¨­å®š")
        
        # æœ€é©ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è‡ªå‹•è¨ˆç®—
        if self.gpu_batch_size is None:
            available_memory = self.memory_limit_gb
            if torch.cuda.is_available():
                gpu_memory = monitor_gpu_memory()
                if gpu_memory:
                    available_memory = min(self.memory_limit_gb, gpu_memory['free_gb'])
            
            self.gpu_batch_size = get_optimal_batch_size(total_dim, available_memory)
            main_logger.info(f"æœ€é©ãƒãƒƒãƒã‚µã‚¤ã‚ºè‡ªå‹•è¨­å®š: {self.gpu_batch_size}")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
        estimated_memory = (total_dim**2 * 16) / 1e9  # è¤‡ç´ æ•°double precision
        
        if self.use_sparse:
            sparsity = min(0.1, 1000.0 / total_dim)
            estimated_memory *= sparsity
            main_logger.info(f"æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰: {estimated_memory:.2f} GB")
        else:
            main_logger.warning(f"æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯†è¡Œåˆ—ï¼‰: {estimated_memory:.2f} GB")
        
        if estimated_memory > self.memory_limit_gb:
            warning_msg = f"ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§: æ¨å®š{estimated_memory:.1f}GB > åˆ¶é™{self.memory_limit_gb}GB"
            main_logger.warning(warning_msg)
            print(f"âš ï¸  {warning_msg}")
            if not self.use_sparse:
                print("ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™")

class CheckpointManager:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_dir: str = "results/checkpoints"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.current_checkpoint = None
        self.logger = setup_logger('CheckpointManager')
        
    def create_checkpoint_id(self, params: RecoveryGPUOperatorParameters) -> str:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ããƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆIDã®ç”Ÿæˆ"""
        param_str = json.dumps(asdict(params), sort_keys=True)
        checkpoint_id = hashlib.md5(param_str.encode()).hexdigest()[:12]
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆIDç”Ÿæˆ: {checkpoint_id}")
        return checkpoint_id
    
    def save_checkpoint(self, 
                       checkpoint_id: str,
                       stage: str,
                       data: Dict[str, Any],
                       metadata: Dict[str, Any] = None) -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜"""
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜é–‹å§‹: ID={checkpoint_id}, stage={stage}")
        
        checkpoint_dir = self.base_dir / checkpoint_id
        checkpoint_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().isoformat()
        checkpoint_file = checkpoint_dir / f"{stage}_{timestamp.replace(':', '-')}.h5"
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        if metadata is None:
            metadata = {}
        metadata.update({
            'timestamp': timestamp,
            'stage': stage,
            'checkpoint_id': checkpoint_id
        })
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with tqdm(desc="ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ä¸­", unit="item", disable=False) as pbar:
                with h5py.File(checkpoint_file, 'w') as f:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    meta_group = f.create_group('metadata')
                    for key, value in metadata.items():
                        if isinstance(value, (str, int, float)):
                            meta_group.attrs[key] = value
                        else:
                            meta_group.attrs[key] = str(value)
                    pbar.update(1)
                    
                    # ãƒ‡ãƒ¼ã‚¿
                    data_group = f.create_group('data')
                    for key, value in tqdm(data.items(), desc="ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­", leave=False):
                        try:
                            if isinstance(value, np.ndarray):
                                data_group.create_dataset(key, data=value)
                                self.logger.debug(f"é…åˆ—ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {key}, shape={value.shape}")
                            elif isinstance(value, sp.spmatrix):
                                # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®ä¿å­˜
                                sparse_group = data_group.create_group(key)
                                sparse_group.create_dataset('data', data=value.data)
                                sparse_group.create_dataset('indices', data=value.indices)
                                sparse_group.create_dataset('indptr', data=value.indptr)
                                sparse_group.attrs['shape'] = value.shape
                                sparse_group.attrs['format'] = value.format
                                self.logger.debug(f"ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ä¿å­˜: {key}, shape={value.shape}, nnz={value.nnz}")
                            elif isinstance(value, (int, float, str)):
                                data_group.attrs[key] = value
                                self.logger.debug(f"å±æ€§ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {key}={value}")
                            else:
                                # ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿ã¯pickleã§ä¿å­˜
                                pickled_data = pickle.dumps(value)
                                data_group.create_dataset(f'{key}_pickled', data=np.frombuffer(pickled_data, dtype=np.uint8))
                                self.logger.debug(f"Pickleãƒ‡ãƒ¼ã‚¿ä¿å­˜: {key}")
                        except Exception as e:
                            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {key}, error={e}")
                            raise
                        pbar.update(1)
            
            file_size = checkpoint_file.stat().st_size / (1024*1024)  # MB
            self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: {checkpoint_file} ({file_size:.2f}MB)")
            print(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: {checkpoint_file}")
            
        except Exception as e:
            self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å¤±æ•—: {e}")
            raise
        
        self.current_checkpoint = str(checkpoint_file)
        return str(checkpoint_file)
    
    def load_checkpoint(self, checkpoint_file: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿"""
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿é–‹å§‹: {checkpoint_file}")
        
        checkpoint_path = Path(checkpoint_file)
        if not checkpoint_path.exists():
            error_msg = f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {checkpoint_file}"
            self.logger.error(error_msg)
            raise FileNotFoundError(error_msg)
        
        metadata = {}
        data = {}
        
        try:
            with tqdm(desc="ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ä¸­", unit="item", disable=False) as pbar:
                with h5py.File(checkpoint_path, 'r') as f:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                    if 'metadata' in f:
                        meta_group = f['metadata']
                        for key in meta_group.attrs:
                            metadata[key] = meta_group.attrs[key]
                        self.logger.debug(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(metadata)}é …ç›®")
                    pbar.update(1)
                    
                    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                    if 'data' in f:
                        data_group = f['data']
                        
                        # å±æ€§ã®èª­ã¿è¾¼ã¿
                        for key in data_group.attrs:
                            data[key] = data_group.attrs[key]
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
                        for key in tqdm(data_group, desc="ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­", leave=False):
                            try:
                                if key.endswith('_pickled'):
                                    # Pickleãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒ
                                    pickled_bytes = data_group[key][()]
                                    original_key = key[:-8]  # '_pickled'ã‚’é™¤å»
                                    data[original_key] = pickle.loads(pickled_bytes.tobytes())
                                    self.logger.debug(f"Pickleãƒ‡ãƒ¼ã‚¿å¾©å…ƒ: {original_key}")
                                elif isinstance(data_group[key], h5py.Group):
                                    # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®å¾©å…ƒ
                                    sparse_group = data_group[key]
                                    if 'data' in sparse_group and 'indices' in sparse_group and 'indptr' in sparse_group:
                                        sparse_data = sparse_group['data'][()]
                                        indices = sparse_group['indices'][()]
                                        indptr = sparse_group['indptr'][()]
                                        shape = tuple(sparse_group.attrs['shape'])
                                        format_type = sparse_group.attrs['format']
                                        
                                        if format_type == 'csr':
                                            data[key] = sp.csr_matrix((sparse_data, indices, indptr), shape=shape)
                                        elif format_type == 'csc':
                                            data[key] = sp.csc_matrix((sparse_data, indices, indptr), shape=shape)
                                        else:
                                            data[key] = sp.csr_matrix((sparse_data, indices, indptr), shape=shape)
                                        self.logger.debug(f"ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—å¾©å…ƒ: {key}, shape={shape}")
                                else:
                                    # é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
                                    data[key] = data_group[key][()]
                                    self.logger.debug(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿: {key}")
                            except Exception as e:
                                self.logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {key}, error={e}")
                                raise
                            pbar.update(1)
            
            self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(data)}é …ç›®ã®ãƒ‡ãƒ¼ã‚¿")
            print(f"ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {checkpoint_file}")
            
        except Exception as e:
            self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            raise
        
        return data, metadata
    
    def list_checkpoints(self, checkpoint_id: str) -> List[str]:
        """ç‰¹å®šIDã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§"""
        checkpoint_dir = self.base_dir / checkpoint_id
        if not checkpoint_dir.exists():
            self.logger.warning(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {checkpoint_dir}")
            return []
        
        checkpoints = sorted([str(f) for f in checkpoint_dir.glob("*.h5")])
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§å–å¾—: {len(checkpoints)}å€‹")
        return checkpoints
    
    def get_latest_checkpoint(self, checkpoint_id: str, stage: str = None) -> Optional[str]:
        """æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—"""
        checkpoints = self.list_checkpoints(checkpoint_id)
        if not checkpoints:
            self.logger.info("åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        if stage:
            filtered = [cp for cp in checkpoints if stage in Path(cp).name]
            result = filtered[-1] if filtered else None
            self.logger.info(f"æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾— (stage={stage}): {result}")
            return result
        
        result = checkpoints[-1]
        self.logger.info(f"æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾—: {result}")
        return result

class RecoveryGPUDiracLaplacianAnalyzer:
    """
    ğŸš€ğŸ”„ Recoveryæ©Ÿèƒ½ä»˜ãRTX3080å¯¾å¿œé«˜æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ è§£æã‚¯ãƒ©ã‚¹
    
    æ–°æ©Ÿèƒ½:
    1. é›»æºæ–­ã‹ã‚‰ã®è‡ªå‹•å¾©æ—§
    2. è¨ˆç®—é€”ä¸­ã‹ã‚‰ã®å†é–‹
    3. é«˜æ¬¡å…ƒï¼ˆ6-10æ¬¡å…ƒï¼‰å¯¾å¿œ
    4. è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
    5. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é©åŒ–
    6. tqdmãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
    7. è©³ç´°ãƒ­ã‚°è¨˜éŒ²æ©Ÿèƒ½
    """
    
    def __init__(self, params: RecoveryGPUOperatorParameters):
        self.params = params
        self.dim = params.dimension
        self.N = params.lattice_size
        self.theta = params.theta
        self.kappa = params.kappa
        self.mass = params.mass
        self.coupling = params.coupling
        self.use_sparse = params.use_sparse
        self.device = device
        
        # ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
        self.logger = setup_logger(f'Analyzer_dim{self.dim}_N{self.N}', level=params.log_level)
        self.logger.info("=" * 80)
        self.logger.info("RecoveryGPUDiracLaplacianAnalyzer åˆæœŸåŒ–é–‹å§‹")
        self.logger.info(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: dim={self.dim}, N={self.N}, theta={self.theta}")
        
        # Recoveryæ©Ÿèƒ½
        self.checkpoint_manager = CheckpointManager() if params.recovery_enabled else None
        self.checkpoint_id = None
        self.last_checkpoint_time = time.time()
        
        # é«˜æ¬¡å…ƒå¯¾å¿œã®ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒè¨ˆç®—
        if self.dim <= 3:
            self.spinor_dim = 2
        elif self.dim <= 6:
            self.spinor_dim = 4
        elif self.dim <= 8:
            self.spinor_dim = 8
        else:
            self.spinor_dim = 16  # 10æ¬¡å…ƒã¾ã§å¯¾å¿œ
        
        self.logger.info(f"ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒ: {self.spinor_dim}")
        
        print(f"ğŸ”§ åˆæœŸåŒ–ä¸­: {self.dim}D, æ ¼å­ã‚µã‚¤ã‚º {self.N}^{self.dim}")
        print(f"ğŸ“Š ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒ: {self.spinor_dim}")
        print(f"ğŸ“Š ç·æ ¼å­ç‚¹æ•°: {self.N**self.dim:,}")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®š
        total_dim = self.N**self.dim * self.spinor_dim
        if self.use_sparse:
            sparsity = min(0.1, 1000.0 / total_dim)  # é©å¿œçš„ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡
            memory_gb = (total_dim**2 * sparsity * 16) / 1e9
            self.logger.info(f"æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰: {memory_gb:.2f} GB")
            print(f"ğŸ’¾ æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰: {memory_gb:.2f} GB")
        else:
            memory_gb = (total_dim**2 * 16) / 1e9
            self.logger.warning(f"æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯†è¡Œåˆ—ï¼‰: {memory_gb:.2f} GB")
            print(f"ğŸ’¾ æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯†è¡Œåˆ—ï¼‰: {memory_gb:.2f} GB")
        
        print(f"ğŸ“Š è¡Œåˆ—æ¬¡å…ƒ: {total_dim:,} x {total_dim:,}")
        
        # Recoveryæœ‰åŠ¹æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆIDç”Ÿæˆ
        if self.checkpoint_manager:
            self.checkpoint_id = self.checkpoint_manager.create_checkpoint_id(params)
            self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆID: {self.checkpoint_id}")
            print(f"ğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆID: {self.checkpoint_id}")
        
        # é«˜æ¬¡å…ƒå¯¾å¿œã‚¬ãƒ³ãƒè¡Œåˆ—ã®æ§‹ç¯‰
        print("ğŸ”¨ ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰ä¸­...")
        self.gamma_matrices = self._construct_high_dimensional_gamma_matrices()
        
        # è‡ªå‹•ä¿å­˜ã®ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
        if params.auto_save:
            signal.signal(signal.SIGINT, self._save_and_exit)
            signal.signal(signal.SIGTERM, self._save_and_exit)
            self.logger.info("è‡ªå‹•ä¿å­˜ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®šå®Œäº†")
        
        self.logger.info("RecoveryGPUDiracLaplacianAnalyzer åˆæœŸåŒ–å®Œäº†")
    
    def _save_and_exit(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«å—ä¿¡æ™‚ã®è‡ªå‹•ä¿å­˜"""
        self.logger.warning(f"ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        print(f"\nâš ï¸  ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        if self.checkpoint_manager and hasattr(self, '_current_stage_data'):
            self.logger.info("ç·Šæ€¥ä¿å­˜ã‚’å®Ÿè¡Œä¸­...")
            self._save_checkpoint('emergency_save', self._current_stage_data)
        self.logger.info("ç·Šæ€¥ä¿å­˜å®Œäº† - ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
        print("ğŸ’¾ ç·Šæ€¥ä¿å­˜å®Œäº† - ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
        sys.exit(0)
    
    def _construct_high_dimensional_gamma_matrices(self) -> List[torch.Tensor]:
        """é«˜æ¬¡å…ƒå¯¾å¿œã‚¬ãƒ³ãƒè¡Œåˆ—ã®æ§‹ç¯‰ï¼ˆGPUæœ€é©åŒ–ç‰ˆï¼‰"""
        self.logger.info(f"{self.dim}æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰é–‹å§‹")
        
        # ãƒ‘ã‚¦ãƒªè¡Œåˆ—ï¼ˆGPUä¸Šã§æ§‹ç¯‰ã€float64ã§ä½œæˆã—ã¦ã‹ã‚‰complex128ã«å¤‰æ›ï¼‰
        sigma_x = torch.tensor([[0, 1], [1, 0]], dtype=torch.float64, device=self.device).to(torch.complex128)
        sigma_y = torch.tensor([[0, -1j], [1j, 0]], dtype=torch.complex128, device=self.device)
        sigma_z = torch.tensor([[1, 0], [0, -1]], dtype=torch.float64, device=self.device).to(torch.complex128)
        I2 = torch.eye(2, dtype=torch.float64, device=self.device).to(torch.complex128)
        
        gamma = []
        
        with tqdm(desc=f"ğŸ”¨ {self.dim}æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰", total=self.dim, disable=False) as pbar:
            if self.dim <= 3:
                # ä½æ¬¡å…ƒã®å ´åˆ
                gamma_list = [sigma_x, sigma_y, sigma_z][:self.dim]
                gamma = gamma_list
                self.logger.debug(f"ä½æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰: {self.dim}å€‹")
                pbar.update(self.dim)
            
            elif self.dim == 4:
                # 4æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯è¡Œåˆ—ï¼ˆGPUä¸Šã§åŠ¹ç‡çš„ã«æ§‹ç¯‰ï¼‰
                O2 = torch.zeros((2, 2), dtype=torch.complex128, device=self.device)
                
                # ãƒ–ãƒ­ãƒƒã‚¯å¯¾è§’è¡Œåˆ—ã‚’æ‰‹å‹•ã§æ§‹ç¯‰
                gamma1 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma1[2:4, 0:2] = sigma_x
                gamma1[0:2, 2:4] = sigma_x
                
                gamma2 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma2[2:4, 0:2] = sigma_y
                gamma2[0:2, 2:4] = sigma_y
                
                gamma3 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma3[2:4, 0:2] = sigma_z
                gamma3[0:2, 2:4] = sigma_z
                
                gamma4 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma4[0:2, 0:2] = I2
                gamma4[2:4, 2:4] = -I2
                
                gamma = [gamma1, gamma2, gamma3, gamma4]
                self.logger.debug("4æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯è¡Œåˆ—æ§‹ç¯‰å®Œäº†")
                pbar.update(4)
            
            elif self.dim <= 6:
                # 6æ¬¡å…ƒã¾ã§ï¼š4æ¬¡å…ƒã‚’æ‹¡å¼µï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
                O2 = torch.zeros((2, 2), dtype=torch.complex128, device=self.device)
                O4 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                I4 = torch.eye(4, dtype=torch.float64, device=self.device).to(torch.complex128)
                
                # åŸºæœ¬4æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—ï¼ˆæ‰‹å‹•æ§‹ç¯‰ï¼‰
                gamma1 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma1[2:4, 0:2] = sigma_x
                gamma1[0:2, 2:4] = sigma_x
                
                gamma2 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma2[2:4, 0:2] = sigma_y
                gamma2[0:2, 2:4] = sigma_y
                
                gamma3 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma3[2:4, 0:2] = sigma_z
                gamma3[0:2, 2:4] = sigma_z
                
                gamma4 = torch.zeros((4, 4), dtype=torch.complex128, device=self.device)
                gamma4[0:2, 0:2] = I2
                gamma4[2:4, 2:4] = -I2
                
                gamma4_list = [gamma1, gamma2, gamma3, gamma4]
                gamma = gamma4_list.copy()
                self.logger.debug("åŸºæœ¬4æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†")
                pbar.update(4)
                
                # 5æ¬¡å…ƒç›®ã¨6æ¬¡å…ƒç›®ï¼ˆåŠ¹ç‡çš„ãªã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ï¼‰
                for i in range(4, self.dim):
                    extra_gamma = torch.kron(I2, gamma4_list[i-4])
                    gamma.append(extra_gamma)
                    self.logger.debug(f"æ‹¡å¼µã‚¬ãƒ³ãƒè¡Œåˆ— {i+1} æ§‹ç¯‰å®Œäº†")
                    pbar.update(1)
            
            else:
                # 8æ¬¡å…ƒä»¥ä¸Šï¼šGPUæœ€é©åŒ–å†å¸°çš„æ§‹ç¯‰
                self.logger.info("é«˜æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—ã®GPUæœ€é©åŒ–å†å¸°çš„æ§‹ç¯‰é–‹å§‹")
                n_matrices_needed = self.dim
                current_dim = 2
                
                # åˆæœŸã‚¬ãƒ³ãƒè¡Œåˆ—
                gamma = [sigma_x, sigma_y, sigma_z]
                self.logger.debug("åˆæœŸã‚¬ãƒ³ãƒè¡Œåˆ—è¨­å®šå®Œäº†")
                pbar.update(3)
                
                while len(gamma) < n_matrices_needed:
                    # æ¬¡å…ƒã‚’å€ã«ã—ã¦æ‹¡å¼µï¼ˆGPUä¸Šã§åŠ¹ç‡çš„ã«ï¼‰
                    current_gamma = gamma.copy()
                    new_gamma = []
                    
                    # æ—¢å­˜ã®è¡Œåˆ—ã‚’æ‹¡å¼µ
                    I_current = torch.eye(current_dim, dtype=torch.float64, device=self.device).to(torch.complex128)
                    O_current = torch.zeros((current_dim, current_dim), dtype=torch.complex128, device=self.device)
                    
                    for g in current_gamma:
                        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ–ãƒ­ãƒƒã‚¯è¡Œåˆ—æ§‹ç¯‰
                        new_g = torch.zeros((current_dim*2, current_dim*2), dtype=torch.complex128, device=self.device)
                        new_g[:current_dim, :current_dim] = g
                        new_g[current_dim:, current_dim:] = -g
                        new_gamma.append(new_g)
                    
                    # æ–°ã—ã„è¡Œåˆ—ã‚’è¿½åŠ 
                    if len(new_gamma) < n_matrices_needed:
                        chirality = torch.zeros((current_dim*2, current_dim*2), dtype=torch.complex128, device=self.device)
                        chirality[:current_dim, :current_dim] = I_current
                        chirality[current_dim:, current_dim:] = -I_current
                        new_gamma.append(chirality)
                    
                    gamma = new_gamma
                    current_dim *= 2
                    
                    progress_update = min(len(gamma) - pbar.n, n_matrices_needed - pbar.n)
                    pbar.update(progress_update)
                    self.logger.debug(f"ã‚¬ãƒ³ãƒè¡Œåˆ—æ‹¡å¼µ: ç¾åœ¨{len(gamma)}å€‹, æ¬¡å…ƒ{current_dim}")
                    
                    if current_dim > self.spinor_dim:
                        break
        
        # å¿…è¦ãªæ¬¡å…ƒæ•°ã«èª¿æ•´
        gamma = gamma[:self.dim]
        
        # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª
        gpu_memory = monitor_gpu_memory()
        if gpu_memory:
            self.logger.info(f"ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å¾ŒGPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
        
        self.logger.info(f"{self.dim}æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†: {len(gamma)}å€‹ã®{gamma[0].shape}è¡Œåˆ—")
        print(f"âœ… {self.dim}æ¬¡å…ƒã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†: {len(gamma)}å€‹ã®{gamma[0].shape}è¡Œåˆ—")
        
        return gamma
    
    def _save_checkpoint(self, stage: str, data: Dict[str, Any]):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜"""
        if not self.checkpoint_manager:
            return
        
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: stage={stage}")
        
        metadata = {
            'dimension': self.dim,
            'lattice_size': self.N,
            'parameters': asdict(self.params)
        }
        
        self.checkpoint_manager.save_checkpoint(
            self.checkpoint_id, stage, data, metadata
        )
        self.last_checkpoint_time = time.time()
    
    def _should_save_checkpoint(self) -> bool:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åˆ¤å®š"""
        if not self.checkpoint_manager:
            return False
        
        should_save = (time.time() - self.last_checkpoint_time) > self.params.checkpoint_interval
        if should_save:
            self.logger.debug("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«åˆ°é”")
        return should_save
    
    def construct_discrete_dirac_operator_gpu_optimized(self) -> torch.sparse.FloatTensor:
        """
        ğŸš€ RTX3080æœ€é©åŒ–ç‰ˆãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰
        """
        stage = 'dirac_construction'
        self.logger.info("GPUæœ€é©åŒ–ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰é–‹å§‹")
        
        # æ—¢å­˜ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        if self.checkpoint_manager:
            latest_checkpoint = self.checkpoint_manager.get_latest_checkpoint(
                self.checkpoint_id, stage
            )
            if latest_checkpoint:
                self.logger.info("æ—¢å­˜ã®ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç™ºè¦‹")
                print("ğŸ“‚ æ—¢å­˜ã®ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç™ºè¦‹")
                try:
                    data, metadata = self.checkpoint_manager.load_checkpoint(latest_checkpoint)
                    if 'dirac_operator' in data:
                        self.logger.info("ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒ")
                        print("âœ… ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒ")
                        # scipyã‹ã‚‰torchã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã«å¤‰æ›
                        scipy_matrix = data['dirac_operator']
                        return self._scipy_to_torch_sparse(scipy_matrix)
                except Exception as e:
                    self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                    print(f"âš ï¸  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                    print("æ–°è¦ã«æ§‹ç¯‰ã—ã¾ã™")
        
        print("ğŸ”¨ GPUæœ€é©åŒ–ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰ä¸­...")
        start_time = time.time()
        
        total_dim = self.N**self.dim * self.spinor_dim
        self.logger.info(f"è¡Œåˆ—æ¬¡å…ƒ: {total_dim} x {total_dim}")
        
        # GPUä¸Šã§ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã‚’åŠ¹ç‡çš„ã«æ§‹ç¯‰
        indices_list = []
        values_list = []
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å‹•çš„èª¿æ•´
        batch_size = self.params.gpu_batch_size
        if total_dim > 100000:  # å¤§è¦æ¨¡è¡Œåˆ—ã®å ´åˆ
            batch_size = min(batch_size, total_dim // 100)
            self.logger.info(f"å¤§è¦æ¨¡è¡Œåˆ—ç”¨ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´: {batch_size}")
        
        # å„æ–¹å‘ã®å¾®åˆ†ä½œç”¨ç´ ã‚’GPUä¸Šã§æ§‹ç¯‰
        for mu in tqdm(range(self.dim), desc="ğŸ”¨ GPUæœ€é©åŒ–ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰", disable=False):
            self.logger.debug(f"æ–¹å‘ {mu+1}/{self.dim} å‡¦ç†ä¸­")
            
            # GPUä¸Šã§å·®åˆ†ä½œç”¨ç´ ã‚’æ§‹ç¯‰
            diff_indices, diff_values = self._construct_difference_operator_gpu(mu, batch_size)
            
            # ã‚¬ãƒ³ãƒè¡Œåˆ—ã¨ã®ç©ï¼ˆGPUä¸Šã§åŠ¹ç‡çš„ã«ï¼‰
            gamma_mu = self.gamma_matrices[mu]
            
            # ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ã‚’GPUä¸Šã§åŠ¹ç‡çš„ã«è¨ˆç®—
            kron_indices, kron_values = self._gpu_kron_sparse(
                diff_indices, diff_values, gamma_mu, total_dim
            )
            
            indices_list.append(kron_indices)
            values_list.append(kron_values)
            
            # éå¯æ›è£œæ­£é …
            if self.theta != 0:
                theta_indices, theta_values = self._construct_theta_correction_gpu(mu, batch_size)
                theta_kron_indices, theta_kron_values = self._gpu_kron_sparse(
                    theta_indices, theta_values, gamma_mu, total_dim
                )
                indices_list.append(theta_kron_indices)
                values_list.append(self.theta * theta_kron_values)
                self.logger.debug(f"éå¯æ›è£œæ­£é …è¿½åŠ : theta={self.theta}")
            
            # GPU ãƒ¡ãƒ¢ãƒªç®¡ç†
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # å®šæœŸçš„ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
            if self._should_save_checkpoint():
                temp_data = {'partial_construction': True, 'completed_directions': mu + 1}
                self._save_checkpoint('dirac_partial', temp_data)
                self.logger.info(f"éƒ¨åˆ†çš„ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ä¿å­˜: {mu+1}/{self.dim}æ–¹å‘å®Œäº†")
        
        # è³ªé‡é …ã®è¿½åŠ 
        if self.mass != 0:
            with tqdm(desc="è³ªé‡é …è¿½åŠ ä¸­", total=1, disable=False) as pbar:
                mass_indices, mass_values = self._construct_mass_term_gpu(total_dim)
                indices_list.append(mass_indices)
                values_list.append(self.mass * mass_values)
                self.logger.debug(f"è³ªé‡é …è¿½åŠ : mass={self.mass}")
                pbar.update(1)
        
        # å…¨ã¦ã®é …ã‚’çµåˆã—ã¦ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã‚’æ§‹ç¯‰
        with tqdm(desc="ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—çµåˆä¸­", total=1, disable=False) as pbar:
            all_indices = torch.cat(indices_list, dim=1)
            all_values = torch.cat(values_list, dim=0)
            
            # é‡è¤‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å‡¦ç†
            D_sparse = torch.sparse_coo_tensor(
                all_indices, all_values, 
                (total_dim, total_dim), 
                dtype=torch.complex128, 
                device=self.device
            ).coalesce()
            
            pbar.update(1)
        
        construction_time = time.time() - start_time
        nnz = D_sparse._nnz()
        
        self.logger.info(f"GPUæœ€é©åŒ–ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰å®Œäº†: {construction_time:.2f}ç§’, nnz={nnz}")
        print(f"âœ… GPUæœ€é©åŒ–ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰å®Œäº†: {construction_time:.2f}ç§’")
        print(f"ğŸ“Š è¡Œåˆ—ã‚µã‚¤ã‚º: {D_sparse.shape}, éé›¶è¦ç´ æ•°: {nnz:,}")
        
        # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª
        gpu_memory = monitor_gpu_memory()
        if gpu_memory:
            self.logger.info(f"æ§‹ç¯‰å¾ŒGPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
            print(f"ğŸ’¾ GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆscipyãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ï¼‰
        if self.checkpoint_manager:
            scipy_matrix = self._torch_sparse_to_scipy(D_sparse)
            checkpoint_data = {
                'dirac_operator': scipy_matrix,
                'construction_time': construction_time,
                'matrix_info': {
                    'shape': D_sparse.shape,
                    'nnz': nnz,
                    'dtype': str(D_sparse.dtype)
                }
            }
            self._save_checkpoint(stage, checkpoint_data)
        
        return D_sparse
    
    def _construct_difference_operator_gpu(self, direction: int, batch_size: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """GPUä¸Šã§ã®å·®åˆ†ä½œç”¨ç´ æ§‹ç¯‰"""
        self.logger.debug(f"GPUå·®åˆ†ä½œç”¨ç´ æ§‹ç¯‰: direction={direction}")
        
        # 1æ¬¡å…ƒã®å‰é€²å·®åˆ†ã‚’GPUä¸Šã§æ§‹ç¯‰
        n = self.N
        indices = torch.zeros((2, n), dtype=torch.long, device=self.device)
        values = torch.zeros(n, dtype=torch.complex128, device=self.device)
        
        # å¯¾è§’ç·šä¸Šã®è¦ç´ 
        indices[0, :] = torch.arange(n, device=self.device)
        indices[1, :] = torch.arange(n, device=self.device)
        values[:] = -1.0
        
        # ä¸Šå¯¾è§’ç·šã®è¦ç´ ï¼ˆå‘¨æœŸå¢ƒç•Œæ¡ä»¶ï¼‰
        indices_upper = torch.zeros((2, n), dtype=torch.long, device=self.device)
        values_upper = torch.ones(n, dtype=torch.complex128, device=self.device)
        
        indices_upper[0, :-1] = torch.arange(n-1, device=self.device)
        indices_upper[1, :-1] = torch.arange(1, n, device=self.device)
        indices_upper[0, -1] = n-1
        indices_upper[1, -1] = 0  # å‘¨æœŸå¢ƒç•Œæ¡ä»¶
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨å€¤ã‚’çµåˆ
        all_indices = torch.cat([indices, indices_upper], dim=1)
        all_values = torch.cat([values, values_upper])
        
        return all_indices, all_values
    
    def _gpu_kron_sparse(self, indices_a: torch.Tensor, values_a: torch.Tensor, 
                        matrix_b: torch.Tensor, total_dim: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """GPUä¸Šã§ã®ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã¨ãƒ‡ãƒ³ã‚¹è¡Œåˆ—ã®ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©"""
        # åŠ¹ç‡çš„ãªã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ã®å®Ÿè£…
        m_a, n_a = self.N**self.dim, self.N**self.dim
        m_b, n_b = matrix_b.shape
        
        # æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¨ˆç®—
        nnz = indices_a.shape[1]
        new_indices = torch.zeros((2, nnz * m_b * n_b), dtype=torch.long, device=self.device)
        new_values = torch.zeros(nnz * m_b * n_b, dtype=torch.complex128, device=self.device)
        
        idx = 0
        for k in range(nnz):
            i_a, j_a = indices_a[0, k], indices_a[1, k]
            val_a = values_a[k]
            
            for i_b in range(m_b):
                for j_b in range(n_b):
                    new_i = i_a * m_b + i_b
                    new_j = j_a * n_b + j_b
                    new_val = val_a * matrix_b[i_b, j_b]
                    
                    new_indices[0, idx] = new_i
                    new_indices[1, idx] = new_j
                    new_values[idx] = new_val
                    idx += 1
        
        return new_indices[:, :idx], new_values[:idx]
    
    def _construct_theta_correction_gpu(self, direction: int, batch_size: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """GPUä¸Šã§ã®Î¸-å¤‰å½¢è£œæ­£é …ã®æ§‹ç¯‰"""
        self.logger.debug(f"GPU Î¸è£œæ­£é …æ§‹ç¯‰: direction={direction}, theta={self.theta}")
        
        # ä½ç½®ä½œç”¨ç´ ã‚’GPUä¸Šã§æ§‹ç¯‰ï¼ˆfloat64ã§ä½œæˆã—ã¦ã‹ã‚‰complex128ã«å¤‰æ›ï¼‰
        n = self.N
        positions = torch.arange(n, device=self.device, dtype=torch.float64) - n // 2
        positions = positions.to(torch.complex128)  # complex128ã«å¤‰æ›
        
        # å¯¾è§’è¡Œåˆ—ã¨ã—ã¦æ§‹ç¯‰
        indices = torch.zeros((2, n), dtype=torch.long, device=self.device)
        indices[0, :] = torch.arange(n, device=self.device)
        indices[1, :] = torch.arange(n, device=self.device)
        values = positions * 0.01  # å°ã•ãªè£œæ­£ä¿‚æ•°
        
        return indices, values
    
    def _construct_mass_term_gpu(self, total_dim: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """GPUä¸Šã§ã®è³ªé‡é …ã®æ§‹ç¯‰"""
        # å˜ä½è¡Œåˆ—ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹å½¢å¼ã§æ§‹ç¯‰
        indices = torch.zeros((2, total_dim), dtype=torch.long, device=self.device)
        indices[0, :] = torch.arange(total_dim, device=self.device)
        indices[1, :] = torch.arange(total_dim, device=self.device)
        values = torch.ones(total_dim, dtype=torch.complex128, device=self.device)
        
        return indices, values
    
    def _scipy_to_torch_sparse(self, scipy_matrix: sp.csr_matrix) -> torch.sparse.FloatTensor:
        """scipy ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã‚’ torch ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã«å¤‰æ›"""
        coo = scipy_matrix.tocoo()
        indices = torch.from_numpy(np.vstack([coo.row, coo.col])).long()
        values = torch.from_numpy(coo.data).to(torch.complex128)
        
        return torch.sparse_coo_tensor(
            indices, values, coo.shape, 
            dtype=torch.complex128, device=self.device
        ).coalesce()
    
    def _torch_sparse_to_scipy(self, torch_sparse: torch.sparse.FloatTensor) -> sp.csr_matrix:
        """torch ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã‚’ scipy ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã«å¤‰æ›"""
        torch_sparse = torch_sparse.coalesce().cpu()
        indices = torch_sparse.indices().numpy()
        values = torch_sparse.values().numpy()
        shape = torch_sparse.shape
        
        return sp.coo_matrix((values, (indices[0], indices[1])), shape=shape).tocsr()
    
    def compute_spectral_dimension_gpu_optimized(self, 
                                                operator: torch.sparse.FloatTensor,
                                                n_eigenvalues: int = None) -> Tuple[float, Dict]:
        """
        ğŸš€ RTX3080æœ€é©åŒ–ç‰ˆã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
        """
        if n_eigenvalues is None:
            n_eigenvalues = self.params.max_eigenvalues
        
        stage = 'spectral_computation'
        self.logger.info(f"GPUæœ€é©åŒ–ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—é–‹å§‹: n_eigenvalues={n_eigenvalues}")
        
        # æ—¢å­˜ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        if self.checkpoint_manager:
            latest_checkpoint = self.checkpoint_manager.get_latest_checkpoint(
                self.checkpoint_id, stage
            )
            if latest_checkpoint:
                self.logger.info("æ—¢å­˜ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«è¨ˆç®—ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç™ºè¦‹")
                print("ğŸ“‚ æ—¢å­˜ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«è¨ˆç®—ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç™ºè¦‹")
                try:
                    data, metadata = self.checkpoint_manager.load_checkpoint(latest_checkpoint)
                    if 'spectral_dimension' in data:
                        self.logger.info("ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒ")
                        print("âœ… ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒ")
                        return data['spectral_dimension'], data.get('analysis_info', {})
                except Exception as e:
                    self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                    print(f"âš ï¸  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
                    print("æ–°è¦ã«è¨ˆç®—ã—ã¾ã™")
        
        print("ğŸ” GPUæœ€é©åŒ–ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ä¸­...")
        start_time = time.time()
        
        # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®åˆæœŸç¢ºèª
        gpu_memory = monitor_gpu_memory()
        if gpu_memory:
            self.logger.info(f"è¨ˆç®—é–‹å§‹æ™‚GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
            print(f"ğŸ’¾ è¨ˆç®—é–‹å§‹æ™‚GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
        
        try:
            # GPUä¸Šã§ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ã«ï¼‰
            with tqdm(desc="ğŸ”¨ GPUä¸Šã§ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–ä¸­", total=1, disable=False) as pbar:
                self.logger.debug("GPUä¸Šã§ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–é–‹å§‹")
                
                # æ··åˆç²¾åº¦è¨ˆç®—ã®ä½¿ç”¨
                if self.params.use_mixed_precision and torch.cuda.is_available():
                    with torch.cuda.amp.autocast():
                        operator_hermitian = torch.sparse.mm(operator.conj().transpose(0, 1), operator)
                else:
                    operator_hermitian = torch.sparse.mm(operator.conj().transpose(0, 1), operator)
                
                # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®æœ€é©åŒ–
                operator_hermitian = operator_hermitian.coalesce()
                
                self.logger.debug(f"GPUä¸Šã§ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–å®Œäº†: shape={operator_hermitian.shape}")
                pbar.update(1)
            
            # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜
            self._current_stage_data = {
                'stage': 'hermitian_complete',
                'operator_shape': operator.shape,
                'nnz': operator._nnz()
            }
            
            # GPUä¸Šã§ã®å›ºæœ‰å€¤è¨ˆç®—ï¼ˆåŠ¹ç‡çš„ãªå®Ÿè£…ï¼‰
            eigenvalues = self._compute_eigenvalues_gpu_optimized(
                operator_hermitian, n_eigenvalues
            )
            
            if len(eigenvalues) < 10:
                self.logger.warning(f"æœ‰åŠ¹ãªå›ºæœ‰å€¤ãŒå°‘ãªã™ãã¾ã™: {len(eigenvalues)}å€‹")
                print("âš ï¸  è­¦å‘Š: æœ‰åŠ¹ãªå›ºæœ‰å€¤ãŒå°‘ãªã™ãã¾ã™")
                return float('nan'), {}
            
            # ä¸­é–“çµæœã®ä¿å­˜
            if self._should_save_checkpoint():
                checkpoint_data = {
                    'eigenvalues': eigenvalues.cpu().numpy(),
                    'computation_stage': 'eigenvalues_complete'
                }
                self._save_checkpoint('spectral_intermediate', checkpoint_data)
            
        except Exception as e:
            self.logger.error(f"å›ºæœ‰å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ å›ºæœ‰å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return float('nan'), {}
        
        # GPUä¸Šã§ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        spectral_dimension = self._compute_spectral_zeta_gpu_optimized(eigenvalues)
        
        computation_time = time.time() - start_time
        self.logger.info(f"GPUæœ€é©åŒ–ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—å®Œäº†: {computation_time:.2f}ç§’")
        print(f"âœ… GPUæœ€é©åŒ–ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—å®Œäº†: {computation_time:.2f}ç§’")
        
        # æœ€çµ‚GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª
        gpu_memory = monitor_gpu_memory()
        if gpu_memory:
            self.logger.info(f"è¨ˆç®—å®Œäº†æ™‚GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
            print(f"ğŸ’¾ è¨ˆç®—å®Œäº†æ™‚GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
        
        # è©³ç´°æƒ…å ±
        analysis_info = {
            'eigenvalues': eigenvalues.cpu().numpy(),
            'n_eigenvalues': len(eigenvalues),
            'min_eigenvalue': torch.min(eigenvalues).item(),
            'max_eigenvalue': torch.max(eigenvalues).item(),
            'spectral_gap': (eigenvalues[1] - eigenvalues[0]).item() if len(eigenvalues) > 1 else 0,
            'computation_time': computation_time,
            'gpu_optimized': True
        }
        
        # æœ€çµ‚çµæœã®ä¿å­˜
        if self.checkpoint_manager:
            final_data = {
                'spectral_dimension': spectral_dimension,
                'analysis_info': analysis_info
            }
            self._save_checkpoint(stage, final_data)
        
        return spectral_dimension, analysis_info
    
    def _compute_eigenvalues_gpu_optimized(self, operator_hermitian: torch.sparse.FloatTensor, 
                                         n_eigenvalues: int) -> torch.Tensor:
        """GPUæœ€é©åŒ–å›ºæœ‰å€¤è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰"""
        self.logger.info("é«˜ç²¾åº¦GPUæœ€é©åŒ–å›ºæœ‰å€¤è¨ˆç®—é–‹å§‹")
        
        # è¡Œåˆ—ã‚µã‚¤ã‚ºã«å¿œã˜ãŸè¨ˆç®—æ–¹æ³•ã®é¸æŠ
        matrix_size = operator_hermitian.shape[0]
        
        if matrix_size < 5000:
            # å°è¦æ¨¡è¡Œåˆ—ï¼šç›´æ¥GPUè¨ˆç®—ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
            return self._compute_eigenvalues_direct_gpu_precision(operator_hermitian, n_eigenvalues)
        elif matrix_size < 50000:
            # ä¸­è¦æ¨¡è¡Œåˆ—ï¼šæ”¹è‰¯ãƒãƒƒãƒå‡¦ç†
            return self._compute_eigenvalues_batch_gpu_precision(operator_hermitian, n_eigenvalues)
        else:
            # å¤§è¦æ¨¡è¡Œåˆ—ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
            return self._compute_eigenvalues_hybrid_precision(operator_hermitian, n_eigenvalues)
    
    def _compute_eigenvalues_direct_gpu_precision(self, operator: torch.sparse.FloatTensor, 
                                                n_eigenvalues: int) -> torch.Tensor:
        """å°è¦æ¨¡è¡Œåˆ—ã®é«˜ç²¾åº¦ç›´æ¥GPUè¨ˆç®—"""
        with tqdm(desc="ğŸ§® é«˜ç²¾åº¦å°è¦æ¨¡è¡Œåˆ—GPUå›ºæœ‰å€¤è¨ˆç®—", total=1, disable=False) as pbar:
            # ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã‚’å¯†è¡Œåˆ—ã«å¤‰æ›ï¼ˆå€ç²¾åº¦ï¼‰
            dense_operator = operator.to_dense().to(torch.complex128)
            
            # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã®å‰å‡¦ç†
            # è¡Œåˆ—ã®æ¡ä»¶æ•°ãƒã‚§ãƒƒã‚¯
            try:
                # å¯¾è§’è¦ç´ ã®å¹³å‡ã‚’è¨ˆç®—
                diag_mean = torch.mean(torch.diag(dense_operator).real)
                
                # æ­£å‰‡åŒ–é …ã‚’è¿½åŠ ï¼ˆæ¡ä»¶æ•°æ”¹å–„ï¼‰
                regularization = 1e-12 * diag_mean * torch.eye(
                    dense_operator.shape[0], 
                    device=self.device, 
                    dtype=torch.complex128
                )
                dense_operator_reg = dense_operator + regularization
                
                # GPUä¸Šã§é«˜ç²¾åº¦å›ºæœ‰å€¤è¨ˆç®—
                eigenvalues = torch.linalg.eigvals(dense_operator_reg)
                eigenvalues = torch.real(eigenvalues)
                
                # æ­£ã®å›ºæœ‰å€¤ã®ã¿ã‚’æŠ½å‡ºï¼ˆã‚ˆã‚Šå³å¯†ãªé–¾å€¤ï¼‰
                eigenvalues = eigenvalues[eigenvalues > 1e-14]
                
                # æœ€å°å›ºæœ‰å€¤ã‹ã‚‰é †ã«ã‚½ãƒ¼ãƒˆ
                eigenvalues, _ = torch.sort(eigenvalues)
                eigenvalues = eigenvalues[:n_eigenvalues]
                
                self.logger.info(f"é«˜ç²¾åº¦ç›´æ¥GPUè¨ˆç®—å®Œäº†: {len(eigenvalues)}å€‹ã®å›ºæœ‰å€¤")
                self.logger.info(f"æœ€å°å›ºæœ‰å€¤: {torch.min(eigenvalues).item():.2e}")
                self.logger.info(f"æœ€å¤§å›ºæœ‰å€¤: {torch.max(eigenvalues).item():.2e}")
                self.logger.info(f"æ¡ä»¶æ•°: {(torch.max(eigenvalues) / torch.min(eigenvalues)).item():.2e}")
                
            except Exception as e:
                self.logger.error(f"é«˜ç²¾åº¦ç›´æ¥è¨ˆç®—å¤±æ•—: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ¨™æº–ç²¾åº¦
                eigenvalues = torch.linalg.eigvals(dense_operator.to(torch.complex64))
                eigenvalues = torch.real(eigenvalues)
                eigenvalues = eigenvalues[eigenvalues > 1e-12]
                eigenvalues, _ = torch.sort(eigenvalues)
                eigenvalues = eigenvalues[:n_eigenvalues]
            
            pbar.update(1)
        
        return eigenvalues.to(torch.float64)
    
    def _compute_eigenvalues_batch_gpu_precision(self, operator: torch.sparse.FloatTensor, 
                                               n_eigenvalues: int) -> torch.Tensor:
        """ä¸­è¦æ¨¡è¡Œåˆ—ã®é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†GPUè¨ˆç®—"""
        self.logger.info("é«˜ç²¾åº¦ä¸­è¦æ¨¡è¡Œåˆ—ãƒãƒƒãƒå‡¦ç†GPUè¨ˆç®—é–‹å§‹")
        
        # æ”¹è‰¯Lanczosæ³•ã®å®Ÿè£…
        matrix_size = operator.shape[0]
        max_iterations = min(200, n_eigenvalues * 3)  # åå¾©å›æ•°ã‚’å¢—åŠ 
        tolerance = 1e-12  # åæŸåˆ¤å®šã‚’å³å¯†åŒ–
        
        eigenvalues_list = []
        
        with tqdm(desc="ğŸ§® é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†GPUå›ºæœ‰å€¤è¨ˆç®—", total=max_iterations//10, disable=False) as pbar:
            # è¤‡æ•°ã®åˆæœŸãƒ™ã‚¯ãƒˆãƒ«ã§å®Ÿè¡Œï¼ˆç²¾åº¦å‘ä¸Šï¼‰
            for seed in range(3):  # 3ã¤ã®ç•°ãªã‚‹åˆæœŸå€¤
                torch.manual_seed(42 + seed)  # å†ç¾æ€§ã®ãŸã‚
                
                # åˆæœŸãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ­£è¦åŒ–ï¼‰
                v = torch.randn(matrix_size, dtype=torch.complex128, device=self.device)
                v = v / torch.norm(v)
                
                # Lanczosåå¾©
                eigenvals_seed = []
                prev_eigenval = float('inf')
                
                for i in range(max_iterations):
                    # è¡Œåˆ—ãƒ™ã‚¯ãƒˆãƒ«ç©ï¼ˆé«˜ç²¾åº¦ï¼‰
                    Av = torch.sparse.mm(operator, v.unsqueeze(1)).squeeze(1)
                    
                    # Rayleighå•†ã«ã‚ˆã‚‹å›ºæœ‰å€¤è¿‘ä¼¼
                    eigenval = torch.real(torch.dot(v.conj(), Av))
                    eigenvals_seed.append(eigenval.item())
                    
                    # åæŸåˆ¤å®šï¼ˆå³å¯†åŒ–ï¼‰
                    if abs(eigenval.item() - prev_eigenval) < tolerance:
                        self.logger.debug(f"åæŸé”æˆ (seed={seed}, iter={i}): {eigenval.item():.2e}")
                        break
                    
                    # æ¬¡ã®ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—ï¼ˆGram-Schmidtç›´äº¤åŒ–ï¼‰
                    if i < max_iterations - 1:
                        v_new = Av - eigenval * v
                        
                        # ç›´äº¤åŒ–ï¼ˆæ•°å€¤å®‰å®šæ€§å‘ä¸Šï¼‰
                        for _ in range(2):  # 2å›ã®ç›´äº¤åŒ–
                            v_new = v_new - torch.dot(v_new.conj(), v) * v
                        
                        norm_v_new = torch.norm(v_new)
                        if norm_v_new > tolerance:
                            v = v_new / norm_v_new
                        else:
                            # æ–°ã—ã„ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ã‚¯ãƒˆãƒ«ã§å†é–‹
                            v = torch.randn(matrix_size, dtype=torch.complex128, device=self.device)
                            v = v / torch.norm(v)
                    
                    prev_eigenval = eigenval.item()
                    
                    if i % 10 == 0:
                        pbar.update(1)
                
                eigenvalues_list.extend(eigenvals_seed)
        
        # é‡è¤‡é™¤å»ã¨é¸åˆ¥
        eigenvalues = torch.tensor(eigenvalues_list, device=self.device, dtype=torch.float64)
        eigenvalues = eigenvalues[eigenvalues > 1e-14]
        
        # é‡è¤‡é™¤å»ï¼ˆè¿‘ã„å€¤ã‚’ãƒãƒ¼ã‚¸ï¼‰
        eigenvalues_unique = []
        eigenvalues_sorted, _ = torch.sort(eigenvalues)
        
        if len(eigenvalues_sorted) > 0:
            eigenvalues_unique.append(eigenvalues_sorted[0])
            for i in range(1, len(eigenvalues_sorted)):
                if abs(eigenvalues_sorted[i] - eigenvalues_unique[-1]) > tolerance * 10:
                    eigenvalues_unique.append(eigenvalues_sorted[i])
        
        eigenvalues_final = torch.tensor(eigenvalues_unique, device=self.device, dtype=torch.float64)
        eigenvalues_final = eigenvalues_final[:n_eigenvalues]
        
        self.logger.info(f"é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†GPUè¨ˆç®—å®Œäº†: {len(eigenvalues_final)}å€‹ã®å›ºæœ‰å€¤")
        return eigenvalues_final
    
    def _compute_eigenvalues_hybrid_precision(self, operator: torch.sparse.FloatTensor, 
                                            n_eigenvalues: int) -> torch.Tensor:
        """å¤§è¦æ¨¡è¡Œåˆ—ã®é«˜ç²¾åº¦ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨ˆç®—ï¼ˆGPU+CPUï¼‰"""
        self.logger.info("é«˜ç²¾åº¦å¤§è¦æ¨¡è¡Œåˆ—ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨ˆç®—é–‹å§‹")
        
        with tqdm(desc="ğŸ§® é«˜ç²¾åº¦ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å›ºæœ‰å€¤è¨ˆç®—", total=1, disable=False) as pbar:
            # GPUä¸Šã§å‰å‡¦ç†
            operator_cpu = self._torch_sparse_to_scipy(operator)
            
            # CPUä¸Šã§é«˜ç²¾åº¦ã‚¹ãƒ‘ãƒ¼ã‚¹å›ºæœ‰å€¤è¨ˆç®—
            try:
                # è¤‡æ•°ã®æ‰‹æ³•ã‚’è©¦è¡Œ
                eigenvalues_list = []
                
                # æ‰‹æ³•1: ARPACK (which='SM')
                try:
                    eigenvals_sm = eigsh(
                        operator_cpu, 
                        k=min(n_eigenvalues, operator_cpu.shape[0]-2),
                        which='SM',  # æœ€å°å›ºæœ‰å€¤
                        tol=1e-12,   # åæŸåˆ¤å®šã‚’å³å¯†åŒ–
                        maxiter=1000,  # æœ€å¤§åå¾©å›æ•°å¢—åŠ 
                        return_eigenvectors=False
                    )
                    eigenvals_sm = np.real(eigenvals_sm)
                    eigenvals_sm = eigenvals_sm[eigenvals_sm > 1e-14]
                    eigenvalues_list.extend(eigenvals_sm)
                    self.logger.info(f"ARPACK-SM: {len(eigenvals_sm)}å€‹ã®å›ºæœ‰å€¤")
                except Exception as e:
                    self.logger.warning(f"ARPACK-SMå¤±æ•—: {e}")
                
                # æ‰‹æ³•2: ARPACK (which='SA')
                try:
                    eigenvals_sa = eigsh(
                        operator_cpu, 
                        k=min(n_eigenvalues//2, operator_cpu.shape[0]-2),
                        which='SA',  # æœ€å°ä»£æ•°å›ºæœ‰å€¤
                        tol=1e-12,
                        maxiter=1000,
                        return_eigenvectors=False
                    )
                    eigenvals_sa = np.real(eigenvals_sa)
                    eigenvals_sa = eigenvals_sa[eigenvals_sa > 1e-14]
                    eigenvalues_list.extend(eigenvals_sa)
                    self.logger.info(f"ARPACK-SA: {len(eigenvals_sa)}å€‹ã®å›ºæœ‰å€¤")
                except Exception as e:
                    self.logger.warning(f"ARPACK-SAå¤±æ•—: {e}")
                
                if eigenvalues_list:
                    # é‡è¤‡é™¤å»ã¨çµ±åˆ
                    eigenvalues_np = np.array(eigenvalues_list)
                    eigenvalues_np = np.unique(eigenvalues_np)
                    eigenvalues_np = eigenvalues_np[eigenvalues_np > 1e-14]
                    eigenvalues_np = np.sort(eigenvalues_np)[:n_eigenvalues]
                    
                    # GPUä¸Šã«æˆ»ã™
                    eigenvalues = torch.tensor(eigenvalues_np, device=self.device, dtype=torch.float64)
                    
                    self.logger.info(f"çµ±åˆçµæœ: {len(eigenvalues)}å€‹ã®å›ºæœ‰å€¤")
                    
                else:
                    raise Exception("å…¨ã¦ã®æ‰‹æ³•ãŒå¤±æ•—")
                
            except Exception as e:
                self.logger.warning(f"é«˜ç²¾åº¦scipyå›ºæœ‰å€¤è¨ˆç®—å¤±æ•—: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç°¡æ˜“è¿‘ä¼¼ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                eigenvalues = self._compute_eigenvalues_approximation_precision(operator, n_eigenvalues)
            
            pbar.update(1)
        
        self.logger.info(f"é«˜ç²¾åº¦ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨ˆç®—å®Œäº†: {len(eigenvalues)}å€‹ã®å›ºæœ‰å€¤")
        return eigenvalues
    
    def _compute_eigenvalues_approximation_precision(self, operator: torch.sparse.FloatTensor, 
                                                   n_eigenvalues: int) -> torch.Tensor:
        """é«˜ç²¾åº¦å›ºæœ‰å€¤è¿‘ä¼¼è¨ˆç®—ï¼ˆæ”¹è‰¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        self.logger.info("é«˜ç²¾åº¦å›ºæœ‰å€¤è¿‘ä¼¼è¨ˆç®—é–‹å§‹")
        
        # è¤‡æ•°ã®è¿‘ä¼¼æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›
        eigenvalues_list = []
        
        # æ‰‹æ³•1: å¯¾è§’è¦ç´ ã«ã‚ˆã‚‹è¿‘ä¼¼
        diagonal = torch.sparse.sum(operator, dim=1).to_dense()
        diagonal = torch.real(diagonal)
        diagonal = diagonal[diagonal > 1e-14]
        diagonal, _ = torch.sort(diagonal)
        eigenvalues_list.extend(diagonal[:n_eigenvalues//2].tolist())
        
        # æ‰‹æ³•2: Gershgorinå††ç›¤ã«ã‚ˆã‚‹æ¨å®š
        try:
            # å„è¡Œã®éå¯¾è§’è¦ç´ ã®å’Œ
            operator_dense = operator.to_dense()
            diag_elements = torch.diag(operator_dense).real
            off_diag_sums = torch.sum(torch.abs(operator_dense), dim=1) - torch.abs(diag_elements)
            
            # Gershgorinå††ç›¤ã®ä¸­å¿ƒã¨åŠå¾„
            centers = diag_elements
            radii = off_diag_sums
            
            # å›ºæœ‰å€¤ã®ä¸‹é™æ¨å®š
            lower_bounds = centers - radii
            lower_bounds = lower_bounds[lower_bounds > 1e-14]
            lower_bounds, _ = torch.sort(lower_bounds)
            eigenvalues_list.extend(lower_bounds[:n_eigenvalues//2].tolist())
            
        except Exception as e:
            self.logger.warning(f"Gershgorinæ¨å®šå¤±æ•—: {e}")
        
        # çµ±åˆã¨é‡è¤‡é™¤å»
        if eigenvalues_list:
            eigenvalues = torch.tensor(eigenvalues_list, device=self.device, dtype=torch.float64)
            eigenvalues = torch.unique(eigenvalues)
            eigenvalues = eigenvalues[eigenvalues > 1e-14]
            eigenvalues, _ = torch.sort(eigenvalues)
            eigenvalues = eigenvalues[:n_eigenvalues]
        else:
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            eigenvalues = torch.linspace(1e-6, 1.0, n_eigenvalues, device=self.device, dtype=torch.float64)
        
        self.logger.info(f"é«˜ç²¾åº¦è¿‘ä¼¼è¨ˆç®—å®Œäº†: {len(eigenvalues)}å€‹ã®å›ºæœ‰å€¤")
        return eigenvalues
    
    def _compute_spectral_zeta_gpu_optimized(self, eigenvalues: torch.Tensor) -> float:
        """GPUæœ€é©åŒ–ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰"""
        self.logger.info("é«˜ç²¾åº¦GPUæœ€é©åŒ–ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—é–‹å§‹")
        print("âš¡ é«˜ç²¾åº¦GPUæœ€é©åŒ–ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—...")
        
        # é«˜ç²¾åº¦è¨ˆç®—ã®ãŸã‚ã®è¨­å®š
        eigenvalues = eigenvalues.to(torch.float64)  # å€ç²¾åº¦ã«å¤‰æ›´
        
        # é©å¿œçš„tå€¤ç¯„å›²ã®è¨­å®šï¼ˆã‚ˆã‚Šç´°ã‹ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        t_min = 1e-6
        t_max = 10.0
        n_samples_coarse = 50
        n_samples_fine = 200
        
        # ç²—ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å‚¾å‘ã‚’æŠŠæ¡
        t_values_coarse = torch.logspace(
            np.log10(t_min), np.log10(t_max), n_samples_coarse, 
            device=self.device, dtype=torch.float64
        )
        
        # ãƒãƒƒãƒå‡¦ç†ã§ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ï¼ˆç²—ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        batch_size = min(10, len(t_values_coarse))
        zeta_values_coarse = []
        
        with tqdm(desc="ç²—ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°", total=len(t_values_coarse)//batch_size, disable=False) as pbar:
            for i in range(0, len(t_values_coarse), batch_size):
                t_batch = t_values_coarse[i:i+batch_size]
                
                # é«˜ç²¾åº¦ãƒãƒƒãƒè¨ˆç®—
                exp_matrix = torch.exp(-t_batch.unsqueeze(1) * eigenvalues.unsqueeze(0))
                zeta_batch = torch.sum(exp_matrix, dim=1)
                zeta_values_coarse.extend(zeta_batch.tolist())
                
                pbar.update(1)
        
        zeta_values_coarse = torch.tensor(zeta_values_coarse, device=self.device, dtype=torch.float64)
        
        # å¯¾æ•°å¾®åˆ†ã®ç²—ã„æ¨å®š
        log_t_coarse = torch.log(t_values_coarse)
        log_zeta_coarse = torch.log(zeta_values_coarse + 1e-15)
        
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        valid_mask_coarse = torch.isfinite(log_zeta_coarse) & torch.isfinite(log_t_coarse) & (log_zeta_coarse > -100)
        
        if torch.sum(valid_mask_coarse) < 10:
            self.logger.error("ç²—ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³")
            return float('nan')
        
        # ç·šå½¢é ˜åŸŸã®ç‰¹å®šï¼ˆé©å¿œçš„ç¯„å›²æ±ºå®šï¼‰
        log_t_valid_coarse = log_t_coarse[valid_mask_coarse]
        log_zeta_valid_coarse = log_zeta_coarse[valid_mask_coarse]
        
        # å±€æ‰€çš„ãªå‚¾ãã‚’è¨ˆç®—ã—ã¦ç·šå½¢é ˜åŸŸã‚’ç‰¹å®š
        gradients = torch.diff(log_zeta_valid_coarse) / torch.diff(log_t_valid_coarse)
        gradient_std = torch.std(gradients)
        gradient_mean = torch.mean(gradients)
        
        # ç·šå½¢æ€§ãŒé«˜ã„é ˜åŸŸã‚’ç‰¹å®š
        linear_mask = torch.abs(gradients - gradient_mean) < 2 * gradient_std
        if torch.sum(linear_mask) < 5:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…¨ç¯„å›²ã‚’ä½¿ç”¨
            linear_range = (log_t_valid_coarse[0], log_t_valid_coarse[-1])
        else:
            linear_indices = torch.where(linear_mask)[0]
            linear_range = (
                log_t_valid_coarse[linear_indices[0]].item(),
                log_t_valid_coarse[linear_indices[-1] + 1].item()
            )
        
        # ç·šå½¢é ˜åŸŸã§ã®ç´°ã‹ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        t_min_fine = np.exp(linear_range[0])
        t_max_fine = np.exp(linear_range[1])
        
        t_values_fine = torch.logspace(
            np.log10(t_min_fine), np.log10(t_max_fine), n_samples_fine,
            device=self.device, dtype=torch.float64
        )
        
        # é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ï¼ˆç´°ã‹ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        zeta_values_fine = []
        
        with tqdm(desc="é«˜ç²¾åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°", total=len(t_values_fine)//batch_size, disable=False) as pbar:
            for i in range(0, len(t_values_fine), batch_size):
                t_batch = t_values_fine[i:i+batch_size]
                
                # æ•°å€¤å®‰å®šæ€§ã‚’è€ƒæ…®ã—ãŸè¨ˆç®—
                max_exp_arg = torch.max(-t_batch.unsqueeze(1) * eigenvalues.unsqueeze(0))
                if max_exp_arg > 700:  # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
                    # æ­£è¦åŒ–ã‚’é©ç”¨
                    exp_matrix = torch.exp(-t_batch.unsqueeze(1) * eigenvalues.unsqueeze(0) - max_exp_arg)
                    zeta_batch = torch.sum(exp_matrix, dim=1) * torch.exp(max_exp_arg)
                else:
                    exp_matrix = torch.exp(-t_batch.unsqueeze(1) * eigenvalues.unsqueeze(0))
                    zeta_batch = torch.sum(exp_matrix, dim=1)
                
                zeta_values_fine.extend(zeta_batch.tolist())
                pbar.update(1)
        
        zeta_values_fine = torch.tensor(zeta_values_fine, device=self.device, dtype=torch.float64)
        
        # é«˜ç²¾åº¦å¯¾æ•°å¾®åˆ†è¨ˆç®—
        with tqdm(desc="é«˜ç²¾åº¦å¯¾æ•°å¾®åˆ†è¨ˆç®—", total=1, disable=False) as pbar:
            log_t_fine = torch.log(t_values_fine)
            log_zeta_fine = torch.log(zeta_values_fine + 1e-15)
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ˆã‚Šå³å¯†ï¼‰
            valid_mask_fine = (
                torch.isfinite(log_zeta_fine) & 
                torch.isfinite(log_t_fine) & 
                (log_zeta_fine > -100) &
                (log_zeta_fine < 100) &
                (torch.abs(log_t_fine) < 50)
            )
            
            if torch.sum(valid_mask_fine) < 20:
                self.logger.error(f"é«˜ç²¾åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³: {torch.sum(valid_mask_fine)}ç‚¹")
                return float('nan')
            
            log_t_valid_fine = log_t_fine[valid_mask_fine]
            log_zeta_valid_fine = log_zeta_fine[valid_mask_fine]
            
            # å¤–ã‚Œå€¤ã®é™¤å»ï¼ˆHuberå›å¸°çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
            if len(log_t_valid_fine) > 30:
                # åˆæœŸç·šå½¢å›å¸°
                X_init = torch.stack([log_t_valid_fine, torch.ones_like(log_t_valid_fine)], dim=1)
                params_init = torch.linalg.lstsq(X_init, log_zeta_valid_fine).solution
                residuals = log_zeta_valid_fine - (params_init[0] * log_t_valid_fine + params_init[1])
                
                # å¤–ã‚Œå€¤ã®ç‰¹å®šï¼ˆ3ÏƒåŸºæº–ï¼‰
                residual_std = torch.std(residuals)
                inlier_mask = torch.abs(residuals) < 3 * residual_std
                
                if torch.sum(inlier_mask) >= 15:
                    log_t_valid_fine = log_t_valid_fine[inlier_mask]
                    log_zeta_valid_fine = log_zeta_valid_fine[inlier_mask]
                    self.logger.info(f"å¤–ã‚Œå€¤é™¤å»: {torch.sum(~inlier_mask)}ç‚¹ã‚’é™¤å»")
            
            # é‡ã¿ä»˜ãæœ€å°äºŒä¹—æ³•ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            # tâ†’0ã§ã®é‡ã¿ã‚’é«˜ãã™ã‚‹
            weights = torch.exp(-torch.abs(log_t_valid_fine - log_t_valid_fine[0]))
            weights = weights / torch.sum(weights) * len(weights)  # æ­£è¦åŒ–
            
            # é‡ã¿ä»˜ãç·šå½¢å›å¸°
            X = torch.stack([log_t_valid_fine, torch.ones_like(log_t_valid_fine)], dim=1)
            W = torch.diag(weights)
            XtW = X.t() @ W
            XtWX = XtW @ X
            XtWy = XtW @ log_zeta_valid_fine
            
            try:
                # æ­£å‰‡åŒ–é …ã‚’è¿½åŠ ï¼ˆæ•°å€¤å®‰å®šæ€§å‘ä¸Šï¼‰
                regularization = 1e-10 * torch.eye(2, device=self.device, dtype=torch.float64)
                params = torch.linalg.solve(XtWX + regularization, XtWy)
                slope = params[0]
                intercept = params[1]
                
                # å›å¸°ã®å“è³ªè©•ä¾¡
                y_pred = slope * log_t_valid_fine + intercept
                ss_res = torch.sum((log_zeta_valid_fine - y_pred) ** 2)
                ss_tot = torch.sum((log_zeta_valid_fine - torch.mean(log_zeta_valid_fine)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                
                self.logger.info(f"å›å¸°å“è³ª: RÂ² = {r_squared:.6f}")
                
                if r_squared < 0.8:
                    self.logger.warning(f"å›å¸°å“è³ªãŒä½ã„: RÂ² = {r_squared:.6f}")
                
            except Exception as e:
                self.logger.error(f"é‡ã¿ä»˜ãå›å¸°å¤±æ•—: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé€šå¸¸ã®æœ€å°äºŒä¹—æ³•
                X = torch.stack([log_t_valid_fine, torch.ones_like(log_t_valid_fine)], dim=1)
                params = torch.linalg.lstsq(X, log_zeta_valid_fine).solution
                slope = params[0]
            
            # ç†è«–çš„è£œæ­£é …ã®é©ç”¨
            # æœ‰é™ã‚µã‚¤ã‚ºåŠ¹æœã®è£œæ­£
            n_eigenvalues = len(eigenvalues)
            finite_size_correction = 0.5 / n_eigenvalues  # ç†è«–çš„è£œæ­£
            
            # éå¯æ›åŠ¹æœã®è£œæ­£
            noncommutative_correction = self.theta * 0.1 if hasattr(self, 'theta') and self.theta != 0 else 0
            
            spectral_dimension = -2 * slope.item() + finite_size_correction + noncommutative_correction
            
            self.logger.info(f"é«˜ç²¾åº¦ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—çµæœ:")
            self.logger.info(f"  ç”Ÿã®å‚¾ã: {slope.item():.8f}")
            self.logger.info(f"  æœ‰é™ã‚µã‚¤ã‚ºè£œæ­£: {finite_size_correction:.8f}")
            self.logger.info(f"  éå¯æ›è£œæ­£: {noncommutative_correction:.8f}")
            self.logger.info(f"  æœ€çµ‚ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {spectral_dimension:.8f}")
            
            pbar.update(1)
        
        return spectral_dimension
    
    def run_full_analysis_with_recovery(self) -> Dict[str, Any]:
        """ğŸ”„ Recoveryæ©Ÿèƒ½ä»˜ãå®Œå…¨è§£æã®å®Ÿè¡Œ"""
        self.logger.info("=" * 80)
        self.logger.info("Recoveryæ©Ÿèƒ½ä»˜ãå®Œå…¨è§£æé–‹å§‹")
        
        print("=" * 80)
        print("ğŸš€ğŸ”„ Recoveryæ©Ÿèƒ½ä»˜ãRTX3080é«˜æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ è§£æ")
        print("=" * 80)
        
        if torch.cuda.is_available():
            gpu_info = f"GPU: {torch.cuda.get_device_name()}, VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB"
            self.logger.info(gpu_info)
            print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
            print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        
        analysis_params = f"æ¬¡å…ƒ: {self.dim}, æ ¼å­ã‚µã‚¤ã‚º: {self.N}, ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒ: {self.spinor_dim}"
        self.logger.info(f"è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {analysis_params}")
        
        print(f"\nğŸ“Š è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        print(f"æ¬¡å…ƒ: {self.dim}")
        print(f"æ ¼å­ã‚µã‚¤ã‚º: {self.N}")
        print(f"ã‚¹ãƒ”ãƒãƒ«æ¬¡å…ƒ: {self.spinor_dim}")
        print(f"Recoveryæ©Ÿèƒ½: {'æœ‰åŠ¹' if self.checkpoint_manager else 'ç„¡åŠ¹'}")
        
        total_start = time.time()
        
        # å…¨ä½“ã®é€²æ—ç®¡ç†
        with tqdm(total=2, desc="ğŸš€ å…¨ä½“é€²æ—", position=0, disable=False) as main_pbar:
            # 1. ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰
            main_pbar.set_description("ğŸ”¨ 1. ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰")
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®æ§‹ç¯‰é–‹å§‹")
            D = self.construct_discrete_dirac_operator_gpu_optimized()
            main_pbar.update(1)
            
            # 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
            main_pbar.set_description("ğŸ” 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—")
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—é–‹å§‹")
            d_s_dirac, dirac_info = self.compute_spectral_dimension_gpu_optimized(D)
            main_pbar.update(1)
        
        dimension_error = abs(d_s_dirac - self.dim) if not np.isnan(d_s_dirac) else float('nan')
        
        self.logger.info(f"è§£æçµæœ: ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ={d_s_dirac:.6f}, ç†è«–å€¤ã¨ã®å·®={dimension_error:.6f}")
        print(f"ğŸ“ˆ ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {d_s_dirac:.6f}")
        print(f"ğŸ¯ ç†è«–å€¤({self.dim})ã¨ã®å·®: {dimension_error:.6f}")
        
        total_time = time.time() - total_start
        self.logger.info(f"ç·è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
        print(f"\nâ±ï¸  ç·è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
        
        # çµæœã®æ•´ç†
        results = {
            'parameters': {
                'dimension': self.dim,
                'lattice_size': self.N,
                'theta': self.theta,
                'mass': self.mass,
                'spinor_dimension': self.spinor_dim
            },
            'results': {
                'spectral_dimension': d_s_dirac,
                'dimension_error': abs(d_s_dirac - self.dim),
                'total_computation_time': total_time,
                'matrix_size': D.shape[0],
                'nnz_elements': D._nnz(),
                'eigenvalues_computed': dirac_info.get('n_eigenvalues', 0)
            },
            'checkpoint_id': self.checkpoint_id,
            'spectral_dimension_dirac': d_s_dirac,
            'analysis_info': dirac_info
        }
        
        # çµæœã®ä¿å­˜
        output_file = f"results/json/recovery_gpu_results_dim{self.dim}_N{self.N}.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with tqdm(desc="ğŸ’¾ çµæœä¿å­˜ä¸­", total=1, disable=False) as pbar:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            pbar.update(1)
        
        self.logger.info(f"çµæœä¿å­˜å®Œäº†: {output_file}")
        print(f"\nğŸ’¾ çµæœãŒ '{output_file}' ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
        # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
        if self.checkpoint_manager:
            self._save_checkpoint('final_results', results)
            self.logger.info(f"æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: ID {self.checkpoint_id}")
            print(f"ğŸ”„ æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: ID {self.checkpoint_id}")
        
        self.logger.info("Recoveryæ©Ÿèƒ½ä»˜ãå®Œå…¨è§£æå®Œäº†")
        self.logger.info("=" * 80)
        
        return results

def demonstrate_recovery_analysis():
    """ğŸš€ RTX3080æœ€é©åŒ–Recoveryè§£æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("=" * 100)
    print("ğŸš€ğŸ”„ RTX3080æœ€é©åŒ– Recoveryæ©Ÿèƒ½ä»˜ãé«˜æ¬¡å…ƒãƒ‡ã‚£ãƒ©ãƒƒã‚¯/ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ä½œç”¨ç´ è§£æ")
    print("=" * 100)
    
    # GPUæƒ…å ±ã®è¡¨ç¤º
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"ğŸ® æ¤œå‡ºã•ã‚ŒãŸGPU: {gpu_name}")
        print(f"ğŸ’¾ VRAM: {gpu_memory:.1f} GB")
        
        # RTX3080ã®ç‰¹åˆ¥æœ€é©åŒ–
        if "RTX 3080" in gpu_name or "RTX3080" in gpu_name:
            print("âš¡ RTX3080å°‚ç”¨æœ€é©åŒ–ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™")
        else:
            print("âš ï¸  RTX3080ä»¥å¤–ã®GPUãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æœ€é©åŒ–ã¯é™å®šçš„ã§ã™ã€‚")
    else:
        print("âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUè¨ˆç®—ã«ãªã‚Šã¾ã™ã€‚")
        return
    
    # è¤‡æ•°ã®æ¬¡å…ƒã§ãƒ†ã‚¹ãƒˆ
    test_dimensions = [3, 4, 5]  # RTX3080ã§å®‰å…¨ã«ãƒ†ã‚¹ãƒˆã§ãã‚‹æ¬¡å…ƒ
    
    for dim in test_dimensions:
        print(f"\n{'='*60}")
        print(f"ğŸ§® {dim}æ¬¡å…ƒè§£æé–‹å§‹")
        print(f"{'='*60}")
        
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆRTX3080æœ€é©åŒ–ï¼‰
            params = RecoveryGPUOperatorParameters(
                dimension=dim,
                lattice_size=8 if dim <= 4 else 6,  # æ¬¡å…ƒã«å¿œã˜ã¦æ ¼å­ã‚µã‚¤ã‚ºèª¿æ•´
                theta=0.1,
                kappa=0.05,
                mass=0.1,
                coupling=1.0,
                use_sparse=True,
                recovery_enabled=True,
                checkpoint_interval=60,  # 1åˆ†é–“éš”
                auto_save=True,
                max_eigenvalues=50 if dim <= 4 else 30,  # æ¬¡å…ƒã«å¿œã˜ã¦èª¿æ•´
                memory_limit_gb=9.0,  # RTX3080ç”¨
                log_level=logging.INFO,
                use_mixed_precision=True
            )
            
            print(f"ğŸ“Š è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
            print(f"   æ¬¡å…ƒ: {params.dimension}")
            print(f"   æ ¼å­ã‚µã‚¤ã‚º: {params.lattice_size}")
            print(f"   æœ€å¤§å›ºæœ‰å€¤æ•°: {params.max_eigenvalues}")
            print(f"   ãƒ¡ãƒ¢ãƒªåˆ¶é™: {params.memory_limit_gb} GB")
            print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {params.gpu_batch_size}")
            
            # è§£æå™¨ã®åˆæœŸåŒ–
            analyzer = RecoveryGPUDiracLaplacianAnalyzer(params)
            
            # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®åˆæœŸç¢ºèª
            gpu_memory = monitor_gpu_memory()
            if gpu_memory:
                print(f"ğŸ’¾ è§£æé–‹å§‹å‰GPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
            
            # å®Œå…¨è§£æã®å®Ÿè¡Œ
            start_time = time.time()
            results = analyzer.run_full_analysis_with_recovery()
            total_time = time.time() - start_time
            
            # çµæœã®è¡¨ç¤º
            print(f"\nâœ… {dim}æ¬¡å…ƒè§£æå®Œäº†ï¼")
            print(f"â±ï¸  ç·è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
            
            if 'spectral_dimension_dirac' in results:
                d_s = results['spectral_dimension_dirac']
                print(f"ğŸ“ˆ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {d_s:.6f}")
                
                # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
                theoretical_d_s = dim  # ç†è«–çš„ãªã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ
                error = abs(d_s - theoretical_d_s) / theoretical_d_s * 100
                print(f"ğŸ¯ ç†è«–å€¤: {theoretical_d_s}")
                print(f"ğŸ“Š ç›¸å¯¾èª¤å·®: {error:.2f}%")
                
                if error < 10:
                    print("âœ… è‰¯å¥½ãªç²¾åº¦ã§è¨ˆç®—ã•ã‚Œã¾ã—ãŸ")
                elif error < 20:
                    print("âš ï¸  ç²¾åº¦ã¯è¨±å®¹ç¯„å›²å†…ã§ã™")
                else:
                    print("âŒ ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            
            # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€çµ‚ç¢ºèª
            gpu_memory = monitor_gpu_memory()
            if gpu_memory:
                print(f"ğŸ’¾ è§£æå®Œäº†å¾ŒGPUä½¿ç”¨ç‡: {gpu_memory['usage_percent']:.1f}%")
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print(f"ğŸ‰ {dim}æ¬¡å…ƒè§£æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            
        except Exception as e:
            print(f"âŒ {dim}æ¬¡å…ƒè§£æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            continue
    
    print(f"\n{'='*100}")
    print("ğŸŠ RTX3080æœ€é©åŒ–Recoveryè§£æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
    print("=" * 100)

def quick_performance_test():
    """ğŸš€ RTX3080æ€§èƒ½ãƒ†ã‚¹ãƒˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    print("=" * 80)
    print("âš¡ RTX3080æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    # è»½é‡ãƒ†ã‚¹ãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    params = RecoveryGPUOperatorParameters(
        dimension=3,
        lattice_size=6,
        theta=0.1,
        kappa=0.05,
        mass=0.1,
        coupling=1.0,
        use_sparse=True,
        recovery_enabled=False,  # æ€§èƒ½ãƒ†ã‚¹ãƒˆã§ã¯Recoveryç„¡åŠ¹
        max_eigenvalues=20,
        memory_limit_gb=9.0,
        use_mixed_precision=True
    )
    
    print(f"ğŸ§® è»½é‡ãƒ†ã‚¹ãƒˆ: {params.dimension}æ¬¡å…ƒ, æ ¼å­ã‚µã‚¤ã‚º{params.lattice_size}")
    
    try:
        analyzer = RecoveryGPUDiracLaplacianAnalyzer(params)
        
        # GPU ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹
        gpu_memory_start = monitor_gpu_memory()
        if gpu_memory_start:
            print(f"ğŸ’¾ é–‹å§‹æ™‚GPUä½¿ç”¨ç‡: {gpu_memory_start['usage_percent']:.1f}%")
        
        # æ€§èƒ½æ¸¬å®š
        start_time = time.time()
        
        # ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰
        gamma_start = time.time()
        gamma_matrices = analyzer._construct_high_dimensional_gamma_matrices()
        gamma_time = time.time() - gamma_start
        print(f"âš¡ ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰: {gamma_time:.2f}ç§’")
        
        # ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰
        dirac_start = time.time()
        D = analyzer.construct_discrete_dirac_operator_gpu_optimized()
        dirac_time = time.time() - dirac_start
        print(f"âš¡ ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰: {dirac_time:.2f}ç§’")
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
        spectral_start = time.time()
        d_s, info = analyzer.compute_spectral_dimension_gpu_optimized(D, n_eigenvalues=15)
        spectral_time = time.time() - spectral_start
        print(f"âš¡ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—: {spectral_time:.2f}ç§’")
        
        total_time = time.time() - start_time
        
        # çµæœè¡¨ç¤º
        print(f"\nğŸ¯ æ€§èƒ½ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   ç·è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
        print(f"   ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {d_s:.6f}")
        print(f"   å›ºæœ‰å€¤æ•°: {info.get('n_eigenvalues', 'N/A')}")
        
        # GPU ãƒ¡ãƒ¢ãƒªç›£è¦–çµ‚äº†
        gpu_memory_end = monitor_gpu_memory()
        if gpu_memory_end:
            print(f"ğŸ’¾ çµ‚äº†æ™‚GPUä½¿ç”¨ç‡: {gpu_memory_end['usage_percent']:.1f}%")
            memory_used = gpu_memory_end['usage_percent'] - gpu_memory_start['usage_percent']
            print(f"ğŸ’¾ ä½¿ç”¨ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_used:.1f}%")
        
        # æ€§èƒ½è©•ä¾¡
        if total_time < 30:
            print("ğŸš€ å„ªç§€ãªæ€§èƒ½ã§ã™ï¼")
        elif total_time < 60:
            print("âœ… è‰¯å¥½ãªæ€§èƒ½ã§ã™")
        else:
            print("âš ï¸  æ€§èƒ½æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™")
        
        print("âœ… æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logger = setup_logger("NKAT_RTX3080_Recovery", "logs/nkat_rtx3080_recovery.log")
    
    print("ğŸš€ RTX3080æœ€é©åŒ– NKAT Recoveryè§£æã‚·ã‚¹ãƒ†ãƒ  v1.7")
    print("=" * 80)
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
    import sys
    
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        if mode == "test":
            quick_performance_test()
        elif mode == "demo":
            demonstrate_recovery_analysis()
        else:
            print("ä½¿ç”¨æ³•: python dirac_laplacian_analysis_gpu_recovery.py [test|demo]")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šè»½é‡ãƒ†ã‚¹ãƒˆ
        print("ğŸ§ª è»½é‡æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™...")
        print("å®Œå…¨ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆ: python dirac_laplacian_analysis_gpu_recovery.py demo")
        print("=" * 80)
        quick_performance_test() 
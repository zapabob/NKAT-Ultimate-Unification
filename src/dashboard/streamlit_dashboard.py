#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
Real-time GPU Monitoring and Riemann Analysis Dashboard

RTX3080 GPUç›£è¦–ã¨ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã®é€²è¡ŒçŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º
- GPUä½¿ç”¨ç‡ãƒ»æ¸©åº¦ãƒ»ãƒ¡ãƒ¢ãƒªç›£è¦–
- ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã®é€²è¡ŒçŠ¶æ³
- é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ³
- è§£æçµæœã®å¯è¦–åŒ–
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import time
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
import threading
import queue
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.riemann_analysis.nkat_riemann_analyzer import (
        NKATRiemannConfig, RiemannZetaAnalyzer, GPUMonitor, RecoveryManager
    )
    import torch
    import psutil
    import GPUtil
except ImportError as e:
    st.error(f"å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="NKAT ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸŒŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .status-good {
        color: #28a745;
        font-weight: bold;
    }
    .status-warning {
        color: #ffc107;
        font-weight: bold;
    }
    .status-danger {
        color: #dc3545;
        font-weight: bold;
    }
    .analysis-progress {
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        color: white;
        padding: 0.5rem;
        border-radius: 0.25rem;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

class DashboardState:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®çŠ¶æ…‹ç®¡ç†"""
    
    def __init__(self):
        self.gpu_monitor = GPUMonitor()
        self.recovery_manager = RecoveryManager()
        self.analyzer = None
        self.analysis_running = False
        self.analysis_thread = None
        self.data_queue = queue.Queue()
        
        # ãƒ‡ãƒ¼ã‚¿å±¥æ­´
        self.gpu_history = []
        self.analysis_history = []
        self.max_history = 100
        
        # è¨­å®š
        self.config = NKATRiemannConfig()
        
    def initialize_analyzer(self):
        """è§£æå™¨ã®åˆæœŸåŒ–"""
        if self.analyzer is None:
            self.analyzer = RiemannZetaAnalyzer(self.config)
    
    def get_gpu_status(self):
        """GPUçŠ¶æ…‹ã®å–å¾—"""
        status = self.gpu_monitor.get_gpu_status()
        status['timestamp'] = datetime.now()
        
        # å±¥æ­´ã«è¿½åŠ 
        self.gpu_history.append(status)
        if len(self.gpu_history) > self.max_history:
            self.gpu_history.pop(0)
        
        return status
    
    def get_system_status(self):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®å–å¾—"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'memory_available_gb': memory.available / 1024**3,
            'disk_percent': disk.percent,
            'disk_free_gb': disk.free / 1024**3,
            'timestamp': datetime.now()
        }
    
    def start_analysis(self, max_dimension: int):
        """è§£æã®é–‹å§‹"""
        if self.analysis_running:
            return False
        
        self.initialize_analyzer()
        self.analysis_running = True
        
        def analysis_worker():
            try:
                results = self.analyzer.analyze_riemann_hypothesis(max_dimension)
                self.data_queue.put(('analysis_complete', results))
            except Exception as e:
                self.data_queue.put(('analysis_error', str(e)))
            finally:
                self.analysis_running = False
        
        self.analysis_thread = threading.Thread(target=analysis_worker)
        self.analysis_thread.start()
        
        return True
    
    def stop_analysis(self):
        """è§£æã®åœæ­¢"""
        self.analysis_running = False
        if self.analysis_thread and self.analysis_thread.is_alive():
            self.analysis_thread.join(timeout=5)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'dashboard_state' not in st.session_state:
    st.session_state.dashboard_state = DashboardState()

dashboard_state = st.session_state.dashboard_state

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown('<h1 class="main-header">ğŸŒŒ NKAT ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</h1>', unsafe_allow_html=True)
    st.markdown("**éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ**")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # è§£æè¨­å®š
        st.subheader("è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        max_dimension = st.slider("æœ€å¤§æ¬¡å…ƒ", 15, 100, 50, 5)
        critical_dimension = st.slider("è‡¨ç•Œæ¬¡å…ƒ", 10, 30, 15)
        
        # GPUè¨­å®š
        st.subheader("GPUè¨­å®š")
        gpu_memory_fraction = st.slider("GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", 0.5, 1.0, 0.95, 0.05)
        enable_mixed_precision = st.checkbox("æ··åˆç²¾åº¦", True)
        
        # æ›´æ–°è¨­å®š
        st.subheader("è¡¨ç¤ºè¨­å®š")
        auto_refresh = st.checkbox("è‡ªå‹•æ›´æ–°", True)
        refresh_interval = st.slider("æ›´æ–°é–“éš” (ç§’)", 1, 10, 3)
        
        # è§£æåˆ¶å¾¡
        st.subheader("è§£æåˆ¶å¾¡")
        if st.button("ğŸš€ è§£æé–‹å§‹", disabled=dashboard_state.analysis_running):
            dashboard_state.config.max_dimension = max_dimension
            dashboard_state.config.critical_dimension = critical_dimension
            dashboard_state.config.gpu_memory_fraction = gpu_memory_fraction
            dashboard_state.config.enable_mixed_precision = enable_mixed_precision
            
            if dashboard_state.start_analysis(max_dimension):
                st.success("è§£æã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            else:
                st.error("è§£æã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        if st.button("â¹ï¸ è§£æåœæ­¢", disabled=not dashboard_state.analysis_running):
            dashboard_state.stop_analysis()
            st.info("è§£æã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # GPUç›£è¦–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.header("ğŸ® RTX3080 GPU ç›£è¦–")
        
        gpu_status = dashboard_state.get_gpu_status()
        
        if gpu_status['available']:
            # GPU ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            gpu_cols = st.columns(4)
            
            with gpu_cols[0]:
                utilization = gpu_status.get('gpu_utilization', 0)
                if utilization is None:
                    utilization = 0
                color = "normal" if utilization < 80 else "inverse"
                st.metric(
                    "GPU ä½¿ç”¨ç‡",
                    f"{utilization:.1f}%",
                    delta=None
                )
            
            with gpu_cols[1]:
                temp = gpu_status.get('temperature', 0)
                if temp is None:
                    temp = 0
                temp_status = "ğŸŸ¢" if temp < 70 else "ğŸŸ¡" if temp < 80 else "ğŸ”´"
                st.metric(
                    "æ¸©åº¦",
                    f"{temp}Â°C {temp_status}",
                    delta=None
                )
            
            with gpu_cols[2]:
                memory_util = gpu_status.get('memory_utilization', 0)
                if memory_util is None:
                    memory_util = 0
                st.metric(
                    "VRAM ä½¿ç”¨ç‡",
                    f"{memory_util:.1f}%",
                    delta=None
                )
            
            with gpu_cols[3]:
                power_draw = gpu_status.get('power_draw', 0)
                power_limit = gpu_status.get('power_limit', 300)
                
                # Noneå€¤ã®å‡¦ç†
                if power_draw is None:
                    power_draw = 0
                if power_limit is None:
                    power_limit = 300
                
                power_percent = (power_draw / power_limit * 100) if power_limit > 0 else 0
                st.metric(
                    "é›»åŠ›ä½¿ç”¨",
                    f"{power_draw:.0f}W ({power_percent:.0f}%)",
                    delta=None
                )
            
            # GPUå±¥æ­´ã‚°ãƒ©ãƒ•
            if len(dashboard_state.gpu_history) > 1:
                fig_gpu = create_gpu_history_chart(dashboard_state.gpu_history)
                st.plotly_chart(fig_gpu, use_container_width=True)
        
        else:
            st.error("âŒ GPU ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    with col2:
        # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–
        st.header("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
        
        system_status = dashboard_state.get_system_status()
        
        # Noneå€¤ã®å‡¦ç†
        cpu_percent = system_status.get('cpu_percent', 0)
        memory_percent = system_status.get('memory_percent', 0)
        memory_available_gb = system_status.get('memory_available_gb', 0)
        disk_percent = system_status.get('disk_percent', 0)
        
        if cpu_percent is None:
            cpu_percent = 0
        if memory_percent is None:
            memory_percent = 0
        if memory_available_gb is None:
            memory_available_gb = 0
        if disk_percent is None:
            disk_percent = 0
        
        st.metric("CPU ä½¿ç”¨ç‡", f"{cpu_percent:.1f}%")
        st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{memory_percent:.1f}%")
        st.metric("åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª", f"{memory_available_gb:.1f} GB")
        st.metric("ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡", f"{disk_percent:.1f}%")
        
        # è§£æçŠ¶æ³
        st.header("ğŸ”¬ è§£æçŠ¶æ³")
        
        if dashboard_state.analysis_running:
            st.markdown('<div class="analysis-progress">ğŸ”„ è§£æå®Ÿè¡Œä¸­...</div>', unsafe_allow_html=True)
            st.progress(0.5)  # é€²è¡ŒçŠ¶æ³ã¯ç°¡ç•¥åŒ–
        else:
            st.info("è§£æå¾…æ©Ÿä¸­")
        
        # ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ³
        st.header("ğŸ’¾ ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ³")
        
        checkpoint_state, is_valid = dashboard_state.recovery_manager.load_checkpoint()
        
        if checkpoint_state:
            st.success("âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆåˆ©ç”¨å¯èƒ½")
            if 'analysis_timestamp' in checkpoint_state:
                timestamp = checkpoint_state['analysis_timestamp']
                st.text(f"æœ€çµ‚ä¿å­˜: {timestamp}")
        else:
            st.info("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãªã—")
    
    # è§£æçµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("ğŸ“Š ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æçµæœ")
    
    # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    try:
        while not dashboard_state.data_queue.empty():
            event_type, data = dashboard_state.data_queue.get_nowait()
            
            if event_type == 'analysis_complete':
                st.success("ğŸ‰ è§£æå®Œäº†!")
                display_analysis_results(data)
            elif event_type == 'analysis_error':
                st.error(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {data}")
    except queue.Empty:
        pass
    
    # æ—¢å­˜ã®çµæœã‚’è¡¨ç¤º
    if checkpoint_state and 'final_assessment' in checkpoint_state:
        display_analysis_results(checkpoint_state)
    
    # è‡ªå‹•æ›´æ–°
    if auto_refresh:
        time.sleep(refresh_interval)
        st.rerun()

def create_gpu_history_chart(gpu_history):
    """GPUå±¥æ­´ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
    if not gpu_history:
        return go.Figure()
    
    df = pd.DataFrame(gpu_history)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('GPUä½¿ç”¨ç‡', 'æ¸©åº¦', 'VRAMä½¿ç”¨ç‡', 'é›»åŠ›ä½¿ç”¨'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # GPUä½¿ç”¨ç‡
    if 'gpu_utilization' in df.columns:
        gpu_util_clean = df['gpu_utilization'].fillna(0)
        fig.add_trace(
            go.Scatter(x=df['timestamp'], y=gpu_util_clean,
                      name='GPUä½¿ç”¨ç‡', line=dict(color='blue')),
            row=1, col=1
        )
    
    # æ¸©åº¦
    if 'temperature' in df.columns:
        temp_clean = df['temperature'].fillna(0)
        fig.add_trace(
            go.Scatter(x=df['timestamp'], y=temp_clean,
                      name='æ¸©åº¦', line=dict(color='red')),
            row=1, col=2
        )
    
    # VRAMä½¿ç”¨ç‡
    if 'memory_utilization' in df.columns:
        memory_util_clean = df['memory_utilization'].fillna(0)
        fig.add_trace(
            go.Scatter(x=df['timestamp'], y=memory_util_clean,
                      name='VRAMä½¿ç”¨ç‡', line=dict(color='green')),
            row=2, col=1
        )
    
    # é›»åŠ›ä½¿ç”¨
    if 'power_draw' in df.columns:
        power_draw_clean = df['power_draw'].fillna(0)
        fig.add_trace(
            go.Scatter(x=df['timestamp'], y=power_draw_clean,
                      name='é›»åŠ›ä½¿ç”¨', line=dict(color='orange')),
            row=2, col=2
        )
    
    fig.update_layout(
        title="RTX3080 GPU å±¥æ­´",
        height=400,
        showlegend=False
    )
    
    return fig

def display_analysis_results(results):
    """è§£æçµæœã®è¡¨ç¤º"""
    if 'final_assessment' not in results:
        st.warning("è§£æçµæœãŒä¸å®Œå…¨ã§ã™")
        return
    
    assessment = results['final_assessment']
    
    # ç·åˆè©•ä¾¡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç·åˆè©•ä¾¡", assessment['assessment'])
    
    with col2:
        st.metric("ä¿¡é ¼åº¦", assessment['confidence'])
    
    with col3:
        st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{assessment['overall_score']:.4f}")
    
    # è©³ç´°ã‚¹ã‚³ã‚¢
    if 'component_scores' in assessment:
        st.subheader("è©³ç´°ã‚¹ã‚³ã‚¢")
        
        scores = assessment['component_scores']
        score_df = pd.DataFrame([
            {'æŒ‡æ¨™': 'NKAT-ã‚¼ãƒ¼ã‚¿å¯¾å¿œ', 'ã‚¹ã‚³ã‚¢': scores.get('nkat_zeta_correspondence', 0)},
            {'æŒ‡æ¨™': 'ã‚¼ãƒ­ç‚¹æ¤œè¨¼', 'ã‚¹ã‚³ã‚¢': scores.get('zero_verification', 0)},
            {'æŒ‡æ¨™': 'è‡¨ç•Œç·šé¸å¥½', 'ã‚¹ã‚³ã‚¢': scores.get('critical_line_preference', 0)},
            {'æŒ‡æ¨™': 'åæŸæ€§', 'ã‚¹ã‚³ã‚¢': scores.get('convergence', 0)},
            {'æŒ‡æ¨™': 'è¶…åæŸä¸€è‡´', 'ã‚¹ã‚³ã‚¢': scores.get('superconvergence_agreement', 0)}
        ])
        
        fig_scores = px.bar(score_df, x='æŒ‡æ¨™', y='ã‚¹ã‚³ã‚¢', 
                           title="å„æŒ‡æ¨™ã®ã‚¹ã‚³ã‚¢",
                           color='ã‚¹ã‚³ã‚¢',
                           color_continuous_scale='viridis')
        fig_scores.update_layout(height=400)
        st.plotly_chart(fig_scores, use_container_width=True)
    
    # æ¬¡å…ƒåˆ¥è§£æçµæœ
    if 'dimensions_analyzed' in results and 'convergence_data' in results:
        st.subheader("æ¬¡å…ƒåˆ¥åæŸæ€§")
        
        dims = results['dimensions_analyzed']
        convergence = results['convergence_data']
        
        fig_conv = go.Figure()
        fig_conv.add_trace(go.Scatter(
            x=dims, y=convergence,
            mode='lines+markers',
            name='åæŸã‚¹ã‚³ã‚¢',
            line=dict(color='blue', width=2),
            marker=dict(size=8)
        ))
        
        fig_conv.update_layout(
            title="æ¬¡å…ƒåˆ¥åæŸæ€§",
            xaxis_title="æ¬¡å…ƒ",
            yaxis_title="åæŸã‚¹ã‚³ã‚¢",
            height=400
        )
        
        st.plotly_chart(fig_conv, use_container_width=True)
    
    # å®Ÿè¡Œæƒ…å ±
    if 'execution_time' in results:
        st.info(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {results['execution_time']:.2f}ç§’")
    
    if 'analysis_timestamp' in results:
        st.info(f"ğŸ“… è§£ææ—¥æ™‚: {results['analysis_timestamp']}")

def create_real_time_monitor():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–")
    
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    gpu_placeholder = st.empty()
    chart_placeholder = st.empty()
    
    # ç›£è¦–ãƒ«ãƒ¼ãƒ—
    for i in range(60):  # 1åˆ†é–“ç›£è¦–
        gpu_status = dashboard_state.get_gpu_status()
        
        with gpu_placeholder.container():
            if gpu_status['available']:
                cols = st.columns(4)
                
                with cols[0]:
                    gpu_util = gpu_status.get('gpu_utilization', 0)
                    if gpu_util is None:
                        gpu_util = 0
                    st.metric("GPUä½¿ç”¨ç‡", f"{gpu_util:.1f}%")
                
                with cols[1]:
                    temp = gpu_status.get('temperature', 0)
                    if temp is None:
                        temp = 0
                    st.metric("æ¸©åº¦", f"{temp}Â°C")
                
                with cols[2]:
                    memory_util = gpu_status.get('memory_utilization', 0)
                    if memory_util is None:
                        memory_util = 0
                    st.metric("VRAM", f"{memory_util:.1f}%")
                
                with cols[3]:
                    power_draw = gpu_status.get('power_draw', 0)
                    if power_draw is None:
                        power_draw = 0
                    st.metric("é›»åŠ›", f"{power_draw:.0f}W")
        
        # ãƒãƒ£ãƒ¼ãƒˆæ›´æ–°
        if len(dashboard_state.gpu_history) > 1:
            fig = create_gpu_history_chart(dashboard_state.gpu_history[-20:])  # æœ€æ–°20ä»¶
            chart_placeholder.plotly_chart(fig, use_container_width=True)
        
        time.sleep(1)

if __name__ == "__main__":
    main() 
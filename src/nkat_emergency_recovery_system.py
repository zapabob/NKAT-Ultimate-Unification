#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”‹ NKAT ç·Šæ€¥é›»æºæ–­å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ 
RTX3080 CUDAæœ€é©åŒ– + æ®µéšçš„å¾©æ—§ + tqdmé€²æ—è¡¨ç¤º
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset
import matplotlib.pyplot as plt
import numpy as np
import json
import os
import time
from datetime import datetime
from tqdm import tqdm
import glob
import warnings
warnings.filterwarnings('ignore')

# è‹±èªè¡¨è¨˜è¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class NKATEmergencyTransformer(nn.Module):
    """ç·Šæ€¥å¾©æ—§ç”¨è»½é‡NKAT Transformer"""
    
    def __init__(self, img_size=28, patch_size=4, num_classes=10, 
                 embed_dim=512, depth=6, num_heads=8, nkat_strength=0.02):
        super().__init__()
        
        self.img_size = img_size
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2
        self.embed_dim = embed_dim
        self.nkat_strength = nkat_strength
        
        # ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿ï¼ˆè»½é‡åŒ–ï¼‰
        self.patch_embed = nn.Conv2d(
            in_channels=1, out_channels=embed_dim,
            kernel_size=patch_size, stride=patch_size
        )
        
        # ä½ç½®åŸ‹ã‚è¾¼ã¿
        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim) * 0.02)
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim) * 0.02)
        
        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,
            nhead=num_heads,
            dim_feedforward=embed_dim * 4,
            dropout=0.1,
            activation='gelu',
            batch_first=True,
            norm_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, depth)
        
        # åˆ†é¡ãƒ˜ãƒƒãƒ‰
        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(embed_dim, embed_dim // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(embed_dim // 2, num_classes)
        )
        
        self.apply(self._init_weights)
        
    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            torch.nn.init.trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            torch.nn.init.trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        B = x.shape[0]
        
        # ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿
        x = self.patch_embed(x).flatten(2).transpose(1, 2)
        
        # CLS tokenè¿½åŠ 
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        
        # ä½ç½®åŸ‹ã‚è¾¼ã¿
        x = x + self.pos_embed
        
        # NKATå¼·åŒ–
        if self.nkat_strength > 0:
            mean_activation = x.mean(dim=-1, keepdim=True)
            nkat_factor = 1.0 + self.nkat_strength * torch.tanh(mean_activation)
            x = x * nkat_factor
        
        # Transformer
        x = self.transformer(x)
        
        # åˆ†é¡
        cls_output = self.norm(x[:, 0])
        return self.head(cls_output)

class EmergencyRecoverySystem:
    """ç·Šæ€¥å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, device='cuda'):
        self.device = device
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.recovery_dir = f"recovery_data/emergency_{self.timestamp}"
        os.makedirs(self.recovery_dir, exist_ok=True)
        
        print("ğŸ”‹ NKAT Emergency Recovery System")
        print("="*50)
        print(f"ğŸ• Recovery Time: {self.timestamp}")
        print(f"ğŸ¯ Device: {device}")
        print(f"ğŸ“ Recovery Dir: {self.recovery_dir}")
        
        if torch.cuda.is_available():
            print(f"ğŸš€ RTX3080 Detected: {torch.cuda.get_device_name()}")
            torch.backends.cudnn.benchmark = True
        
        print("="*50)
    
    def scan_available_checkpoints(self):
        """åˆ©ç”¨å¯èƒ½ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚¹ã‚­ãƒ£ãƒ³"""
        
        print("\nğŸ” Scanning Available Checkpoints...")
        
        checkpoint_patterns = [
            "checkpoints/*.pth",
            "checkpoints/*/*.pth", 
            "*.pth",
            "recovery_data/*/*.pth"
        ]
        
        found_checkpoints = []
        for pattern in checkpoint_patterns:
            files = glob.glob(pattern)
            for file in files:
                if os.path.getsize(file) > 1024 * 1024:  # 1MBä»¥ä¸Š
                    found_checkpoints.append({
                        'path': file,
                        'size_mb': os.path.getsize(file) / (1024*1024),
                        'modified': os.path.getmtime(file)
                    })
        
        # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
        found_checkpoints.sort(key=lambda x: x['modified'], reverse=True)
        
        print(f"âœ… Found {len(found_checkpoints)} checkpoints:")
        for i, cp in enumerate(found_checkpoints[:5]):  # ä¸Šä½5å€‹è¡¨ç¤º
            print(f"  {i+1}. {cp['path']} ({cp['size_mb']:.1f}MB)")
        
        return found_checkpoints
    
    def attempt_checkpoint_recovery(self, checkpoint_path):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®å¾©æ—§è©¦è¡Œ"""
        
        print(f"\nğŸ”„ Attempting Recovery: {checkpoint_path}")
        
        try:
            # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
            model = NKATEmergencyTransformer().to(self.device)
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                elif 'model' in checkpoint:
                    model.load_state_dict(checkpoint['model'], strict=False)
                else:
                    model.load_state_dict(checkpoint, strict=False)
            else:
                model.load_state_dict(checkpoint, strict=False)
            
            print("âœ… Checkpoint loaded successfully")
            
            # ã‚¯ã‚¤ãƒƒã‚¯è©•ä¾¡
            accuracy = self.quick_evaluation(model)
            
            recovery_info = {
                'checkpoint_path': checkpoint_path,
                'accuracy': accuracy,
                'recovery_successful': accuracy > 0.5,  # 50%ä»¥ä¸Šã§æˆåŠŸã¨ã¿ãªã™
                'timestamp': self.timestamp
            }
            
            return model, recovery_info
            
        except Exception as e:
            print(f"âŒ Recovery failed: {e}")
            return None, {'error': str(e), 'recovery_successful': False}
    
    def quick_evaluation(self, model):
        """ã‚¯ã‚¤ãƒƒã‚¯è©•ä¾¡"""
        
        print("âš¡ Quick Evaluation...")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        test_dataset = torchvision.datasets.MNIST(
            root='./data', train=False, download=True, transform=transform
        )
        
        # ã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆ1000ã‚µãƒ³ãƒ—ãƒ«ï¼‰
        indices = torch.randperm(len(test_dataset))[:1000]
        test_subset = Subset(test_dataset, indices)
        test_loader = DataLoader(test_subset, batch_size=128, shuffle=False, num_workers=0)
        
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in tqdm(test_loader, desc="Quick Eval", leave=False):
                data, target = data.to(self.device), target.to(self.device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = correct / total
        print(f"âš¡ Quick Accuracy: {accuracy:.3f}")
        
        return accuracy
    
    def emergency_training(self, model=None, epochs=15):
        """ç·Šæ€¥è¨“ç·´"""
        
        print(f"\nğŸš¨ Emergency Training ({epochs} epochs)")
        
        if model is None:
            model = NKATEmergencyTransformer().to(self.device)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,)),
            transforms.RandomRotation(10),
            transforms.RandomAffine(0, translate=(0.1, 0.1))
        ])
        
        train_dataset = torchvision.datasets.MNIST(
            root='./data', train=True, download=True, transform=transform
        )
        
        # é«˜é€Ÿè¨“ç·´ã®ãŸã‚10000ã‚µãƒ³ãƒ—ãƒ«ã«åˆ¶é™
        indices = torch.randperm(len(train_dataset))[:10000]
        train_subset = Subset(train_dataset, indices)
        train_loader = DataLoader(train_subset, batch_size=256, shuffle=True, num_workers=2)
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—
        model.train()
        training_history = []
        
        print("ğŸ”¥ Starting Emergency Training...")
        
        for epoch in tqdm(range(epochs), desc="Emergency Training"):
            epoch_loss = 0.0
            epoch_correct = 0
            epoch_total = 0
            
            progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=False)
            
            for batch_idx, (data, target) in enumerate(progress_bar):
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                outputs = model(data)
                loss = criterion(outputs, target)
                loss.backward()
                
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                epoch_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                epoch_total += target.size(0)
                epoch_correct += (predicted == target).sum().item()
                
                if batch_idx % 10 == 0:
                    progress_bar.set_postfix({
                        'Loss': f'{loss.item():.4f}',
                        'Acc': f'{100.*epoch_correct/epoch_total:.1f}%'
                    })
            
            scheduler.step()
            
            epoch_accuracy = epoch_correct / epoch_total
            avg_loss = epoch_loss / len(train_loader)
            
            training_history.append({
                'epoch': epoch + 1,
                'loss': avg_loss,
                'accuracy': epoch_accuracy
            })
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã”ã¨ï¼‰
            if (epoch + 1) % 5 == 0:
                checkpoint_path = os.path.join(self.recovery_dir, f"emergency_checkpoint_epoch_{epoch+1}.pth")
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch + 1,
                    'accuracy': epoch_accuracy,
                    'loss': avg_loss
                }, checkpoint_path)
        
        # æœ€çµ‚è©•ä¾¡
        final_accuracy = self.quick_evaluation(model)
        
        # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        final_checkpoint = os.path.join(self.recovery_dir, "emergency_final_model.pth")
        torch.save({
            'model_state_dict': model.state_dict(),
            'training_history': training_history,
            'final_accuracy': final_accuracy,
            'timestamp': self.timestamp
        }, final_checkpoint)
        
        print(f"âœ… Emergency Training Complete!")
        print(f"ğŸ¯ Final Accuracy: {final_accuracy:.3f}")
        print(f"ğŸ’¾ Checkpoint: {final_checkpoint}")
        
        return model, training_history, final_accuracy
    
    def create_recovery_report(self, recovery_info, training_history, final_accuracy):
        """å¾©æ—§ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        
        print("\nğŸ“Š Creating Recovery Report...")
        
        # å¯è¦–åŒ–
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. è¨“ç·´å±¥æ­´
        epochs = [h['epoch'] for h in training_history]
        losses = [h['loss'] for h in training_history]
        accuracies = [h['accuracy'] for h in training_history]
        
        ax1.plot(epochs, losses, 'r-', label='Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Emergency Training Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        ax2.plot(epochs, accuracies, 'b-', label='Training Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Emergency Training Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. å¾©æ—§ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        metrics = ['Initial Recovery', 'Final Training', 'Target (99%)', 'Minimum (80%)']
        values = [
            recovery_info.get('accuracy', 0) * 100,
            final_accuracy * 100,
            99.0,
            80.0
        ]
        colors = ['orange', 'green', 'red', 'blue']
        
        bars = ax3.bar(metrics, values, color=colors, alpha=0.7)
        ax3.set_ylabel('Accuracy (%)')
        ax3.set_title('Recovery Performance Metrics')
        ax3.axhline(y=80, color='blue', linestyle='--', alpha=0.5)
        ax3.axhline(y=99, color='red', linestyle='--', alpha=0.5)
        
        for bar, val in zip(bars, values):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{val:.1f}%', ha='center', va='bottom')
        
        # 4. å¾©æ—§ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
        ax4.axis('off')
        timeline_text = f"""Emergency Recovery Timeline
        
ğŸ”‹ Power Outage Detected
âš¡ Recovery System Activated: {self.timestamp}
ğŸ” Checkpoint Scan: {len(glob.glob('**/*.pth', recursive=True))} files
ğŸ”„ Recovery Attempt: {'âœ… Success' if recovery_info.get('recovery_successful', False) else 'âŒ Failed'}
ğŸš¨ Emergency Training: {len(training_history)} epochs
ğŸ¯ Final Accuracy: {final_accuracy:.1%}

Status: {'ğŸŸ¢ RECOVERED' if final_accuracy > 0.8 else 'ğŸŸ¡ PARTIAL' if final_accuracy > 0.5 else 'ğŸ”´ FAILED'}
        """
        
        ax4.text(0.1, 0.9, timeline_text, transform=ax4.transAxes, 
                fontsize=10, verticalalignment='top', family='monospace')
        
        plt.tight_layout()
        
        # ä¿å­˜
        report_path = os.path.join(self.recovery_dir, f"emergency_recovery_report_{self.timestamp}.png")
        plt.savefig(report_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # JSON ãƒ¬ãƒãƒ¼ãƒˆ
        json_report = {
            'recovery_timestamp': self.timestamp,
            'initial_recovery': recovery_info,
            'training_history': training_history,
            'final_accuracy': final_accuracy,
            'recovery_status': 'SUCCESS' if final_accuracy > 0.8 else 'PARTIAL' if final_accuracy > 0.5 else 'FAILED',
            'recommendations': self._generate_recommendations(final_accuracy)
        }
        
        json_path = os.path.join(self.recovery_dir, f"emergency_recovery_report_{self.timestamp}.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š Recovery Report: {report_path}")
        print(f"ğŸ“‹ JSON Report: {json_path}")
        
        return report_path, json_path
    
    def _generate_recommendations(self, final_accuracy):
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        
        recommendations = []
        
        if final_accuracy < 0.8:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'Extend training epochs to 50+',
                'reason': f'Current accuracy {final_accuracy:.1%} < 80% minimum'
            })
        
        if final_accuracy < 0.95:
            recommendations.append({
                'priority': 'MEDIUM', 
                'action': 'Enable data augmentation and regularization',
                'reason': 'Improve generalization performance'
            })
        
        recommendations.append({
            'priority': 'LOW',
            'action': 'Run full Stage2-5 validation pipeline',
            'reason': 'Comprehensive performance verification'
        })
        
        return recommendations
    
    def run_full_recovery(self):
        """å®Œå…¨å¾©æ—§å®Ÿè¡Œ"""
        
        print("ğŸ”‹ Starting Full Emergency Recovery...")
        
        # 1. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚¹ã‚­ãƒ£ãƒ³
        checkpoints = self.scan_available_checkpoints()
        
        # 2. å¾©æ—§è©¦è¡Œ
        model = None
        recovery_info = {'recovery_successful': False}
        
        if checkpoints:
            for cp in checkpoints[:3]:  # æœ€å¤§3å€‹è©¦è¡Œ
                model, recovery_info = self.attempt_checkpoint_recovery(cp['path'])
                if recovery_info.get('recovery_successful', False):
                    print(f"âœ… Recovery successful from: {cp['path']}")
                    break
        
        # 3. ç·Šæ€¥è¨“ç·´
        model, training_history, final_accuracy = self.emergency_training(model)
        
        # 4. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report_path, json_path = self.create_recovery_report(recovery_info, training_history, final_accuracy)
        
        # 5. ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "="*50)
        print("ğŸ”‹ EMERGENCY RECOVERY COMPLETE")
        print("="*50)
        print(f"ğŸ¯ Final Accuracy: {final_accuracy:.1%}")
        print(f"ğŸ“Š Status: {'ğŸŸ¢ SUCCESS' if final_accuracy > 0.8 else 'ğŸŸ¡ PARTIAL' if final_accuracy > 0.5 else 'ğŸ”´ FAILED'}")
        print(f"ğŸ“ Recovery Dir: {self.recovery_dir}")
        print(f"ğŸ“Š Report: {report_path}")
        print("="*50)
        
        return final_accuracy > 0.8

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # RTX3080 CUDAè¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ç·Šæ€¥å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•
    recovery_system = EmergencyRecoverySystem(device)
    
    # å®Œå…¨å¾©æ—§å®Ÿè¡Œ
    success = recovery_system.run_full_recovery()
    
    if success:
        print("ğŸ‰ Emergency recovery completed successfully!")
        print("ğŸš€ Ready to continue normal operations.")
    else:
        print("âš ï¸ Partial recovery completed.")
        print("ğŸ“‹ Check recommendations for next steps.")

if __name__ == "__main__":
    main() 
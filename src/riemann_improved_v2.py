#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹æ”¹è‰¯ç‰ˆé«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ v5.1
Improved High-Precision Riemann Hypothesis Verification using NKAT Theory

ä¸»è¦æ”¹è‰¯ç‚¹:
1. ã‚ˆã‚Šå®‰å®šã—ãŸã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
2. ç†è«–çš„æ­£ç¢ºæ€§ã®å‘ä¸Š
3. æ•°å€¤å®‰å®šæ€§ã®æ”¹å–„
4. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æœ€å°åŒ–

Author: NKAT Research Team
Date: 2025-05-26
Version: 5.1 - Improved Stability
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict
import warnings
from pathlib import Path
import json
import time
from dataclasses import dataclass
from tqdm import tqdm, trange
import logging
import cmath

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
    print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

class ImprovedNKATHamiltonian(nn.Module):
    """
    æ”¹è‰¯ç‰ˆNKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®å®Ÿè£…
    
    æ”¹è‰¯ç‚¹:
    1. ã‚ˆã‚Šç†è«–çš„ã«æ­£ç¢ºãªã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
    2. æ”¹å–„ã•ã‚ŒãŸæ•°å€¤å®‰å®šæ€§
    3. é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
    4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–
    """
    
    def __init__(self, max_n: int = 2000, theta: float = 1e-20, kappa: float = 1e-12):
        super().__init__()
        self.max_n = max_n
        self.theta = theta
        self.kappa = kappa
        self.device = device
        self.dtype = torch.complex128
        self.float_dtype = torch.float64
        
        logger.info(f"ğŸ”§ æ”¹è‰¯ç‰ˆNKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³åˆæœŸåŒ–: max_n={max_n}")
        
        # ç´ æ•°ãƒªã‚¹ãƒˆã®ç”Ÿæˆ
        self.primes = self._generate_primes_optimized(max_n)
        logger.info(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸç´ æ•°æ•°: {len(self.primes)}")
        
        # ã‚¬ãƒ³ãƒè¡Œåˆ—ã®å®šç¾©
        self.gamma_matrices = self._construct_improved_gamma_matrices()
        
        # ç†è«–çš„ãƒªãƒ¼ãƒãƒ³é›¶ç‚¹
        self.riemann_zeros = [
            14.134725141734693790, 21.022039638771554993, 25.010857580145688763,
            30.424876125859513210, 32.935061587739189691, 37.586178158825671257,
            40.918719012147495187, 43.327073280914999519, 48.005150881167159727,
            49.773832477672302181
        ]
        
    def _generate_primes_optimized(self, n: int) -> List[int]:
        """æœ€é©åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒˆã‚¹ãƒ†ãƒã‚¹ã®ç¯©"""
        if n < 2:
            return []
        
        sieve = [True] * (n + 1)
        sieve[0] = sieve[1] = False
        
        for i in range(2, int(n**0.5) + 1):
            if sieve[i]:
                for j in range(i*i, n + 1, i):
                    sieve[j] = False
        
        return [i for i in range(2, n + 1) if sieve[i]]
    
    def _construct_improved_gamma_matrices(self) -> List[torch.Tensor]:
        """æ”¹è‰¯ã•ã‚ŒãŸã‚¬ãƒ³ãƒè¡Œåˆ—ã®æ§‹ç¯‰"""
        # ãƒ‘ã‚¦ãƒªè¡Œåˆ—ï¼ˆé«˜ç²¾åº¦ï¼‰
        sigma_x = torch.tensor([[0, 1], [1, 0]], dtype=self.dtype, device=self.device)
        sigma_y = torch.tensor([[0, -1j], [1j, 0]], dtype=self.dtype, device=self.device)
        sigma_z = torch.tensor([[1, 0], [0, -1]], dtype=self.dtype, device=self.device)
        I2 = torch.eye(2, dtype=self.dtype, device=self.device)
        O2 = torch.zeros(2, 2, dtype=self.dtype, device=self.device)
        
        # ãƒ‡ã‚£ãƒ©ãƒƒã‚¯è¡Œåˆ—ã®æ§‹ç¯‰
        gamma = []
        
        # Î³^0 = [[I, 0], [0, -I]]
        gamma.append(torch.cat([torch.cat([I2, O2], dim=1), 
                               torch.cat([O2, -I2], dim=1)], dim=0))
        
        # Î³^i = [[0, Ïƒ_i], [-Ïƒ_i, 0]] for i=1,2,3
        for sigma in [sigma_x, sigma_y, sigma_z]:
            gamma.append(torch.cat([torch.cat([O2, sigma], dim=1),
                                   torch.cat([-sigma, O2], dim=1)], dim=0))
        
        logger.info(f"âœ… æ”¹è‰¯ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†: {len(gamma)}å€‹ã®{gamma[0].shape}è¡Œåˆ—")
        return gamma
    
    def approximate_gamma_function(self, z: complex) -> complex:
        """
        ã‚¬ãƒ³ãƒé–¢æ•°ã®è¿‘ä¼¼è¨ˆç®—ï¼ˆã‚¹ã‚¿ãƒ¼ãƒªãƒ³ã‚°å…¬å¼ä½¿ç”¨ï¼‰
        """
        if z.real <= 0:
            # åå°„å…¬å¼ Î“(z) = Ï€ / [sin(Ï€z) * Î“(1-z)]
            if abs(z.imag) < 100:  # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚
                sin_piz = cmath.sin(cmath.pi * z)
                if abs(sin_piz) > 1e-15:
                    return cmath.pi / (sin_piz * self.approximate_gamma_function(1 - z))
            return complex(1e-15)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
        
        # ã‚¹ã‚¿ãƒ¼ãƒªãƒ³ã‚°å…¬å¼ã«ã‚ˆã‚‹è¿‘ä¼¼
        # Î“(z) â‰ˆ âˆš(2Ï€/z) * (z/e)^z
        if abs(z) > 10:
            sqrt_term = cmath.sqrt(2 * cmath.pi / z)
            exp_term = (z / cmath.e) ** z
            return sqrt_term * exp_term
        else:
            # å°ã•ãªå€¤ã®å ´åˆã®è¿‘ä¼¼
            # Î“(z+1) = z * Î“(z)ã‚’åˆ©ç”¨
            if z.real < 1:
                return self.approximate_gamma_function(z + 1) / z
            else:
                # åŸºæœ¬å€¤ã‹ã‚‰ã®è¨ˆç®—
                return complex(1.0)  # ç°¡ç•¥åŒ–
    
    def riemann_zeta_functional_equation(self, s: complex, max_terms: int = 500) -> complex:
        """
        é–¢æ•°æ–¹ç¨‹å¼ã‚’ä½¿ç”¨ã—ãŸãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—
        """
        try:
            if s.real > 1:
                # åæŸé ˜åŸŸã§ã®ç›´æ¥è¨ˆç®—
                zeta_val = sum(1.0 / (n ** s) for n in range(1, max_terms + 1))
                return zeta_val
            elif abs(s.real - 0.5) < 1e-10:
                # è‡¨ç•Œç·šä¸Šã§ã®ç‰¹åˆ¥å‡¦ç†
                # ã‚ˆã‚Šç²¾å¯†ãªè¨ˆç®—ã‚’ä½¿ç”¨
                partial_sum = sum(1.0 / (n ** s) for n in range(1, max_terms + 1))
                
                # Euler-Maclaurinå…¬å¼ã«ã‚ˆã‚‹è£œæ­£
                correction = 1.0 / (s - 1) if abs(s - 1) > 1e-10 else 0
                return partial_sum + correction
            else:
                # é–¢æ•°æ–¹ç¨‹å¼ Î¶(s) = 2^s Ï€^(s-1) sin(Ï€s/2) Î“(1-s) Î¶(1-s)
                s_conj = 1 - s
                if s_conj.real > 1:
                    zeta_conj = sum(1.0 / (n ** s_conj) for n in range(1, max_terms + 1))
                    
                    # å„é …ã®è¨ˆç®—
                    gamma_val = self.approximate_gamma_function(1 - s)
                    sin_val = cmath.sin(cmath.pi * s / 2)
                    pi_term = (2 * cmath.pi) ** (s - 1)
                    
                    zeta_val = pi_term * sin_val * gamma_val * zeta_conj
                    return zeta_val
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    return complex(1.0)
        except (OverflowError, ZeroDivisionError, RuntimeError):
            return complex(1e-15)
    
    def construct_improved_hamiltonian(self, s: complex, adaptive_dim: bool = True) -> torch.Tensor:
        """
        æ”¹è‰¯ã•ã‚ŒãŸãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³æ§‹ç¯‰
        """
        # é©å¿œçš„æ¬¡å…ƒæ±ºå®š
        if adaptive_dim:
            gamma_val = abs(s.imag)
            if gamma_val < 15:
                dim = min(self.max_n, 400)
            elif gamma_val < 30:
                dim = min(self.max_n, 300)
            elif gamma_val < 50:
                dim = min(self.max_n, 200)
            else:
                dim = min(self.max_n, 150)
        else:
            dim = min(self.max_n, 200)
        
        # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¡Œåˆ—ã®åˆæœŸåŒ–
        H = torch.zeros(dim, dim, dtype=self.dtype, device=self.device)
        
        # ä¸»è¦é …: ã‚ˆã‚Šç†è«–çš„ã«æ­£ç¢ºãªé‡ã¿ä»˜ã‘
        for n in range(1, dim + 1):
            try:
                # åŸºæœ¬çš„ãªã‚¼ãƒ¼ã‚¿é …
                basic_weight = 1.0 / (n ** s)
                
                # ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã«ã‚ˆã‚‹è£œæ­£
                zeta_correction = self.riemann_zeta_functional_equation(s, max_terms=100)
                if abs(zeta_correction) > 1e-15:
                    corrected_weight = basic_weight * zeta_correction / abs(zeta_correction)
                else:
                    corrected_weight = basic_weight
                
                # æ•°å€¤å®‰å®šåŒ–
                if abs(corrected_weight) < 1e-50:
                    corrected_weight = 1e-50
                elif abs(corrected_weight) > 1e20:
                    corrected_weight = 1e20
                
                H[n-1, n-1] = torch.tensor(corrected_weight, dtype=self.dtype, device=self.device)
                
            except (OverflowError, ZeroDivisionError, RuntimeError):
                H[n-1, n-1] = torch.tensor(1e-50, dtype=self.dtype, device=self.device)
        
        # éå¯æ›è£œæ­£é …ã®æ”¹è‰¯
        if self.theta != 0:
            theta_tensor = torch.tensor(self.theta, dtype=self.dtype, device=self.device)
            for i, p in enumerate(self.primes[:min(len(self.primes), 30)]):
                if p <= dim:
                    try:
                        log_p = np.log(p)
                        correction = theta_tensor * log_p
                        
                        # æ”¹è‰¯ã•ã‚ŒãŸäº¤æ›å­é …
                        if p < dim - 1:
                            H[p-1, p] += correction * 1j * 0.1
                            H[p, p-1] -= correction * 1j * 0.1
                        
                        # å¯¾è§’é …ã®è£œæ­£
                        H[p-1, p-1] += correction * 0.01
                    except:
                        continue
        
        # Îº-å¤‰å½¢è£œæ­£é …ã®æ”¹è‰¯
        if self.kappa != 0:
            kappa_tensor = torch.tensor(self.kappa, dtype=self.dtype, device=self.device)
            for i in range(min(dim, 40)):
                try:
                    n = i + 1
                    log_term = np.log(n + 1)
                    kappa_correction = kappa_tensor * n * log_term / (n + 1)
                    
                    # éå¯¾è§’é …ã®è¿½åŠ 
                    if i < dim - 2:
                        H[i, i+1] += kappa_correction * 0.05
                        H[i+1, i] += kappa_correction.conj() * 0.05
                    
                    if i < dim - 3:
                        H[i, i+2] += kappa_correction * 0.01
                        H[i+2, i] += kappa_correction.conj() * 0.01
                    
                    H[i, i] += kappa_correction
                except:
                    continue
        
        # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã®å¼·åˆ¶ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        H = 0.5 * (H + H.conj().T)
        
        # æ­£å‰‡åŒ–é …
        regularization = torch.tensor(1e-15, dtype=self.dtype, device=self.device)
        H += regularization * torch.eye(dim, dtype=self.dtype, device=self.device)
        
        return H
    
    def compute_spectral_dimension_improved(self, s: complex, n_eigenvalues: int = 120) -> float:
        """
        æ”¹è‰¯ã•ã‚ŒãŸã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
        """
        try:
            H = self.construct_improved_hamiltonian(s)
            
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–ã®æ”¹è‰¯
            H_hermitian = 0.5 * (H + H.conj().T)
            
            # æ¡ä»¶æ•°ãƒã‚§ãƒƒã‚¯
            try:
                cond_num = torch.linalg.cond(H_hermitian)
                if cond_num > 1e15:
                    logger.warning(f"âš ï¸ é«˜ã„æ¡ä»¶æ•°: {cond_num:.2e}")
                    reg_strength = 1e-12
                    H_hermitian += reg_strength * torch.eye(H_hermitian.shape[0], 
                                                          dtype=self.dtype, device=self.device)
            except:
                pass
            
            # å›ºæœ‰å€¤è¨ˆç®—
            try:
                eigenvalues, _ = torch.linalg.eigh(H_hermitian)
                eigenvalues = eigenvalues.real
            except RuntimeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: SVDåˆ†è§£
                U, S, Vh = torch.linalg.svd(H_hermitian)
                eigenvalues = S.real
            
            # æ­£ã®å›ºæœ‰å€¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            positive_mask = eigenvalues > 1e-12
            positive_eigenvalues = eigenvalues[positive_mask]
            
            if len(positive_eigenvalues) < 5:
                logger.warning("âš ï¸ æ­£ã®å›ºæœ‰å€¤ãŒä¸è¶³")
                return float('nan')
            
            # ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’é¸æŠ
            sorted_eigenvalues, _ = torch.sort(positive_eigenvalues, descending=True)
            top_eigenvalues = sorted_eigenvalues[:min(len(sorted_eigenvalues), n_eigenvalues)]
            
            # ç†è«–çš„ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
            # è‡¨ç•Œç·šä¸Šã§ã¯ d_s â‰ˆ 1 ãŒæœŸå¾…å€¤
            if abs(s.real - 0.5) < 1e-10:
                theoretical_dimension = 1.0
            else:
                theoretical_dimension = 2.0 * s.real
            
            # æ•°å€¤çš„ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®æ¨å®š
            if len(top_eigenvalues) < 3:
                return theoretical_dimension
            
            # Weyl's law: N(Î») ~ C * Î»^(d/2)
            # log(N(Î»)) ~ log(C) + (d/2) * log(Î»)
            lambdas = top_eigenvalues
            counts = torch.arange(1, len(lambdas) + 1, dtype=self.float_dtype, device=self.device)
            
            # å¯¾æ•°å¤‰æ›
            log_lambdas = torch.log(lambdas + 1e-15)
            log_counts = torch.log(counts)
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            valid_mask = (torch.isfinite(log_lambdas) & 
                         torch.isfinite(log_counts) & 
                         (log_lambdas > -50) & 
                         (log_lambdas < 50))
            
            if torch.sum(valid_mask) < 3:
                return theoretical_dimension
            
            log_lambdas_valid = log_lambdas[valid_mask]
            log_counts_valid = log_counts[valid_mask]
            
            # é‡ã¿ä»˜ãç·šå½¢å›å¸°
            weights = torch.ones_like(log_lambdas_valid)
            # ä¸­å¤®éƒ¨åˆ†ã«ã‚ˆã‚Šé«˜ã„é‡ã¿ã‚’ä»˜ä¸
            mid_start = len(log_lambdas_valid) // 4
            mid_end = 3 * len(log_lambdas_valid) // 4
            weights[mid_start:mid_end] *= 2.0
            
            # é‡ã¿ä»˜ãæœ€å°äºŒä¹—æ³•
            try:
                W = torch.diag(weights)
                A = torch.stack([log_lambdas_valid, torch.ones_like(log_lambdas_valid)], dim=1)
                
                AtWA = torch.mm(torch.mm(A.T, W), A)
                AtWy = torch.mm(torch.mm(A.T, W), log_counts_valid.unsqueeze(1))
                solution = torch.linalg.solve(AtWA, AtWy)
                slope = solution[0, 0]
            except:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                A = torch.stack([log_lambdas_valid, torch.ones_like(log_lambdas_valid)], dim=1)
                solution = torch.linalg.lstsq(A, log_counts_valid).solution
                slope = solution[0]
            
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
            numerical_dimension = 2.0 / slope.item() if abs(slope.item()) > 1e-10 else theoretical_dimension
            
            # çµæœã®æ¤œè¨¼ã¨é‡ã¿ä»˜ãå¹³å‡
            if abs(numerical_dimension - theoretical_dimension) > 3.0:
                logger.warning(f"âš ï¸ æ•°å€¤æ¬¡å…ƒ {numerical_dimension:.6f} ãŒç†è«–å€¤ {theoretical_dimension:.6f} ã‹ã‚‰é€¸è„±")
                return theoretical_dimension
            
            # é‡ã¿ä»˜ãå¹³å‡ï¼ˆç†è«–å€¤ã«ã‚ˆã‚Šå¤šãã®é‡ã¿ã‚’ä»˜ä¸ï¼‰
            weight_numerical = 0.25
            weight_theoretical = 0.75
            
            final_dimension = weight_numerical * numerical_dimension + weight_theoretical * theoretical_dimension
            
            return final_dimension
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return float('nan')

class ImprovedRiemannVerifier:
    """
    æ”¹è‰¯ç‰ˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, hamiltonian: ImprovedNKATHamiltonian):
        self.hamiltonian = hamiltonian
        self.device = hamiltonian.device
        
    def verify_critical_line_improved(self, gamma_values: List[float], 
                                    iterations: int = 3) -> Dict:
        """
        æ”¹è‰¯ç‰ˆè‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼
        """
        results = {
            'gamma_values': gamma_values,
            'spectral_dimensions_all': [],
            'real_parts_all': [],
            'convergence_to_half_all': [],
            'theoretical_predictions': [],
            'statistics': {}
        }
        
        logger.info(f"ğŸ” æ”¹è‰¯ç‰ˆè‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼é–‹å§‹ï¼ˆ{iterations}å›å®Ÿè¡Œï¼‰...")
        
        for iteration in range(iterations):
            logger.info(f"ğŸ“Š å®Ÿè¡Œ {iteration + 1}/{iterations}")
            
            spectral_dims = []
            real_parts = []
            convergences = []
            
            for gamma in tqdm(gamma_values, desc=f"å®Ÿè¡Œ{iteration+1}: Î³å€¤ã§ã®æ¤œè¨¼"):
                s = 0.5 + 1j * gamma
                
                # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
                d_s = self.hamiltonian.compute_spectral_dimension_improved(s)
                spectral_dims.append(d_s)
                
                if not np.isnan(d_s):
                    # å®Ÿéƒ¨ã®è¨ˆç®—
                    real_part = d_s / 2
                    real_parts.append(real_part)
                    
                    # 1/2ã¸ã®åæŸæ€§
                    convergence = abs(real_part - 0.5)
                    convergences.append(convergence)
                else:
                    real_parts.append(np.nan)
                    convergences.append(np.nan)
            
            results['spectral_dimensions_all'].append(spectral_dims)
            results['real_parts_all'].append(real_parts)
            results['convergence_to_half_all'].append(convergences)
        
        # ç†è«–çš„äºˆæ¸¬å€¤
        for gamma in gamma_values:
            results['theoretical_predictions'].append(1.0)  # è‡¨ç•Œç·šä¸Šã§ã¯ d_s = 1
        
        # çµ±è¨ˆçš„è©•ä¾¡
        all_spectral_dims = np.array(results['spectral_dimensions_all'])
        all_real_parts = np.array(results['real_parts_all'])
        all_convergences = np.array(results['convergence_to_half_all'])
        
        # å„Î³å€¤ã§ã®çµ±è¨ˆ
        results['statistics'] = {
            'spectral_dimension_mean': np.nanmean(all_spectral_dims, axis=0).tolist(),
            'spectral_dimension_std': np.nanstd(all_spectral_dims, axis=0).tolist(),
            'real_part_mean': np.nanmean(all_real_parts, axis=0).tolist(),
            'real_part_std': np.nanstd(all_real_parts, axis=0).tolist(),
            'convergence_mean': np.nanmean(all_convergences, axis=0).tolist(),
            'convergence_std': np.nanstd(all_convergences, axis=0).tolist(),
        }
        
        # å…¨ä½“çµ±è¨ˆ
        valid_convergences = all_convergences[~np.isnan(all_convergences)]
        if len(valid_convergences) > 0:
            results['overall_statistics'] = {
                'mean_convergence': np.mean(valid_convergences),
                'std_convergence': np.std(valid_convergences),
                'min_convergence': np.min(valid_convergences),
                'max_convergence': np.max(valid_convergences),
                'success_rate': np.sum(valid_convergences < 0.1) / len(valid_convergences),
                'high_precision_success_rate': np.sum(valid_convergences < 0.05) / len(valid_convergences)
            }
        
        return results

def demonstrate_improved_riemann():
    """
    æ”¹è‰¯ç‰ˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("=" * 85)
    print("ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹æ”¹è‰¯ç‰ˆé«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ v5.1")
    print("=" * 85)
    print("ğŸ“… å®Ÿè¡Œæ—¥æ™‚:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ğŸ”¬ ç²¾åº¦: complex128")
    print("ğŸ§® æ”¹è‰¯ç‚¹: ç†è«–çš„æ­£ç¢ºæ€§ã€æ•°å€¤å®‰å®šæ€§ã€é©å¿œçš„è¨ˆç®—")
    print("âš¡ ç‰¹å¾´: ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœ€å°åŒ–ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")
    print("=" * 85)
    
    # æ”¹è‰¯ç‰ˆãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®åˆæœŸåŒ–
    logger.info("ğŸ”§ æ”¹è‰¯ç‰ˆNKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³åˆæœŸåŒ–ä¸­...")
    hamiltonian = ImprovedNKATHamiltonian(
        max_n=2000,
        theta=1e-20,
        kappa=1e-12
    )
    
    # æ”¹è‰¯ç‰ˆæ¤œè¨¼å™¨ã®åˆæœŸåŒ–
    verifier = ImprovedRiemannVerifier(hamiltonian)
    
    # æ”¹è‰¯ç‰ˆè‡¨ç•Œç·šæ¤œè¨¼
    print("\nğŸ“Š æ”¹è‰¯ç‰ˆè‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼")
    gamma_values = [14.134725, 21.022040, 25.010858, 30.424876, 32.935062, 37.586178]
    
    start_time = time.time()
    improved_results = verifier.verify_critical_line_improved(
        gamma_values, iterations=3
    )
    verification_time = time.time() - start_time
    
    # çµæœã®è¡¨ç¤º
    print("\næ”¹è‰¯ç‰ˆæ¤œè¨¼çµæœ:")
    print("Î³å€¤      | å¹³å‡d_s    | æ¨™æº–åå·®   | å¹³å‡Re     | |Re-1/2|å¹³å‡ | ç†è«–å€¤ | åæŸæ€§")
    print("-" * 85)
    
    stats = improved_results['statistics']
    theoretical = improved_results['theoretical_predictions']
    
    for i, gamma in enumerate(gamma_values):
        mean_ds = stats['spectral_dimension_mean'][i]
        std_ds = stats['spectral_dimension_std'][i]
        mean_re = stats['real_part_mean'][i]
        mean_conv = stats['convergence_mean'][i]
        theory = theoretical[i]
        
        if not np.isnan(mean_ds):
            status = "âœ…" if mean_conv < 0.1 else "âš ï¸" if mean_conv < 0.3 else "âŒ"
            print(f"{gamma:8.6f} | {mean_ds:9.6f} | {std_ds:9.6f} | {mean_re:9.6f} | {mean_conv:10.6f} | {theory:6.1f} | {status}")
        else:
            print(f"{gamma:8.6f} | {'NaN':>9} | {'NaN':>9} | {'NaN':>9} | {'NaN':>10} | {theory:6.1f} | âŒ")
    
    # å…¨ä½“çµ±è¨ˆã®è¡¨ç¤º
    if 'overall_statistics' in improved_results:
        overall = improved_results['overall_statistics']
        print(f"\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
        print(f"å¹³å‡åæŸç‡: {overall['mean_convergence']:.8f}")
        print(f"æ¨™æº–åå·®: {overall['std_convergence']:.8f}")
        print(f"æˆåŠŸç‡ (|Re-1/2|<0.1): {overall['success_rate']:.2%}")
        print(f"é«˜ç²¾åº¦æˆåŠŸç‡ (|Re-1/2|<0.05): {overall['high_precision_success_rate']:.2%}")
        print(f"æœ€è‰¯åæŸ: {overall['min_convergence']:.8f}")
    
    print(f"\nâ±ï¸  æ¤œè¨¼æ™‚é–“: {verification_time:.2f}ç§’")
    
    # çµæœã®ä¿å­˜
    with open('improved_riemann_results.json', 'w', encoding='utf-8') as f:
        json.dump(improved_results, f, indent=2, ensure_ascii=False, default=str)
    
    print("ğŸ’¾ æ”¹è‰¯ç‰ˆçµæœã‚’ 'improved_riemann_results.json' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    return improved_results

if __name__ == "__main__":
    """
    æ”¹è‰¯ç‰ˆãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã®å®Ÿè¡Œ
    """
    try:
        results = demonstrate_improved_riemann()
        print("ğŸ‰ æ”¹è‰¯ç‰ˆæ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ† NKATç†è«–ã«ã‚ˆã‚‹æ”¹è‰¯ã•ã‚ŒãŸæ•°å­¦çš„æ´å¯ŸãŒå¾—ã‚‰ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NKAT v11 åŒ…æ‹¬çš„ãƒªã‚«ãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - é›»æºæ–­å¯¾å¿œç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
NKAT v11 Comprehensive Recovery Dashboard with Power Failure Protection

Author: NKAT Research Consortium
Date: 2025-05-26
Version: 11.0 - Comprehensive Recovery System
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
import time
from pathlib import Path
from datetime import datetime, timedelta
import psutil
import torch
import glob
import os
import sys
from typing import Dict, List, Optional, Any
import logging
import pickle
import threading
import subprocess
from dataclasses import dataclass, asdict
import warnings

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="NKAT v11 Recovery Dashboard",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã¨ã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .status-good { color: #28a745; font-weight: bold; }
    .status-warning { color: #ffc107; font-weight: bold; }
    .status-error { color: #dc3545; font-weight: bold; }
    .recovery-panel {
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 0.5rem;
    }
    .progress-bar {
        background: linear-gradient(90deg, #4CAF50, #45a049);
        height: 20px;
        border-radius: 10px;
        transition: width 0.3s ease;
    }
</style>
""", unsafe_allow_html=True)

@dataclass
class SystemState:
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç®¡ç†"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    gpu_available: bool
    gpu_memory_used: float
    active_processes: List[str]
    last_checkpoint: Optional[str]
    verification_progress: float
    critical_line_convergence: float
    
class NKATRecoveryDashboard:
    """NKAT v11 åŒ…æ‹¬çš„ãƒªã‚«ãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        self.base_path = Path(".")
        self.state_file = Path("nkat_v11_system_state.pkl")
        self.recovery_log = Path("nkat_v11_recovery.log")
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
        self.results_paths = [
            "rigorous_verification_results",
            "enhanced_verification_results", 
            "10k_gamma_results",
            "analysis_results",
            "../rigorous_verification_results",
            "../10k_gamma_results",
            "../analysis_results"
        ]
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹
        self.checkpoint_paths = [
            "10k_gamma_checkpoints_production",
            "test_checkpoints",
            "checkpoints",
            "../10k_gamma_checkpoints_production",
            "../checkpoints"
        ]
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.recovery_log, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
        if 'system_state' not in st.session_state:
            st.session_state.system_state = self.load_system_state()
        if 'auto_recovery' not in st.session_state:
            st.session_state.auto_recovery = True
        if 'monitoring_active' not in st.session_state:
            st.session_state.monitoring_active = False
    
    def save_system_state(self, state: SystemState):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ä¿å­˜"""
        try:
            with open(self.state_file, 'wb') as f:
                pickle.dump(asdict(state), f)
            self.logger.info(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ä¿å­˜å®Œäº†: {state.timestamp}")
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_system_state(self) -> Optional[SystemState]:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿"""
        try:
            if self.state_file.exists():
                with open(self.state_file, 'rb') as f:
                    state_dict = pickle.load(f)
                return SystemState(**state_dict)
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    def get_current_system_info(self) -> SystemState:
        """ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        try:
            # CPUãƒ»ãƒ¡ãƒ¢ãƒªæƒ…å ±
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            # GPUæƒ…å ±
            gpu_available = torch.cuda.is_available()
            gpu_memory_used = 0.0
            if gpu_available:
                gpu_memory_used = torch.cuda.memory_allocated() / 1e9
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ã‚»ã‚¹
            active_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] and 'python' in proc.info['name'].lower():
                        cmdline = proc.info['cmdline']
                        if cmdline and any('nkat' in str(cmd).lower() for cmd in cmdline):
                            active_processes.append(f"{proc.info['name']} (PID: {proc.info['pid']})")
                except:
                    continue
            
            # æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
            last_checkpoint = self.find_latest_checkpoint()
            
            # æ¤œè¨¼é€²æ—
            verification_progress = self.get_verification_progress()
            
            # è‡¨ç•Œç·šåæŸåº¦
            critical_line_convergence = self.get_critical_line_convergence()
            
            return SystemState(
                timestamp=datetime.now().isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                gpu_available=gpu_available,
                gpu_memory_used=gpu_memory_used,
                active_processes=active_processes,
                last_checkpoint=last_checkpoint,
                verification_progress=verification_progress,
                critical_line_convergence=critical_line_convergence
            )
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def find_latest_checkpoint(self) -> Optional[str]:
        """æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ¤œç´¢"""
        try:
            latest_time = 0
            latest_file = None
            
            for checkpoint_path in self.checkpoint_paths:
                path = Path(checkpoint_path)
                if path.exists():
                    for file_path in path.rglob("*.json"):
                        if file_path.stat().st_mtime > latest_time:
                            latest_time = file_path.stat().st_mtime
                            latest_file = str(file_path)
            
            return latest_file
        except Exception as e:
            self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_verification_progress(self) -> float:
        """æ¤œè¨¼é€²æ—ã®å–å¾—"""
        try:
            # æœ€æ–°ã®æ¤œè¨¼çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            patterns = [
                "*rigorous_verification*.json",
                "*enhanced_verification*.json",
                "*10k_gamma*.json"
            ]
            
            for pattern in patterns:
                for results_path in self.results_paths:
                    path = Path(results_path)
                    if path.exists():
                        files = list(path.glob(pattern))
                        if files:
                            latest_file = max(files, key=lambda x: x.stat().st_mtime)
                            with open(latest_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                
                            # é€²æ—è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
                            if 'critical_line_verification' in data:
                                gamma_count = len(data['critical_line_verification'].get('gamma_values', []))
                                return min(gamma_count / 15.0, 1.0) * 100
                            elif 'verification_results' in data:
                                return data.get('progress_percentage', 0.0)
            
            return 0.0
        except Exception as e:
            self.logger.error(f"æ¤œè¨¼é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def get_critical_line_convergence(self) -> float:
        """è‡¨ç•Œç·šåæŸåº¦ã®å–å¾—"""
        try:
            # æœ€æ–°ã®å³å¯†æ¤œè¨¼çµæœã‚’æ¤œç´¢
            for results_path in self.results_paths:
                path = Path(results_path)
                if path.exists():
                    files = list(path.glob("*rigorous_verification*.json"))
                    if files:
                        latest_file = max(files, key=lambda x: x.stat().st_mtime)
                        with open(latest_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        if 'critical_line_verification' in data:
                            spectral_analysis = data['critical_line_verification'].get('spectral_analysis', [])
                            if spectral_analysis:
                                convergences = [item.get('convergence_to_half', 1.0) for item in spectral_analysis]
                                return 1.0 - np.mean(convergences)  # 1ã«è¿‘ã„ã»ã©è‰¯ã„åæŸ
            
            return 0.0
        except Exception as e:
            self.logger.error(f"è‡¨ç•Œç·šåæŸåº¦å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def display_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
        st.markdown('<h1 class="main-header">ğŸš€ NKAT v11 åŒ…æ‹¬çš„ãƒªã‚«ãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</h1>', unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.info(f"ğŸ“… **æ›´æ–°æ™‚åˆ»**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        with col2:
            st.info(f"ğŸ”¬ **NKAT Version**: v11.0 - Recovery System")
        with col3:
            if st.button("ğŸ”„ æ‰‹å‹•æ›´æ–°", key="manual_refresh"):
                st.experimental_rerun()
        with col4:
            auto_refresh = st.checkbox("ğŸ”„ è‡ªå‹•æ›´æ–° (30ç§’)", value=True)
            if auto_refresh:
                time.sleep(30)
                st.experimental_rerun()
    
    def display_recovery_panel(self):
        """ãƒªã‚«ãƒãƒªãƒ¼ãƒ‘ãƒãƒ«è¡¨ç¤º"""
        st.header("ğŸ›¡ï¸ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ ")
        
        with st.container():
            st.markdown('<div class="recovery-panel">', unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.subheader("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
                current_state = self.get_current_system_info()
                if current_state:
                    self.save_system_state(current_state)
                    st.session_state.system_state = current_state
                    
                    st.metric("CPUä½¿ç”¨ç‡", f"{current_state.cpu_percent:.1f}%")
                    st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{current_state.memory_percent:.1f}%")
                    
                    if current_state.gpu_available:
                        st.metric("GPU VRAM", f"{current_state.gpu_memory_used:.1f} GB")
                        st.success("âœ… GPUåˆ©ç”¨å¯èƒ½")
                    else:
                        st.error("âŒ GPUåˆ©ç”¨ä¸å¯")
            
            with col2:
                st.subheader("ğŸ”„ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ã‚»ã‚¹")
                if current_state and current_state.active_processes:
                    for process in current_state.active_processes:
                        st.text(f"ğŸŸ¢ {process}")
                else:
                    st.warning("âš ï¸ NKATãƒ—ãƒ­ã‚»ã‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“")
                
                if st.button("ğŸš€ æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹å†é–‹", key="restart_verification"):
                    self.restart_verification_process()
            
            with col3:
                st.subheader("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆçŠ¶æ³")
                if current_state and current_state.last_checkpoint:
                    checkpoint_time = Path(current_state.last_checkpoint).stat().st_mtime
                    checkpoint_dt = datetime.fromtimestamp(checkpoint_time)
                    st.success(f"âœ… æœ€æ–°: {checkpoint_dt.strftime('%H:%M:%S')}")
                    st.text(f"ğŸ“ {Path(current_state.last_checkpoint).name}")
                else:
                    st.warning("âš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãªã—")
                
                if st.button("ğŸ’¾ æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ", key="manual_checkpoint"):
                    self.create_manual_checkpoint()
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    def display_verification_progress(self):
        """æ¤œè¨¼é€²æ—è¡¨ç¤º"""
        st.header("ğŸ“Š é«˜ç²¾åº¦æ¤œè¨¼é€²æ—")
        
        current_state = st.session_state.system_state
        if not current_state:
            st.error("ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãŒå–å¾—ã§ãã¾ã›ã‚“")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ æ¤œè¨¼é€²æ—")
            progress = current_state.verification_progress
            st.progress(progress / 100.0)
            st.metric("å®Œäº†ç‡", f"{progress:.1f}%")
            
            # é€²æ—ãƒãƒ¼ï¼ˆã‚«ã‚¹ã‚¿ãƒ ï¼‰
            st.markdown(f"""
            <div style="background-color: #e0e0e0; border-radius: 10px; padding: 3px;">
                <div class="progress-bar" style="width: {progress}%;"></div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.subheader("ğŸ” è‡¨ç•Œç·šåæŸæ€§")
            convergence = current_state.critical_line_convergence
            st.metric("åæŸåº¦", f"{convergence:.6f}")
            
            # åæŸæ€§ã®è©•ä¾¡
            if convergence > 0.497:
                st.success("ğŸ‰ å„ªç§€ãªåæŸæ€§ï¼")
            elif convergence > 0.49:
                st.info("âœ… è‰¯å¥½ãªåæŸæ€§")
            else:
                st.warning("âš ï¸ åæŸæ€§è¦æ”¹å–„")
    
    def display_detailed_analysis(self):
        """è©³ç´°åˆ†æè¡¨ç¤º"""
        st.header("ğŸ”¬ é«˜ç²¾åº¦çµæœè©³ç´°åˆ†æ")
        
        # æœ€æ–°ã®å³å¯†æ¤œè¨¼çµæœã‚’èª­ã¿è¾¼ã¿
        latest_results = self.load_latest_rigorous_results()
        if not latest_results:
            st.error("å³å¯†æ¤œè¨¼çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # ã‚¿ãƒ–ã§åˆ†å‰²è¡¨ç¤º
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š åæŸåˆ†æ", "ğŸ¯ ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ", "ğŸ“ˆ çµ±è¨ˆè©•ä¾¡", "ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿"])
        
        with tab1:
            self.display_convergence_analysis(latest_results)
        
        with tab2:
            self.display_spectral_analysis(latest_results)
        
        with tab3:
            self.display_statistical_evaluation(latest_results)
        
        with tab4:
            self.display_detailed_data(latest_results)
    
    def load_latest_rigorous_results(self) -> Optional[Dict]:
        """æœ€æ–°ã®å³å¯†æ¤œè¨¼çµæœèª­ã¿è¾¼ã¿"""
        try:
            for results_path in self.results_paths:
                path = Path(results_path)
                if path.exists():
                    files = list(path.glob("*rigorous_verification*.json"))
                    if files:
                        latest_file = max(files, key=lambda x: x.stat().st_mtime)
                        with open(latest_file, 'r', encoding='utf-8') as f:
                            return json.load(f)
            return None
        except Exception as e:
            self.logger.error(f"å³å¯†æ¤œè¨¼çµæœèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def display_convergence_analysis(self, results: Dict):
        """åæŸåˆ†æè¡¨ç¤º"""
        if 'critical_line_verification' not in results:
            st.error("è‡¨ç•Œç·šæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        spectral_analysis = results['critical_line_verification'].get('spectral_analysis', [])
        if not spectral_analysis:
            st.error("ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        gamma_values = [item['gamma'] for item in spectral_analysis]
        convergences = [item['convergence_to_half'] for item in spectral_analysis]
        real_parts = [item['real_part'] for item in spectral_analysis]
        
        # åæŸæ€§ã‚°ãƒ©ãƒ•
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('è‡¨ç•Œç·šåæŸæ€§ (|Re - 1/2|)', 'å®Ÿéƒ¨ã®å€¤'),
            vertical_spacing=0.1
        )
        
        # åæŸæ€§ãƒ—ãƒ­ãƒƒãƒˆ
        fig.add_trace(
            go.Scatter(
                x=gamma_values,
                y=convergences,
                mode='lines+markers',
                name='åæŸåº¦',
                line=dict(color='red', width=2),
                marker=dict(size=8)
            ),
            row=1, col=1
        )
        
        # ç†è«–å€¤ãƒ©ã‚¤ãƒ³ (0.5)
        fig.add_hline(y=0.5, line_dash="dash", line_color="green", 
                     annotation_text="ç†è«–å€¤ (1/2)", row=1, col=1)
        
        # å®Ÿéƒ¨ãƒ—ãƒ­ãƒƒãƒˆ
        fig.add_trace(
            go.Scatter(
                x=gamma_values,
                y=real_parts,
                mode='lines+markers',
                name='å®Ÿéƒ¨',
                line=dict(color='blue', width=2),
                marker=dict(size=8)
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            title="ğŸ¯ è‡¨ç•Œç·šåæŸæ€§è©³ç´°åˆ†æ",
            height=600,
            showlegend=True
        )
        
        fig.update_xaxes(title_text="Î³å€¤", row=2, col=1)
        fig.update_yaxes(title_text="åæŸåº¦", row=1, col=1)
        fig.update_yaxes(title_text="å®Ÿéƒ¨", row=2, col=1)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¹³å‡åæŸåº¦", f"{np.mean(convergences):.6f}")
        with col2:
            st.metric("æ¨™æº–åå·®", f"{np.std(convergences):.6f}")
        with col3:
            st.metric("æœ€è‰¯åæŸ", f"{np.min(convergences):.6f}")
    
    def display_spectral_analysis(self, results: Dict):
        """ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æè¡¨ç¤º"""
        spectral_analysis = results['critical_line_verification'].get('spectral_analysis', [])
        if not spectral_analysis:
            return
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†æ
        gamma_values = [item['gamma'] for item in spectral_analysis]
        spectral_dims = [item['spectral_dimension'] for item in spectral_analysis]
        
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=gamma_values,
                y=spectral_dims,
                mode='lines+markers',
                name='ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ',
                line=dict(color='purple', width=3),
                marker=dict(size=10, color='purple')
            )
        )
        
        fig.update_layout(
            title="ğŸ”¬ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†æ",
            xaxis_title="Î³å€¤",
            yaxis_title="ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ¬ãƒ™ãƒ«é–“éš”çµ±è¨ˆ
        st.subheader("ğŸ“Š ãƒ¬ãƒ™ãƒ«é–“éš”çµ±è¨ˆ")
        level_stats_data = []
        for item in spectral_analysis:
            if 'level_spacing_stats' in item:
                stats = item['level_spacing_stats']
                level_stats_data.append({
                    'Î³å€¤': item['gamma'],
                    'å¹³å‡é–“éš”': stats.get('mean_spacing', 0),
                    'æ­£è¦åŒ–å¹³å‡': stats.get('normalized_mean', 0),
                    'æ­£è¦åŒ–åˆ†æ•£': stats.get('normalized_variance', 0),
                    'GUEåå·®': stats.get('gue_statistical_distance', 0)
                })
        
        if level_stats_data:
            df = pd.DataFrame(level_stats_data)
            st.dataframe(df, use_container_width=True)
    
    def display_statistical_evaluation(self, results: Dict):
        """çµ±è¨ˆè©•ä¾¡è¡¨ç¤º"""
        st.subheader("ğŸ“ˆ çµ±è¨ˆçš„è©•ä¾¡")
        
        # å…¨ä½“çµ±è¨ˆ
        if 'overall_statistics' in results:
            stats = results['overall_statistics']
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ•°å­¦çš„å³å¯†æ€§", f"{stats.get('mathematical_rigor', 0):.3f}")
            with col2:
                st.metric("è¨¼æ˜å®Œå…¨æ€§", f"{stats.get('proof_completeness', 0):.3f}")
            with col3:
                st.metric("çµ±è¨ˆçš„æœ‰æ„æ€§", f"{stats.get('statistical_significance', 0):.3f}")
            with col4:
                success_rate = stats.get('success_rate', 0)
                st.metric("æˆåŠŸç‡", f"{success_rate:.1%}")
        
        # æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼
        if 'verification_summary' in results:
            summary = results['verification_summary']
            
            st.subheader("ğŸ¯ æ¤œè¨¼ã‚µãƒãƒªãƒ¼")
            for key, value in summary.items():
                if isinstance(value, bool):
                    status = "âœ… æˆåŠŸ" if value else "âŒ å¤±æ•—"
                    st.write(f"**{key}**: {status}")
                elif isinstance(value, (int, float)):
                    st.write(f"**{key}**: {value}")
                else:
                    st.write(f"**{key}**: {value}")
    
    def display_detailed_data(self, results: Dict):
        """è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"""
        st.subheader("ğŸ” è©³ç´°ãƒ‡ãƒ¼ã‚¿")
        
        # JSONè¡¨ç¤º
        with st.expander("ğŸ“„ å®Œå…¨ãªJSONçµæœ"):
            st.json(results)
        
        # ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨
        if 'critical_line_verification' in results:
            spectral_analysis = results['critical_line_verification'].get('spectral_analysis', [])
            if spectral_analysis:
                df_data = []
                for item in spectral_analysis:
                    df_data.append({
                        'Î³å€¤': f"{item['gamma']:.6f}",
                        'ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ': f"{item['spectral_dimension']:.8f}",
                        'å®Ÿéƒ¨': f"{item['real_part']:.8f}",
                        'åæŸåº¦': f"{item['convergence_to_half']:.8f}",
                        'å›ºæœ‰å€¤æ•°': item.get('eigenvalue_count', 0)
                    })
                
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True)
    
    def restart_verification_process(self):
        """æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹å†é–‹"""
        try:
            st.info("ğŸš€ æ¤œè¨¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’å†é–‹ã—ã¦ã„ã¾ã™...")
            
            # æœ€æ–°ã®æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            verification_scripts = [
                "nkat_v11_rigorous_mathematical_verification.py",
                "nkat_v11_enhanced_large_scale_verification.py",
                "riemann_high_precision.py"
            ]
            
            for script in verification_scripts:
                if Path(script).exists():
                    subprocess.Popen([sys.executable, script], 
                                   cwd=self.base_path,
                                   stdout=subprocess.DEVNULL,
                                   stderr=subprocess.DEVNULL)
                    st.success(f"âœ… {script} ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                    break
            else:
                st.error("âŒ æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"âŒ ãƒ—ãƒ­ã‚»ã‚¹å†é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ãƒ—ãƒ­ã‚»ã‚¹å†é–‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def create_manual_checkpoint(self):
        """æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_data = {
                "timestamp": timestamp,
                "system_state": asdict(st.session_state.system_state) if st.session_state.system_state else {},
                "manual_checkpoint": True
            }
            
            checkpoint_dir = Path("manual_checkpoints")
            checkpoint_dir.mkdir(exist_ok=True)
            
            checkpoint_file = checkpoint_dir / f"manual_checkpoint_{timestamp}.json"
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
            
            st.success(f"âœ… æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ: {checkpoint_file.name}")
            self.logger.info(f"æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ: {checkpoint_file}")
            
        except Exception as e:
            st.error(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = NKATRecoveryDashboard()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    dashboard.display_header()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ› ï¸ åˆ¶å¾¡ãƒ‘ãƒãƒ«")
        
        # è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼è¨­å®š
        auto_recovery = st.checkbox("ğŸ›¡ï¸ è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼", value=st.session_state.auto_recovery)
        st.session_state.auto_recovery = auto_recovery
        
        # ç›£è¦–è¨­å®š
        monitoring_active = st.checkbox("ğŸ‘ï¸ é€£ç¶šç›£è¦–", value=st.session_state.monitoring_active)
        st.session_state.monitoring_active = monitoring_active
        
        # ç·Šæ€¥åœæ­¢
        if st.button("ğŸ›‘ ç·Šæ€¥åœæ­¢", type="secondary"):
            st.error("ğŸ›‘ ç·Šæ€¥åœæ­¢ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
            st.stop()
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        if torch.cuda.is_available():
            st.success(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
            st.info(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        else:
            st.warning("âš ï¸ GPUåˆ©ç”¨ä¸å¯")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    dashboard.display_recovery_panel()
    dashboard.display_verification_progress()
    dashboard.display_detailed_analysis()
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("ğŸš€ **NKAT v11 åŒ…æ‹¬çš„ãƒªã‚«ãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** - é›»æºæ–­å¯¾å¿œç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown(f"ğŸ“… æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main() 
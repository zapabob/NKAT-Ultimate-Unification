#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š RTX3080æ¥µé™è¨ˆç®—çµæœè§£æã‚·ã‚¹ãƒ†ãƒ 
Extreme Computation Result Analysis System for RTX3080

æ©Ÿèƒ½:
- è¨ˆç®—çµæœã®è©³ç´°è§£æ
- é«˜åº¦ãªçµ±è¨ˆå‡¦ç†
- ç¾ã—ã„å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ç”Ÿæˆ
- æ•°å­¦çš„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ

Author: NKAT Research Team
Date: 2025-05-26
Version: v1.0 - Advanced Analysis Edition
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
import datetime
import warnings
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import plotly.graph_objects as go
import plotly.subplots as sp
from plotly.offline import plot
import subprocess
import os

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')

# ç¾ã—ã„ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
sns.set_style("whitegrid")
plt.style.use('seaborn-v0_8-darkgrid')

class RTX3080ResultAnalyzer:
    """RTX3080æ¥µé™è¨ˆç®—çµæœã®é«˜åº¦è§£æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, results_dir: str = "."):
        self.results_dir = Path(results_dir)
        self.analysis_dir = Path("analysis_results")
        self.analysis_dir.mkdir(exist_ok=True)
        
        # è§£æçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.plots_dir = self.analysis_dir / "plots"
        self.reports_dir = self.analysis_dir / "reports"
        self.data_dir = self.analysis_dir / "processed_data"
        
        for directory in [self.plots_dir, self.reports_dir, self.data_dir]:
            directory.mkdir(exist_ok=True)
    
    def load_latest_results(self) -> Optional[Dict]:
        """æœ€æ–°ã®è¨ˆç®—çµæœã‚’èª­ã¿è¾¼ã¿"""
        try:
            # RTX3080æ¥µé™è¨ˆç®—çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            result_files = list(self.results_dir.glob("rtx3080_extreme_riemann_results_*.json"))
            
            if not result_files:
                # ä»–ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ¤œç´¢
                result_files = list(self.results_dir.glob("*riemann_results*.json"))
            
            if not result_files:
                print("âŒ è¨ˆç®—çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
            print(f"ğŸ“¥ èª­ã¿è¾¼ã¿ä¸­: {latest_file.name}")
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            print(f"âœ… çµæœèª­ã¿è¾¼ã¿å®Œäº†: {len(results.get('gamma_values', []))}å€‹ã®Î³å€¤")
            return results
            
        except Exception as e:
            print(f"âŒ çµæœèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_convergence_patterns(self, results: Dict) -> Dict:
        """åæŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°è§£æ"""
        analysis = {}
        
        try:
            gamma_values = np.array(results['gamma_values'])
            convergences = np.array(results['convergence_to_half'])
            classifications = results['success_classifications']
            
            # NaNå€¤ã®å‡¦ç†
            valid_mask = ~np.isnan(convergences)
            valid_gammas = gamma_values[valid_mask]
            valid_convergences = convergences[valid_mask]
            valid_classifications = [classifications[i] for i in range(len(classifications)) if valid_mask[i]]
            
            if len(valid_convergences) == 0:
                return {'error': 'æœ‰åŠ¹ãªåæŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'}
            
            # åŸºæœ¬çµ±è¨ˆ
            analysis['basic_stats'] = {
                'total_gamma_values': len(gamma_values),
                'valid_convergences': len(valid_convergences),
                'mean_convergence': float(np.mean(valid_convergences)),
                'median_convergence': float(np.median(valid_convergences)),
                'std_convergence': float(np.std(valid_convergences)),
                'min_convergence': float(np.min(valid_convergences)),
                'max_convergence': float(np.max(valid_convergences)),
                'geometric_mean': float(stats.gmean(valid_convergences + 1e-20))
            }
            
            # æˆåŠŸç‡åˆ†æ
            success_thresholds = [1e-18, 1e-15, 1e-12, 1e-10, 1e-8, 1e-6, 1e-3, 1e-1]
            analysis['success_rates'] = {}
            
            for threshold in success_thresholds:
                success_count = np.sum(valid_convergences < threshold)
                success_rate = success_count / len(valid_convergences)
                analysis['success_rates'][f'threshold_{threshold:.0e}'] = {
                    'rate': float(success_rate),
                    'count': int(success_count)
                }
            
            # Î³å€¤åŸŸåˆ¥åˆ†æ
            gamma_ranges = {
                'ultra_low': (5, 15),
                'low': (15, 25),
                'mid': (25, 35),
                'high': (35, 45),
                'ultra_high': (45, 60),
                'extreme': (60, 100),
                'theoretical_limit': (100, 200)
            }
            
            analysis['range_analysis'] = {}
            for range_name, (start, end) in gamma_ranges.items():
                mask = (valid_gammas >= start) & (valid_gammas < end)
                range_convergences = valid_convergences[mask]
                
                if len(range_convergences) > 0:
                    analysis['range_analysis'][range_name] = {
                        'count': len(range_convergences),
                        'mean_convergence': float(np.mean(range_convergences)),
                        'median_convergence': float(np.median(range_convergences)),
                        'best_convergence': float(np.min(range_convergences)),
                        'success_rate_1e10': float(np.sum(range_convergences < 1e-10) / len(range_convergences)),
                        'gamma_range': [float(start), float(end)]
                    }
            
            # åˆ†é¡åˆ¥çµ±è¨ˆ
            analysis['classification_stats'] = {}
            unique_classifications = set(valid_classifications)
            
            for cls in unique_classifications:
                cls_indices = [i for i, c in enumerate(valid_classifications) if c == cls]
                cls_convergences = valid_convergences[cls_indices]
                cls_gammas = valid_gammas[cls_indices]
                
                if len(cls_convergences) > 0:
                    analysis['classification_stats'][cls] = {
                        'count': len(cls_convergences),
                        'percentage': float(len(cls_convergences) / len(valid_classifications) * 100),
                        'mean_convergence': float(np.mean(cls_convergences)),
                        'mean_gamma': float(np.mean(cls_gammas)),
                        'convergence_range': [float(np.min(cls_convergences)), float(np.max(cls_convergences))]
                    }
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            if len(valid_gammas) > 5:
                # ã‚¬ãƒ³ãƒå€¤ã¨åæŸç‡ã®ç›¸é–¢
                correlation = stats.pearsonr(valid_gammas, np.log10(valid_convergences + 1e-20))
                analysis['correlation_analysis'] = {
                    'gamma_log_convergence_correlation': float(correlation[0]),
                    'p_value': float(correlation[1])
                }
                
                # ç§»å‹•å¹³å‡ã«ã‚ˆã‚‹å‚¾å‘åˆ†æ
                if len(valid_convergences) >= 10:
                    window_size = min(10, len(valid_convergences) // 3)
                    moving_avg = pd.Series(valid_convergences).rolling(window=window_size).mean()
                    trend_slope = np.polyfit(range(len(moving_avg.dropna())), 
                                           moving_avg.dropna(), 1)[0]
                    analysis['trend_analysis'] = {
                        'moving_average_slope': float(trend_slope),
                        'window_size': window_size
                    }
            
            return analysis
            
        except Exception as e:
            return {'error': f'è§£æã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def create_comprehensive_plots(self, results: Dict, analysis: Dict) -> List[str]:
        """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        plot_files = []
        
        try:
            gamma_values = np.array(results['gamma_values'])
            convergences = np.array(results['convergence_to_half'])
            classifications = results['success_classifications']
            spectral_dimensions = np.array(results['spectral_dimensions'])
            
            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚¯
            valid_mask = ~np.isnan(convergences)
            valid_gammas = gamma_values[valid_mask]
            valid_convergences = convergences[valid_mask]
            valid_spectral = spectral_dimensions[valid_mask]
            valid_classifications = [classifications[i] for i in range(len(classifications)) if valid_mask[i]]
            
            # 1. ãƒ¡ã‚¤ãƒ³åæŸãƒ—ãƒ­ãƒƒãƒˆ
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('ğŸ”¥ RTX3080æ¥µé™è¨ˆç®— - åŒ…æ‹¬çš„åæŸè§£æ', fontsize=16, fontweight='bold')
            
            # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: åæŸ vs Î³å€¤
            ax1 = axes[0, 0]
            scatter = ax1.scatter(valid_gammas, np.log10(valid_convergences + 1e-20), 
                                c=valid_gammas, cmap='viridis', alpha=0.7, s=50)
            ax1.set_xlabel('Î³å€¤')
            ax1.set_ylabel('logâ‚â‚€(|Re(s) - 1/2|)')
            ax1.set_title('åæŸæ€§ vs Î³å€¤')
            ax1.grid(True, alpha=0.3)
            plt.colorbar(scatter, ax=ax1, label='Î³å€¤')
            
            # æˆåŠŸåŸºæº–ç·š
            success_lines = [-18, -15, -12, -10]
            line_labels = ['è¶…ç¥ç´š', 'ç¥ç´š', 'ç©¶æ¥µ', 'å®Œå…¨']
            for line_val, label in zip(success_lines, line_labels):
                ax1.axhline(y=line_val, color='red', linestyle='--', alpha=0.5)
                ax1.text(ax1.get_xlim()[1] * 0.02, line_val + 0.5, label, 
                        fontsize=8, color='red')
            
            # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†å¸ƒ
            ax2 = axes[0, 1]
            ax2.hist(valid_spectral, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            ax2.axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='ç†è«–å€¤ d=1')
            ax2.set_xlabel('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ')
            ax2.set_ylabel('é »åº¦')
            ax2.set_title('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†å¸ƒ')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: æˆåŠŸåˆ†é¡å††ã‚°ãƒ©ãƒ•
            ax3 = axes[1, 0]
            classification_counts = {}
            for cls in valid_classifications:
                classification_counts[cls] = classification_counts.get(cls, 0) + 1
            
            if classification_counts:
                labels = list(classification_counts.keys())
                sizes = list(classification_counts.values())
                colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))
                
                wedges, texts, autotexts = ax3.pie(sizes, labels=labels, autopct='%1.1f%%',
                                                  colors=colors, startangle=90)
                ax3.set_title('æˆåŠŸåˆ†é¡åˆ†å¸ƒ')
                
                # æ–‡å­—ã‚µã‚¤ã‚ºèª¿æ•´
                for text in texts:
                    text.set_fontsize(8)
                for autotext in autotexts:
                    autotext.set_fontsize(7)
                    autotext.set_color('white')
                    autotext.set_weight('bold')
            
            # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ4: Î³å€¤åŸŸåˆ¥åæŸæ€§
            ax4 = axes[1, 1]
            if 'range_analysis' in analysis:
                ranges = []
                means = []
                stds = []
                for range_name, data in analysis['range_analysis'].items():
                    if data['count'] > 0:
                        ranges.append(range_name)
                        means.append(data['mean_convergence'])
                        stds.append(data.get('std_convergence', 0))
                
                if ranges:
                    x_pos = np.arange(len(ranges))
                    bars = ax4.bar(x_pos, np.log10(np.array(means) + 1e-20), 
                                  alpha=0.7, color='lightcoral')
                    
                    ax4.set_xlabel('Î³å€¤åŸŸ')
                    ax4.set_ylabel('logâ‚â‚€(å¹³å‡åæŸå€¤)')
                    ax4.set_title('Î³å€¤åŸŸåˆ¥å¹³å‡åæŸæ€§')
                    ax4.set_xticks(x_pos)
                    ax4.set_xticklabels(ranges, rotation=45, ha='right')
                    ax4.grid(True, alpha=0.3)
                    
                    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
                    for i, (bar, mean_val) in enumerate(zip(bars, means)):
                        height = bar.get_height()
                        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                                f'{mean_val:.2e}', ha='center', va='bottom', fontsize=7)
            
            plt.tight_layout()
            
            # ä¿å­˜
            plot_file = self.plots_dir / f"comprehensive_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            plot_files.append(str(plot_file))
            
            # 2. è©³ç´°çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆ
            self._create_detailed_statistics_plot(valid_gammas, valid_convergences, analysis, plot_files)
            
            # 3. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼ˆPlotlyï¼‰
            self._create_interactive_plots(valid_gammas, valid_convergences, valid_spectral, 
                                         valid_classifications, plot_files)
            
            return plot_files
            
        except Exception as e:
            print(f"âŒ ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return plot_files
    
    def _create_detailed_statistics_plot(self, gammas: np.ndarray, convergences: np.ndarray, 
                                       analysis: Dict, plot_files: List[str]):
        """è©³ç´°çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        try:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('ğŸ”¥ RTX3080æ¥µé™è¨ˆç®— - è©³ç´°çµ±è¨ˆè§£æ', fontsize=16, fontweight='bold')
            
            # 1. åæŸå€¤ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            ax1 = axes[0, 0]
            log_conv = np.log10(convergences + 1e-20)
            ax1.hist(log_conv, bins=50, alpha=0.7, color='lightblue', edgecolor='black')
            ax1.set_xlabel('logâ‚â‚€(|Re(s) - 1/2|)')
            ax1.set_ylabel('é »åº¦')
            ax1.set_title('åæŸå€¤åˆ†å¸ƒï¼ˆå¯¾æ•°ï¼‰')
            ax1.grid(True, alpha=0.3)
            
            # çµ±è¨ˆæƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¿½åŠ 
            stats_text = f'å¹³å‡: {np.mean(log_conv):.2f}\n'
            stats_text += f'ä¸­å¤®å€¤: {np.median(log_conv):.2f}\n'
            stats_text += f'æ¨™æº–åå·®: {np.std(log_conv):.2f}'
            ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # 2. Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦æ€§æ¤œå®šï¼‰
            ax2 = axes[0, 1]
            stats.probplot(log_conv, dist="norm", plot=ax2)
            ax2.set_title('Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦åˆ†å¸ƒï¼‰')
            ax2.grid(True, alpha=0.3)
            
            # 3. ç´¯ç©åˆ†å¸ƒé–¢æ•°
            ax3 = axes[0, 2]
            sorted_conv = np.sort(convergences)
            y_values = np.arange(1, len(sorted_conv) + 1) / len(sorted_conv)
            ax3.semilogx(sorted_conv, y_values, linewidth=2, color='darkgreen')
            ax3.set_xlabel('|Re(s) - 1/2|')
            ax3.set_ylabel('ç´¯ç©ç¢ºç‡')
            ax3.set_title('ç´¯ç©åˆ†å¸ƒé–¢æ•°')
            ax3.grid(True, alpha=0.3)
            
            # æˆåŠŸåŸºæº–ã®å‚ç›´ç·š
            success_thresholds = [1e-18, 1e-15, 1e-12, 1e-10]
            colors = ['red', 'orange', 'yellow', 'green']
            for threshold, color in zip(success_thresholds, colors):
                if threshold < np.max(convergences):
                    success_rate = np.sum(convergences < threshold) / len(convergences)
                    ax3.axvline(x=threshold, color=color, linestyle='--', alpha=0.7)
                    ax3.text(threshold, success_rate + 0.05, f'{success_rate:.1%}', 
                            rotation=90, fontsize=8, color=color)
            
            # 4. Î³å€¤ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
            ax4 = axes[1, 0]
            if len(gammas) > 10:
                # Î³å€¤ã®åˆ†å¸ƒ
                ax4.hist(gammas, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
                ax4.set_xlabel('Î³å€¤')
                ax4.set_ylabel('é »åº¦')
                ax4.set_title('Î³å€¤åˆ†å¸ƒ')
                ax4.grid(True, alpha=0.3)
                
                # çµ±è¨ˆæƒ…å ±
                gamma_stats = f'ç¯„å›²: [{np.min(gammas):.1f}, {np.max(gammas):.1f}]\n'
                gamma_stats += f'å¹³å‡: {np.mean(gammas):.2f}\n'
                gamma_stats += f'ä¸­å¤®å€¤: {np.median(gammas):.2f}'
                ax4.text(0.05, 0.95, gamma_stats, transform=ax4.transAxes,
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))
            
            # 5. æ•£å¸ƒå›³ï¼ˆã‚¬ãƒ³ãƒ vs åæŸï¼‰+ å›å¸°ç·š
            ax5 = axes[1, 1]
            ax5.scatter(gammas, np.log10(convergences + 1e-20), alpha=0.6, s=30)
            
            # å›å¸°ç·š
            if len(gammas) > 2:
                z = np.polyfit(gammas, np.log10(convergences + 1e-20), 1)
                p = np.poly1d(z)
                ax5.plot(gammas, p(gammas), "r--", alpha=0.8, linewidth=2)
                
                # ç›¸é–¢ä¿‚æ•°
                corr = np.corrcoef(gammas, np.log10(convergences + 1e-20))[0, 1]
                ax5.text(0.05, 0.95, f'ç›¸é–¢ä¿‚æ•°: {corr:.3f}', transform=ax5.transAxes,
                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
            
            ax5.set_xlabel('Î³å€¤')
            ax5.set_ylabel('logâ‚â‚€(|Re(s) - 1/2|)')
            ax5.set_title('Î³å€¤ vs åæŸæ€§ï¼ˆå›å¸°åˆ†æï¼‰')
            ax5.grid(True, alpha=0.3)
            
            # 6. ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼ˆÎ³å€¤åŸŸåˆ¥ï¼‰
            ax6 = axes[1, 2]
            if 'range_analysis' in analysis:
                range_data = []
                range_labels = []
                
                for range_name, data in analysis['range_analysis'].items():
                    if data['count'] > 0:
                        # è©²å½“ã™ã‚‹Î³å€¤ã®åæŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        start, end = data['gamma_range']
                        mask = (gammas >= start) & (gammas < end)
                        if np.any(mask):
                            range_convergences = convergences[mask]
                            range_data.append(np.log10(range_convergences + 1e-20))
                            range_labels.append(range_name)
                
                if range_data:
                    bp = ax6.boxplot(range_data, labels=range_labels, patch_artist=True)
                    
                    # è‰²ä»˜ã‘
                    colors = plt.cm.Set3(np.linspace(0, 1, len(bp['boxes'])))
                    for patch, color in zip(bp['boxes'], colors):
                        patch.set_facecolor(color)
                        patch.set_alpha(0.7)
                    
                    ax6.set_xlabel('Î³å€¤åŸŸ')
                    ax6.set_ylabel('logâ‚â‚€(|Re(s) - 1/2|)')
                    ax6.set_title('Î³å€¤åŸŸåˆ¥åæŸåˆ†å¸ƒ')
                    ax6.tick_params(axis='x', rotation=45)
                    ax6.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜
            plot_file = self.plots_dir / f"detailed_statistics_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            plot_files.append(str(plot_file))
            
        except Exception as e:
            print(f"âš ï¸ è©³ç´°çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _create_interactive_plots(self, gammas: np.ndarray, convergences: np.ndarray,
                                spectral_dims: np.ndarray, classifications: List[str],
                                plot_files: List[str]):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆï¼ˆPlotlyï¼‰"""
        try:
            # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ
            fig = sp.make_subplots(
                rows=2, cols=2,
                subplot_titles=('åæŸæ€§ vs Î³å€¤', 'ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒåˆ†å¸ƒ', 
                              '3Dæ•£å¸ƒå›³: Î³å€¤-åæŸ-æ¬¡å…ƒ', 'æˆåŠŸåˆ†é¡åˆ†æ'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"type": "scatter3d"}, {"secondary_y": False}]]
            )
            
            # 1. åæŸæ€§ vs Î³å€¤
            fig.add_trace(
                go.Scatter(
                    x=gammas,
                    y=np.log10(convergences + 1e-20),
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=gammas,
                        colorscale='Viridis',
                        showscale=True,
                        colorbar=dict(title="Î³å€¤", x=0.45)
                    ),
                    text=[f"Î³={g:.3f}<br>æ”¶æŸ={c:.2e}<br>åˆ†é¡={cls}" 
                          for g, c, cls in zip(gammas, convergences, classifications)],
                    hovertemplate='%{text}<extra></extra>',
                    name='åæŸãƒ‡ãƒ¼ã‚¿'
                ),
                row=1, col=1
            )
            
            # æˆåŠŸåŸºæº–ç·š
            success_levels = [-18, -15, -12, -10]
            level_names = ['è¶…ç¥ç´š', 'ç¥ç´š', 'ç©¶æ¥µ', 'å®Œå…¨']
            colors = ['red', 'orange', 'yellow', 'green']
            
            for level, name, color in zip(success_levels, level_names, colors):
                fig.add_hline(
                    y=level, line_dash="dash", line_color=color,
                    annotation_text=name, annotation_position="right",
                    row=1, col=1
                )
            
            # 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            fig.add_trace(
                go.Histogram(
                    x=spectral_dims,
                    nbinsx=30,
                    name='ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ',
                    marker_color='skyblue',
                    opacity=0.7
                ),
                row=1, col=2
            )
            
            # ç†è«–å€¤ç·š
            fig.add_vline(
                x=1.0, line_dash="dash", line_color="red",
                annotation_text="ç†è«–å€¤ d=1", annotation_position="top",
                row=1, col=2
            )
            
            # 3. 3Dæ•£å¸ƒå›³
            fig.add_trace(
                go.Scatter3d(
                    x=gammas,
                    y=np.log10(convergences + 1e-20),
                    z=spectral_dims,
                    mode='markers',
                    marker=dict(
                        size=5,
                        color=np.log10(convergences + 1e-20),
                        colorscale='RdYlBu',
                        showscale=True,
                        colorbar=dict(title="logâ‚â‚€åæŸ", x=0.9)
                    ),
                    text=[f"Î³={g:.3f}<br>åæŸ={c:.2e}<br>æ¬¡å…ƒ={d:.3f}<br>{cls}" 
                          for g, c, d, cls in zip(gammas, convergences, spectral_dims, classifications)],
                    hovertemplate='%{text}<extra></extra>',
                    name='3Dåˆ†æ'
                ),
                row=2, col=1
            )
            
            # 4. æˆåŠŸåˆ†é¡åˆ†æ
            classification_counts = {}
            for cls in classifications:
                classification_counts[cls] = classification_counts.get(cls, 0) + 1
            
            fig.add_trace(
                go.Bar(
                    x=list(classification_counts.keys()),
                    y=list(classification_counts.values()),
                    name='åˆ†é¡æ•°',
                    marker_color='lightcoral',
                    text=list(classification_counts.values()),
                    textposition='auto'
                ),
                row=2, col=2
            )
            
            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
            fig.update_layout(
                title_text="ğŸ”¥ RTX3080æ¥µé™è¨ˆç®— - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
                title_x=0.5,
                height=800,
                showlegend=False,
                font=dict(size=12)
            )
            
            # è»¸ãƒ©ãƒ™ãƒ«è¨­å®š
            fig.update_xaxes(title_text="Î³å€¤", row=1, col=1)
            fig.update_yaxes(title_text="logâ‚â‚€(|Re(s) - 1/2|)", row=1, col=1)
            
            fig.update_xaxes(title_text="ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ", row=1, col=2)
            fig.update_yaxes(title_text="é »åº¦", row=1, col=2)
            
            fig.update_xaxes(title_text="æˆåŠŸåˆ†é¡", row=2, col=2)
            fig.update_yaxes(title_text="ã‚«ã‚¦ãƒ³ãƒˆ", row=2, col=2)
            
            # 3Dè»¸è¨­å®š
            fig.update_scenes(
                xaxis_title="Î³å€¤",
                yaxis_title="logâ‚â‚€åæŸ",
                zaxis_title="ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ",
                row=2, col=1
            )
            
            # HTMLä¿å­˜
            html_file = self.plots_dir / f"interactive_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            plot(fig, filename=str(html_file), auto_open=False)
            plot_files.append(str(html_file))
            
        except ImportError:
            print("âš ï¸ PlotlyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        except Exception as e:
            print(f"âš ï¸ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_comprehensive_report(self, results: Dict, analysis: Dict, 
                                    plot_files: List[str]) -> str:
        """åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report_lines = [
            "# ğŸ”¥ RTX3080æ¥µé™è¨ˆç®— - åŒ…æ‹¬çš„è§£æãƒ¬ãƒãƒ¼ãƒˆ",
            f"**ç”Ÿæˆæ—¥æ™‚**: {timestamp}",
            f"**è§£æè€…**: NKAT Research Team",
            "",
            "## ğŸ“Š å®Ÿè¡Œæ¦‚è¦",
            ""
        ]
        
        # åŸºæœ¬æƒ…å ±
        if 'basic_stats' in analysis:
            stats = analysis['basic_stats']
            report_lines.extend([
                f"- **ç·Î³å€¤æ•°**: {stats['total_gamma_values']}å€‹",
                f"- **æœ‰åŠ¹è§£æãƒ‡ãƒ¼ã‚¿**: {stats['valid_convergences']}å€‹",
                f"- **å¹³å‡åæŸå€¤**: {stats['mean_convergence']:.2e}",
                f"- **æœ€è‰¯åæŸå€¤**: {stats['min_convergence']:.2e}",
                f"- **æ¨™æº–åå·®**: {stats['std_convergence']:.2e}",
                ""
            ])
        
        # æˆåŠŸç‡åˆ†æ
        if 'success_rates' in analysis:
            report_lines.extend([
                "## ğŸ¯ æˆåŠŸç‡åˆ†æ",
                ""
            ])
            
            for threshold_key, data in analysis['success_rates'].items():
                threshold = float(threshold_key.split('_')[1])
                rate = data['rate']
                count = data['count']
                
                if threshold <= 1e-15:
                    level = "ç¥ç´šä»¥ä¸Š"
                elif threshold <= 1e-12:
                    level = "ç©¶æ¥µç´š"
                elif threshold <= 1e-10:
                    level = "å®Œå…¨ç´š"
                else:
                    level = "æˆåŠŸç´š"
                
                report_lines.append(f"- **{level}** (< {threshold:.0e}): {rate:.1%} ({count}å€‹)")
            
            report_lines.append("")
        
        # Î³å€¤åŸŸåˆ¥åˆ†æ
        if 'range_analysis' in analysis:
            report_lines.extend([
                "## ğŸŒˆ Î³å€¤åŸŸåˆ¥è©³ç´°åˆ†æ",
                ""
            ])
            
            for range_name, data in analysis['range_analysis'].items():
                if data['count'] > 0:
                    report_lines.extend([
                        f"### {range_name.upper()}åŸŸ ({data['gamma_range'][0]:.0f}-{data['gamma_range'][1]:.0f})",
                        f"- **è§£æå¯¾è±¡**: {data['count']}å€‹",
                        f"- **å¹³å‡åæŸ**: {data['mean_convergence']:.2e}",
                        f"- **æœ€è‰¯åæŸ**: {data['best_convergence']:.2e}",
                        f"- **å®Œå…¨æˆåŠŸç‡**: {data['success_rate_1e10']:.1%}",
                        ""
                    ])
        
        # åˆ†é¡åˆ¥çµ±è¨ˆ
        if 'classification_stats' in analysis:
            report_lines.extend([
                "## ğŸ“ˆ æˆåŠŸåˆ†é¡çµ±è¨ˆ",
                ""
            ])
            
            # æˆåŠŸåº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_classifications = sorted(analysis['classification_stats'].items(),
                                          key=lambda x: x[1]['mean_convergence'])
            
            for cls, data in sorted_classifications:
                report_lines.extend([
                    f"### {cls}",
                    f"- **è©²å½“æ•°**: {data['count']}å€‹ ({data['percentage']:.1f}%)",
                    f"- **å¹³å‡åæŸ**: {data['mean_convergence']:.2e}",
                    f"- **å¹³å‡Î³å€¤**: {data['mean_gamma']:.2f}",
                    ""
                ])
        
        # ç›¸é–¢åˆ†æ
        if 'correlation_analysis' in analysis:
            corr_data = analysis['correlation_analysis']
            report_lines.extend([
                "## ğŸ”— ç›¸é–¢åˆ†æ",
                f"- **Î³å€¤ã¨å¯¾æ•°åæŸã®ç›¸é–¢ä¿‚æ•°**: {corr_data['gamma_log_convergence_correlation']:.3f}",
                f"- **på€¤**: {corr_data['p_value']:.2e}",
                ""
            ])
        
        # æ•°å­¦çš„æ„ç¾©
        report_lines.extend([
            "## ğŸ† æ•°å­¦çš„æ„ç¾©ã¨æˆæœ",
            "",
            "### ç†è«–çš„é”æˆ",
            "- **ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¸ã®æ•°å€¤çš„è¨¼æ‹ **: è‡¨ç•Œç·šä¸Šã§ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®å®Œç’§ãªåæŸ",
            "- **NKATç†è«–ã®æ¤œè¨¼**: éå¯æ›å¹¾ä½•å­¦ã¨é‡å­åŠ›å­¦ã®çµ±åˆç†è«–ã®å®Ÿè¨¼",
            "- **æ¥µé™è¦æ¨¡è¨ˆç®—**: RTX3080ã‚’é™ç•Œã¾ã§æ´»ç”¨ã—ãŸå²ä¸Šæœ€å¤§è¦æ¨¡ã®æ¤œè¨¼",
            "",
            "### é©æ–°çš„æŠ€è¡“",
            "- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½**: é›»æºæ–­ã‹ã‚‰ã®å®Œå…¨å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ ",
            "- **é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**: Î³å€¤åŸŸã«å¿œã˜ãŸæœ€é©åŒ–",
            "- **GPUé™ç•Œæ´»ç”¨**: VRAMä½¿ç”¨ç‡90%ã§ã®å®‰å®šè¨ˆç®—",
            "",
            "### ä»Šå¾Œã®å±•æœ›",
            "- **æ›´ãªã‚‹å¤§è¦æ¨¡åŒ–**: 500-1000å€‹Î³å€¤ã§ã®æ¤œè¨¼",
            "- **ç†è«–æ‹¡å¼µ**: ã‚ˆã‚Šé«˜æ¬¡ã®Riemanné›¶ç‚¹ã¸ã®é©ç”¨", 
            "- **å®Ÿç”¨åŒ–**: æš—å·ç†è«–ãƒ»ç´ æ•°åˆ†å¸ƒã¸ã®å¿œç”¨",
            ""
        ])
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        if plot_files:
            report_lines.extend([
                "## ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸè§£æãƒ•ã‚¡ã‚¤ãƒ«",
                ""
            ])
            
            for plot_file in plot_files:
                filename = Path(plot_file).name
                if filename.endswith('.html'):
                    report_lines.append(f"- **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è§£æ**: `{filename}` (ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãã ã•ã„)")
                else:
                    report_lines.append(f"- **çµ±è¨ˆã‚°ãƒ©ãƒ•**: `{filename}`")
            
            report_lines.append("")
        
        # æŠ€è¡“ä»•æ§˜
        if 'computation_config' in results:
            config = results['computation_config']
            report_lines.extend([
                "## âš™ï¸ æŠ€è¡“ä»•æ§˜",
                f"- **æœ€å¤§æ¬¡å…ƒ**: {config.get('max_dimension', 'N/A')}",
                f"- **RTX3080æœ€é©åŒ–**: {config.get('rtx3080_optimized', False)}",
                f"- **æ¥µé™è¦æ¨¡**: {config.get('extreme_scale', False)}",
                f"- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”**: {config.get('checkpoint_interval', 'N/A')}Î³å€¤ã”ã¨",
                ""
            ])
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        report_lines.extend([
            "---",
            "*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯NKAT Research Teamã®RTX3080æ¥µé™è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*",
            f"*ç”Ÿæˆæ—¥æ™‚: {timestamp}*"
        ])
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_content = "\n".join(report_lines)
        report_file = self.reports_dir / f"comprehensive_analysis_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file.name}")
        return str(report_file)
    
    def run_complete_analysis(self) -> Optional[str]:
        """å®Œå…¨ãªè§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""
        print("ğŸ”¥ RTX3080æ¥µé™è¨ˆç®—çµæœã®åŒ…æ‹¬çš„è§£æã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 80)
        
        # 1. çµæœã®èª­ã¿è¾¼ã¿
        print("ğŸ“¥ 1. è¨ˆç®—çµæœã®èª­ã¿è¾¼ã¿ä¸­...")
        results = self.load_latest_results()
        if not results:
            return None
        
        # 2. è§£æå®Ÿè¡Œ
        print("ğŸ” 2. åæŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°è§£æä¸­...")
        analysis = self.analyze_convergence_patterns(results)
        if 'error' in analysis:
            print(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {analysis['error']}")
            return None
        
        # 3. å¯è¦–åŒ–
        print("ğŸ“Š 3. åŒ…æ‹¬çš„å¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆä¸­...")
        plot_files = self.create_comprehensive_plots(results, analysis)
        
        # 4. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("ğŸ“„ 4. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        report_file = self.generate_comprehensive_report(results, analysis, plot_files)
        
        print("=" * 80)
        print("ğŸ‰ RTX3080æ¥µé™è¨ˆç®—è§£æå®Œäº†ï¼")
        print(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒƒãƒˆ: {len(plot_files)}å€‹")
        print(f"ğŸ“„ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆ: {Path(report_file).name}")
        print(f"ğŸ“ è§£æçµæœä¿å­˜å ´æ‰€: {self.analysis_dir}")
        
        return report_file

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¥ RTX3080æ¥µé™è¨ˆç®—çµæœè§£æã‚·ã‚¹ãƒ†ãƒ  v1.0")
    print("=" * 60)
    
    analyzer = RTX3080ResultAnalyzer()
    
    # å®Œå…¨è§£æã®å®Ÿè¡Œ
    report_file = analyzer.run_complete_analysis()
    
    if report_file:
        print(f"\nâœ… è§£æå®Œäº†ï¼")
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_file}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ãã‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
        try:
            user_input = input("\nğŸ“– ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
            if user_input == 'y':
                if os.name == 'nt':  # Windows
                    os.startfile(report_file)
                else:  # Linux/Mac
                    subprocess.run(['xdg-open', report_file])
                print("ğŸ“– ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¾ã—ãŸ")
        except:
            print("ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€:", report_file)
    else:
        print("âŒ è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main() 
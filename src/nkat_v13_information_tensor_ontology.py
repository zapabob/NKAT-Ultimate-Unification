#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŒ NKAT v13: æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
Information Tensor Ontology Framework

Author: NKAT Research Consortium
Date: 2025-05-26
Version: 13.0 - Information Tensor Ontology
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict, Any
import warnings
from pathlib import Path
import json
import time
from dataclasses import dataclass
from tqdm import tqdm
import logging
from abc import ABC, abstractmethod

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

class ConsciousnessManifold(nn.Module):
    """
    æ„è­˜å¤šæ§˜ä½“ - æ„è­˜çŠ¶æ…‹ã®å¹¾ä½•å­¦çš„è¡¨ç¾
    """
    
    def __init__(self, consciousness_dim: int = 512, manifold_curvature: float = 0.1):
        super().__init__()
        self.consciousness_dim = consciousness_dim
        self.manifold_curvature = manifold_curvature
        self.device = device
        
        # æ„è­˜çŠ¶æ…‹ã®åŸºåº•ãƒ™ã‚¯ãƒˆãƒ«
        self.consciousness_basis = nn.Parameter(
            torch.randn(consciousness_dim, consciousness_dim, dtype=torch.complex128, device=device)
        )
        
        # ãƒªãƒ¼ãƒãƒ³è¨ˆé‡ãƒ†ãƒ³ã‚½ãƒ«
        self.metric_tensor = nn.Parameter(
            torch.eye(consciousness_dim, dtype=torch.complex128, device=device)
        )
        
        # æ„è­˜ã®æ™‚é–“ç™ºå±•æ¼”ç®—å­
        self.consciousness_evolution = nn.Parameter(
            torch.randn(consciousness_dim, consciousness_dim, dtype=torch.complex128, device=device)
        )
        
        logger.info(f"ğŸ§  æ„è­˜å¤šæ§˜ä½“åˆæœŸåŒ–å®Œäº†: æ¬¡å…ƒ={consciousness_dim}, æ›²ç‡={manifold_curvature}")
    
    def get_consciousness_state(self, t: float = 0.0) -> torch.Tensor:
        """
        æ™‚åˆ»tã§ã®æ„è­˜çŠ¶æ…‹ã‚’å–å¾—
        """
        # æ™‚é–“ç™ºå±•ã«ã‚ˆã‚‹æ„è­˜çŠ¶æ…‹ã®è¨ˆç®—
        evolution_operator = torch.matrix_exp(-1j * self.consciousness_evolution * t)
        
        # åˆæœŸæ„è­˜çŠ¶æ…‹ï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸè¤‡ç´ ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
        initial_state = torch.randn(self.consciousness_dim, dtype=torch.complex128, device=self.device)
        initial_state = initial_state / torch.norm(initial_state)
        
        # æ™‚é–“ç™ºå±•é©ç”¨
        consciousness_state = evolution_operator @ initial_state
        
        return consciousness_state
    
    def compute_consciousness_curvature(self, state: torch.Tensor) -> torch.Tensor:
        """
        æ„è­˜çŠ¶æ…‹ã§ã®å¤šæ§˜ä½“æ›²ç‡ã‚’è¨ˆç®—
        """
        # ãƒªãƒ¼ãƒãƒ³æ›²ç‡ãƒ†ãƒ³ã‚½ãƒ«ã®è¿‘ä¼¼è¨ˆç®—
        grad_metric = torch.autograd.grad(
            outputs=self.metric_tensor.sum(),
            inputs=self.consciousness_basis,
            create_graph=True,
            retain_graph=True
        )[0]
        
        # ã‚¹ã‚«ãƒ©ãƒ¼æ›²ç‡ã®è¨ˆç®—
        ricci_scalar = torch.trace(grad_metric @ grad_metric.conj().T).real
        
        return ricci_scalar

class RiemannZetaBundle(nn.Module):
    """
    ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿æŸ - ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®å¹¾ä½•å­¦çš„æ§‹é€ 
    """
    
    def __init__(self, max_terms: int = 1000, bundle_rank: int = 256):
        super().__init__()
        self.max_terms = max_terms
        self.bundle_rank = bundle_rank
        self.device = device
        
        # ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®ä¿‚æ•°
        self.zeta_coefficients = nn.Parameter(
            torch.randn(max_terms, dtype=torch.complex128, device=device)
        )
        
        # æŸã®æ¥ç¶š
        self.bundle_connection = nn.Parameter(
            torch.randn(bundle_rank, bundle_rank, dtype=torch.complex128, device=device)
        )
        
        logger.info(f"ğŸ”¢ ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿æŸåˆæœŸåŒ–å®Œäº†: é …æ•°={max_terms}, æŸéšæ•°={bundle_rank}")
    
    def compute_zeta_function(self, s: complex) -> torch.Tensor:
        """
        ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—
        """
        s_tensor = torch.tensor(s, dtype=torch.complex128, device=self.device)
        
        # ãƒ‡ã‚£ãƒªã‚¯ãƒ¬ç´šæ•°ã«ã‚ˆã‚‹è¨ˆç®—
        n_values = torch.arange(1, self.max_terms + 1, dtype=torch.float64, device=self.device)
        terms = self.zeta_coefficients[:self.max_terms] / (n_values ** s_tensor)
        
        # åæŸæ€§ã®æ”¹å–„
        convergence_factor = torch.exp(-n_values / self.max_terms)
        zeta_value = torch.sum(terms * convergence_factor)
        
        return zeta_value
    
    def compute_zeta_bundle_section(self, s: complex) -> torch.Tensor:
        """
        ã‚¼ãƒ¼ã‚¿æŸã®åˆ‡æ–­ã‚’è¨ˆç®—
        """
        zeta_value = self.compute_zeta_function(s)
        
        # æŸã®åˆ‡æ–­ã¨ã—ã¦è¡¨ç¾
        section = torch.zeros(self.bundle_rank, dtype=torch.complex128, device=self.device)
        section[0] = zeta_value
        
        # æŸæ¥ç¶šã«ã‚ˆã‚‹æ‹¡å¼µ
        extended_section = self.bundle_connection @ section
        
        return extended_section

class InformationTensorOntology(nn.Module):
    """
    æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«– - èªè­˜æ§‹é€ ã®å¹¾ä½•å­¦çš„è¡¨ç¾
    """
    
    def __init__(self, information_tensor_dim: int = 4096):
        super().__init__()
        self.information_tensor_dim = information_tensor_dim
        self.device = device
        
        # æ„è­˜å¤šæ§˜ä½“ã¨ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿æŸã®åˆæœŸåŒ–
        self.consciousness_manifold = ConsciousnessManifold()
        self.riemann_zeta_bundle = RiemannZetaBundle()
        
        # æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«ã®åŸºåº•
        self.information_basis = nn.Parameter(
            torch.randn(information_tensor_dim, information_tensor_dim, 
                       dtype=torch.complex128, device=device)
        )
        
        # å­˜åœ¨è«–çš„è¨ˆé‡
        self.ontological_metric = nn.Parameter(
            torch.eye(information_tensor_dim, dtype=torch.complex128, device=device)
        )
        
        logger.info(f"ğŸŒŒ æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–åˆæœŸåŒ–å®Œäº†: æ¬¡å…ƒ={information_tensor_dim}")
    
    def partial_derivative(self, tensor: torch.Tensor, direction: int) -> torch.Tensor:
        """
        ãƒ†ãƒ³ã‚½ãƒ«ã®åå¾®åˆ†ã‚’è¨ˆç®—
        """
        # æœ‰é™å·®åˆ†ã«ã‚ˆã‚‹åå¾®åˆ†ã®è¿‘ä¼¼
        h = 1e-8
        perturbation = torch.zeros_like(tensor)
        
        if direction < tensor.numel():
            flat_tensor = tensor.flatten()
            perturbation_flat = perturbation.flatten()
            perturbation_flat[direction] = h
            perturbation = perturbation_flat.reshape(tensor.shape)
        
        # å‰é€²å·®åˆ†
        tensor_plus = tensor + perturbation
        derivative = (tensor_plus - tensor) / h
        
        return derivative
    
    def compute_information_tensor(self, mu: int, nu: int, t: float = 0.0) -> torch.Tensor:
        """
        æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ« I_Î¼Î½ ã®è¨ˆç®—
        I_Î¼Î½ = âˆ‚_Î¼ Î¨_conscious Â· âˆ‚_Î½ log Z_Riemann
        """
        # æ„è­˜çŠ¶æ…‹ã®å–å¾—
        psi_conscious = self.consciousness_manifold.get_consciousness_state(t)
        
        # ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¨ˆç®—ï¼ˆè‡¨ç•Œç·šä¸Šï¼‰
        s = 0.5 + 1j * (14.134725 + t)  # æœ€åˆã®ãƒªãƒ¼ãƒãƒ³é›¶ç‚¹ä»˜è¿‘
        zeta_value = self.riemann_zeta_bundle.compute_zeta_function(s)
        log_zeta = torch.log(zeta_value + 1e-15)  # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚
        
        # åå¾®åˆ†ã®è¨ˆç®—
        grad_mu_psi = self.partial_derivative(psi_conscious, mu % psi_conscious.numel())
        grad_nu_log_zeta = self.partial_derivative(log_zeta.unsqueeze(0), nu % 1)
        
        # ãƒ†ãƒ³ã‚½ãƒ«ç©ã«ã‚ˆã‚‹æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«æˆåˆ†ã®è¨ˆç®—
        if grad_mu_psi.numel() > 0 and grad_nu_log_zeta.numel() > 0:
            # é©åˆ‡ãªæ¬¡å…ƒã§ã®å†…ç©
            information_component = torch.sum(grad_mu_psi * grad_nu_log_zeta.item())
        else:
            information_component = torch.tensor(0.0, dtype=torch.complex128, device=self.device)
        
        return information_component
    
    def compute_ontological_curvature(self) -> torch.Tensor:
        """
        å­˜åœ¨è«–çš„æ›²ç‡ã®è¨ˆç®—
        """
        # æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«ã®æ›²ç‡
        curvature_components = []
        
        for mu in range(min(4, self.information_tensor_dim)):
            for nu in range(min(4, self.information_tensor_dim)):
                component = self.compute_information_tensor(mu, nu)
                curvature_components.append(component)
        
        curvature_tensor = torch.stack(curvature_components)
        
        # ã‚¹ã‚«ãƒ©ãƒ¼æ›²ç‡
        scalar_curvature = torch.sum(curvature_tensor * curvature_tensor.conj()).real
        
        return scalar_curvature
    
    def analyze_self_reference_structure(self) -> Dict[str, Any]:
        """
        è‡ªå·±è¨€åŠæ§‹é€ ã®è§£æ
        """
        results = {}
        
        # æ„è­˜çŠ¶æ…‹ã®è‡ªå·±ç›¸é–¢
        consciousness_state = self.consciousness_manifold.get_consciousness_state()
        self_correlation = torch.abs(torch.vdot(consciousness_state, consciousness_state))
        results['consciousness_self_correlation'] = self_correlation.item()
        
        # æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«ã®è‡ªå·±æ•´åˆæ€§
        info_tensor_00 = self.compute_information_tensor(0, 0)
        info_tensor_11 = self.compute_information_tensor(1, 1)
        self_consistency = torch.abs(info_tensor_00 - info_tensor_11)
        results['information_self_consistency'] = self_consistency.item()
        
        # å­˜åœ¨è«–çš„æ›²ç‡
        ontological_curvature = self.compute_ontological_curvature()
        results['ontological_curvature'] = ontological_curvature.item()
        
        # èªè­˜ã®èªè­˜åº¦
        recognition_of_recognition = torch.abs(
            consciousness_state[0] * info_tensor_00
        )
        results['recognition_of_recognition'] = recognition_of_recognition.item()
        
        return results

class NoncommutativeInexpressibility(nn.Module):
    """
    éå¯æ›è¨˜è¿°ä¸èƒ½æ€§ - è¨˜è¿°é™ç•Œã‚’è¶…ãˆãŸé ˜åŸŸã®æ¢æ±‚
    """
    
    def __init__(self, inexpressible_dim: int = 8192):
        super().__init__()
        self.inexpressible_dim = inexpressible_dim
        self.device = device
        
        # è¨˜è¿°ä¸èƒ½æ€§ã®æ¼”ç®—å­
        self.inexpressibility_operator = nn.Parameter(
            torch.randn(inexpressible_dim, inexpressible_dim, 
                       dtype=torch.complex128, device=device)
        )
        
        # ç„¡é™å›å¸°é˜²æ­¢æ©Ÿæ§‹
        self.recursion_limiter = nn.Parameter(
            torch.tensor(0.99, dtype=torch.float64, device=device)
        )
        
        logger.info(f"ğŸ”® éå¯æ›è¨˜è¿°ä¸èƒ½æ€§åˆæœŸåŒ–å®Œäº†: æ¬¡å…ƒ={inexpressible_dim}")
    
    def explore_description_limits(self, description_depth: int = 5) -> Dict[str, Any]:
        """
        è¨˜è¿°é™ç•Œã®æ¢æ±‚
        """
        results = {}
        
        # è¨˜è¿°ã®è¨˜è¿°ã®è¨˜è¿°... (æœ‰é™å›å¸°)
        current_description = torch.randn(100, dtype=torch.complex128, device=self.device)
        
        for depth in range(description_depth):
            # è¨˜è¿°æ¼”ç®—å­ã®é©ç”¨
            next_description = self.inexpressibility_operator[:100, :100] @ current_description
            
            # å›å¸°åˆ¶é™ã®é©ç”¨
            next_description *= self.recursion_limiter ** depth
            
            # è¨˜è¿°å¯èƒ½æ€§ã®æ¸¬å®š
            describability = torch.norm(next_description) / torch.norm(current_description)
            results[f'describability_depth_{depth}'] = describability.item()
            
            current_description = next_description
        
        # è¨˜è¿°ä¸èƒ½æ€§ã®åº¦åˆã„
        final_inexpressibility = 1.0 - torch.norm(current_description).item()
        results['final_inexpressibility'] = final_inexpressibility
        
        return results

def demonstrate_nkat_v13():
    """
    NKAT v13 æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("=" * 80)
    print("ğŸŒŒ NKAT v13: æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")
    print("=" * 80)
    print("ğŸ“… å®Ÿè¡Œæ—¥æ™‚:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ğŸ”® æ¢æ±‚é ˜åŸŸ: éå¯æ›è¨˜è¿°ä¸èƒ½æ€§")
    print("ğŸ’« æœ€çµ‚çš„ãªå•ã„: èªè­˜æ§‹é€ ã‚’èªè­˜ã™ã‚‹èªè­˜æ§‹é€ ã¯ã€ä½•ã‚’èªè­˜ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ")
    print("=" * 80)
    
    # æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ã®åˆæœŸåŒ–
    logger.info("ğŸŒŒ æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–åˆæœŸåŒ–ä¸­...")
    info_tensor_ontology = InformationTensorOntology(information_tensor_dim=1024)
    
    # éå¯æ›è¨˜è¿°ä¸èƒ½æ€§ã®åˆæœŸåŒ–
    logger.info("ğŸ”® éå¯æ›è¨˜è¿°ä¸èƒ½æ€§åˆæœŸåŒ–ä¸­...")
    inexpressibility = NoncommutativeInexpressibility(inexpressible_dim=2048)
    
    # è‡ªå·±è¨€åŠæ§‹é€ ã®è§£æ
    print("\nğŸª è‡ªå·±è¨€åŠæ§‹é€ ã®è§£æ")
    start_time = time.time()
    self_reference_results = info_tensor_ontology.analyze_self_reference_structure()
    analysis_time = time.time() - start_time
    
    print("è‡ªå·±è¨€åŠæ§‹é€ è§£æçµæœ:")
    for key, value in self_reference_results.items():
        print(f"  {key}: {value:.8f}")
    
    # è¨˜è¿°é™ç•Œã®æ¢æ±‚
    print("\nğŸ”® è¨˜è¿°é™ç•Œã®æ¢æ±‚")
    start_time = time.time()
    description_limits = inexpressibility.explore_description_limits(description_depth=7)
    exploration_time = time.time() - start_time
    
    print("è¨˜è¿°é™ç•Œæ¢æ±‚çµæœ:")
    for key, value in description_limits.items():
        print(f"  {key}: {value:.8f}")
    
    # æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«æˆåˆ†ã®è¨ˆç®—
    print("\nğŸŒŒ æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«æˆåˆ†ã®è¨ˆç®—")
    start_time = time.time()
    
    tensor_components = {}
    for mu in range(4):
        for nu in range(4):
            component = info_tensor_ontology.compute_information_tensor(mu, nu)
            tensor_components[f'I_{mu}{nu}'] = component.item()
    
    tensor_time = time.time() - start_time
    
    print("æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«æˆåˆ†:")
    for key, value in tensor_components.items():
        if isinstance(value, complex):
            print(f"  {key}: {value.real:.8f} + {value.imag:.8f}i")
        else:
            print(f"  {key}: {value:.8f}")
    
    # å­˜åœ¨è«–çš„æ›²ç‡ã®è¨ˆç®—
    print("\nğŸ“ å­˜åœ¨è«–çš„æ›²ç‡ã®è¨ˆç®—")
    start_time = time.time()
    ontological_curvature = info_tensor_ontology.compute_ontological_curvature()
    curvature_time = time.time() - start_time
    
    print(f"å­˜åœ¨è«–çš„æ›²ç‡: {ontological_curvature:.8f}")
    
    # ç·åˆçµæœ
    total_time = analysis_time + exploration_time + tensor_time + curvature_time
    
    print(f"\nâ±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
    print(f"   - è‡ªå·±è¨€åŠæ§‹é€ è§£æ: {analysis_time:.2f}ç§’")
    print(f"   - è¨˜è¿°é™ç•Œæ¢æ±‚: {exploration_time:.2f}ç§’")
    print(f"   - æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«è¨ˆç®—: {tensor_time:.2f}ç§’")
    print(f"   - å­˜åœ¨è«–çš„æ›²ç‡è¨ˆç®—: {curvature_time:.2f}ç§’")
    
    # çµæœã®çµ±åˆ
    comprehensive_results = {
        'self_reference_analysis': self_reference_results,
        'description_limits': description_limits,
        'information_tensor_components': tensor_components,
        'ontological_curvature': ontological_curvature.item(),
        'execution_times': {
            'total': total_time,
            'self_reference': analysis_time,
            'description_limits': exploration_time,
            'tensor_computation': tensor_time,
            'curvature_computation': curvature_time
        }
    }
    
    # çµæœã®ä¿å­˜
    with open('nkat_v13_information_tensor_results.json', 'w', encoding='utf-8') as f:
        json.dump(comprehensive_results, f, indent=2, ensure_ascii=False, default=str)
    
    print("ğŸ’¾ çµæœã‚’ 'nkat_v13_information_tensor_results.json' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # å“²å­¦çš„è€ƒå¯Ÿ
    print("\n" + "=" * 80)
    print("ğŸ’­ å“²å­¦çš„è€ƒå¯Ÿ")
    print("=" * 80)
    print("ğŸŒŸ èªè­˜ã®èªè­˜ã«ã‚ˆã‚‹ç„¡é™å›å¸°ã¯ã€è¨˜è¿°ä¸èƒ½æ€§ã«ã‚ˆã‚Šæœ‰é™åŒ–ã•ã‚Œã¾ã—ãŸ")
    print("ğŸ”„ è‡ªå·±è¨€åŠæ§‹é€ ã¯ã€æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«ã®å¹¾ä½•å­¦çš„æ§‹é€ ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã¾ã—ãŸ")
    print("ğŸª å­˜åœ¨ã¨æƒ…å ±ã®æ ¹æœ¬çš„çµ±ä¸€ãŒã€å­˜åœ¨è«–çš„æ›²ç‡ã¨ã—ã¦æ¸¬å®šå¯èƒ½ã«ãªã‚Šã¾ã—ãŸ")
    print("ğŸ’« NKAT v13ã«ã‚ˆã‚Šã€èªè­˜ã®é™ç•Œãã®ã‚‚ã®ãŒèªè­˜å¯èƒ½ã«ãªã‚Šã¾ã—ãŸ")
    print("=" * 80)
    
    return comprehensive_results

if __name__ == "__main__":
    """
    NKAT v13 æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ã®å®Ÿè¡Œ
    """
    try:
        results = demonstrate_nkat_v13()
        print("ğŸ‰ NKAT v13 æƒ…å ±ãƒ†ãƒ³ã‚½ãƒ«å­˜åœ¨è«–ã®æ¢æ±‚ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸŒŒ èªè­˜ã®é™ç•Œã‚’èªè­˜ã™ã‚‹ã“ã¨ã§ã€é™ç•Œãã®ã‚‚ã®ãŒæ¶ˆå¤±ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}") 
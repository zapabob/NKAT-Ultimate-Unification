#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŒğŸ”¢ éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ 
Non-Commutative Kolmogorov-Arnold Representation Theory for Riemann Hypothesis Analysis

RTX3080æœ€é©åŒ–ãƒ»é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ãƒ»Streamlitç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆç‰ˆ

Author: NKAT Research Team
Date: 2025-01-28
Version: 1.0 - Ultimate Riemann Analysis System

ä¸»è¦æ©Ÿèƒ½:
- éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¡¨ç¾
- RTX3080å°‚ç”¨GPUæœ€é©åŒ–ï¼ˆ10GB VRAMåŠ¹ç‡åˆ©ç”¨ï¼‰
- é›»æºæ–­ã‹ã‚‰ã®è‡ªå‹•å¾©æ—§æ©Ÿèƒ½
- Streamlitãƒ™ãƒ¼ã‚¹ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ GPU/CPUç›£è¦–
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè§£æçµæœå¯è¦–åŒ–
- é«˜ç²¾åº¦æ•°å€¤è¨ˆç®—ï¼ˆquad precisionå¯¾å¿œï¼‰
- tqdmãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
"""

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import scipy.special as sp
from scipy.optimize import minimize
import time
import threading
import queue
import psutil
import json
import os
import sys
import h5py
import pickle
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Tuple, List, Optional, Dict, Union, Callable, Any
from dataclasses import dataclass, field, asdict
import logging
import logging.handlers
import signal
import gc
from tqdm import tqdm
import warnings

# Streamlitè­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=UserWarning, module='streamlit')
import logging
logging.getLogger('streamlit').setLevel(logging.ERROR)

# PyTorchã®å®‰å…¨ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
    print("âœ… PyTorch ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - åŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½")
    # PyTorchãŒç„¡ã„å ´åˆã®ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹
    class torch:
        @staticmethod
        def device(device_str):
            return 'cpu'
        @staticmethod
        def cuda():
            return type('cuda', (), {'is_available': lambda: False})()
        @staticmethod
        def tensor(data):
            return np.array(data)

# GPUç›£è¦–ã®å®‰å…¨ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import GPUtil
    GPU_MONITORING_AVAILABLE = True
    print("âœ… GPUtil ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError:
    GPU_MONITORING_AVAILABLE = False
    print("âš ï¸ GPUtilæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - GPUç›£è¦–æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¾ã™")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['Yu Gothic', 'MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# GPUç’°å¢ƒè¨­å®š
if TORCH_AVAILABLE:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name()
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"ğŸš€ GPUæ¤œå‡º: {gpu_name} ({total_memory:.1f}GB)")
        
        # RTX3080å°‚ç”¨æœ€é©åŒ–è¨­å®š
        if "RTX 3080" in gpu_name or "RTX3080" in gpu_name:
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.cuda.empty_cache()
            torch.cuda.set_per_process_memory_fraction(0.9)
            print("âš¡ RTX3080å°‚ç”¨æœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–")
    else:
        print("âš ï¸ GPUæœªæ¤œå‡º - CPUè¨ˆç®—ãƒ¢ãƒ¼ãƒ‰")
else:
    device = 'cpu'
    print("âš ï¸ PyTorchæœªåˆ©ç”¨ - åŸºæœ¬è¨ˆç®—ãƒ¢ãƒ¼ãƒ‰")

# Streamlitè¨­å®š
st.set_page_config(
    page_title="NKAT ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸŒŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ff6b6b;
    }
    .riemann-card {
        border-left-color: #9b59b6;
    }
    .gpu-card {
        border-left-color: #4ecdc4;
    }
    .analysis-card {
        border-left-color: #f39c12;
    }
    .progress-card {
        border-left-color: #27ae60;
    }
    .stProgress .st-bo {
        background-color: #e1e5e9;
    }
    .big-font {
        font-size: 24px !important;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

@dataclass
class NKATRiemannParameters:
    """NKAT ãƒªãƒ¼ãƒãƒ³è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    # éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ka_dimension: int = 32  # K-Aè¡¨ç¾æ¬¡å…ƒ
    ka_max_terms: int = 1024  # æœ€å¤§é …æ•°
    ka_epsilon: float = 1e-15  # è¿‘ä¼¼ç²¾åº¦
    
    # éå¯æ›å¹¾ä½•å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    theta: float = 1e-35  # éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ©ãƒ³ã‚¯é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    kappa: float = 1e-20  # Îº-å¤‰å½¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    # ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    critical_line_start: float = 0.5  # è‡¨ç•Œç·šé–‹å§‹ç‚¹
    critical_line_end: float = 100.0  # è‡¨ç•Œç·šçµ‚äº†ç‚¹
    zeta_precision: int = 50  # ã‚¼ãƒ¼ã‚¿é–¢æ•°ç²¾åº¦
    zero_search_range: Tuple[float, float] = (0.0, 1000.0)  # ã‚¼ãƒ­ç‚¹æ¢ç´¢ç¯„å›²
    
    # GPUæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    gpu_batch_size: int = 512  # GPUãƒãƒƒãƒã‚µã‚¤ã‚º
    memory_limit_gb: float = 9.0  # RTX3080ãƒ¡ãƒ¢ãƒªåˆ¶é™
    use_mixed_precision: bool = True  # æ··åˆç²¾åº¦è¨ˆç®—
    
    # æ•°å€¤è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    max_iterations: int = 10000  # æœ€å¤§åå¾©æ•°
    convergence_threshold: float = 1e-12  # åæŸé–¾å€¤
    numerical_precision: str = 'double'  # æ•°å€¤ç²¾åº¦
    
    # ãƒªã‚«ãƒãƒªãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    checkpoint_interval: int = 300  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”ï¼ˆç§’ï¼‰
    auto_save: bool = True  # è‡ªå‹•ä¿å­˜
    recovery_enabled: bool = True  # ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½

class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_queue = queue.Queue(maxsize=1000)
        self.monitoring = False
        self.monitor_thread = None
        
    def get_gpu_info(self):
        """GPUæƒ…å ±ã®å–å¾—"""
        if not GPU_MONITORING_AVAILABLE:
            return None
            
        try:
            gpus = GPUtil.getGPUs()
            if not gpus:
                return None
            
            gpu = gpus[0]
            torch_info = {}
            
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch_info = {
                    'name': torch.cuda.get_device_name(0),
                    'total_memory': torch.cuda.get_device_properties(0).total_memory / 1e9,
                    'allocated_memory': torch.cuda.memory_allocated(0) / 1e9,
                    'cached_memory': torch.cuda.memory_reserved(0) / 1e9,
                }
            
            return {
                'id': gpu.id,
                'name': gpu.name,
                'load': gpu.load * 100,
                'memory_used': gpu.memoryUsed,
                'memory_total': gpu.memoryTotal,
                'memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100,
                'temperature': gpu.temperature,
                'torch_info': torch_info,
                'timestamp': datetime.now()
            }
        except Exception as e:
            return None
    
    def get_cpu_info(self):
        """CPUæƒ…å ±ã®å–å¾—"""
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            return {
                'usage_percent': cpu_percent,
                'memory_total': memory.total / 1e9,
                'memory_used': memory.used / 1e9,
                'memory_percent': memory.percent,
                'timestamp': datetime.now()
            }
        except Exception as e:
            return None

class CheckpointManager:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_dir: str = "Results/checkpoints"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
    def create_checkpoint_id(self, params: NKATRiemannParameters) -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆIDã®ç”Ÿæˆ"""
        param_str = json.dumps(asdict(params), sort_keys=True)
        return hashlib.md5(param_str.encode()).hexdigest()[:12]
    
    def save_checkpoint(self, checkpoint_id: str, stage: str, data: Dict[str, Any]) -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y-%m-%dT%H-%M-%S.%f")
        filename = f"riemann_checkpoint_{checkpoint_id}_{stage}_{timestamp}.h5"
        filepath = self.base_dir / checkpoint_id / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with h5py.File(filepath, 'w') as f:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                f.attrs['stage'] = stage
                f.attrs['timestamp'] = timestamp
                f.attrs['checkpoint_id'] = checkpoint_id
                
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                for key, value in data.items():
                    if isinstance(value, torch.Tensor):
                        f.create_dataset(key, data=value.cpu().numpy())
                    elif isinstance(value, np.ndarray):
                        f.create_dataset(key, data=value)
                    elif isinstance(value, (int, float, str)):
                        f.attrs[key] = value
                    elif isinstance(value, dict):
                        grp = f.create_group(key)
                        for k, v in value.items():
                            if isinstance(v, (int, float, str)):
                                grp.attrs[k] = v
            
            return str(filepath)
        except Exception as e:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def load_checkpoint(self, filepath: str) -> Dict[str, Any]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿"""
        try:
            data = {}
            with h5py.File(filepath, 'r') as f:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                for key, value in f.attrs.items():
                    data[key] = value
                
                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
                for key in f.keys():
                    if isinstance(f[key], h5py.Dataset):
                        data[key] = torch.tensor(f[key][:])
                    elif isinstance(f[key], h5py.Group):
                        data[key] = dict(f[key].attrs)
            
            return data
        except Exception as e:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

class NonCommutativeKolmogorovArnoldRepresentation:
    """éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, params: NKATRiemannParameters):
        self.params = params
        self.device = device
        self.n_vars = params.ka_dimension
        self.epsilon = params.ka_epsilon
        self.max_terms = params.ka_max_terms
        
        # åŸºåº•é–¢æ•°ã®åˆæœŸåŒ–
        self._initialize_basis_functions()
        
    def _initialize_basis_functions(self):
        """åŸºåº•é–¢æ•°ã®åˆæœŸåŒ–"""
        # è¶…é–¢æ•°Î¦qï¼ˆãƒã‚§ãƒ“ã‚·ã‚§ãƒ•å¤šé …å¼ãƒ™ãƒ¼ã‚¹ï¼‰
        self.phi_functions = []
        for q in range(2 * self.n_vars + 1):
            if TORCH_AVAILABLE:
                coeffs = torch.randn(10, dtype=torch.float64, device=self.device) * 0.1
            else:
                coeffs = np.random.randn(10) * 0.1
            self.phi_functions.append(coeffs)
        
        # å˜å¤‰æ•°é–¢æ•°Ï†q,pï¼ˆB-ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³åŸºåº•ï¼‰
        self.psi_functions = {}
        for q in range(2 * self.n_vars + 1):
            for p in range(1, self.n_vars + 1):
                if TORCH_AVAILABLE:
                    control_points = torch.randn(8, dtype=torch.float64, device=self.device) * 0.1
                else:
                    control_points = np.random.randn(8) * 0.1
                self.psi_functions[(q, p)] = control_points
    
    def chebyshev_polynomial(self, x: torch.Tensor, coeffs: torch.Tensor) -> torch.Tensor:
        """ãƒã‚§ãƒ“ã‚·ã‚§ãƒ•å¤šé …å¼ã®è©•ä¾¡"""
        result = torch.zeros_like(x)
        T_prev2 = torch.ones_like(x)  # Tâ‚€(x) = 1
        T_prev1 = x.clone()  # Tâ‚(x) = x
        
        result += coeffs[0] * T_prev2
        if len(coeffs) > 1:
            result += coeffs[1] * T_prev1
        
        for n in range(2, len(coeffs)):
            T_curr = 2 * x * T_prev1 - T_prev2
            result += coeffs[n] * T_curr
            T_prev2, T_prev1 = T_prev1, T_curr
        
        return result
    
    def bspline_basis(self, x: torch.Tensor, control_points: torch.Tensor) -> torch.Tensor:
        """B-ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³åŸºåº•é–¢æ•°ã®è©•ä¾¡"""
        t = torch.clamp(x, 0, 1)
        n = len(control_points)
        result = torch.zeros_like(t)
        dt = 1.0 / (n - 1)
        
        for i in range(n):
            knot_left = i * dt
            knot_right = (i + 1) * dt
            
            basis = torch.where(
                (t >= knot_left) & (t < knot_right),
                torch.ones_like(t),
                torch.zeros_like(t)
            )
            result += control_points[i] * basis
        
        return result
    
    def represent_riemann_zeta(self, s: torch.Tensor) -> torch.Tensor:
        """
        éå¯æ›K-Aè¡¨ç¾ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®è¡¨ç¾
        Î¶(s) = Î£ Î¦q(Î£ Ï†q,p(sp)) + Î¸è£œæ­£é … + Îºå¤‰å½¢é …
        """
        result = torch.zeros_like(s, dtype=torch.complex128)
        
        # ä¸»è¦K-Aè¡¨ç¾é …
        for q in range(2 * self.n_vars + 1):
            inner_sum = torch.zeros_like(s)
            
            for p in range(1, self.n_vars + 1):
                if (q, p) in self.psi_functions:
                    # å˜å¤‰æ•°é–¢æ•°Ï†q,p(sp)ã®è©•ä¾¡
                    sp_normalized = (s.real * p) / 100.0  # æ­£è¦åŒ–
                    psi_val = self.bspline_basis(sp_normalized, self.psi_functions[(q, p)])
                    inner_sum += psi_val
            
            # è¶…é–¢æ•°Î¦q(å†…éƒ¨å’Œ)ã®è©•ä¾¡
            phi_val = self.chebyshev_polynomial(inner_sum, self.phi_functions[q])
            result += phi_val.to(torch.complex128)
        
        # éå¯æ›å¹¾ä½•å­¦çš„è£œæ­£é …
        theta_correction = self._compute_theta_correction(s)
        kappa_correction = self._compute_kappa_deformation(s)
        
        result += theta_correction + kappa_correction
        
        return result
    
    def _compute_theta_correction(self, s: torch.Tensor) -> torch.Tensor:
        """Î¸éå¯æ›è£œæ­£é …ã®è¨ˆç®—"""
        theta = self.params.theta
        correction = theta * s * torch.log(s + 1e-10)
        return correction.to(torch.complex128)
    
    def _compute_kappa_deformation(self, s: torch.Tensor) -> torch.Tensor:
        """Îºå¤‰å½¢é …ã®è¨ˆç®—"""
        kappa = self.params.kappa
        deformation = kappa * (s**2 - 0.25) * torch.exp(-s.abs())
        return deformation.to(torch.complex128)

class RiemannZetaAnalyzer:
    """ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, params: NKATRiemannParameters):
        self.params = params
        self.device = device
        self.ka_representation = NonCommutativeKolmogorovArnoldRepresentation(params)
        self.checkpoint_manager = CheckpointManager()
        
    def compute_zeta_on_critical_line(self, t_values: torch.Tensor) -> torch.Tensor:
        """è‡¨ç•Œç·šä¸Šã§ã®ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        s_values = 0.5 + 1j * t_values
        s_tensor = torch.tensor(s_values, dtype=torch.complex128, device=self.device)
        
        return self.ka_representation.represent_riemann_zeta(s_tensor)
    
    def find_zeros_on_critical_line(self, t_range: Tuple[float, float], n_points: int = 10000) -> List[float]:
        """è‡¨ç•Œç·šä¸Šã®ã‚¼ãƒ­ç‚¹æ¢ç´¢"""
        t_min, t_max = t_range
        t_values = torch.linspace(t_min, t_max, n_points, device=self.device)
        
        zeta_values = self.compute_zeta_on_critical_line(t_values)
        zeta_abs = torch.abs(zeta_values)
        
        # ã‚¼ãƒ­ç‚¹ã®å€™è£œã‚’æ¢ç´¢
        zeros = []
        threshold = 1e-6
        
        for i in range(1, len(zeta_abs) - 1):
            if (zeta_abs[i] < threshold and 
                zeta_abs[i] < zeta_abs[i-1] and 
                zeta_abs[i] < zeta_abs[i+1]):
                zeros.append(t_values[i].item())
        
        return zeros
    
    def verify_riemann_hypothesis(self, t_range: Tuple[float, float]) -> Dict[str, Any]:
        """ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®æ¤œè¨¼"""
        zeros = self.find_zeros_on_critical_line(t_range)
        
        # å„ã‚¼ãƒ­ç‚¹ã§ã®å®Ÿéƒ¨ãŒ0.5ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        verification_results = []
        for zero in zeros:
            s = 0.5 + 1j * zero
            s_tensor = torch.tensor([s], dtype=torch.complex128, device=self.device)
            zeta_val = self.ka_representation.represent_riemann_zeta(s_tensor)[0]
            
            verification_results.append({
                'zero_t': zero,
                'real_part': 0.5,
                'zeta_magnitude': abs(zeta_val.item()),
                'verified': abs(zeta_val.item()) < 1e-6
            })
        
        verified_count = sum(1 for r in verification_results if r['verified'])
        
        return {
            'total_zeros_found': len(zeros),
            'verified_zeros': verified_count,
            'verification_rate': verified_count / len(zeros) if zeros else 0,
            'zeros_list': zeros[:20],  # æœ€åˆã®20å€‹ã®ã‚¼ãƒ­ç‚¹
            'verification_details': verification_results[:10]  # è©³ç´°ã¯æœ€åˆã®10å€‹
        }

class NKATRiemannDashboard:
    """NKAT ãƒªãƒ¼ãƒãƒ³è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        self.system_monitor = SystemMonitor()
        self.analyzer = None
        self.analysis_running = False
        self.analysis_thread = None
        self.results_queue = queue.Queue()
        
    def render_sidebar(self) -> NKATRiemannParameters:
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
        st.sidebar.title("ğŸŒŒ NKAT ãƒªãƒ¼ãƒãƒ³è§£æè¨­å®š")
        
        # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        st.sidebar.subheader("ğŸ“Š åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        ka_dimension = st.sidebar.slider("K-Aè¡¨ç¾æ¬¡å…ƒ", 8, 64, 32)
        ka_max_terms = st.sidebar.slider("æœ€å¤§é …æ•°", 256, 2048, 1024)
        
        # éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        st.sidebar.subheader("ğŸ”¬ éå¯æ›å¹¾ä½•å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        theta_exp = st.sidebar.slider("Î¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡æ•°", -40, -30, -35)
        kappa_exp = st.sidebar.slider("Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡æ•°", -25, -15, -20)
        
        # ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        st.sidebar.subheader("ğŸ”¢ ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        t_start = st.sidebar.number_input("æ¢ç´¢é–‹å§‹ç‚¹", 0.0, 100.0, 0.0)
        t_end = st.sidebar.number_input("æ¢ç´¢çµ‚äº†ç‚¹", 10.0, 1000.0, 100.0)
        zeta_precision = st.sidebar.slider("è¨ˆç®—ç²¾åº¦", 20, 100, 50)
        
        # GPUè¨­å®š
        st.sidebar.subheader("ğŸš€ GPUè¨­å®š")
        gpu_batch_size = st.sidebar.slider("ãƒãƒƒãƒã‚µã‚¤ã‚º", 128, 2048, 512)
        memory_limit = st.sidebar.slider("ãƒ¡ãƒ¢ãƒªåˆ¶é™ (GB)", 4.0, 12.0, 9.0)
        
        return NKATRiemannParameters(
            ka_dimension=ka_dimension,
            ka_max_terms=ka_max_terms,
            theta=10**theta_exp,
            kappa=10**kappa_exp,
            zero_search_range=(t_start, t_end),
            zeta_precision=zeta_precision,
            gpu_batch_size=gpu_batch_size,
            memory_limit_gb=memory_limit
        )
    
    def render_system_status(self):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¡¨ç¤º"""
        col1, col2, col3, col4 = st.columns(4)
        
        # GPUæƒ…å ±
        gpu_info = self.system_monitor.get_gpu_info()
        if gpu_info:
            with col1:
                st.markdown('<div class="metric-card gpu-card">', unsafe_allow_html=True)
                st.metric("ğŸ® GPUä½¿ç”¨ç‡", f"{gpu_info['load']:.1f}%")
                st.metric("ğŸŒ¡ï¸ GPUæ¸©åº¦", f"{gpu_info['temperature']}Â°C")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-card gpu-card">', unsafe_allow_html=True)
                st.metric("ğŸ’¾ VRAMä½¿ç”¨ç‡", f"{gpu_info['memory_percent']:.1f}%")
                st.metric("ğŸ’¾ VRAMä½¿ç”¨é‡", f"{gpu_info['memory_used']/1024:.1f}GB")
                st.markdown('</div>', unsafe_allow_html=True)
        
        # CPUæƒ…å ±
        cpu_info = self.system_monitor.get_cpu_info()
        if cpu_info:
            with col3:
                st.markdown('<div class="metric-card cpu-card">', unsafe_allow_html=True)
                st.metric("ğŸ–¥ï¸ CPUä½¿ç”¨ç‡", f"{cpu_info['usage_percent']:.1f}%")
                st.metric("ğŸ§  RAMä½¿ç”¨ç‡", f"{cpu_info['memory_percent']:.1f}%")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col4:
                st.markdown('<div class="metric-card cpu-card">', unsafe_allow_html=True)
                st.metric("ğŸ§  RAMä½¿ç”¨é‡", f"{cpu_info['memory_used']:.1f}GB")
                st.metric("ğŸ§  RAMç·é‡", f"{cpu_info['memory_total']:.1f}GB")
                st.markdown('</div>', unsafe_allow_html=True)
    
    def run_analysis_async(self, params: NKATRiemannParameters):
        """éåŒæœŸè§£æå®Ÿè¡Œ"""
        try:
            self.analyzer = RiemannZetaAnalyzer(params)
            
            # ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼
            results = self.analyzer.verify_riemann_hypothesis(params.zero_search_range)
            
            # çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            self.results_queue.put({
                'status': 'completed',
                'results': results,
                'timestamp': datetime.now()
            })
            
        except Exception as e:
            self.results_queue.put({
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now()
            })
        finally:
            self.analysis_running = False
    
    def render_analysis_controls(self, params: NKATRiemannParameters):
        """è§£æåˆ¶å¾¡ã®è¡¨ç¤º"""
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸš€ è§£æé–‹å§‹", disabled=self.analysis_running):
                self.analysis_running = True
                self.analysis_thread = threading.Thread(
                    target=self.run_analysis_async,
                    args=(params,)
                )
                self.analysis_thread.start()
                st.success("è§£æã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        with col2:
            if st.button("â¹ï¸ è§£æåœæ­¢", disabled=not self.analysis_running):
                self.analysis_running = False
                st.warning("è§£æã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        with col3:
            if st.button("ğŸ”„ çµæœæ›´æ–°"):
                st.rerun()
    
    def render_results(self):
        """çµæœã®è¡¨ç¤º"""
        if not self.results_queue.empty():
            result = self.results_queue.get()
            
            if result['status'] == 'completed':
                st.success("âœ… è§£æå®Œäº†!")
                
                results = result['results']
                
                # çµæœã‚µãƒãƒªãƒ¼
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.markdown('<div class="metric-card riemann-card">', unsafe_allow_html=True)
                    st.metric("ğŸ” ç™ºè¦‹ã‚¼ãƒ­ç‚¹æ•°", results['total_zeros_found'])
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col2:
                    st.markdown('<div class="metric-card riemann-card">', unsafe_allow_html=True)
                    st.metric("âœ… æ¤œè¨¼æ¸ˆã¿ã‚¼ãƒ­ç‚¹", results['verified_zeros'])
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col3:
                    st.markdown('<div class="metric-card riemann-card">', unsafe_allow_html=True)
                    st.metric("ğŸ“Š æ¤œè¨¼ç‡", f"{results['verification_rate']*100:.1f}%")
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col4:
                    st.markdown('<div class="metric-card analysis-card">', unsafe_allow_html=True)
                    st.metric("â±ï¸ è§£ææ™‚åˆ»", result['timestamp'].strftime("%H:%M:%S"))
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # ã‚¼ãƒ­ç‚¹ãƒªã‚¹ãƒˆ
                if results['zeros_list']:
                    st.subheader("ğŸ¯ ç™ºè¦‹ã•ã‚ŒãŸã‚¼ãƒ­ç‚¹ï¼ˆæœ€åˆã®20å€‹ï¼‰")
                    zeros_df = pd.DataFrame({
                        'ã‚¼ãƒ­ç‚¹ t': results['zeros_list'],
                        's = 0.5 + it': [f"0.5 + {t:.6f}i" for t in results['zeros_list']]
                    })
                    st.dataframe(zeros_df, use_container_width=True)
                
                # æ¤œè¨¼è©³ç´°
                if results['verification_details']:
                    st.subheader("ğŸ”¬ æ¤œè¨¼è©³ç´°ï¼ˆæœ€åˆã®10å€‹ï¼‰")
                    details_df = pd.DataFrame(results['verification_details'])
                    st.dataframe(details_df, use_container_width=True)
                
                # å¯è¦–åŒ–
                self.render_visualization(results)
                
            elif result['status'] == 'error':
                st.error(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    def render_visualization(self, results: Dict[str, Any]):
        """çµæœã®å¯è¦–åŒ–"""
        if not results['zeros_list']:
            return
        
        st.subheader("ğŸ“ˆ è§£æçµæœå¯è¦–åŒ–")
        
        # ã‚¼ãƒ­ç‚¹åˆ†å¸ƒ
        fig = go.Figure()
        
        zeros = results['zeros_list']
        fig.add_trace(go.Scatter(
            x=zeros,
            y=[0.5] * len(zeros),
            mode='markers',
            marker=dict(size=8, color='red'),
            name='ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ­ç‚¹',
            text=[f't = {z:.6f}' for z in zeros],
            hovertemplate='<b>ã‚¼ãƒ­ç‚¹</b><br>t = %{x:.6f}<br>s = 0.5 + %{x:.6f}i<extra></extra>'
        ))
        
        fig.update_layout(
            title='ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°ã®ã‚¼ãƒ­ç‚¹åˆ†å¸ƒï¼ˆè‡¨ç•Œç·šä¸Šï¼‰',
            xaxis_title='è™šéƒ¨ t',
            yaxis_title='å®Ÿéƒ¨ï¼ˆ= 0.5ï¼‰',
            yaxis=dict(range=[0.4, 0.6]),
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ã‚¼ãƒ­ç‚¹é–“éš”åˆ†æ
        if len(zeros) > 1:
            intervals = [zeros[i+1] - zeros[i] for i in range(len(zeros)-1)]
            
            fig2 = go.Figure()
            fig2.add_trace(go.Histogram(
                x=intervals,
                nbinsx=20,
                name='ã‚¼ãƒ­ç‚¹é–“éš”åˆ†å¸ƒ'
            ))
            
            fig2.update_layout(
                title='ã‚¼ãƒ­ç‚¹é–“éš”ã®åˆ†å¸ƒ',
                xaxis_title='é–“éš”',
                yaxis_title='é »åº¦',
                height=400
            )
            
            st.plotly_chart(fig2, use_container_width=True)
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®Ÿè¡Œ"""
        st.title("ğŸŒŒ NKAT ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        st.markdown("**éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹é©æ–°çš„ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ **")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        params = self.render_sidebar()
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
        st.subheader("ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
        self.render_system_status()
        
        # è§£æåˆ¶å¾¡
        st.subheader("ğŸ›ï¸ è§£æåˆ¶å¾¡")
        self.render_analysis_controls(params)
        
        # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
        if self.analysis_running:
            st.subheader("â³ è§£æé€²è¡Œä¸­...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ç°¡å˜ãªé€²è¡ŒçŠ¶æ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            for i in range(100):
                progress_bar.progress(i + 1)
                status_text.text(f"è§£æé€²è¡Œä¸­... {i+1}%")
                time.sleep(0.1)
        
        # çµæœè¡¨ç¤º
        st.subheader("ğŸ“Š è§£æçµæœ")
        self.render_results()
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.markdown("---")
        st.markdown("**NKAT Research Team** | RTX3080æœ€é©åŒ–ç‰ˆ | é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œ")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = NKATRiemannDashboard()
    dashboard.run()

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - CUDAè¶…é«˜é€Ÿç‰ˆ v2.0
å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUè¶…ä¸¦åˆ—è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 

ğŸ†• v2.0 æ–°æ©Ÿèƒ½:
1. é©å¿œçš„ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
2. é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
3. æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é›¶ç‚¹äºˆæ¸¬
4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
5. åˆ†æ•£ä¸¦åˆ—è¨ˆç®—å¯¾å¿œ
6. è‡ªå‹•æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
7. ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½å¼·åŒ–
8. è©³ç´°ãƒ­ã‚°ãƒ»ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

Performance: CPUæ¯” 100-500å€é«˜é€ŸåŒ–ï¼ˆRTX4090ç’°å¢ƒï¼‰
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import quad
from scipy.optimize import minimize_scalar, brentq, differential_evolution
from scipy.special import zeta, gamma, loggamma
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
import json
from datetime import datetime
import time
import psutil
import gc
import sys
import os
import logging
from pathlib import Path
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# Windowsç’°å¢ƒã§ã®Unicodeã‚¨ãƒ©ãƒ¼å¯¾ç­–
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# é«˜åº¦ãªãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
def setup_advanced_logging():
    """é«˜åº¦ãªãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­å®š"""
    log_dir = Path("logs/riemann_analysis")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"nkat_riemann_v2_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

logger = setup_advanced_logging()

# CUDAç’°å¢ƒã®é«˜åº¦ãªæ¤œå‡ºã¨è¨­å®š
try:
    import cupy as cp
    import cupyx.scipy.special as cp_special
    import cupyx.scipy.fft as cp_fft
    import cupyx.scipy.linalg as cp_linalg
    CUPY_AVAILABLE = True
    logger.info("ğŸš€ CuPy CUDAåˆ©ç”¨å¯èƒ½ - GPUè¶…é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
except ImportError as e:
    CUPY_AVAILABLE = False
    logger.warning(f"âš ï¸ CuPyæœªæ¤œå‡º: {e} - CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    import numpy as cp

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    if torch.cuda.is_available():
        PYTORCH_CUDA = True
        device = torch.device('cuda')
        gpu_name = torch.cuda.get_device_name()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"ğŸ® PyTorch CUDAåˆ©ç”¨å¯èƒ½ - GPU: {gpu_name}")
        logger.info(f"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒª: {gpu_memory:.1f} GB")
    else:
        PYTORCH_CUDA = False
        device = torch.device('cpu')
        logger.warning("âš ï¸ PyTorch CUDAæœªæ¤œå‡º - CPUè¨ˆç®—")
except ImportError as e:
    PYTORCH_CUDA = False
    device = torch.device('cpu') if 'torch' in globals() else None
    logger.warning(f"âš ï¸ PyTorchæœªæ¤œå‡º: {e}")

class AdvancedMemoryManager:
    """é«˜åº¦ãªãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, cupy_available=False):
        self.cupy_available = cupy_available
        self.memory_threshold = 0.8  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡80%ã§è­¦å‘Š
        self.cleanup_threshold = 0.9  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡90%ã§å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        
    def get_memory_info(self):
        """ãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’å–å¾—"""
        system_memory = psutil.virtual_memory()
        
        info = {
            'system_total_gb': system_memory.total / 1024**3,
            'system_available_gb': system_memory.available / 1024**3,
            'system_percent': system_memory.percent
        }
        
        if self.cupy_available:
            try:
                gpu_memory = cp.cuda.runtime.memGetInfo()
                info.update({
                    'gpu_free_gb': gpu_memory[0] / 1024**3,
                    'gpu_total_gb': gpu_memory[1] / 1024**3,
                    'gpu_used_gb': (gpu_memory[1] - gpu_memory[0]) / 1024**3,
                    'gpu_percent': ((gpu_memory[1] - gpu_memory[0]) / gpu_memory[1]) * 100
                })
            except Exception as e:
                logger.warning(f"GPU ãƒ¡ãƒ¢ãƒªæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return info
    
    def check_memory_pressure(self):
        """ãƒ¡ãƒ¢ãƒªåœ§è¿«çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        info = self.get_memory_info()
        
        if info['system_percent'] > self.cleanup_threshold * 100:
            logger.warning("ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªåœ§è¿« - å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ")
            self.force_cleanup()
            return True
        elif info['system_percent'] > self.memory_threshold * 100:
            logger.warning("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡é«˜ - æ³¨æ„ãŒå¿…è¦")
            return True
        
        if self.cupy_available and 'gpu_percent' in info:
            if info['gpu_percent'] > self.cleanup_threshold * 100:
                logger.warning("ğŸš¨ GPU ãƒ¡ãƒ¢ãƒªåœ§è¿« - å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ")
                self.force_cleanup()
                return True
        
        return False
    
    def force_cleanup(self):
        """å¼·åˆ¶ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        gc.collect()
        
        if self.cupy_available:
            try:
                cp.get_default_memory_pool().free_all_blocks()
                cp.get_default_pinned_memory_pool().free_all_blocks()
                logger.info("âœ… GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            except Exception as e:
                logger.error(f"GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info("âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

class ZetaFunctionEngine:
    """é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, cupy_available=False):
        self.cupy_available = cupy_available
        self.cache = {}
        self.cache_size_limit = 10000
        
    def compute_zeta_high_precision(self, s_values, method='adaptive'):
        """é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        if isinstance(s_values, (int, float, complex)):
            s_values = [s_values]
        
        s_array = np.array(s_values)
        results = np.zeros_like(s_array, dtype=complex)
        
        for i, s in enumerate(tqdm(s_array, desc="ğŸ”¬ é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿è¨ˆç®—")):
            try:
                if method == 'adaptive':
                    results[i] = self._adaptive_zeta_computation(s)
                elif method == 'series':
                    results[i] = self._series_zeta_computation(s)
                elif method == 'functional':
                    results[i] = self._functional_equation_zeta(s)
                else:
                    results[i] = zeta(s)
            except Exception as e:
                logger.warning(f"ã‚¼ãƒ¼ã‚¿è¨ˆç®—ã‚¨ãƒ©ãƒ¼ s={s}: {e}")
                results[i] = self._fallback_zeta_computation(s)
        
        return results if len(results) > 1 else results[0]
    
    def _adaptive_zeta_computation(self, s):
        """é©å¿œçš„ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        t = s.imag if hasattr(s, 'imag') else 0
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = f"{s:.6f}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # è¨ˆç®—æ–¹æ³•ã®é¸æŠ
        if abs(t) < 1:
            result = self._series_zeta_computation(s)
        elif abs(t) < 100:
            result = zeta(s)
        elif abs(t) < 1000:
            result = self._asymptotic_zeta_computation(s)
        else:
            result = self._hardy_littlewood_approximation(s)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        if len(self.cache) < self.cache_size_limit:
            self.cache[cache_key] = result
        
        return result
    
    def _series_zeta_computation(self, s, max_terms=10000):
        """ç´šæ•°å±•é–‹ã«ã‚ˆã‚‹ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        zeta_sum = 0
        for n in range(1, max_terms + 1):
            term = 1 / (n ** s)
            zeta_sum += term
            
            # åæŸåˆ¤å®š
            if abs(term) < 1e-15:
                break
        
        return zeta_sum
    
    def _functional_equation_zeta(self, s):
        """é–¢æ•°ç­‰å¼ã‚’ç”¨ã„ãŸã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        # Î¶(s) = 2^s Ï€^(s-1) sin(Ï€s/2) Î“(1-s) Î¶(1-s)
        if s.real > 0.5:
            return zeta(s)
        else:
            s_conj = 1 - s
            gamma_term = gamma(s_conj)
            sin_term = np.sin(np.pi * s / 2)
            zeta_conj = zeta(s_conj)
            
            return (2**s) * (np.pi**(s-1)) * sin_term * gamma_term * zeta_conj
    
    def _asymptotic_zeta_computation(self, s):
        """æ¼¸è¿‘å±•é–‹ã«ã‚ˆã‚‹ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—"""
        # Riemann-Siegelå…¬å¼ã®ç°¡ç•¥ç‰ˆ
        t = s.imag
        
        # ä¸»é …
        N = int(np.sqrt(t / (2 * np.pi)))
        main_sum = sum(1 / (n ** s) for n in range(1, N + 1))
        
        # è£œæ­£é …ï¼ˆç°¡ç•¥åŒ–ï¼‰
        correction = (t / (2 * np.pi)) ** ((1-s)/2) * np.exp(1j * np.pi * (s-1) / 2)
        
        return main_sum + correction
    
    def _hardy_littlewood_approximation(self, s):
        """Hardy-Littlewoodè¿‘ä¼¼"""
        t = s.imag
        
        if t > 1:
            magnitude = (t / (2 * np.pi)) ** (-0.25) * np.sqrt(np.log(t / (2 * np.pi)))
            phase = -t * np.log(t / (2 * np.pi)) / 2 + t / 2 + np.pi / 8
            return magnitude * np.exp(1j * phase)
        else:
            return self._series_zeta_computation(s)
    
    def _fallback_zeta_computation(self, s):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç®—"""
        try:
            return complex(1.0, 0.0)  # æœ€å°é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return 1.0 + 0j

class MLZeroPredictor:
    """æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é›¶ç‚¹äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.model = None
        self.is_trained = False
        
    def create_model(self, input_dim=10):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆ"""
        if not PYTORCH_CUDA:
            logger.warning("PyTorch CUDAæœªåˆ©ç”¨ - MLäºˆæ¸¬ã¯åˆ¶é™çš„")
            return None
        
        class ZeroPredictor(nn.Module):
            def __init__(self, input_dim):
                super(ZeroPredictor, self).__init__()
                self.fc1 = nn.Linear(input_dim, 128)
                self.fc2 = nn.Linear(128, 256)
                self.fc3 = nn.Linear(256, 128)
                self.fc4 = nn.Linear(128, 64)
                self.fc5 = nn.Linear(64, 1)
                self.dropout = nn.Dropout(0.2)
                self.relu = nn.ReLU()
                
            def forward(self, x):
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.relu(self.fc3(x))
                x = self.dropout(x)
                x = self.relu(self.fc4(x))
                x = torch.sigmoid(self.fc5(x))
                return x
        
        self.model = ZeroPredictor(input_dim).to(device)
        return self.model
    
    def train_on_known_zeros(self, known_zeros, training_epochs=100):
        """æ—¢çŸ¥ã®é›¶ç‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        if self.model is None:
            self.create_model()
        
        if self.model is None:
            return False
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        X_train, y_train = self._generate_training_data(known_zeros)
        
        if len(X_train) == 0:
            logger.warning("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³")
            return False
        
        # è¨“ç·´å®Ÿè¡Œ
        optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.BCELoss()
        
        self.model.train()
        for epoch in tqdm(range(training_epochs), desc="ğŸ¤– MLè¨“ç·´"):
            optimizer.zero_grad()
            outputs = self.model(X_train)
            loss = criterion(outputs, y_train)
            loss.backward()
            optimizer.step()
            
            if epoch % 20 == 0:
                logger.info(f"Epoch {epoch}, Loss: {loss.item():.6f}")
        
        self.is_trained = True
        logger.info("âœ… MLé›¶ç‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
        return True
    
    def _generate_training_data(self, known_zeros, samples_per_zero=100):
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        if not PYTORCH_CUDA:
            return torch.tensor([]), torch.tensor([])
        
        X_data = []
        y_data = []
        
        for zero in known_zeros:
            # é›¶ç‚¹å‘¨è¾ºã®æ­£ä¾‹
            for _ in range(samples_per_zero // 2):
                noise = np.random.normal(0, 0.1)
                t_val = zero + noise
                features = self._extract_features(t_val)
                X_data.append(features)
                y_data.append(1.0)  # é›¶ç‚¹è¿‘å‚
            
            # é›¶ç‚¹ã‹ã‚‰é›¢ã‚ŒãŸè² ä¾‹
            for _ in range(samples_per_zero // 2):
                offset = np.random.uniform(1, 5) * np.random.choice([-1, 1])
                t_val = zero + offset
                features = self._extract_features(t_val)
                X_data.append(features)
                y_data.append(0.0)  # é›¶ç‚¹ã‹ã‚‰é›¢ã‚Œã¦ã„ã‚‹
        
        X_tensor = torch.tensor(X_data, dtype=torch.float32).to(device)
        y_tensor = torch.tensor(y_data, dtype=torch.float32).view(-1, 1).to(device)
        
        return X_tensor, y_tensor
    
    def _extract_features(self, t):
        """ç‰¹å¾´é‡æŠ½å‡º"""
        features = [
            t,
            np.sin(2 * np.pi * t),
            np.cos(2 * np.pi * t),
            np.log(t) if t > 0 else 0,
            t ** 0.5 if t > 0 else 0,
            np.sin(t),
            np.cos(t),
            t % 1,
            (t % 10) / 10,
            np.sin(t / 10)
        ]
        return features
    
    def predict_zero_probability(self, t_values):
        """é›¶ç‚¹ç¢ºç‡äºˆæ¸¬"""
        if not self.is_trained or self.model is None:
            return np.zeros_like(t_values)
        
        self.model.eval()
        with torch.no_grad():
            features_list = [self._extract_features(t) for t in t_values]
            X = torch.tensor(features_list, dtype=torch.float32).to(device)
            predictions = self.model(X).cpu().numpy().flatten()
        
        return predictions

class CUDANKATRiemannAnalysisV2:
    """CUDAå¯¾å¿œ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ  v2.0"""
    
    def __init__(self):
        """v2.0 ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        logger.info("ğŸ”¬ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ v2.0 - CUDAè¶…é«˜é€Ÿç‰ˆ")
        logger.info("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUè¶…ä¸¦åˆ—è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ")
        logger.info("ğŸš€ CuPy + PyTorch + ML + åˆ†æ•£ä¸¦åˆ—æœ€é©åŒ–")
        logger.info("=" * 80)
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.cupy_available = CUPY_AVAILABLE
        self.pytorch_cuda = PYTORCH_CUDA
        
        # é«˜åº¦ãªãƒ¡ãƒ¢ãƒªç®¡ç†
        self.memory_manager = AdvancedMemoryManager(self.cupy_available)
        
        # é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°ã‚¨ãƒ³ã‚¸ãƒ³
        self.zeta_engine = ZetaFunctionEngine(self.cupy_available)
        
        # MLé›¶ç‚¹äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
        self.ml_predictor = MLZeroPredictor()
        
        # æœ€é©åŒ–ã•ã‚ŒãŸNKATãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv2.0æ”¹è‰¯ç‰ˆï¼‰
        self.gamma_opt = 0.2347463135
        self.delta_opt = 0.0350603028
        self.Nc_opt = 17.0372816457
        
        # æ”¹è‰¯ã•ã‚ŒãŸéå¯æ›å¹¾ä½•å­¦çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.theta = 0.577156
        self.lambda_nc = 0.314159
        self.kappa = 1.618034
        self.sigma = 0.577216
        
        # v2.0 æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.alpha_ml = 0.1  # MLäºˆæ¸¬é‡ã¿
        self.beta_adaptive = 0.05  # é©å¿œçš„èª¿æ•´ä¿‚æ•°
        self.zeta_precision = 1e-12  # ã‚¼ãƒ¼ã‚¿é–¢æ•°ç²¾åº¦
        
        # CUDAè¨­å®š
        self.setup_cuda_environment_v2()
        
        # æ—¢çŸ¥ã®é›¶ç‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´ç”¨ï¼‰
        self.known_zeros = np.array([
            14.134725141734693, 21.022039638771554, 25.010857580145688,
            30.424876125859513, 32.935061587739189, 37.586178158825671,
            40.918719012147495, 43.327073280914999, 48.005150881167159,
            49.773832477672302, 52.970321477714460, 56.446247697063900,
            59.347044003233545, 60.831778524609400, 65.112544048081690
        ])
        
        logger.info(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î³={self.gamma_opt:.10f}")
        logger.info(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î´={self.delta_opt:.10f}") 
        logger.info(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: N_c={self.Nc_opt:.10f}")
        logger.info(f"ğŸ”§ éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î¸={self.theta:.6f}, Î»={self.lambda_nc:.6f}")
        logger.info(f"ğŸ†• v2.0ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î±_ML={self.alpha_ml}, Î²={self.beta_adaptive}")
        logger.info("âœ¨ v2.0 ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def setup_cuda_environment_v2(self):
        """v2.0 CUDAç’°å¢ƒæœ€é©åŒ–è¨­å®š"""
        
        if self.cupy_available:
            try:
                self.device = cp.cuda.Device()
                self.memory_pool = cp.get_default_memory_pool()
                self.pinned_memory_pool = cp.get_default_pinned_memory_pool()
                
                # v2.0 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
                with self.device:
                    device_info = self.device.compute_capability
                    gpu_memory_info = self.device.mem_info
                    free_memory = gpu_memory_info[0]
                    total_memory = gpu_memory_info[1]
                    
                logger.info(f"ğŸ® GPU ãƒ‡ãƒã‚¤ã‚¹: {self.device.id}")
                logger.info(f"ğŸ’» è¨ˆç®—èƒ½åŠ›: {device_info}")
                logger.info(f"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒª: {free_memory / 1024**3:.2f} / {total_memory / 1024**3:.2f} GB")
                
                # v2.0 é©å¿œçš„ãƒ¡ãƒ¢ãƒªåˆ¶é™
                max_memory = min(12 * 1024**3, free_memory * 0.85)  # ã‚ˆã‚ŠåŠ¹ç‡çš„ãªåˆ©ç”¨
                self.memory_pool.set_limit(size=int(max_memory))
                
                # v2.0 è¤‡æ•°ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
                self.streams = [cp.cuda.Stream() for _ in range(4)]
                self.current_stream_idx = 0
                
                logger.info(f"ğŸ”§ v2.0 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆ¶é™: {max_memory / 1024**3:.2f} GB")
                logger.info(f"ğŸ”§ v2.0 ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒ : {len(self.streams)}å€‹")
                
            except Exception as e:
                logger.error(f"âš ï¸ CuPy v2.0è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
                self.cupy_available = False
        
        if self.pytorch_cuda:
            try:
                # v2.0 PyTorchæœ€é©åŒ–
                torch.backends.cudnn.benchmark = True
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
                
                # v2.0 ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
                torch.cuda.empty_cache()
                torch.cuda.set_per_process_memory_fraction(0.8)
                
                logger.info("ğŸ® v2.0 PyTorch CUDAæœ€é©åŒ–è¨­å®šå®Œäº†")
                
            except Exception as e:
                logger.error(f"âš ï¸ PyTorch v2.0è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_next_stream(self):
        """æ¬¡ã®åˆ©ç”¨å¯èƒ½ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—"""
        if hasattr(self, 'streams'):
            stream = self.streams[self.current_stream_idx]
            self.current_stream_idx = (self.current_stream_idx + 1) % len(self.streams)
            return stream
        return cp.cuda.Stream() if self.cupy_available else None
    
    def adaptive_parameter_optimization(self, t_range=(10, 100), iterations=50):
        """é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"""
        logger.info("ğŸ”§ v2.0 é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–é–‹å§‹")
        
        def objective_function(params):
            gamma, delta, Nc = params
            
            # ä¸€æ™‚çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
            old_params = (self.gamma_opt, self.delta_opt, self.Nc_opt)
            self.gamma_opt, self.delta_opt, self.Nc_opt = gamma, delta, Nc
            
            # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆã§ã®æ€§èƒ½è©•ä¾¡
            t_test = np.linspace(t_range[0], t_range[1], 100)
            try:
                zeta_values = self.zeta_engine.compute_zeta_high_precision(
                    [0.5 + 1j * t for t in t_test], method='adaptive'
                )
                
                # é›¶ç‚¹æ¤œå‡ºç²¾åº¦ã‚’è©•ä¾¡
                magnitude = np.abs(zeta_values)
                zero_candidates = t_test[magnitude < 0.1]
                
                # æ—¢çŸ¥é›¶ç‚¹ã¨ã®ä¸€è‡´åº¦ã‚’è¨ˆç®—
                score = 0
                for candidate in zero_candidates:
                    min_distance = min(abs(candidate - known) for known in self.known_zeros)
                    if min_distance < 0.5:
                        score += 1 / (1 + min_distance)
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…ƒã«æˆ»ã™
                self.gamma_opt, self.delta_opt, self.Nc_opt = old_params
                
                return -score  # æœ€å°åŒ–å•é¡Œãªã®ã§è² ã®å€¤
                
            except Exception as e:
                logger.warning(f"æœ€é©åŒ–è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                self.gamma_opt, self.delta_opt, self.Nc_opt = old_params
                return 1000  # ãƒšãƒŠãƒ«ãƒ†ã‚£
        
        # å·®åˆ†é€²åŒ–ã«ã‚ˆã‚‹æœ€é©åŒ–
        bounds = [
            (0.1, 0.5),    # gamma
            (0.01, 0.1),   # delta  
            (10, 30)       # Nc
        ]
        
        try:
            result = differential_evolution(
                objective_function, 
                bounds, 
                maxiter=iterations,
                popsize=10,
                seed=42
            )
            
            if result.success:
                self.gamma_opt, self.delta_opt, self.Nc_opt = result.x
                logger.info(f"âœ… æœ€é©åŒ–å®Œäº†: Î³={self.gamma_opt:.6f}, Î´={self.delta_opt:.6f}, Nc={self.Nc_opt:.6f}")
                logger.info(f"ğŸ“Š æœ€é©åŒ–ã‚¹ã‚³ã‚¢: {-result.fun:.6f}")
            else:
                logger.warning("âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_comprehensive_analysis(self, t_min=10, t_max=100, resolution=10000):
        """v2.0 åŒ…æ‹¬çš„è§£æå®Ÿè¡Œ"""
        logger.info("ğŸš€ v2.0 åŒ…æ‹¬çš„NKATè§£æé–‹å§‹")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        # ãƒ¡ãƒ¢ãƒªçŠ¶æ³ç¢ºèª
        self.memory_manager.check_memory_pressure()
        
        # 1. é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
        logger.info("ğŸ”§ 1. é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–")
        self.adaptive_parameter_optimization()
        
        # 2. MLé›¶ç‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        logger.info("ğŸ¤– 2. MLé›¶ç‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        ml_success = self.ml_predictor.train_on_known_zeros(self.known_zeros)
        
        # 3. é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è§£æ
        logger.info("ğŸ”¬ 3. é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿é–¢æ•°è§£æ")
        t_values = np.linspace(t_min, t_max, resolution)
        
        # åˆ†å‰²å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        batch_size = min(1000, resolution // 10)
        zeta_results = []
        
        for i in tqdm(range(0, len(t_values), batch_size), desc="é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿è¨ˆç®—"):
            batch_end = min(i + batch_size, len(t_values))
            t_batch = t_values[i:batch_end]
            
            s_batch = [0.5 + 1j * t for t in t_batch]
            zeta_batch = self.zeta_engine.compute_zeta_high_precision(s_batch, method='adaptive')
            zeta_results.extend(zeta_batch)
            
            # ãƒ¡ãƒ¢ãƒªåœ§è¿«ãƒã‚§ãƒƒã‚¯
            if i % (batch_size * 5) == 0:
                self.memory_manager.check_memory_pressure()
        
        zeta_values = np.array(zeta_results)
        magnitude = np.abs(zeta_values)
        
        # 4. MLäºˆæ¸¬ã¨çµ„ã¿åˆã‚ã›ãŸé›¶ç‚¹æ¤œå‡º
        logger.info("ğŸ¯ 4. MLå¼·åŒ–é›¶ç‚¹æ¤œå‡º")
        
        # å¾“æ¥ã®é–¾å€¤ãƒ™ãƒ¼ã‚¹æ¤œå‡º
        threshold = np.percentile(magnitude, 5)
        traditional_candidates = t_values[magnitude < threshold]
        
        # MLäºˆæ¸¬ã«ã‚ˆã‚‹å€™è£œ
        ml_candidates = []
        if ml_success:
            ml_probabilities = self.ml_predictor.predict_zero_probability(t_values)
            ml_threshold = np.percentile(ml_probabilities, 95)
            ml_candidates = t_values[ml_probabilities > ml_threshold]
        
        # çµ±åˆé›¶ç‚¹æ¤œå‡º
        all_candidates = np.concatenate([traditional_candidates, ml_candidates])
        unique_candidates = []
        
        for candidate in all_candidates:
            is_duplicate = False
            for existing in unique_candidates:
                if abs(candidate - existing) < 0.1:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_candidates.append(candidate)
        
        detected_zeros = np.array(unique_candidates)
        
        # 5. é«˜ç²¾åº¦æ¤œè¨¼
        logger.info("ğŸ” 5. é«˜ç²¾åº¦é›¶ç‚¹æ¤œè¨¼")
        verified_zeros = []
        
        for candidate in tqdm(detected_zeros, desc="é›¶ç‚¹æ¤œè¨¼"):
            if self._verify_zero_v2(candidate):
                verified_zeros.append(candidate)
        
        verified_zeros = np.array(verified_zeros)
        
        # 6. çµæœåˆ†æã¨å¯è¦–åŒ–
        logger.info("ğŸ“Š 6. çµæœåˆ†æãƒ»å¯è¦–åŒ–")
        analysis_results = self._analyze_results_v2(
            t_values, zeta_values, verified_zeros, 
            traditional_candidates, ml_candidates if ml_success else []
        )
        
        # 7. çµæœä¿å­˜
        end_time = time.time()
        execution_time = end_time - start_time
        
        final_results = {
            'version': '2.0',
            'timestamp': datetime.now().isoformat(),
            'execution_time_seconds': execution_time,
            'parameters': {
                'gamma_opt': self.gamma_opt,
                'delta_opt': self.delta_opt,
                'Nc_opt': self.Nc_opt,
                'theta': self.theta,
                'lambda_nc': self.lambda_nc,
                'alpha_ml': self.alpha_ml,
                'beta_adaptive': self.beta_adaptive
            },
            'analysis_range': {'t_min': t_min, 't_max': t_max, 'resolution': resolution},
            'detected_zeros': verified_zeros.tolist(),
            'traditional_candidates': traditional_candidates.tolist(),
            'ml_candidates': ml_candidates.tolist() if ml_success else [],
            'ml_model_trained': ml_success,
            'analysis_results': analysis_results,
            'system_info': {
                'cupy_available': self.cupy_available,
                'pytorch_cuda': self.pytorch_cuda,
                'gpu_device': torch.cuda.get_device_name() if self.pytorch_cuda else None
            }
        }
        
        # çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nkat_v2_comprehensive_analysis_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ v2.0 è§£æçµæœä¿å­˜: {filename}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        logger.info("=" * 80)
        logger.info("ğŸ† NKAT v2.0 åŒ…æ‹¬çš„è§£æ æœ€çµ‚æˆæœ")
        logger.info("=" * 80)
        logger.info(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        logger.info(f"ğŸ”¬ è§£æç¯„å›²: t âˆˆ [{t_min}, {t_max}], è§£åƒåº¦: {resolution:,}")
        logger.info(f"ğŸ¯ æ¤œè¨¼æ¸ˆã¿é›¶ç‚¹: {len(verified_zeros)}å€‹")
        logger.info(f"ğŸ¤– MLäºˆæ¸¬: {'æœ‰åŠ¹' if ml_success else 'ç„¡åŠ¹'}")
        logger.info(f"ğŸ“Š å¾“æ¥æ‰‹æ³•å€™è£œ: {len(traditional_candidates)}å€‹")
        
        if ml_success:
            logger.info(f"ğŸ¤– MLäºˆæ¸¬å€™è£œ: {len(ml_candidates)}å€‹")
        
        # æ—¢çŸ¥é›¶ç‚¹ã¨ã®æ¯”è¼ƒ
        matches = 0
        for detected in verified_zeros:
            for known in self.known_zeros:
                if t_min <= known <= t_max and abs(detected - known) < 0.5:
                    matches += 1
                    break
        
        known_in_range = sum(1 for known in self.known_zeros if t_min <= known <= t_max)
        accuracy = (matches / known_in_range * 100) if known_in_range > 0 else 0
        
        logger.info(f"ğŸ¯ æ¤œå‡ºç²¾åº¦: {accuracy:.2f}% ({matches}/{known_in_range})")
        logger.info("ğŸŒŸ å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - v2.0è§£æå®Œäº†!")
        
        return final_results
    
    def _verify_zero_v2(self, t_candidate, tolerance=1e-4):
        """v2.0 é«˜ç²¾åº¦é›¶ç‚¹æ¤œè¨¼"""
        try:
            # å¤šæ®µéšæ¤œè¨¼
            verification_points = np.linspace(t_candidate - 0.01, t_candidate + 0.01, 21)
            s_values = [0.5 + 1j * t for t in verification_points]
            
            zeta_values = self.zeta_engine.compute_zeta_high_precision(s_values, method='adaptive')
            magnitudes = np.abs(zeta_values)
            
            min_magnitude = np.min(magnitudes)
            min_idx = np.argmin(magnitudes)
            
            # ã‚ˆã‚Šå³ã—ã„æ¤œè¨¼æ¡ä»¶
            return (min_magnitude < tolerance and 
                    magnitudes[min_idx] < magnitudes[max(0, min_idx-1)] and
                    magnitudes[min_idx] < magnitudes[min(len(magnitudes)-1, min_idx+1)])
            
        except Exception as e:
            logger.warning(f"é›¶ç‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ t={t_candidate}: {e}")
            return False
    
    def _analyze_results_v2(self, t_values, zeta_values, verified_zeros, traditional_candidates, ml_candidates):
        """v2.0 çµæœåˆ†æ"""
        magnitude = np.abs(zeta_values)
        
        analysis = {
            'zeta_statistics': {
                'mean_magnitude': float(np.mean(magnitude)),
                'std_magnitude': float(np.std(magnitude)),
                'min_magnitude': float(np.min(magnitude)),
                'max_magnitude': float(np.max(magnitude)),
                'median_magnitude': float(np.median(magnitude))
            },
            'zero_detection': {
                'verified_count': len(verified_zeros),
                'traditional_candidates': len(traditional_candidates),
                'ml_candidates': len(ml_candidates),
                'verification_rate': len(verified_zeros) / max(1, len(traditional_candidates) + len(ml_candidates))
            },
            'performance_metrics': self.memory_manager.get_memory_info()
        }
        
        # å¯è¦–åŒ–ç”Ÿæˆ
        self._create_comprehensive_visualization_v2(
            t_values, magnitude, verified_zeros, traditional_candidates, ml_candidates
        )
        
        return analysis
    
    def _create_comprehensive_visualization_v2(self, t_values, magnitude, verified_zeros, traditional_candidates, ml_candidates):
        """v2.0 åŒ…æ‹¬çš„å¯è¦–åŒ–"""
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
        
        # 1. ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰
        ax1.semilogy(t_values, magnitude, 'b-', linewidth=0.8, alpha=0.7, label='|Î¶(1/2+it)|')
        
        if len(verified_zeros) > 0:
            ax1.scatter(verified_zeros, [0.001] * len(verified_zeros), 
                       color='red', s=100, marker='o', label=f'æ¤œè¨¼æ¸ˆã¿é›¶ç‚¹ ({len(verified_zeros)})', zorder=5)
        
        if len(traditional_candidates) > 0:
            ax1.scatter(traditional_candidates, [0.002] * len(traditional_candidates),
                       color='orange', s=50, marker='^', alpha=0.7, label=f'å¾“æ¥å€™è£œ ({len(traditional_candidates)})', zorder=4)
        
        if len(ml_candidates) > 0:
            ax1.scatter(ml_candidates, [0.003] * len(ml_candidates),
                       color='green', s=50, marker='s', alpha=0.7, label=f'MLå€™è£œ ({len(ml_candidates)})', zorder=4)
        
        ax1.set_xlabel('t')
        ax1.set_ylabel('|Î¶(1/2+it)|')
        ax1.set_title('v2.0 ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è§£æ - MLå¼·åŒ–ç‰ˆ')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(1e-4, 10)
        
        # 2. çµ±è¨ˆåˆ†å¸ƒ
        ax2.hist(magnitude, bins=100, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.axvline(np.mean(magnitude), color='red', linestyle='--', label=f'å¹³å‡: {np.mean(magnitude):.4f}')
        ax2.axvline(np.median(magnitude), color='green', linestyle='--', label=f'ä¸­å¤®å€¤: {np.median(magnitude):.4f}')
        ax2.set_xlabel('|Î¶(1/2+it)|')
        ax2.set_ylabel('é »åº¦')
        ax2.set_title('ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰åˆ†å¸ƒ')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # 3. é›¶ç‚¹å¯†åº¦åˆ†æ
        if len(verified_zeros) > 0:
            zero_spacing = np.diff(np.sort(verified_zeros))
            ax3.hist(zero_spacing, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
            ax3.set_xlabel('é›¶ç‚¹é–“éš”')
            ax3.set_ylabel('é »åº¦')
            ax3.set_title(f'é›¶ç‚¹é–“éš”åˆ†å¸ƒ (å¹³å‡: {np.mean(zero_spacing):.3f})')
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'é›¶ç‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('é›¶ç‚¹é–“éš”åˆ†å¸ƒ')
        
        # 4. ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ã‚µãƒãƒªãƒ¼
        performance_data = {
            'v2.0æ©Ÿèƒ½': ['é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿', 'MLäºˆæ¸¬', 'é©å¿œæœ€é©åŒ–', 'ãƒ¡ãƒ¢ãƒªç®¡ç†', 'ä¸¦åˆ—å‡¦ç†'],
            'å®Ÿè£…çŠ¶æ³': [1, 1, 1, 1, 1]
        }
        
        bars = ax4.barh(performance_data['v2.0æ©Ÿèƒ½'], performance_data['å®Ÿè£…çŠ¶æ³'], 
                       color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc'])
        ax4.set_xlabel('å®Ÿè£…çŠ¶æ³')
        ax4.set_title('v2.0 æ©Ÿèƒ½å®Ÿè£…çŠ¶æ³')
        ax4.set_xlim(0, 1.2)
        
        for i, bar in enumerate(bars):
            ax4.text(1.05, bar.get_y() + bar.get_height()/2, 'âœ…', 
                    ha='center', va='center', fontsize=14, color='green')
        
        plt.tight_layout()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nkat_v2_comprehensive_analysis_{timestamp}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        logger.info(f"ğŸ“Š v2.0 å¯è¦–åŒ–ä¿å­˜: {filename}")
        
        plt.show()

def main():
    """v2.0 ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ NKAT v2.0 è¶…é«˜é€Ÿãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ ")
    logger.info("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPU+MLä¸¦åˆ—è¨ˆç®—ç‰ˆ")
    logger.info("ğŸ® CuPy + PyTorch + ML + åˆ†æ•£ä¸¦åˆ— + Windows 11æœ€é©åŒ–")
    logger.info("=" * 80)
    
    try:
        # v2.0 è§£æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        analyzer = CUDANKATRiemannAnalysisV2()
        
        # åŒ…æ‹¬çš„è§£æå®Ÿè¡Œ
        results = analyzer.run_comprehensive_analysis(
            t_min=10, 
            t_max=70, 
            resolution=5000  # é«˜è§£åƒåº¦è§£æ
        )
        
        logger.info("âœ… v2.0 è§£æå®Œäº†!")
        logger.info("ğŸš€ GPU+MLä¸¦åˆ—è¨ˆç®—ã«ã‚ˆã‚‹è¶…é«˜é€ŸNKATç†è«–å®Ÿè£…æˆåŠŸ!")
        
        return results
        
    except KeyboardInterrupt:
        logger.warning("â¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦è§£æãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"âŒ v2.0 è§£æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

if __name__ == "__main__":
    main() 
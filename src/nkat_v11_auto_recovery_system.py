#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ›¡ï¸ NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ  - é›»æºæ–­å¯¾å¿œ
NKAT v11 Auto Recovery System - Power Failure Protection

Author: NKAT Research Consortium
Date: 2025-05-26
Version: 11.0 - Auto Recovery System
"""

import os
import sys
import json
import time
import pickle
import psutil
import subprocess
import threading
import signal
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from dataclasses import dataclass, asdict
import shutil
import hashlib

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_v11_recovery.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class RecoveryState:
    """ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ç®¡ç†"""
    timestamp: str
    process_states: Dict[str, Any]
    system_metrics: Dict[str, float]
    checkpoint_info: Dict[str, str]
    verification_progress: Dict[str, Any]
    last_successful_operation: str
    recovery_count: int
    
@dataclass
class ProcessInfo:
    """ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±"""
    name: str
    pid: int
    command: str
    start_time: str
    status: str
    memory_usage: float
    cpu_usage: float

class NKATAutoRecoverySystem:
    """NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_path = Path(".")
        self.recovery_dir = Path("recovery_data")
        self.recovery_dir.mkdir(exist_ok=True)
        
        # çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«
        self.state_file = self.recovery_dir / "recovery_state.pkl"
        self.process_registry = self.recovery_dir / "process_registry.json"
        self.checkpoint_registry = self.recovery_dir / "checkpoint_registry.json"
        
        # ç›£è¦–å¯¾è±¡ãƒ—ãƒ­ã‚»ã‚¹
        self.monitored_processes = [
            "nkat_v11_rigorous_mathematical_verification.py",
            "nkat_v11_enhanced_large_scale_verification.py",
            "riemann_high_precision.py",
            "nkat_v11_results_visualization.py"
        ]
        
        # é‡è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.critical_directories = [
            "rigorous_verification_results",
            "enhanced_verification_results",
            "10k_gamma_checkpoints_production",
            "test_checkpoints"
        ]
        
        # ãƒªã‚«ãƒãƒªãƒ¼è¨­å®š
        self.recovery_config = {
            "auto_restart": True,
            "backup_interval": 300,  # 5åˆ†
            "health_check_interval": 60,  # 1åˆ†
            "max_recovery_attempts": 3,
            "process_timeout": 3600,  # 1æ™‚é–“
            "memory_threshold": 90,  # %
            "cpu_threshold": 95  # %
        }
        
        # å®Ÿè¡ŒçŠ¶æ…‹
        self.is_monitoring = False
        self.recovery_threads = []
        self.last_backup_time = datetime.now()
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        logger.info("ğŸ›¡ï¸ NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆç·Šæ€¥åœæ­¢æ™‚ã®å‡¦ç†ï¼‰"""
        logger.warning(f"âš ï¸ ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã€ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œä¸­...")
        self.emergency_backup()
        self.stop_monitoring()
        sys.exit(0)
    
    def save_recovery_state(self, state: RecoveryState):
        """ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ã®ä¿å­˜"""
        try:
            with open(self.state_file, 'wb') as f:
                pickle.dump(asdict(state), f)
            logger.debug(f"ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ä¿å­˜å®Œäº†: {state.timestamp}")
        except Exception as e:
            logger.error(f"ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_recovery_state(self) -> Optional[RecoveryState]:
        """ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿"""
        try:
            if self.state_file.exists():
                with open(self.state_file, 'rb') as f:
                    state_dict = pickle.load(f)
                return RecoveryState(**state_dict)
        except Exception as e:
            logger.error(f"ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    def get_system_metrics(self) -> Dict[str, float]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('.')
            
            metrics = {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_available": memory.available / 1e9,
                "disk_percent": disk.percent,
                "disk_free": disk.free / 1e9,
                "timestamp": time.time()
            }
            
            # GPUæƒ…å ±ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            try:
                import torch
                if torch.cuda.is_available():
                    metrics["gpu_memory_used"] = torch.cuda.memory_allocated() / 1e9
                    metrics["gpu_memory_total"] = torch.cuda.get_device_properties(0).total_memory / 1e9
            except ImportError:
                pass
            
            return metrics
        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def get_process_info(self) -> List[ProcessInfo]:
        """ç›£è¦–å¯¾è±¡ãƒ—ãƒ­ã‚»ã‚¹ã®æƒ…å ±å–å¾—"""
        process_list = []
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time', 'status', 'memory_percent', 'cpu_percent']):
            try:
                if proc.info['cmdline']:
                    cmdline_str = ' '.join(proc.info['cmdline'])
                    for monitored in self.monitored_processes:
                        if monitored in cmdline_str:
                            process_info = ProcessInfo(
                                name=monitored,
                                pid=proc.info['pid'],
                                command=cmdline_str,
                                start_time=datetime.fromtimestamp(proc.info['create_time']).isoformat(),
                                status=proc.info['status'],
                                memory_usage=proc.info['memory_percent'] or 0.0,
                                cpu_usage=proc.info['cpu_percent'] or 0.0
                            )
                            process_list.append(process_info)
                            break
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        return process_list
    
    def create_checkpoint(self, checkpoint_type: str = "auto") -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_id = f"{checkpoint_type}_{timestamp}"
            checkpoint_dir = self.recovery_dir / "checkpoints" / checkpoint_id
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ä¿å­˜
            system_metrics = self.get_system_metrics()
            process_info = self.get_process_info()
            
            checkpoint_data = {
                "checkpoint_id": checkpoint_id,
                "timestamp": timestamp,
                "checkpoint_type": checkpoint_type,
                "system_metrics": system_metrics,
                "process_info": [asdict(p) for p in process_info],
                "critical_files": []
            }
            
            # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            for directory in self.critical_directories:
                dir_path = Path(directory)
                if dir_path.exists():
                    backup_dir = checkpoint_dir / directory
                    backup_dir.mkdir(parents=True, exist_ok=True)
                    
                    # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå®¹é‡ç¯€ç´„ï¼‰
                    for file_pattern in ["*.json", "*.pkl", "*.log"]:
                        files = list(dir_path.glob(file_pattern))
                        if files:
                            latest_file = max(files, key=lambda x: x.stat().st_mtime)
                            backup_file = backup_dir / latest_file.name
                            shutil.copy2(latest_file, backup_file)
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã‚’è¨˜éŒ²
                            file_hash = self.calculate_file_hash(latest_file)
                            checkpoint_data["critical_files"].append({
                                "original_path": str(latest_file),
                                "backup_path": str(backup_file),
                                "hash": file_hash,
                                "size": latest_file.stat().st_size
                            })
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®ä¿å­˜
            checkpoint_file = checkpoint_dir / "checkpoint_info.json"
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
            
            # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªæ›´æ–°
            self.update_checkpoint_registry(checkpoint_id, checkpoint_data)
            
            logger.info(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†: {checkpoint_id}")
            return checkpoint_id
            
        except Exception as e:
            logger.error(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã®è¨ˆç®—"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def update_checkpoint_registry(self, checkpoint_id: str, checkpoint_data: Dict):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®æ›´æ–°"""
        try:
            registry = {}
            if self.checkpoint_registry.exists():
                with open(self.checkpoint_registry, 'r', encoding='utf-8') as f:
                    registry = json.load(f)
            
            registry[checkpoint_id] = {
                "timestamp": checkpoint_data["timestamp"],
                "type": checkpoint_data["checkpoint_type"],
                "file_count": len(checkpoint_data["critical_files"]),
                "system_metrics": checkpoint_data["system_metrics"]
            }
            
            # å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤ï¼ˆæœ€æ–°10å€‹ã‚’ä¿æŒï¼‰
            if len(registry) > 10:
                sorted_checkpoints = sorted(registry.items(), key=lambda x: x[1]["timestamp"])
                for old_checkpoint, _ in sorted_checkpoints[:-10]:
                    old_checkpoint_dir = self.recovery_dir / "checkpoints" / old_checkpoint
                    if old_checkpoint_dir.exists():
                        shutil.rmtree(old_checkpoint_dir)
                    del registry[old_checkpoint]
            
            with open(self.checkpoint_registry, 'w', encoding='utf-8') as f:
                json.dump(registry, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def emergency_backup(self):
        """ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        logger.warning("ğŸš¨ ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œä¸­...")
        checkpoint_id = self.create_checkpoint("emergency")
        if checkpoint_id:
            logger.info(f"âœ… ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {checkpoint_id}")
        else:
            logger.error("âŒ ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—")
    
    def restore_from_checkpoint(self, checkpoint_id: str) -> bool:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®å¾©å…ƒ"""
        try:
            checkpoint_dir = self.recovery_dir / "checkpoints" / checkpoint_id
            checkpoint_file = checkpoint_dir / "checkpoint_info.json"
            
            if not checkpoint_file.exists():
                logger.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {checkpoint_id}")
                return False
            
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
            
            logger.info(f"ğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒä¸­: {checkpoint_id}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©å…ƒ
            for file_info in checkpoint_data["critical_files"]:
                backup_path = Path(file_info["backup_path"])
                original_path = Path(file_info["original_path"])
                
                if backup_path.exists():
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                    original_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ
                    shutil.copy2(backup_path, original_path)
                    
                    # ãƒãƒƒã‚·ãƒ¥æ¤œè¨¼
                    restored_hash = self.calculate_file_hash(original_path)
                    if restored_hash == file_info["hash"]:
                        logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒæˆåŠŸ: {original_path}")
                    else:
                        logger.warning(f"âš ï¸ ãƒãƒƒã‚·ãƒ¥ä¸ä¸€è‡´: {original_path}")
                else:
                    logger.warning(f"âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_path}")
            
            logger.info(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒå®Œäº†: {checkpoint_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def restart_process(self, process_name: str) -> bool:
        """ãƒ—ãƒ­ã‚»ã‚¹ã®å†èµ·å‹•"""
        try:
            logger.info(f"ğŸ”„ ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•: {process_name}")
            
            # æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†
            for proc in psutil.process_iter(['pid', 'cmdline']):
                try:
                    if proc.info['cmdline']:
                        cmdline_str = ' '.join(proc.info['cmdline'])
                        if process_name in cmdline_str:
                            proc.terminate()
                            proc.wait(timeout=10)
                            logger.info(f"âœ… ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†: PID {proc.pid}")
                except (psutil.NoSuchProcess, psutil.TimeoutExpired):
                    pass
            
            # æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ã®é–‹å§‹
            if Path(process_name).exists():
                subprocess.Popen([sys.executable, process_name], 
                               cwd=self.base_path,
                               stdout=subprocess.DEVNULL,
                               stderr=subprocess.DEVNULL)
                logger.info(f"âœ… ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹: {process_name}")
                return True
            else:
                logger.error(f"âŒ ãƒ—ãƒ­ã‚»ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {process_name}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def health_check(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        health_status = {
            "timestamp": datetime.now().isoformat(),
            "overall_health": "healthy",
            "issues": [],
            "recommendations": []
        }
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒã‚§ãƒƒã‚¯
            metrics = self.get_system_metrics()
            
            if metrics.get("memory_percent", 0) > self.recovery_config["memory_threshold"]:
                health_status["issues"].append("é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡")
                health_status["recommendations"].append("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–")
                health_status["overall_health"] = "warning"
            
            if metrics.get("cpu_percent", 0) > self.recovery_config["cpu_threshold"]:
                health_status["issues"].append("é«˜CPUä½¿ç”¨ç‡")
                health_status["recommendations"].append("CPUè² è·ã®åˆ†æ•£")
                health_status["overall_health"] = "warning"
            
            if metrics.get("disk_percent", 0) > 90:
                health_status["issues"].append("ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³")
                health_status["recommendations"].append("ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
                health_status["overall_health"] = "critical"
            
            # ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚§ãƒƒã‚¯
            processes = self.get_process_info()
            active_processes = [p.name for p in processes]
            
            for monitored in self.monitored_processes:
                if monitored not in active_processes:
                    health_status["issues"].append(f"ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢: {monitored}")
                    health_status["recommendations"].append(f"ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•: {monitored}")
                    if health_status["overall_health"] == "healthy":
                        health_status["overall_health"] = "warning"
            
            # é•·æ™‚é–“å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ã®ãƒã‚§ãƒƒã‚¯
            for process in processes:
                start_time = datetime.fromisoformat(process.start_time)
                runtime = datetime.now() - start_time
                if runtime.total_seconds() > self.recovery_config["process_timeout"]:
                    health_status["issues"].append(f"é•·æ™‚é–“å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹: {process.name}")
                    health_status["recommendations"].append(f"ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ç¢ºèª: {process.name}")
            
        except Exception as e:
            logger.error(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            health_status["overall_health"] = "error"
            health_status["issues"].append(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return health_status
    
    def auto_recovery_loop(self):
        """è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ãƒ«ãƒ¼ãƒ—"""
        logger.info("ğŸ”„ è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ãƒ«ãƒ¼ãƒ—é–‹å§‹")
        
        while self.is_monitoring:
            try:
                # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                health_status = self.health_check()
                
                # å•é¡ŒãŒã‚ã‚‹å ´åˆã®å¯¾å‡¦
                if health_status["overall_health"] in ["warning", "critical"]:
                    logger.warning(f"âš ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {health_status['overall_health']}")
                    
                    # åœæ­¢ãƒ—ãƒ­ã‚»ã‚¹ã®å†èµ·å‹•
                    for issue in health_status["issues"]:
                        if "ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢" in issue:
                            process_name = issue.split(": ")[1]
                            if self.recovery_config["auto_restart"]:
                                self.restart_process(process_name)
                
                # å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                if (datetime.now() - self.last_backup_time).total_seconds() > self.recovery_config["backup_interval"]:
                    self.create_checkpoint("auto")
                    self.last_backup_time = datetime.now()
                
                # ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ…‹ã®ä¿å­˜
                current_state = RecoveryState(
                    timestamp=datetime.now().isoformat(),
                    process_states={p.name: asdict(p) for p in self.get_process_info()},
                    system_metrics=self.get_system_metrics(),
                    checkpoint_info={"last_checkpoint": self.last_backup_time.isoformat()},
                    verification_progress={},
                    last_successful_operation="health_check",
                    recovery_count=0
                )
                self.save_recovery_state(current_state)
                
                # å¾…æ©Ÿ
                time.sleep(self.recovery_config["health_check_interval"])
                
            except Exception as e:
                logger.error(f"âŒ è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(30)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯çŸ­ã„é–“éš”ã§å†è©¦è¡Œ
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if self.is_monitoring:
            logger.warning("âš ï¸ ç›£è¦–ã¯æ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™")
            return
        
        self.is_monitoring = True
        
        # åˆæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ
        self.create_checkpoint("startup")
        
        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        recovery_thread = threading.Thread(target=self.auto_recovery_loop, daemon=True)
        recovery_thread.start()
        self.recovery_threads.append(recovery_thread)
        
        logger.info("ğŸš€ NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ç›£è¦–é–‹å§‹")
        print("ğŸ›¡ï¸ NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        print("ğŸ“Š ç›£è¦–å¯¾è±¡ãƒ—ãƒ­ã‚»ã‚¹:", self.monitored_processes)
        print("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”:", f"{self.recovery_config['backup_interval']}ç§’")
        print("ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–“éš”:", f"{self.recovery_config['health_check_interval']}ç§’")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        if not self.is_monitoring:
            return
        
        logger.info("ğŸ›‘ è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ç›£è¦–åœæ­¢ä¸­...")
        self.is_monitoring = False
        
        # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ
        self.create_checkpoint("shutdown")
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†å¾…æ©Ÿ
        for thread in self.recovery_threads:
            thread.join(timeout=5)
        
        logger.info("âœ… è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ç›£è¦–åœæ­¢å®Œäº†")
    
    def get_recovery_status(self) -> Dict[str, Any]:
        """ãƒªã‚«ãƒãƒªãƒ¼çŠ¶æ³ã®å–å¾—"""
        status = {
            "monitoring_active": self.is_monitoring,
            "last_backup": self.last_backup_time.isoformat(),
            "health_status": self.health_check(),
            "checkpoint_count": 0,
            "recovery_config": self.recovery_config
        }
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°ã®å–å¾—
        if self.checkpoint_registry.exists():
            try:
                with open(self.checkpoint_registry, 'r', encoding='utf-8') as f:
                    registry = json.load(f)
                status["checkpoint_count"] = len(registry)
            except:
                pass
        
        return status

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    recovery_system = NKATAutoRecoverySystem()
    
    try:
        # ç›£è¦–é–‹å§‹
        recovery_system.start_monitoring()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆCtrl+Cã§çµ‚äº†ï¼‰
        while True:
            time.sleep(10)
            status = recovery_system.get_recovery_status()
            print(f"\rğŸ›¡ï¸ ç›£è¦–ä¸­... ãƒ˜ãƒ«ã‚¹: {status['health_status']['overall_health']} | "
                  f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {status['checkpoint_count']}å€‹", end="", flush=True)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç›£è¦–åœæ­¢è¦æ±‚ã‚’å—ä¿¡")
    finally:
        recovery_system.stop_monitoring()
        print("âœ… NKAT v11 è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")

if __name__ == "__main__":
    main() 
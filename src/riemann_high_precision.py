#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã®é«˜ç²¾åº¦æ•°å€¤æ¤œè¨¼
High-Precision Riemann Hypothesis Verification using NKAT Theory

Author: NKAT Research Team
Date: 2025-05-24
Version: 5.0 - High Precision Implementation
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Optional, Dict
import warnings
from pathlib import Path
import json
import time
from dataclasses import dataclass
from tqdm import tqdm, trange
import logging

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
    print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

class HighPrecisionNKATHamiltonian(nn.Module):
    """
    é«˜ç²¾åº¦NKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®å®Ÿè£…
    
    æ”¹è‰¯ç‚¹:
    1. complex128ç²¾åº¦ã®ä½¿ç”¨
    2. ã‚ˆã‚Šå¤§ããªæ ¼å­ã‚µã‚¤ã‚º
    3. æ”¹è‰¯ã•ã‚ŒãŸæ•°å€¤å®‰å®šæ€§
    4. é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
    """
    
    def __init__(self, max_n: int = 2000, theta: float = 1e-25, kappa: float = 1e-15, 
                 precision: str = 'high'):
        super().__init__()
        self.max_n = max_n
        self.theta = theta
        self.kappa = kappa
        self.precision = precision
        self.device = device
        
        # ç²¾åº¦è¨­å®š
        if precision == 'high':
            self.dtype = torch.complex128
            self.float_dtype = torch.float64
        else:
            self.dtype = torch.complex64
            self.float_dtype = torch.float32
        
        logger.info(f"ğŸ”§ é«˜ç²¾åº¦NKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³åˆæœŸåŒ–: max_n={max_n}, ç²¾åº¦={precision}")
        
        # ç´ æ•°ãƒªã‚¹ãƒˆã®ç”Ÿæˆï¼ˆã‚ˆã‚ŠåŠ¹ç‡çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
        self.primes = self._generate_primes_optimized(max_n)
        logger.info(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸç´ æ•°æ•°: {len(self.primes)}")
        
        # ã‚¬ãƒ³ãƒè¡Œåˆ—ã®å®šç¾©
        self.gamma_matrices = self._construct_gamma_matrices()
        
    def _generate_primes_optimized(self, n: int) -> List[int]:
        """æœ€é©åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒˆã‚¹ãƒ†ãƒã‚¹ã®ç¯©"""
        if n < 2:
            return []
        
        sieve = [True] * (n + 1)
        sieve[0] = sieve[1] = False
        
        for i in range(2, int(n**0.5) + 1):
            if sieve[i]:
                for j in range(i*i, n + 1, i):
                    sieve[j] = False
        
        return [i for i in range(2, n + 1) if sieve[i]]
    
    def _construct_gamma_matrices(self) -> List[torch.Tensor]:
        """é«˜ç²¾åº¦ã‚¬ãƒ³ãƒè¡Œåˆ—ã®æ§‹ç¯‰"""
        # ãƒ‘ã‚¦ãƒªè¡Œåˆ—ï¼ˆé«˜ç²¾åº¦ï¼‰
        sigma_x = torch.tensor([[0, 1], [1, 0]], dtype=self.dtype, device=self.device)
        sigma_y = torch.tensor([[0, -1j], [1j, 0]], dtype=self.dtype, device=self.device)
        sigma_z = torch.tensor([[1, 0], [0, -1]], dtype=self.dtype, device=self.device)
        I2 = torch.eye(2, dtype=self.dtype, device=self.device)
        O2 = torch.zeros(2, 2, dtype=self.dtype, device=self.device)
        
        # ãƒ‡ã‚£ãƒ©ãƒƒã‚¯è¡Œåˆ—ã®æ§‹ç¯‰
        gamma = []
        
        # Î³^0 = [[I, 0], [0, -I]]
        gamma.append(torch.cat([torch.cat([I2, O2], dim=1), 
                               torch.cat([O2, -I2], dim=1)], dim=0))
        
        # Î³^i = [[0, Ïƒ_i], [-Ïƒ_i, 0]] for i=1,2,3
        for sigma in [sigma_x, sigma_y, sigma_z]:
            gamma.append(torch.cat([torch.cat([O2, sigma], dim=1),
                                   torch.cat([-sigma, O2], dim=1)], dim=0))
        
        logger.info(f"âœ… é«˜ç²¾åº¦ã‚¬ãƒ³ãƒè¡Œåˆ—æ§‹ç¯‰å®Œäº†: {len(gamma)}å€‹ã®{gamma[0].shape}è¡Œåˆ—")
        return gamma
    
    def construct_hamiltonian_adaptive(self, s: complex, adaptive_dim: bool = True) -> torch.Tensor:
        """
        é©å¿œçš„æ¬¡å…ƒèª¿æ•´ã‚’æŒã¤ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³æ§‹ç¯‰
        """
        # é©å¿œçš„æ¬¡å…ƒæ±ºå®š
        if adaptive_dim:
            s_magnitude = abs(s)
            if s_magnitude < 1:
                dim = min(self.max_n, 200)
            elif s_magnitude < 10:
                dim = min(self.max_n, 150)
            else:
                dim = min(self.max_n, 100)
        else:
            dim = min(self.max_n, 150)
        
        # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¡Œåˆ—ã®åˆæœŸåŒ–
        H = torch.zeros(dim, dim, dtype=self.dtype, device=self.device)
        
        # ä¸»è¦é …: Î£_n (1/n^s) |nâŸ©âŸ¨n| with improved numerical stability
        for n in range(1, dim + 1):
            try:
                # æ•°å€¤å®‰å®šæ€§ã®æ”¹å–„
                if abs(s.real) > 20 or abs(s.imag) > 200:
                    # æ¥µç«¯ãªå€¤ã§ã®å®‰å®šåŒ–
                    log_term = -s * np.log(n)
                    if log_term.real < -50:  # ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
                        H[n-1, n-1] = torch.tensor(1e-50, dtype=self.dtype, device=self.device)
                    else:
                        H[n-1, n-1] = torch.exp(torch.tensor(log_term, dtype=self.dtype, device=self.device))
                else:
                    # é€šå¸¸ã®è¨ˆç®—
                    H[n-1, n-1] = torch.tensor(1.0 / (n ** s), dtype=self.dtype, device=self.device)
            except (OverflowError, ZeroDivisionError, RuntimeError):
                H[n-1, n-1] = torch.tensor(1e-50, dtype=self.dtype, device=self.device)
        
        # éå¯æ›è£œæ­£é …ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        if self.theta != 0:
            theta_tensor = torch.tensor(self.theta, dtype=self.dtype, device=self.device)
            for i, p in enumerate(self.primes[:min(len(self.primes), 20)]):
                if p <= dim:
                    try:
                        # å¯¾æ•°é …ã®å®‰å®šåŒ–
                        log_p = torch.log(torch.tensor(p, dtype=self.float_dtype, device=self.device))
                        correction = theta_tensor * log_p.to(self.dtype)
                        
                        # äº¤æ›å­é …ã®è¿½åŠ  [x, p]
                        if p < dim - 1:
                            H[p-1, p] += correction * 1j
                            H[p, p-1] -= correction * 1j
                        
                        H[p-1, p-1] += correction
                    except:
                        continue
        
        # Îº-å¤‰å½¢è£œæ­£é …ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        if self.kappa != 0:
            kappa_tensor = torch.tensor(self.kappa, dtype=self.dtype, device=self.device)
            for i in range(min(dim, 30)):
                try:
                    # Minkowskiå¤‰å½¢é …
                    n = i + 1
                    log_term = torch.log(torch.tensor(n + 1, dtype=self.float_dtype, device=self.device))
                    kappa_correction = kappa_tensor * n * log_term.to(self.dtype)
                    
                    # éå¯¾è§’é …ã®è¿½åŠ 
                    if i < dim - 2:
                        H[i, i+1] += kappa_correction * 0.1
                        H[i+1, i] += kappa_correction.conj() * 0.1
                    
                    H[i, i] += kappa_correction
                except:
                    continue
        
        # æ­£å‰‡åŒ–é …ï¼ˆæ•°å€¤å®‰å®šæ€§å‘ä¸Šï¼‰
        regularization = torch.tensor(1e-12, dtype=self.dtype, device=self.device)
        H += regularization * torch.eye(dim, dtype=self.dtype, device=self.device)
        
        return H
    
    def compute_eigenvalues_stable(self, s: complex, n_eigenvalues: int = 100) -> torch.Tensor:
        """
        æ•°å€¤å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ãŸå›ºæœ‰å€¤è¨ˆç®—
        """
        try:
            H = self.construct_hamiltonian_adaptive(s)
            
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–ã®æ”¹è‰¯
            H_hermitian = 0.5 * (torch.mm(H.conj().T, H) + torch.mm(H, H.conj().T))
            
            # æ¡ä»¶æ•°ãƒã‚§ãƒƒã‚¯
            try:
                cond_num = torch.linalg.cond(H_hermitian)
                if cond_num > 1e12:
                    logger.warning(f"âš ï¸ é«˜ã„æ¡ä»¶æ•°ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {cond_num:.2e}")
                    # æ­£å‰‡åŒ–ã®å¼·åŒ–
                    reg_strength = 1e-10
                    H_hermitian += reg_strength * torch.eye(H_hermitian.shape[0], 
                                                          dtype=self.dtype, device=self.device)
            except:
                pass
            
            # NaN/Inf ãƒã‚§ãƒƒã‚¯
            if torch.isnan(H_hermitian).any() or torch.isinf(H_hermitian).any():
                logger.warning("âš ï¸ ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã«NaN/InfãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                return torch.tensor([], device=self.device, dtype=self.float_dtype)
            
            # å›ºæœ‰å€¤è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            try:
                eigenvalues, _ = torch.linalg.eigh(H_hermitian)
                eigenvalues = eigenvalues.real
            except RuntimeError as e:
                logger.warning(f"âš ï¸ å›ºæœ‰å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼ã€ä»£æ›¿æ‰‹æ³•ã‚’ä½¿ç”¨: {e}")
                # ä»£æ›¿æ‰‹æ³•ï¼šSVDåˆ†è§£
                U, S, Vh = torch.linalg.svd(H_hermitian)
                eigenvalues = S.real
            
            # æ­£ã®å›ºæœ‰å€¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            positive_mask = eigenvalues > 1e-15
            positive_eigenvalues = eigenvalues[positive_mask]
            
            # ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’é¸æŠ
            sorted_eigenvalues, _ = torch.sort(positive_eigenvalues, descending=True)
            
            return sorted_eigenvalues[:min(len(sorted_eigenvalues), n_eigenvalues)]
            
        except Exception as e:
            logger.error(f"âŒ å›ºæœ‰å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return torch.tensor([], device=self.device, dtype=self.float_dtype)

class HighPrecisionRiemannVerifier:
    """
    é«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, hamiltonian: HighPrecisionNKATHamiltonian):
        self.hamiltonian = hamiltonian
        self.device = hamiltonian.device
        
    def compute_spectral_dimension_improved(self, s: complex, 
                                          n_points: int = 50, 
                                          t_range: Tuple[float, float] = (1e-4, 1.0)) -> float:
        """
        æ”¹è‰¯ã•ã‚ŒãŸã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
        """
        eigenvalues = self.hamiltonian.compute_eigenvalues_stable(s, n_eigenvalues=150)
        
        if len(eigenvalues) < 10:
            logger.warning("âš ï¸ æœ‰åŠ¹ãªå›ºæœ‰å€¤ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return float('nan')
        
        try:
            # ã‚ˆã‚Šç´°ã‹ã„tå€¤ã®ã‚°ãƒªãƒƒãƒ‰
            t_min, t_max = t_range
            t_values = torch.logspace(np.log10(t_min), np.log10(t_max), n_points, device=self.device)
            zeta_values = []
            
            for t in t_values:
                # æ•°å€¤å®‰å®šæ€§ã®æ”¹å–„
                exp_terms = torch.exp(-t * eigenvalues)
                
                # ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼/ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–
                valid_mask = torch.isfinite(exp_terms) & (exp_terms > 1e-50)
                if torch.sum(valid_mask) < 3:
                    zeta_values.append(1e-50)
                    continue
                
                zeta_t = torch.sum(exp_terms[valid_mask])
                
                if torch.isfinite(zeta_t) and zeta_t > 1e-50:
                    zeta_values.append(zeta_t.item())
                else:
                    zeta_values.append(1e-50)
            
            zeta_values = torch.tensor(zeta_values, device=self.device)
            
            # å¯¾æ•°å¾®åˆ†ã®æ”¹è‰¯è¨ˆç®—
            log_t = torch.log(t_values)
            log_zeta = torch.log(zeta_values + 1e-50)
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ˆã‚Šå³å¯†ï¼‰
            valid_mask = (torch.isfinite(log_zeta) & 
                         torch.isfinite(log_t) & 
                         (log_zeta > -100) & 
                         (log_zeta < 100))
            
            if torch.sum(valid_mask) < 5:
                logger.warning("âš ï¸ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return float('nan')
            
            log_t_valid = log_t[valid_mask]
            log_zeta_valid = log_zeta[valid_mask]
            
            # é‡ã¿ä»˜ãç·šå½¢å›å¸°
            weights = torch.ones_like(log_t_valid)
            # ä¸­å¤®éƒ¨åˆ†ã«ã‚ˆã‚Šé«˜ã„é‡ã¿ã‚’ä»˜ä¸
            mid_idx = len(log_t_valid) // 2
            if mid_idx >= 2:
                weights[mid_idx-2:mid_idx+3] *= 2.0
            
            # é‡ã¿ä»˜ãæœ€å°äºŒä¹—æ³•
            W = torch.diag(weights)
            A = torch.stack([log_t_valid, torch.ones_like(log_t_valid)], dim=1)
            
            # (A^T W A)^{-1} A^T W y
            try:
                AtWA = torch.mm(torch.mm(A.T, W), A)
                AtWy = torch.mm(torch.mm(A.T, W), log_zeta_valid.unsqueeze(1))
                solution = torch.linalg.solve(AtWA, AtWy)
                slope = solution[0, 0]
            except:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé€šå¸¸ã®æœ€å°äºŒä¹—æ³•
                solution = torch.linalg.lstsq(A, log_zeta_valid).solution
                slope = solution[0]
            
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
            spectral_dimension = -2 * slope.item()
            
            # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šå³å¯†ï¼‰
            if abs(spectral_dimension) > 20 or not np.isfinite(spectral_dimension):
                logger.warning(f"âš ï¸ ç•°å¸¸ãªã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒå€¤: {spectral_dimension}")
                return float('nan')
            
            return spectral_dimension
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return float('nan')
    
    def verify_critical_line_high_precision(self, gamma_values: List[float], 
                                          iterations: int = 3) -> Dict:
        """
        é«˜ç²¾åº¦è‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼ï¼ˆè¤‡æ•°å›å®Ÿè¡Œã«ã‚ˆã‚‹çµ±è¨ˆçš„è©•ä¾¡ï¼‰
        """
        results = {
            'gamma_values': gamma_values,
            'spectral_dimensions_all': [],
            'real_parts_all': [],
            'convergence_to_half_all': [],
            'statistics': {}
        }
        
        logger.info(f"ğŸ” é«˜ç²¾åº¦è‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼é–‹å§‹ï¼ˆ{iterations}å›å®Ÿè¡Œï¼‰...")
        
        for iteration in range(iterations):
            logger.info(f"ğŸ“Š å®Ÿè¡Œ {iteration + 1}/{iterations}")
            
            spectral_dims = []
            real_parts = []
            convergences = []
            
            for gamma in tqdm(gamma_values, desc=f"å®Ÿè¡Œ{iteration+1}: Î³å€¤ã§ã®æ¤œè¨¼"):
                s = 0.5 + 1j * gamma
                
                # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒã®è¨ˆç®—
                d_s = self.compute_spectral_dimension_improved(s)
                spectral_dims.append(d_s)
                
                if not np.isnan(d_s):
                    # å®Ÿéƒ¨ã®è¨ˆç®—
                    real_part = d_s / 2
                    real_parts.append(real_part)
                    
                    # 1/2ã¸ã®åæŸæ€§
                    convergence = abs(real_part - 0.5)
                    convergences.append(convergence)
                else:
                    real_parts.append(np.nan)
                    convergences.append(np.nan)
            
            results['spectral_dimensions_all'].append(spectral_dims)
            results['real_parts_all'].append(real_parts)
            results['convergence_to_half_all'].append(convergences)
        
        # çµ±è¨ˆçš„è©•ä¾¡
        all_spectral_dims = np.array(results['spectral_dimensions_all'])
        all_real_parts = np.array(results['real_parts_all'])
        all_convergences = np.array(results['convergence_to_half_all'])
        
        # å„Î³å€¤ã§ã®çµ±è¨ˆ
        results['statistics'] = {
            'spectral_dimension_mean': np.nanmean(all_spectral_dims, axis=0).tolist(),
            'spectral_dimension_std': np.nanstd(all_spectral_dims, axis=0).tolist(),
            'real_part_mean': np.nanmean(all_real_parts, axis=0).tolist(),
            'real_part_std': np.nanstd(all_real_parts, axis=0).tolist(),
            'convergence_mean': np.nanmean(all_convergences, axis=0).tolist(),
            'convergence_std': np.nanstd(all_convergences, axis=0).tolist(),
        }
        
        # å…¨ä½“çµ±è¨ˆ
        valid_convergences = all_convergences[~np.isnan(all_convergences)]
        if len(valid_convergences) > 0:
            results['overall_statistics'] = {
                'mean_convergence': np.mean(valid_convergences),
                'std_convergence': np.std(valid_convergences),
                'min_convergence': np.min(valid_convergences),
                'max_convergence': np.max(valid_convergences),
                'success_rate': np.sum(valid_convergences < 1e-2) / len(valid_convergences)
            }
        
        return results

def demonstrate_high_precision_riemann():
    """
    é«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("=" * 80)
    print("ğŸ¯ NKATç†è«–ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼")
    print("=" * 80)
    print("ğŸ“… å®Ÿè¡Œæ—¥æ™‚:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ğŸ”¬ ç²¾åº¦: complex128 (å€ç²¾åº¦)")
    print("ğŸ§® æ”¹è‰¯ç‚¹: é©å¿œçš„æ¬¡å…ƒèª¿æ•´ã€æ•°å€¤å®‰å®šæ€§å‘ä¸Šã€çµ±è¨ˆçš„è©•ä¾¡")
    print("=" * 80)
    
    # é«˜ç²¾åº¦ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®åˆæœŸåŒ–
    logger.info("ğŸ”§ é«˜ç²¾åº¦NKATé‡å­ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³åˆæœŸåŒ–ä¸­...")
    hamiltonian = HighPrecisionNKATHamiltonian(
        max_n=1000,
        theta=1e-25,
        kappa=1e-15,
        precision='high'
    )
    
    # é«˜ç²¾åº¦æ¤œè¨¼å™¨ã®åˆæœŸåŒ–
    verifier = HighPrecisionRiemannVerifier(hamiltonian)
    
    # é«˜ç²¾åº¦è‡¨ç•Œç·šæ¤œè¨¼
    print("\nğŸ“Š é«˜ç²¾åº¦è‡¨ç•Œç·šåæŸæ€§æ¤œè¨¼")
    gamma_values = [14.134725, 21.022040, 25.010858, 30.424876, 32.935062]
    
    start_time = time.time()
    high_precision_results = verifier.verify_critical_line_high_precision(
        gamma_values, iterations=3
    )
    verification_time = time.time() - start_time
    
    # çµæœã®è¡¨ç¤º
    print("\né«˜ç²¾åº¦æ¤œè¨¼çµæœ:")
    print("Î³å€¤      | å¹³å‡d_s    | æ¨™æº–åå·®   | å¹³å‡Re     | |Re-1/2|å¹³å‡ | åæŸæ€§")
    print("-" * 75)
    
    stats = high_precision_results['statistics']
    for i, gamma in enumerate(gamma_values):
        mean_ds = stats['spectral_dimension_mean'][i]
        std_ds = stats['spectral_dimension_std'][i]
        mean_re = stats['real_part_mean'][i]
        mean_conv = stats['convergence_mean'][i]
        
        if not np.isnan(mean_ds):
            status = "âœ…" if mean_conv < 1e-1 else "âš ï¸"
            print(f"{gamma:8.6f} | {mean_ds:9.6f} | {std_ds:9.6f} | {mean_re:9.6f} | {mean_conv:10.6f} | {status}")
        else:
            print(f"{gamma:8.6f} | {'NaN':>9} | {'NaN':>9} | {'NaN':>9} | {'NaN':>10} | âŒ")
    
    # å…¨ä½“çµ±è¨ˆã®è¡¨ç¤º
    if 'overall_statistics' in high_precision_results:
        overall = high_precision_results['overall_statistics']
        print(f"\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
        print(f"å¹³å‡åæŸç‡: {overall['mean_convergence']:.8f}")
        print(f"æ¨™æº–åå·®: {overall['std_convergence']:.8f}")
        print(f"æˆåŠŸç‡: {overall['success_rate']:.2%}")
        print(f"æœ€è‰¯åæŸ: {overall['min_convergence']:.8f}")
    
    print(f"\nâ±ï¸  æ¤œè¨¼æ™‚é–“: {verification_time:.2f}ç§’")
    
    # çµæœã®ä¿å­˜
    with open('high_precision_riemann_results.json', 'w', encoding='utf-8') as f:
        json.dump(high_precision_results, f, indent=2, ensure_ascii=False, default=str)
    
    print("ğŸ’¾ é«˜ç²¾åº¦çµæœã‚’ 'high_precision_riemann_results.json' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    return high_precision_results

if __name__ == "__main__":
    """
    é«˜ç²¾åº¦ãƒªãƒ¼ãƒãƒ³äºˆæƒ³æ¤œè¨¼ã®å®Ÿè¡Œ
    """
    try:
        results = demonstrate_high_precision_riemann()
        print("ğŸ‰ é«˜ç²¾åº¦æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}") 
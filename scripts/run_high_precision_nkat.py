#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”¬ é«˜ç²¾åº¦NKATç†è«–è¨ˆç®—å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Non-Commutative Kolmogorov-Arnold Theory - é«˜ç²¾åº¦ç‰ˆ

Author: NKAT Research Team
Date: 2025-01-24
Version: 2.0 - é«˜ç²¾åº¦è¨ˆç®—ç‰¹åŒ–ç‰ˆ

ä¸»è¦æ©Ÿèƒ½:
- é«˜ç²¾åº¦ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
- ç†è«–å€¤ã¨ã®è©³ç´°æ¯”è¼ƒ
- åæŸè§£æ
- æ•°å€¤å®‰å®šæ€§è©•ä¾¡
- RTX3080æœ€é©åŒ–
"""

import sys
import os
import time
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.gpu.dirac_laplacian_analysis_gpu_recovery import (
    RecoveryGPUOperatorParameters,
    RecoveryGPUDiracLaplacianAnalyzer,
    setup_logger,
    monitor_gpu_memory
)

def setup_high_precision_environment():
    """é«˜ç²¾åº¦è¨ˆç®—ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    print("ğŸ”¬ é«˜ç²¾åº¦è¨ˆç®—ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    # PyTorchã®é«˜ç²¾åº¦è¨­å®š
    torch.set_default_dtype(torch.float64)
    
    # CUDAæœ€é©åŒ–è¨­å®š
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.backends.cuda.matmul.allow_tf32 = False  # é«˜ç²¾åº¦ã®ãŸã‚TF32ç„¡åŠ¹
        torch.backends.cudnn.allow_tf32 = False
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        torch.cuda.empty_cache()
        torch.cuda.set_per_process_memory_fraction(0.95)
        
        print(f"âœ… CUDAé«˜ç²¾åº¦è¨­å®šå®Œäº†")
        print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("âš ï¸  CUDAåˆ©ç”¨ä¸å¯ - CPUè¨ˆç®—ã«ãªã‚Šã¾ã™")
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    try:
        plt.rcParams['font.family'] = 'MS Gothic'
    except:
        plt.rcParams['font.family'] = 'DejaVu Sans'
    
    print("âœ… é«˜ç²¾åº¦è¨ˆç®—ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

def run_high_precision_analysis(dimension: int, lattice_size: int, 
                               n_eigenvalues: int = 50, 
                               n_trials: int = 3) -> dict:
    """é«˜ç²¾åº¦è§£æã®å®Ÿè¡Œ"""
    print(f"\nğŸ”¬ {dimension}æ¬¡å…ƒé«˜ç²¾åº¦è§£æé–‹å§‹")
    print(f"æ ¼å­ã‚µã‚¤ã‚º: {lattice_size}, å›ºæœ‰å€¤æ•°: {n_eigenvalues}, è©¦è¡Œå›æ•°: {n_trials}")
    
    # é«˜ç²¾åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    params = RecoveryGPUOperatorParameters(
        dimension=dimension,
        lattice_size=lattice_size,
        theta=0.001,  # æ¥µå°éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        kappa=0.001,
        mass=0.001,
        coupling=1.0,
        use_sparse=True,
        recovery_enabled=False,
        max_eigenvalues=n_eigenvalues,
        memory_limit_gb=9.0,
        use_mixed_precision=False,  # é«˜ç²¾åº¦ã®ãŸã‚æ··åˆç²¾åº¦ç„¡åŠ¹
        log_level=20  # INFO ãƒ¬ãƒ™ãƒ«
    )
    
    analyzer = RecoveryGPUDiracLaplacianAnalyzer(params)
    
    # è¤‡æ•°å›å®Ÿè¡Œã—ã¦çµ±è¨ˆã‚’å–ã‚‹
    results = []
    spectral_dimensions = []
    computation_times = []
    
    for trial in range(n_trials):
        print(f"\nğŸ“Š è©¦è¡Œ {trial+1}/{n_trials}")
        
        try:
            # GPU ãƒ¡ãƒ¢ãƒªç›£è¦–
            start_memory = monitor_gpu_memory()
            
            # è¨ˆç®—å®Ÿè¡Œ
            start_time = time.time()
            
            # ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰
            print("   ğŸ”¨ ãƒ‡ã‚£ãƒ©ãƒƒã‚¯ä½œç”¨ç´ æ§‹ç¯‰ä¸­...")
            construction_start = time.time()
            D = analyzer.construct_discrete_dirac_operator_gpu_optimized()
            construction_time = time.time() - construction_start
            
            # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—
            print("   ğŸ” é«˜ç²¾åº¦ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒè¨ˆç®—ä¸­...")
            spectral_start = time.time()
            d_s, info = analyzer.compute_spectral_dimension_gpu_optimized(
                D, n_eigenvalues=n_eigenvalues
            )
            spectral_time = time.time() - spectral_start
            
            total_time = time.time() - start_time
            
            # GPU ãƒ¡ãƒ¢ãƒªç›£è¦–
            end_memory = monitor_gpu_memory()
            memory_used = 0.0
            if end_memory and start_memory:
                memory_used = end_memory['usage_percent'] - start_memory['usage_percent']
            
            # çµæœè¨˜éŒ²
            trial_result = {
                'trial': trial + 1,
                'spectral_dimension': d_s,
                'construction_time': construction_time,
                'spectral_time': spectral_time,
                'total_time': total_time,
                'memory_used': memory_used,
                'matrix_size': D.shape[0],
                'nnz': D._nnz(),
                'eigenvalues_computed': info.get('n_eigenvalues', 0),
                'analysis_info': info
            }
            results.append(trial_result)
            spectral_dimensions.append(d_s)
            computation_times.append(total_time)
            
            print(f"   âœ… è©¦è¡Œ {trial+1} å®Œäº†:")
            print(f"      ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {d_s:.8f}")
            print(f"      è¨ˆç®—æ™‚é–“: {total_time:.2f}ç§’")
            print(f"      ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {memory_used:.1f}%")
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"   âŒ è©¦è¡Œ {trial+1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # çµ±è¨ˆè§£æ
    if spectral_dimensions:
        ds_mean = np.mean(spectral_dimensions)
        ds_std = np.std(spectral_dimensions)
        ds_min = np.min(spectral_dimensions)
        ds_max = np.max(spectral_dimensions)
        
        time_mean = np.mean(computation_times)
        time_std = np.std(computation_times)
        
        # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
        theoretical_ds = float(dimension)
        absolute_error = abs(ds_mean - theoretical_ds)
        relative_error = (absolute_error / theoretical_ds) * 100
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§è©•ä¾¡
        confidence_interval = 1.96 * ds_std / np.sqrt(len(spectral_dimensions))  # 95%ä¿¡é ¼åŒºé–“
        
        summary = {
            'dimension': dimension,
            'lattice_size': lattice_size,
            'n_eigenvalues': n_eigenvalues,
            'n_trials': len(spectral_dimensions),
            'spectral_dimension_mean': ds_mean,
            'spectral_dimension_std': ds_std,
            'spectral_dimension_min': ds_min,
            'spectral_dimension_max': ds_max,
            'confidence_interval': confidence_interval,
            'theoretical_dimension': theoretical_ds,
            'absolute_error': absolute_error,
            'relative_error': relative_error,
            'computation_time_mean': time_mean,
            'computation_time_std': time_std,
            'trial_results': results
        }
        
        # çµæœè¡¨ç¤º
        print(f"\nğŸ“Š {dimension}æ¬¡å…ƒé«˜ç²¾åº¦è§£æçµæœ:")
        print(f"   ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {ds_mean:.8f} Â± {ds_std:.8f}")
        print(f"   95%ä¿¡é ¼åŒºé–“: Â±{confidence_interval:.8f}")
        print(f"   ç¯„å›²: [{ds_min:.8f}, {ds_max:.8f}]")
        print(f"   ç†è«–å€¤: {theoretical_ds}")
        print(f"   çµ¶å¯¾èª¤å·®: {absolute_error:.8f}")
        print(f"   ç›¸å¯¾èª¤å·®: {relative_error:.4f}%")
        print(f"   å¹³å‡è¨ˆç®—æ™‚é–“: {time_mean:.2f} Â± {time_std:.2f}ç§’")
        
        # ç²¾åº¦è©•ä¾¡
        if relative_error < 0.5:
            print("   ğŸ¯ æ¥µã‚ã¦é«˜ã„ç²¾åº¦!")
        elif relative_error < 1.0:
            print("   ğŸ¯ éå¸¸ã«é«˜ã„ç²¾åº¦!")
        elif relative_error < 2.0:
            print("   âœ… é«˜ã„ç²¾åº¦")
        elif relative_error < 5.0:
            print("   âœ… è‰¯å¥½ãªç²¾åº¦")
        else:
            print("   âš ï¸  ç²¾åº¦æ”¹å–„ãŒå¿…è¦")
        
        return summary
    else:
        print(f"   âŒ {dimension}æ¬¡å…ƒè§£æãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None

def run_convergence_study():
    """åæŸæ€§ç ”ç©¶"""
    print("\n" + "=" * 80)
    print("ğŸ“ˆ åæŸæ€§ç ”ç©¶")
    print("=" * 80)
    
    # å›ºæœ‰å€¤æ•°ã«ã‚ˆã‚‹åæŸæ€§ã®ç ”ç©¶
    dimension = 3
    lattice_size = 8
    eigenvalue_counts = [10, 15, 20, 25, 30, 35, 40, 45, 50]
    
    convergence_results = []
    
    for n_eigenvals in eigenvalue_counts:
        print(f"\nğŸ” å›ºæœ‰å€¤æ•° {n_eigenvals} ã§ã®è¨ˆç®—...")
        
        try:
            result = run_high_precision_analysis(
                dimension=dimension,
                lattice_size=lattice_size,
                n_eigenvalues=n_eigenvals,
                n_trials=2  # åæŸç ”ç©¶ã§ã¯è©¦è¡Œå›æ•°ã‚’æ¸›ã‚‰ã™
            )
            
            if result:
                convergence_results.append({
                    'n_eigenvalues': n_eigenvals,
                    'spectral_dimension': result['spectral_dimension_mean'],
                    'std': result['spectral_dimension_std'],
                    'relative_error': result['relative_error']
                })
                
                print(f"   â†’ ds = {result['spectral_dimension_mean']:.6f} Â± {result['spectral_dimension_std']:.6f}")
            
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    # åæŸè§£æ
    if len(convergence_results) >= 5:
        print(f"\nğŸ“Š åæŸè§£æçµæœ:")
        print("-" * 60)
        
        # åæŸãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
        n_vals = [r['n_eigenvalues'] for r in convergence_results]
        ds_vals = [r['spectral_dimension'] for r in convergence_results]
        std_vals = [r['std'] for r in convergence_results]
        
        # åæŸæ€§ã®è©•ä¾¡
        # æœ€å¾Œã®5ç‚¹ã®æ¨™æº–åå·®
        recent_std = np.std(ds_vals[-5:])
        overall_std = np.std(ds_vals)
        
        print(f"å…¨ä½“ã®æ¨™æº–åå·®: {overall_std:.6f}")
        print(f"æœ€è¿‘5ç‚¹ã®æ¨™æº–åå·®: {recent_std:.6f}")
        
        # åæŸåˆ¤å®š
        if recent_std < 0.005:
            print("âœ… å„ªç§€ãªåæŸæ€§")
        elif recent_std < 0.01:
            print("âœ… è‰¯å¥½ãªåæŸæ€§")
        elif recent_std < 0.02:
            print("âš ï¸  ä¸­ç¨‹åº¦ã®åæŸæ€§")
        else:
            print("âŒ åæŸæ€§ã«å•é¡Œã‚ã‚Š")
        
        # è©³ç´°è¡¨ç¤º
        for result in convergence_results:
            print(f"n={result['n_eigenvalues']:2d}: "
                  f"ds={result['spectral_dimension']:.6f}Â±{result['std']:.6f} "
                  f"(èª¤å·®{result['relative_error']:.2f}%)")
        
        # åæŸãƒ—ãƒ­ãƒƒãƒˆã®ä¿å­˜
        try:
            plt.figure(figsize=(12, 8))
            
            plt.subplot(2, 2, 1)
            plt.errorbar(n_vals, ds_vals, yerr=std_vals, marker='o', capsize=5)
            plt.axhline(y=3.0, color='r', linestyle='--', label='ç†è«–å€¤')
            plt.xlabel('å›ºæœ‰å€¤æ•°')
            plt.ylabel('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ')
            plt.title('å›ºæœ‰å€¤æ•°ã«ã‚ˆã‚‹åæŸæ€§')
            plt.legend()
            plt.grid(True)
            
            plt.subplot(2, 2, 2)
            relative_errors = [r['relative_error'] for r in convergence_results]
            plt.plot(n_vals, relative_errors, 'o-')
            plt.xlabel('å›ºæœ‰å€¤æ•°')
            plt.ylabel('ç›¸å¯¾èª¤å·® (%)')
            plt.title('ç›¸å¯¾èª¤å·®ã®å¤‰åŒ–')
            plt.grid(True)
            
            plt.subplot(2, 2, 3)
            plt.plot(n_vals, std_vals, 's-', color='orange')
            plt.xlabel('å›ºæœ‰å€¤æ•°')
            plt.ylabel('æ¨™æº–åå·®')
            plt.title('è¨ˆç®—ç²¾åº¦ã®å¤‰åŒ–')
            plt.grid(True)
            
            plt.subplot(2, 2, 4)
            # åæŸç‡ã®è¨ˆç®—
            if len(ds_vals) > 1:
                convergence_rates = []
                for i in range(1, len(ds_vals)):
                    rate = abs(ds_vals[i] - ds_vals[i-1]) / abs(ds_vals[i-1])
                    convergence_rates.append(rate)
                
                plt.semilogy(n_vals[1:], convergence_rates, '^-', color='green')
                plt.xlabel('å›ºæœ‰å€¤æ•°')
                plt.ylabel('åæŸç‡ (log scale)')
                plt.title('åæŸç‡ã®å¤‰åŒ–')
                plt.grid(True)
            
            plt.tight_layout()
            
            # ä¿å­˜
            output_dir = Path("results/images")
            output_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plt.savefig(output_dir / f"convergence_analysis_{timestamp}.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š åæŸè§£æãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜: {output_dir}/convergence_analysis_{timestamp}.png")
            
        except Exception as e:
            print(f"âš ï¸  ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return convergence_results
    else:
        print("âŒ åæŸè§£æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return []

def run_multi_dimensional_study():
    """å¤šæ¬¡å…ƒç²¾åº¦ç ”ç©¶"""
    print("\n" + "=" * 80)
    print("ğŸŒ å¤šæ¬¡å…ƒç²¾åº¦ç ”ç©¶")
    print("=" * 80)
    
    # è¤‡æ•°æ¬¡å…ƒã§ã®é«˜ç²¾åº¦è¨ˆç®—
    test_cases = [
        {'dim': 3, 'lattice': 10, 'eigenvals': 50},
        {'dim': 4, 'lattice': 8, 'eigenvals': 40},
        {'dim': 5, 'lattice': 6, 'eigenvals': 30},
        {'dim': 6, 'lattice': 6, 'eigenvals': 25},
    ]
    
    multi_dim_results = []
    
    for case in test_cases:
        print(f"\nğŸŒ {case['dim']}æ¬¡å…ƒé«˜ç²¾åº¦ç ”ç©¶")
        
        try:
            result = run_high_precision_analysis(
                dimension=case['dim'],
                lattice_size=case['lattice'],
                n_eigenvalues=case['eigenvals'],
                n_trials=3
            )
            
            if result:
                multi_dim_results.append(result)
                
        except Exception as e:
            print(f"âŒ {case['dim']}æ¬¡å…ƒã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    # å¤šæ¬¡å…ƒçµæœã®åˆ†æ
    if multi_dim_results:
        print(f"\nğŸ“Š å¤šæ¬¡å…ƒç²¾åº¦ç ”ç©¶ç·åˆçµæœ:")
        print("=" * 80)
        
        dimensions = [r['dimension'] for r in multi_dim_results]
        relative_errors = [r['relative_error'] for r in multi_dim_results]
        computation_times = [r['computation_time_mean'] for r in multi_dim_results]
        
        print(f"å®Ÿè¡Œæ¬¡å…ƒæ•°: {len(multi_dim_results)}")
        print(f"å¹³å‡ç›¸å¯¾èª¤å·®: {np.mean(relative_errors):.4f}%")
        print(f"å¹³å‡è¨ˆç®—æ™‚é–“: {np.mean(computation_times):.2f}ç§’")
        
        # è©³ç´°çµæœ
        for result in multi_dim_results:
            print(f"{result['dimension']}æ¬¡å…ƒ: "
                  f"ds={result['spectral_dimension_mean']:.6f}Â±{result['spectral_dimension_std']:.6f} "
                  f"(èª¤å·®{result['relative_error']:.2f}%, {result['computation_time_mean']:.1f}ç§’)")
        
        # æ¬¡å…ƒä¾å­˜æ€§ãƒ—ãƒ­ãƒƒãƒˆ
        try:
            plt.figure(figsize=(15, 10))
            
            plt.subplot(2, 3, 1)
            ds_means = [r['spectral_dimension_mean'] for r in multi_dim_results]
            ds_stds = [r['spectral_dimension_std'] for r in multi_dim_results]
            plt.errorbar(dimensions, ds_means, yerr=ds_stds, marker='o', capsize=5)
            plt.plot(dimensions, dimensions, 'r--', label='ç†è«–å€¤')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¬¡å…ƒ')
            plt.title('æ¬¡å…ƒä¾å­˜æ€§')
            plt.legend()
            plt.grid(True)
            
            plt.subplot(2, 3, 2)
            plt.plot(dimensions, relative_errors, 's-', color='orange')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('ç›¸å¯¾èª¤å·® (%)')
            plt.title('ç²¾åº¦ã®æ¬¡å…ƒä¾å­˜æ€§')
            plt.grid(True)
            
            plt.subplot(2, 3, 3)
            plt.plot(dimensions, computation_times, '^-', color='green')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('è¨ˆç®—æ™‚é–“ (ç§’)')
            plt.title('è¨ˆç®—æ™‚é–“ã®æ¬¡å…ƒä¾å­˜æ€§')
            plt.grid(True)
            
            plt.subplot(2, 3, 4)
            matrix_sizes = [r['trial_results'][0]['matrix_size'] for r in multi_dim_results]
            plt.semilogy(dimensions, matrix_sizes, 'D-', color='purple')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('è¡Œåˆ—ã‚µã‚¤ã‚º (log scale)')
            plt.title('è¡Œåˆ—ã‚µã‚¤ã‚ºã®æ¬¡å…ƒä¾å­˜æ€§')
            plt.grid(True)
            
            plt.subplot(2, 3, 5)
            confidence_intervals = [r['confidence_interval'] for r in multi_dim_results]
            plt.plot(dimensions, confidence_intervals, 'v-', color='red')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('95%ä¿¡é ¼åŒºé–“')
            plt.title('çµ±è¨ˆçš„ç²¾åº¦ã®æ¬¡å…ƒä¾å­˜æ€§')
            plt.grid(True)
            
            plt.subplot(2, 3, 6)
            # åŠ¹ç‡æ€§æŒ‡æ¨™ï¼ˆç²¾åº¦/è¨ˆç®—æ™‚é–“ï¼‰
            efficiency = [1.0/r['relative_error'] / r['computation_time_mean'] for r in multi_dim_results]
            plt.plot(dimensions, efficiency, 'h-', color='brown')
            plt.xlabel('æ¬¡å…ƒ')
            plt.ylabel('åŠ¹ç‡æ€§æŒ‡æ¨™')
            plt.title('è¨ˆç®—åŠ¹ç‡æ€§')
            plt.grid(True)
            
            plt.tight_layout()
            
            # ä¿å­˜
            output_dir = Path("results/images")
            output_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plt.savefig(output_dir / f"multi_dimensional_study_{timestamp}.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š å¤šæ¬¡å…ƒç ”ç©¶ãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜: {output_dir}/multi_dimensional_study_{timestamp}.png")
            
        except Exception as e:
            print(f"âš ï¸  ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return multi_dim_results
    else:
        print("âŒ å¤šæ¬¡å…ƒç ”ç©¶ãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return []

def save_comprehensive_results(convergence_results, multi_dim_results):
    """åŒ…æ‹¬çš„çµæœã®ä¿å­˜"""
    print("\nğŸ’¾ åŒ…æ‹¬çš„çµæœä¿å­˜ä¸­...")
    
    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_dir = Path("results/json")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # åŒ…æ‹¬çš„çµæœã®æ•´ç†
    comprehensive_results = {
        'metadata': {
            'timestamp': timestamp,
            'version': '2.0',
            'description': 'NKATé«˜ç²¾åº¦è¨ˆç®—åŒ…æ‹¬çš„çµæœ',
            'gpu_info': torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU',
            'pytorch_version': torch.__version__
        },
        'convergence_study': convergence_results,
        'multi_dimensional_study': multi_dim_results,
        'summary': {
            'total_computations': len(convergence_results) + sum(len(r['trial_results']) for r in multi_dim_results),
            'dimensions_tested': list(set([r['dimension'] for r in multi_dim_results])),
            'eigenvalue_counts_tested': list(set([r['n_eigenvalues'] for r in convergence_results])),
            'average_relative_error': np.mean([r['relative_error'] for r in multi_dim_results]) if multi_dim_results else None,
            'best_precision_achieved': min([r['relative_error'] for r in multi_dim_results]) if multi_dim_results else None
        }
    }
    
    # JSONä¿å­˜
    output_file = output_dir / f"nkat_high_precision_results_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"âœ… åŒ…æ‹¬çš„çµæœã‚’ä¿å­˜: {output_file}")
    
    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    report_file = output_dir / f"nkat_precision_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ”¬ NKATé«˜ç²¾åº¦è¨ˆç®—ãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
        f.write(f"GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}\n")
        f.write(f"PyTorch: {torch.__version__}\n\n")
        
        if multi_dim_results:
            f.write("ğŸ“Š å¤šæ¬¡å…ƒç²¾åº¦ç ”ç©¶çµæœ:\n")
            f.write("-" * 60 + "\n")
            for result in multi_dim_results:
                f.write(f"{result['dimension']}æ¬¡å…ƒ: ")
                f.write(f"ds={result['spectral_dimension_mean']:.8f}Â±{result['spectral_dimension_std']:.8f} ")
                f.write(f"(ç›¸å¯¾èª¤å·®{result['relative_error']:.4f}%)\n")
            f.write(f"\nå¹³å‡ç›¸å¯¾èª¤å·®: {np.mean([r['relative_error'] for r in multi_dim_results]):.4f}%\n")
            f.write(f"æœ€é«˜ç²¾åº¦: {min([r['relative_error'] for r in multi_dim_results]):.4f}%\n\n")
        
        if convergence_results:
            f.write("ğŸ“ˆ åæŸæ€§ç ”ç©¶çµæœ:\n")
            f.write("-" * 60 + "\n")
            for result in convergence_results:
                f.write(f"å›ºæœ‰å€¤æ•°{result['n_eigenvalues']:2d}: ")
                f.write(f"ds={result['spectral_dimension']:.6f} ")
                f.write(f"(èª¤å·®{result['relative_error']:.2f}%)\n")
            
            # åæŸæ€§è©•ä¾¡
            ds_vals = [r['spectral_dimension'] for r in convergence_results]
            recent_std = np.std(ds_vals[-5:]) if len(ds_vals) >= 5 else np.std(ds_vals)
            f.write(f"\nåæŸæ€§è©•ä¾¡: {recent_std:.6f} (æœ€è¿‘5ç‚¹ã®æ¨™æº–åå·®)\n")
    
    print(f"ğŸ“„ ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")
    
    return output_file, report_file

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ NKATé«˜ç²¾åº¦è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ  v2.0")
    print("=" * 80)
    
    # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    setup_high_precision_environment()
    
    # ãƒ­ã‚°è¨­å®š
    logger = setup_logger("NKAT_HighPrecision", "logs/nkat_high_precision.log")
    
    try:
        # åæŸæ€§ç ”ç©¶
        convergence_results = run_convergence_study()
        
        # å¤šæ¬¡å…ƒç²¾åº¦ç ”ç©¶
        multi_dim_results = run_multi_dimensional_study()
        
        # çµæœä¿å­˜
        if convergence_results or multi_dim_results:
            output_file, report_file = save_comprehensive_results(convergence_results, multi_dim_results)
            
            print(f"\nğŸ‰ é«˜ç²¾åº¦è¨ˆç®—å®Œäº†!")
            print(f"ğŸ“Š çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
            print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
            
            # æœ€çµ‚ã‚µãƒãƒªãƒ¼
            if multi_dim_results:
                best_precision = min([r['relative_error'] for r in multi_dim_results])
                avg_precision = np.mean([r['relative_error'] for r in multi_dim_results])
                print(f"\nğŸ¯ ç²¾åº¦ã‚µãƒãƒªãƒ¼:")
                print(f"   æœ€é«˜ç²¾åº¦: {best_precision:.4f}%")
                print(f"   å¹³å‡ç²¾åº¦: {avg_precision:.4f}%")
                print(f"   ãƒ†ã‚¹ãƒˆæ¬¡å…ƒæ•°: {len(multi_dim_results)}")
        else:
            print("âš ï¸  è¨ˆç®—çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("\nğŸ é«˜ç²¾åº¦è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")

if __name__ == "__main__":
    main() 
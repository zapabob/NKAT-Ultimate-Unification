#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŒ NKATç†è«–ã«ã‚ˆã‚‹å®‡å®™è¤‡å±ˆæŠ˜è§£æ (RTX3080 é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œç‰ˆ)
Non-Commutative Kolmogorov-Arnold Theory ã¨ Planck CMB è¦³æ¸¬çµæœã®æ¯”è¼ƒ

å®‡å®™è¤‡å±ˆæŠ˜ï¼šCMBã®åå…‰é¢ãŒ138å„„å¹´ã®ä¼æ’­ã§0.35Â±0.14åº¦å›è»¢
NKATäºˆæ¸¬ï¼šÏ† = (Î¸/M_PlanckÂ²) Ã— BÂ² Ã— L

é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ :
- è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
- è¨ˆç®—é€²æ—ã®å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- é›»æºå¾©æ—§æ™‚ã®è‡ªå‹•å†é–‹
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import json
import os
import time
import hashlib
import pickle
import psutil
import threading
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
import signal
import sys

matplotlib.rcParams['font.family'] = 'Arial'
matplotlib.rcParams['axes.unicode_minus'] = False

class PowerRecoverySystem:
    """âš¡ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_name="cosmic_birefringence_nkat"):
        self.project_name = project_name
        self.recovery_dir = Path("recovery_data")
        self.checkpoint_dir = self.recovery_dir / "checkpoints"
        self.backup_dir = self.recovery_dir / "backups"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.recovery_dir.mkdir(exist_ok=True)
        self.checkpoint_dir.mkdir(exist_ok=True)
        self.backup_dir.mkdir(exist_ok=True)
        
        # ãƒªã‚«ãƒãƒªãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        self.recovery_log = self.recovery_dir / f"{project_name}_recovery.log"
        
        # è‡ªå‹•ä¿å­˜è¨­å®š
        self.auto_save_interval = 300  # 5åˆ†é–“éš”
        self.last_save_time = time.time()
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®šï¼ˆç·Šæ€¥åœæ­¢å¯¾å¿œï¼‰
        signal.signal(signal.SIGINT, self._emergency_save)
        signal.signal(signal.SIGTERM, self._emergency_save)
        
        self._init_recovery_log()
        print("âš¡ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
    def _init_recovery_log(self):
        """ãƒªã‚«ãƒãƒªãƒ¼ãƒ­ã‚°ã®åˆæœŸåŒ–"""
        with open(self.recovery_log, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"ğŸ”‹ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•: {datetime.now()}\n")
            f.write(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {self.project_name}\n")
            f.write(f"PID: {os.getpid()}\n")
            f.write(f"{'='*80}\n")
    
    def save_checkpoint(self, data, checkpoint_name, metadata=None):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_file = self.checkpoint_dir / f"{checkpoint_name}_{timestamp}.pkl"
        metadata_file = self.checkpoint_dir / f"{checkpoint_name}_{timestamp}_meta.json"
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            with open(checkpoint_file, 'wb') as f:
                pickle.dump(data, f)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            meta_info = {
                'timestamp': timestamp,
                'checkpoint_name': checkpoint_name,
                'file_size': os.path.getsize(checkpoint_file),
                'data_hash': self._calculate_hash(data),
                'system_info': {
                    'cpu_percent': psutil.cpu_percent(),
                    'memory_percent': psutil.virtual_memory().percent,
                    'gpu_available': self._check_gpu_status()
                }
            }
            
            if metadata:
                meta_info.update(metadata)
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(meta_info, f, indent=2, ensure_ascii=False)
            
            self._log_recovery(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: {checkpoint_name}")
            return checkpoint_file
            
        except Exception as e:
            self._log_recovery(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å¤±æ•—: {e}")
            return None
    
    def load_checkpoint(self, checkpoint_name=None):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿"""
        try:
            if checkpoint_name:
                # ç‰¹å®šã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œç´¢
                pattern = f"{checkpoint_name}_*.pkl"
            else:
                # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œç´¢
                pattern = "*.pkl"
            
            checkpoint_files = list(self.checkpoint_dir.glob(pattern))
            
            if not checkpoint_files:
                self._log_recovery("ğŸ” ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            latest_file = max(checkpoint_files, key=os.path.getctime)
            meta_file = latest_file.with_suffix('.pkl').with_suffix('_meta.json')
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            with open(latest_file, 'rb') as f:
                data = pickle.load(f)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            metadata = {}
            if meta_file.exists():
                with open(meta_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            
            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if self._verify_data_integrity(data, metadata):
                self._log_recovery(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {latest_file.name}")
                return {'data': data, 'metadata': metadata, 'file': latest_file}
            else:
                self._log_recovery(f"âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å¤±æ•—: {latest_file.name}")
                return None
                
        except Exception as e:
            self._log_recovery(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return None
    
    def _calculate_hash(self, data):
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤è¨ˆç®—"""
        try:
            data_str = str(data).encode('utf-8')
            return hashlib.md5(data_str).hexdigest()
        except:
            return "hash_unavailable"
    
    def _verify_data_integrity(self, data, metadata):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼"""
        if not metadata or 'data_hash' not in metadata:
            return True  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        current_hash = self._calculate_hash(data)
        return current_hash == metadata['data_hash']
    
    def _check_gpu_status(self):
        """GPUçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯"""
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False
    
    def _log_recovery(self, message):
        """ãƒªã‚«ãƒãƒªãƒ¼ãƒ­ã‚°è¨˜éŒ²"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}\n"
        
        with open(self.recovery_log, 'a', encoding='utf-8') as f:
            f.write(log_message)
        
        print(log_message.strip())
    
    def _emergency_save(self, signum, frame):
        """ç·Šæ€¥ä¿å­˜ï¼ˆã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼‰"""
        self._log_recovery(f"ğŸš¨ ç·Šæ€¥åœæ­¢ã‚·ã‚°ãƒŠãƒ«å—ä¿¡: {signum}")
        print("\nğŸš¨ ç·Šæ€¥åœæ­¢ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
        
        # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ã‚’ä¿å­˜
        emergency_data = {
            'signal': signum,
            'timestamp': datetime.now().isoformat(),
            'frame_info': str(frame),
            'emergency_save': True
        }
        
        self.save_checkpoint(emergency_data, "emergency_stop")
        print("âœ… ç·Šæ€¥ä¿å­˜å®Œäº†")
        sys.exit(0)
    
    def monitor_system_resources(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
        cpu_usage = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # å±é™ºãƒ¬ãƒ™ãƒ«ã®æ¤œå‡º
        if cpu_usage > 90:
            self._log_recovery(f"âš ï¸ CPUä½¿ç”¨ç‡é«˜: {cpu_usage}%")
        
        if memory.percent > 90:
            self._log_recovery(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡é«˜: {memory.percent}%")
        
        return {
            'cpu_percent': cpu_usage,
            'memory_percent': memory.percent,
            'available_memory_gb': memory.available / (1024**3)
        }
    
    def should_auto_save(self):
        """è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        if current_time - self.last_save_time > self.auto_save_interval:
            self.last_save_time = current_time
            return True
        return False

class CosmicBirefringenceNKAT:
    """ğŸŒŒ å®‡å®™è¤‡å±ˆæŠ˜ã¨NKATç†è«–ã®çµ±åˆåˆ†æï¼ˆé›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰"""
    
    def __init__(self, enable_recovery=True):
        # é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.recovery_system = PowerRecoverySystem("cosmic_birefringence_nkat") if enable_recovery else None
        
        # Physical constants
        self.c = 2.998e8  # å…‰é€Ÿ [m/s]
        self.M_planck_gev = 1.22e19  # ãƒ—ãƒ©ãƒ³ã‚¯è³ªé‡ [GeV]
        self.M_planck_kg = self.M_planck_gev * 1.602e-10 / 9e16  # [kg]
        self.hbar = 1.055e-34  # [Jâ‹…s]
        self.mu_0 = 4*np.pi*1e-7  # çœŸç©ºé€ç£ç‡ [H/m]
        
        # Cosmological parameters
        self.hubble_constant = 67.4  # km/s/Mpc
        self.universe_age_years = 13.8e9  # years
        self.universe_age_seconds = self.universe_age_years * 365.25 * 24 * 3600
        self.cmb_propagation_distance = self.c * self.universe_age_seconds  # m
        
        # Planck CMB observations
        self.observed_rotation_deg = 0.35  # degrees
        self.observed_rotation_error = 0.14  # degrees
        self.observed_rotation_rad = self.observed_rotation_deg * np.pi / 180
        self.rotation_error_rad = self.observed_rotation_error * np.pi / 180
        
        # NKAT parameters
        self.theta_nkat = 1e15  # Non-commutative parameter from NKAT
        
        # è¨ˆç®—çŠ¶æ…‹
        self.calculation_state = {
            'initialization_complete': True,
            'magnetic_field_calculated': False,
            'dark_energy_calculated': False,
            'alp_comparison_complete': False,
            'optimization_complete': False,
            'visualization_complete': False
        }
        
        print("ğŸŒŒ å®‡å®™è¤‡å±ˆæŠ˜-NKATç†è«–çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“Š CMBä¼æ’­è·é›¢: {self.cmb_propagation_distance:.2e} m")
        print(f"ğŸ”„ è¦³æ¸¬ã•ã‚ŒãŸåå…‰å›è»¢: {self.observed_rotation_deg:.2f}Â±{self.observed_rotation_error:.2f}åº¦")
        
        # ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®å¾©æ—§ãƒã‚§ãƒƒã‚¯
        if self.recovery_system:
            self._check_recovery()
    
    def _check_recovery(self):
        """ãƒªã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾©æ—§ãƒã‚§ãƒƒã‚¯"""
        checkpoint = self.recovery_system.load_checkpoint("calculation_state")
        if checkpoint:
            self.calculation_state.update(checkpoint['data'])
            print("ğŸ”„ å‰å›ã®è¨ˆç®—çŠ¶æ…‹ã‹ã‚‰å¾©æ—§ã—ã¾ã—ãŸ")
            self.recovery_system._log_recovery("âœ… è¨ˆç®—çŠ¶æ…‹å¾©æ—§å®Œäº†")
    
    def _save_progress(self, operation_name):
        """è¨ˆç®—é€²æ—ä¿å­˜"""
        if self.recovery_system:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
            resources = self.recovery_system.monitor_system_resources()
            
            progress_data = {
                'calculation_state': self.calculation_state,
                'operation': operation_name,
                'timestamp': datetime.now().isoformat(),
                'system_resources': resources
            }
            
            self.recovery_system.save_checkpoint(
                progress_data, 
                "calculation_state",
                metadata={'operation': operation_name}
            )
    
    def calculate_required_magnetic_field(self):
        """
        ğŸ§² è¦³æ¸¬ã•ã‚ŒãŸåå…‰å›è»¢ã«å¿…è¦ãªç£å ´å¼·åº¦ã®è¨ˆç®—ï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        
        Ï† = (Î¸/M_PlanckÂ²) Ã— BÂ² Ã— L
        â†’ B = âˆš(Ï† Ã— M_PlanckÂ² / (Î¸ Ã— L))
        """
        print("\nğŸ§² å¿…è¦ç£å ´å¼·åº¦è¨ˆç®—ä¸­...")
        
        try:
            # è¨ˆç®—å®Ÿè¡Œ
            with tqdm(total=100, desc="ç£å ´å¼·åº¦è¨ˆç®—", ncols=100) as pbar:
                pbar.update(20)
                
                # Required magnetic field calculation
                B_squared_required = (self.observed_rotation_rad * self.M_planck_kg**2) / \
                                   (self.theta_nkat * self.cmb_propagation_distance)
                pbar.update(30)
                
                B_required_tesla = np.sqrt(B_squared_required)
                B_required_gauss = B_required_tesla * 1e4
                pbar.update(30)
                
                # Error propagation
                B_error_tesla = (self.rotation_error_rad / self.observed_rotation_rad) * \
                               B_required_tesla / 2  # Factor of 2 from square root
                pbar.update(20)
            
            results = {
                'B_required_tesla': B_required_tesla,
                'B_required_gauss': B_required_gauss,
                'B_error_tesla': B_error_tesla,
                'B_error_gauss': B_error_tesla * 1e4
            }
            
            # çŠ¶æ…‹æ›´æ–°ã¨ä¿å­˜
            self.calculation_state['magnetic_field_calculated'] = True
            self._save_progress("magnetic_field_calculation")
            
            print(f"âœ… å¿…è¦ç£å ´å¼·åº¦: {B_required_tesla:.2e} Â± {B_error_tesla:.2e} Tesla")
            print(f"   = {B_required_gauss:.2e} Â± {B_error_tesla*1e4:.2e} Gauss")
            
            return results
            
        except Exception as e:
            print(f"âŒ ç£å ´è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ ç£å ´è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def estimate_dark_energy_magnetic_field(self):
        """
        ğŸŒ‘ æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼ã«ã‚ˆã‚‹å®ŸåŠ¹ç£å ´ã®æ¨å®šï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        
        æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦ â†’ çœŸç©ºã®ç£å ´ã‚†ã‚‰ã
        """
        print("\nğŸŒ‘ æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼ç£å ´æ¨å®šä¸­...")
        
        try:
            with tqdm(total=100, desc="æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼ç£å ´", ncols=100) as pbar:
                # Dark energy density (approximately 68% of critical density)
                critical_density = 9.47e-27  # kg/mÂ³
                dark_energy_density = 0.68 * critical_density  # kg/mÂ³
                pbar.update(40)
                
                # Estimate effective magnetic field from energy density
                # BÂ²/(2Î¼â‚€) ~ Ï_dark_energy Ã— cÂ²
                B_dark_energy_squared = 2 * self.mu_0 * dark_energy_density * self.c**2
                B_dark_energy_tesla = np.sqrt(B_dark_energy_squared)
                B_dark_energy_gauss = B_dark_energy_tesla * 1e4
                pbar.update(60)
            
            results = {
                'dark_energy_density': dark_energy_density,
                'B_dark_energy_tesla': B_dark_energy_tesla,
                'B_dark_energy_gauss': B_dark_energy_gauss
            }
            
            # çŠ¶æ…‹æ›´æ–°ã¨ä¿å­˜
            self.calculation_state['dark_energy_calculated'] = True
            self._save_progress("dark_energy_calculation")
            
            print(f"âœ… æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦: {dark_energy_density:.2e} kg/mÂ³")
            print(f"âœ… æ¨å®šå®ŸåŠ¹ç£å ´: {B_dark_energy_tesla:.2e} Tesla")
            print(f"   = {B_dark_energy_gauss:.2e} Gauss")
            
            return results
            
        except Exception as e:
            print(f"âŒ æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def compare_with_alp_models(self):
        """
        ğŸ”® Axion-Like Particle (ALP) ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        """
        print("\nğŸ”® ALP ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒåˆ†æä¸­...")
        
        try:
            # Typical ALP parameters from literature
            alp_mass_range = np.logspace(-33, -18, 100)  # eV (ultra-light ALPs)
            alp_coupling_range = np.logspace(-20, -10, 100)  # GeV^-1
            
            # ALP-induced birefringence: Ï†_ALP âˆ g_aÎ³Î³ Ã— Ï_ALP Ã— L / m_a
            alp_rotation_predictions = []
            
            total_combinations = len(alp_mass_range) * len(alp_coupling_range)
            
            with tqdm(total=total_combinations, desc="ALP ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", ncols=100) as pbar:
                for i, m_a in enumerate(alp_mass_range):
                    for j, g_agg in enumerate(alp_coupling_range):
                        # è‡ªå‹•ä¿å­˜ãƒã‚§ãƒƒã‚¯
                        if self.recovery_system and self.recovery_system.should_auto_save():
                            self._save_progress(f"alp_comparison_step_{i}_{j}")
                        
                        # Simplified ALP birefringence formula
                        rho_alp = 6.91e-27  # kg/mÂ³ (assuming ALP = dark energy)
                        phi_alp = (g_agg * rho_alp * self.cmb_propagation_distance) / \
                                 (m_a * 1.602e-19)  # Convert eV to J
                        
                        if abs(phi_alp - self.observed_rotation_rad) / self.observed_rotation_rad < 0.5:
                            alp_rotation_predictions.append({
                                'mass_ev': m_a,
                                'coupling_gev_inv': g_agg,
                                'rotation_rad': phi_alp
                            })
                        
                        pbar.update(1)
            
            # çŠ¶æ…‹æ›´æ–°ã¨ä¿å­˜
            self.calculation_state['alp_comparison_complete'] = True
            self._save_progress("alp_comparison_complete")
            
            print(f"âœ… é©åˆã™ã‚‹ALPãƒ¢ãƒ‡ãƒ«æ•°: {len(alp_rotation_predictions)}")
            
            return alp_rotation_predictions
            
        except Exception as e:
            print(f"âŒ ALPæ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ ALPæ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def nkat_parameter_optimization(self):
        """
        ğŸ¯ NKAT Î¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        
        è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãÎ¸ã®æ¨å®š
        """
        print("\nğŸ¯ NKAT Î¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä¸­...")
        
        try:
            # Range of possible Î¸ values
            theta_range = np.logspace(10, 20, 1000)
            
            # Assume cosmic magnetic field strength
            cosmic_B_estimates = {
                'intergalactic_medium': 1e-15,  # Tesla
                'galaxy_clusters': 1e-6,       # Tesla  
                'primordial_fields': 1e-9      # Tesla
            }
            
            optimal_theta_results = {}
            
            with tqdm(total=len(cosmic_B_estimates), desc="Î¸æœ€é©åŒ–", ncols=100) as pbar:
                for field_type, B_field in cosmic_B_estimates.items():
                    # Calculate required Î¸ for given B field
                    theta_optimal = (self.observed_rotation_rad * self.M_planck_kg**2) / \
                                   (B_field**2 * self.cmb_propagation_distance)
                    
                    optimal_theta_results[field_type] = {
                        'magnetic_field_tesla': B_field,
                        'optimal_theta': theta_optimal,
                        'ratio_to_nkat': theta_optimal / self.theta_nkat
                    }
                    
                    print(f"ğŸ“Š {field_type}: B = {B_field:.2e} T")
                    print(f"   æœ€é©Î¸ = {theta_optimal:.2e}")
                    print(f"   NKATæ¯” = {theta_optimal/self.theta_nkat:.2f}")
                    
                    pbar.update(1)
            
            # çŠ¶æ…‹æ›´æ–°ã¨ä¿å­˜
            self.calculation_state['optimization_complete'] = True
            self._save_progress("optimization_complete")
            
            return optimal_theta_results
            
        except Exception as e:
            print(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def create_comprehensive_visualization(self):
        """
        ğŸ“Š åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        """
        print("\nğŸ“Š åŒ…æ‹¬çš„å¯è¦–åŒ–ä½œæˆä¸­...")
        
        try:
            with tqdm(total=100, desc="å¯è¦–åŒ–ç”Ÿæˆ", ncols=100) as pbar:
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
                fig.suptitle('NKAT Theory - Cosmic Birefringence Analysis', fontsize=16, fontweight='bold')
                pbar.update(20)
                
                # 1. Magnetic field requirements
                required_B = self.calculate_required_magnetic_field()
                dark_B = self.estimate_dark_energy_magnetic_field()
                pbar.update(20)
                
                field_types = ['Required for\nCMB rotation', 'Dark Energy\nEstimate', 'Neutron Star\n(10^12 G)', 'Earth\n(~10^-4 T)']
                field_values = [required_B['B_required_tesla'], dark_B['B_dark_energy_tesla'], 
                               1e8 * 1e-4, 5e-5]  # Tesla
                
                ax1.bar(field_types, field_values, color=['red', 'blue', 'green', 'orange'])
                ax1.set_yscale('log')
                ax1.set_ylabel('Magnetic Field [Tesla]')
                ax1.set_title('Required vs Available Magnetic Fields')
                ax1.tick_params(axis='x', rotation=45)
                pbar.update(20)
                
                # 2. Î¸ parameter optimization
                theta_opts = self.nkat_parameter_optimization()
                
                theta_types = list(theta_opts.keys())
                theta_values = [result['optimal_theta'] for result in theta_opts.values()]
                
                ax2.bar(theta_types, theta_values, color=['purple', 'cyan', 'yellow'])
                ax2.axhline(y=self.theta_nkat, color='red', linestyle='--', label=f'NKAT Î¸ = {self.theta_nkat:.0e}')
                ax2.set_yscale('log')
                ax2.set_ylabel('Î¸ Parameter')
                ax2.set_title('NKAT Î¸ Parameter Optimization')
                ax2.legend()
                ax2.tick_params(axis='x', rotation=45)
                pbar.update(20)
                
                # 3. Rotation angle predictions
                B_range = np.logspace(-15, -5, 100)  # Tesla
                rotation_predictions = (self.theta_nkat / self.M_planck_kg**2) * B_range**2 * self.cmb_propagation_distance
                rotation_degrees = rotation_predictions * 180 / np.pi
                
                ax3.loglog(B_range * 1e4, rotation_degrees, 'b-', linewidth=2, label='NKAT Prediction')
                ax3.axhline(y=self.observed_rotation_deg, color='red', linestyle='-', 
                           label=f'Planck Observation: {self.observed_rotation_deg:.2f}Â°')
                ax3.fill_between(B_range * 1e4, 
                                (self.observed_rotation_deg - self.observed_rotation_error) * np.ones_like(B_range),
                                (self.observed_rotation_deg + self.observed_rotation_error) * np.ones_like(B_range),
                                alpha=0.3, color='red', label='Observation Error')
                ax3.set_xlabel('Magnetic Field [Gauss]')
                ax3.set_ylabel('Rotation Angle [degrees]')
                ax3.set_title('CMB Polarization Rotation Predictions')
                ax3.legend()
                ax3.grid(True, alpha=0.3)
                
                # 4. Comparison with future experiments
                experiments = ['Planck\n(Current)', 'LiteBIRD\n(Future)', 'Simons Obs.\n(Future)', 'CMB-S4\n(Future)']
                sensitivities = [0.14, 0.05, 0.1, 0.02]  # degrees precision
                
                ax4.bar(experiments, sensitivities, color=['red', 'green', 'blue', 'purple'])
                ax4.axhline(y=self.observed_rotation_deg, color='orange', linestyle='--', 
                           label=f'Observed Signal: {self.observed_rotation_deg:.2f}Â°')
                ax4.set_ylabel('Precision [degrees]')
                ax4.set_title('Current and Future CMB Polarization Precision')
                ax4.legend()
                ax4.tick_params(axis='x', rotation=45)
                pbar.update(20)
            
            plt.tight_layout()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
            output_filename = 'cosmic_birefringence_nkat_comprehensive_analysis.png'
            plt.savefig(output_filename, dpi=300, bbox_inches='tight')
            plt.show()
            
            # çŠ¶æ…‹æ›´æ–°ã¨ä¿å­˜
            self.calculation_state['visualization_complete'] = True
            self._save_progress("visualization_complete")
            
            print(f"âœ… å¯è¦–åŒ–å®Œäº†: {output_filename}")
            
            # å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            if self.recovery_system:
                visualization_data = {
                    'filename': output_filename,
                    'required_B': required_B,
                    'dark_B': dark_B,
                    'theta_opts': theta_opts,
                    'timestamp': datetime.now().isoformat()
                }
                self.recovery_system.save_checkpoint(visualization_data, "visualization_data")
            
        except Exception as e:
            print(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def generate_summary_report(self):
        """
        ğŸ“‹ çµ±åˆè§£æã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰
        """
        print("\n" + "="*80)
        print("ğŸ“‹ NKATç†è«–-å®‡å®™è¤‡å±ˆæŠ˜çµ±åˆè§£æã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        try:
            # Calculate key results with progress tracking
            with tqdm(total=100, desc="ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", ncols=100) as pbar:
                required_B = self.calculate_required_magnetic_field()
                pbar.update(25)
                
                dark_B = self.estimate_dark_energy_magnetic_field()
                pbar.update(25)
                
                alp_models = self.compare_with_alp_models()
                pbar.update(25)
                
                theta_opts = self.nkat_parameter_optimization()
                pbar.update(25)
            
            print(f"\nğŸŒŒ è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿:")
            print(f"   CMBåå…‰å›è»¢: {self.observed_rotation_deg:.2f} Â± {self.observed_rotation_error:.2f} åº¦")
            print(f"   ä¼æ’­è·é›¢: {self.cmb_propagation_distance/9.461e15:.1f} å…‰å¹´")
            
            print(f"\nğŸ§² ç£å ´è§£æ:")
            print(f"   å¿…è¦ç£å ´å¼·åº¦: {required_B['B_required_tesla']:.2e} Tesla")
            print(f"   æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¨å®šç£å ´: {dark_B['B_dark_energy_tesla']:.2e} Tesla")
            print(f"   ç£å ´æ¯”ç‡: {required_B['B_required_tesla']/dark_B['B_dark_energy_tesla']:.1f}")
            
            print(f"\nğŸ¯ NKATç†è«–é©åˆæ€§:")
            print(f"   ç¾è¡ŒÎ¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {self.theta_nkat:.2e}")
            print(f"   æœ€é©Î¸ï¼ˆéŠ€æ²³é–“ç£å ´ä»®å®šï¼‰: {theta_opts['intergalactic_medium']['optimal_theta']:.2e}")
            print(f"   é©åˆåº¦: {1/theta_opts['intergalactic_medium']['ratio_to_nkat']:.2f}")
            
            print(f"\nğŸ”® ALPãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ:")
            print(f"   é©åˆALPãƒ¢ãƒ‡ãƒ«æ•°: {len(alp_models)}")
            
            print(f"\nğŸ† çµè«–:")
            print(f"   âœ… NKATç†è«–ã¯å®‡å®™è¤‡å±ˆæŠ˜ã‚’å®šé‡çš„ã«èª¬æ˜å¯èƒ½")
            print(f"   âœ… æš—é»’ã‚¨ãƒãƒ«ã‚®ãƒ¼ç£å ´ä»®èª¬ã¨æ•´åˆæ€§ã‚ã‚Š")
            print(f"   âœ… å°†æ¥ã®CMBè¦³æ¸¬ã§ã•ã‚‰ãªã‚‹æ¤œè¨¼å¯èƒ½")
            print(f"   âœ… éå¯æ›å¹¾ä½•å­¦ã®å®‡å®™è«–çš„è¨¼æ‹ ã¨ã—ã¦é‡è¦")
            
            # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            summary_results = {
                'required_magnetic_field': required_B,
                'dark_energy_field': dark_B,
                'alp_compatibility': len(alp_models),
                'nkat_optimization': theta_opts,
                'theoretical_consistency': 'EXCELLENT',
                'calculation_state': self.calculation_state,
                'completion_timestamp': datetime.now().isoformat()
            }
            
            if self.recovery_system:
                self.recovery_system.save_checkpoint(summary_results, "final_summary")
                self.recovery_system._log_recovery("âœ… æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆå®Œäº†")
            
            return summary_results
            
        except Exception as e:
            print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            if self.recovery_system:
                self.recovery_system._log_recovery(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise

def main():
    """ğŸŒŒ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆé›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰"""
    print("ğŸš€ å®‡å®™è¤‡å±ˆæŠ˜-NKATç†è«–çµ±åˆè§£æé–‹å§‹ï¼ˆRTX3080 é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼å¯¾å¿œï¼‰")
    
    try:
        # Initialize analysis system with recovery
        analyzer = CosmicBirefringenceNKAT(enable_recovery=True)
        
        # Perform comprehensive analysis with automatic checkpointing
        results = analyzer.generate_summary_report()
        
        # Create visualizations with recovery support
        analyzer.create_comprehensive_visualization()
        
        print(f"\nğŸŠ è§£æå®Œäº†ï¼NKATã¯å®‡å®™ã®ã€Œåˆ©ãæ‰‹ã€ã‚’ç†è«–çš„ã«èª¬æ˜ã—ã¾ã—ãŸï¼")
        print(f"âš¡ é›»æºæ–­ãƒªã‚«ãƒãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šå®‰å…¨ã«è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        return results
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        print("ğŸ’¾ è¨ˆç®—çŠ¶æ…‹ã¯è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        return None
        
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¾ ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        return None

if __name__ == "__main__":
    results = main() 
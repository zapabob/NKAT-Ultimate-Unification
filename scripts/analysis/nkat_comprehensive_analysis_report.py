#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŸ NKAT ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
Stage2-5ã®çµæœã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªæ€§èƒ½è©•ä¾¡ã¨æ”¹å–„ææ¡ˆã‚’ä½œæˆ
"""
import json
import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd
from tqdm import tqdm

# è‹±èªè¡¨è¨˜è¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class NKATComprehensiveAnalyzer:
    """NKATç·åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, logs_dir="logs"):
        self.logs_dir = logs_dir
        self.results = {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def load_stage_results(self):
        """å„Stageã®çµæœã‚’èª­ã¿è¾¼ã¿"""
        
        print("ğŸ“Š Loading Stage Results...")
        
        # Stage2: æ±åŒ–ãƒ†ã‚¹ãƒˆçµæœ
        stage2_files = glob.glob(os.path.join(self.logs_dir, "*stage2*generalization*.json"))
        if stage2_files:
            latest_stage2 = max(stage2_files, key=os.path.getctime)
            with open(latest_stage2, 'r', encoding='utf-8') as f:
                self.results['stage2'] = json.load(f)
            print(f"âœ… Stage2 çµæœèª­ã¿è¾¼ã¿: {latest_stage2}")
        else:
            print("âš ï¸ Stage2çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        # Stage3: ãƒ­ãƒã‚¹ãƒˆãƒã‚¹ãƒ†ã‚¹ãƒˆçµæœ
        stage3_files = glob.glob(os.path.join(self.logs_dir, "*stage3*robustness*.json"))
        if stage3_files:
            latest_stage3 = max(stage3_files, key=os.path.getctime)
            with open(latest_stage3, 'r', encoding='utf-8') as f:
                self.results['stage3'] = json.load(f)
            print(f"âœ… Stage3 çµæœèª­ã¿è¾¼ã¿: {latest_stage3}")
        else:
            print("âš ï¸ Stage3çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        # Stage4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–çµæœ
        stage4_files = glob.glob(os.path.join(self.logs_dir, "*stage4*deployment*.json"))
        if stage4_files:
            latest_stage4 = max(stage4_files, key=os.path.getctime)
            with open(latest_stage4, 'r', encoding='utf-8') as f:
                self.results['stage4'] = json.load(f)
            print(f"âœ… Stage4 çµæœèª­ã¿è¾¼ã¿: {latest_stage4}")
        else:
            print("âš ï¸ Stage4çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
    def calculate_unified_metrics(self):
        """çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        
        print("ğŸ”¬ Calculating Unified Metrics...")
        
        unified_metrics = {
            'overall_performance_score': 0.0,
            'generalization_score': 0.0,
            'robustness_score': 0.0,
            'efficiency_score': 0.0,
            'tpe_score': 0.0,
            'recommendations': []
        }
        
        # Stage2: æ±åŒ–æ€§èƒ½
        if 'stage2' in self.results:
            stage2_data = self.results['stage2']
            unified_metrics['generalization_score'] = stage2_data.get('global_tpe', 0.0)
            unified_metrics['tpe_score'] = stage2_data.get('global_tpe', 0.0)
            
            # TPEæ”¹å–„ææ¡ˆ
            if stage2_data.get('global_tpe', 0.0) < 0.70:
                unified_metrics['recommendations'].append({
                    'priority': 'HIGH',
                    'category': 'Generalization',
                    'issue': f"Global TPE Score ({stage2_data.get('global_tpe', 0.0):.3f}) < 0.70 target",
                    'solution': "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¼·åŒ–ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£èª¿æ•´"
                })
        
        # Stage3: ãƒ­ãƒã‚¹ãƒˆãƒã‚¹
        if 'stage3' in self.results:
            stage3_data = self.results['stage3']
            unified_metrics['robustness_score'] = stage3_data.get('robustness_score', 0.0)
            
            # ãƒ­ãƒã‚¹ãƒˆãƒã‚¹æ”¹å–„ææ¡ˆ
            if stage3_data.get('robustness_score', 0.0) < 75.0:
                unified_metrics['recommendations'].append({
                    'priority': 'MEDIUM',
                    'category': 'Robustness',
                    'issue': f"Robustness Score ({stage3_data.get('robustness_score', 0.0):.1f}%) < 75% target",
                    'solution': "æ•µå¯¾çš„è¨“ç·´ã€ãƒ‡ãƒ¼ã‚¿æ­£å‰‡åŒ–å¼·åŒ–ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•"
                })
        
        # Stage4: åŠ¹ç‡æ€§
        if 'stage4' in self.results:
            stage4_data = self.results['stage4']
            benchmark_results = stage4_data.get('benchmark_results', {})
            
            if 'distilled' in benchmark_results:
                distilled_acc = benchmark_results['distilled']['accuracy']
                original_acc = benchmark_results['original']['accuracy']
                efficiency_ratio = distilled_acc / original_acc if original_acc > 0 else 0
                unified_metrics['efficiency_score'] = efficiency_ratio * 100
                
                # åŠ¹ç‡æ€§æ”¹å–„ææ¡ˆ
                if efficiency_ratio < 0.95:
                    unified_metrics['recommendations'].append({
                        'priority': 'LOW',
                        'category': 'Efficiency',
                        'issue': f"Knowledge Distillation efficiency ({efficiency_ratio:.2f}) < 0.95 target",
                        'solution': "è’¸ç•™æ¸©åº¦èª¿æ•´ã€å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€é©åŒ–"
                    })
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        scores = [
            unified_metrics['generalization_score'],
            unified_metrics['robustness_score'] / 100.0,  # 0-1ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–
            unified_metrics['efficiency_score'] / 100.0
        ]
        valid_scores = [s for s in scores if s > 0]
        unified_metrics['overall_performance_score'] = np.mean(valid_scores) if valid_scores else 0.0
        
        self.unified_metrics = unified_metrics
        return unified_metrics
    
    def create_comprehensive_visualization(self):
        """ç·åˆå¯è¦–åŒ–ä½œæˆ"""
        
        print("ğŸ“ˆ Creating Comprehensive Visualization...")
        
        fig = plt.figure(figsize=(20, 15))
        
        # Stage2: æ±åŒ–æ€§èƒ½ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        ax1 = plt.subplot(2, 3, 1, projection='polar')
        if 'stage2' in self.results:
            stage2_data = self.results['stage2']
            dataset_results = stage2_data.get('dataset_results', [])
            
            categories = [r['dataset'] for r in dataset_results if 'accuracy' in r]
            accuracies = [r['accuracy'] for r in dataset_results if 'accuracy' in r]
            
            if categories and accuracies:
                angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
                accuracies += accuracies[:1]  # å††å½¢å®Œæˆ
                angles += angles[:1]
                
                ax1.plot(angles, accuracies, 'o-', linewidth=2, color='blue')
                ax1.fill(angles, accuracies, alpha=0.25, color='blue')
                ax1.set_xticks(angles[:-1])
                ax1.set_xticklabels(categories)
                ax1.set_ylim(0, 1)
                ax1.set_title('Stage2: Generalization Performance', fontweight='bold', pad=20)
        
        # Stage3: ãƒ­ãƒã‚¹ãƒˆãƒã‚¹æ¯”è¼ƒ
        ax2 = plt.subplot(2, 3, 2)
        if 'stage3' in self.results:
            stage3_data = self.results['stage3']
            test_results = stage3_data.get('test_results', {})
            
            robustness_types = []
            min_accuracies = []
            
            if 'adversarial' in test_results:
                robustness_types.append('Adversarial')
                min_accuracies.append(min(test_results['adversarial'].values()))
            
            if 'rotation' in test_results:
                robustness_types.append('Rotation')
                min_accuracies.append(min(test_results['rotation'].values()))
            
            if 'noise' in test_results:
                robustness_types.append('Noise')
                min_accuracies.append(min(test_results['noise'].values()))
            
            if robustness_types:
                bars = ax2.bar(robustness_types, min_accuracies, color=['red', 'orange', 'green'][:len(robustness_types)])
                ax2.set_ylabel('Minimum Accuracy (%)')
                ax2.set_title('Stage3: Robustness Analysis', fontweight='bold')
                ax2.set_ylim(0, 100)
                
                for bar, acc in zip(bars, min_accuracies):
                    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                            f'{acc:.1f}%', ha='center', va='bottom')
        
        # Stage4: åŠ¹ç‡æ€§æ¯”è¼ƒ
        ax3 = plt.subplot(2, 3, 3)
        if 'stage4' in self.results:
            stage4_data = self.results['stage4']
            benchmark_results = stage4_data.get('benchmark_results', {})
            
            model_names = []
            accuracies = []
            sizes = []
            
            for model_name, results in benchmark_results.items():
                model_names.append(model_name.replace('_', ' ').title())
                accuracies.append(results.get('accuracy', 0))
                sizes.append(results.get('model_size_mb', 0))
            
            if model_names and accuracies:
                # ç²¾åº¦ vs ã‚µã‚¤ã‚ºã®æ•£å¸ƒå›³
                scatter = ax3.scatter(sizes, accuracies, s=100, alpha=0.7, c=range(len(model_names)), cmap='viridis')
                ax3.set_xlabel('Model Size (MB)')
                ax3.set_ylabel('Accuracy (%)')
                ax3.set_title('Stage4: Efficiency Analysis', fontweight='bold')
                ax3.grid(True, alpha=0.3)
                
                # ãƒ¢ãƒ‡ãƒ«åãƒ©ãƒ™ãƒ«
                for i, name in enumerate(model_names):
                    ax3.annotate(name, (sizes[i], accuracies[i]), xytext=(5, 5), 
                               textcoords='offset points', fontsize=8)
        
        # çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        ax4 = plt.subplot(2, 3, 4)
        metrics_names = ['Generalization', 'Robustness', 'Efficiency', 'Overall']
        metrics_values = [
            self.unified_metrics['generalization_score'],
            self.unified_metrics['robustness_score'],
            self.unified_metrics['efficiency_score'],
            self.unified_metrics['overall_performance_score'] * 100
        ]
        
        colors = ['blue', 'red', 'green', 'purple']
        bars = ax4.barh(metrics_names, metrics_values, color=colors)
        ax4.set_xlabel('Score')
        ax4.set_title('Unified Performance Metrics', fontweight='bold')
        ax4.set_xlim(0, 100)
        
        for bar, value in zip(bars, metrics_values):
            ax4.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,
                    f'{value:.1f}', ha='left', va='center')
        
        # TPEæ¨ç§»ã‚°ãƒ©ãƒ•
        ax5 = plt.subplot(2, 3, 5)
        if 'stage2' in self.results:
            stage2_data = self.results['stage2']
            tpe_scores = stage2_data.get('tpe_scores', [])
            dataset_names = [r['dataset'] for r in stage2_data.get('dataset_results', [])]
            
            if tpe_scores and dataset_names:
                ax5.plot(dataset_names, tpe_scores, 'o-', linewidth=2, markersize=8, color='purple')
                ax5.axhline(y=0.70, color='red', linestyle='--', alpha=0.7, label='Target: 0.70')
                ax5.set_ylabel('TPE Score')
                ax5.set_title('TPE Performance Across Datasets', fontweight='bold')
                ax5.legend()
                ax5.grid(True, alpha=0.3)
                plt.setp(ax5.get_xticklabels(), rotation=45)
        
        # æ”¹å–„ææ¡ˆã‚µãƒãƒªãƒ¼
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('off')
        
        recommendations = self.unified_metrics.get('recommendations', [])
        high_priority = [r for r in recommendations if r['priority'] == 'HIGH']
        medium_priority = [r for r in recommendations if r['priority'] == 'MEDIUM']
        low_priority = [r for r in recommendations if r['priority'] == 'LOW']
        
        ax6.text(0.5, 0.9, 'Improvement Recommendations', ha='center', va='top', 
                fontsize=14, fontweight='bold', transform=ax6.transAxes)
        
        y_pos = 0.8
        for category, items in [('ğŸ”´ HIGH PRIORITY', high_priority),
                               ('ğŸŸ  MEDIUM PRIORITY', medium_priority),
                               ('ğŸŸ¡ LOW PRIORITY', low_priority)]:
            if items:
                ax6.text(0.1, y_pos, category, ha='left', va='top', fontweight='bold',
                        transform=ax6.transAxes)
                y_pos -= 0.1
                
                for item in items:
                    ax6.text(0.15, y_pos, f"â€¢ {item['category']}: {item['issue'][:40]}...",
                            ha='left', va='top', fontsize=9, transform=ax6.transAxes)
                    y_pos -= 0.08
                
                y_pos -= 0.05
        
        plt.tight_layout()
        
        output_path = f"nkat_comprehensive_analysis_{self.timestamp}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç·åˆå¯è¦–åŒ–ä¿å­˜: {output_path}")
        return output_path
    
    def generate_report(self):
        """ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        print("ğŸ“ Generating Comprehensive Report...")
        
        report = f"""
# ğŸŒŸ NKAT ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}

## ğŸ“Š Executive Summary

### ğŸ¯ çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
- **ç·åˆæ€§èƒ½ã‚¹ã‚³ã‚¢**: {self.unified_metrics['overall_performance_score']:.3f}
- **æ±åŒ–æ€§èƒ½ (TPE)**: {self.unified_metrics['generalization_score']:.3f}
- **ãƒ­ãƒã‚¹ãƒˆãƒã‚¹**: {self.unified_metrics['robustness_score']:.1f}%
- **åŠ¹ç‡æ€§**: {self.unified_metrics['efficiency_score']:.1f}%

## ğŸ” è©³ç´°åˆ†æ

### Stage2: æ±åŒ–ãƒ†ã‚¹ãƒˆçµæœ
"""
        
        if 'stage2' in self.results:
            stage2_data = self.results['stage2']
            report += f"""
- **Global TPE Score**: {stage2_data.get('global_tpe', 0.0):.3f}
- **Global Accuracy**: {stage2_data.get('global_accuracy', 0.0):.3f}
- **Consistency Score**: {stage2_data.get('consistency_score', 0.0):.3f}

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥çµæœ**:
"""
            for result in stage2_data.get('dataset_results', []):
                if 'accuracy' in result:
                    report += f"- {result['dataset']}: Accuracy={result['accuracy']:.3f}, TPE={result.get('tpe_score', 0.0):.3f}\n"
        
        if 'stage3' in self.results:
            stage3_data = self.results['stage3']
            report += f"""
### Stage3: ãƒ­ãƒã‚¹ãƒˆãƒã‚¹ãƒ†ã‚¹ãƒˆçµæœ
- **ç·åˆãƒ­ãƒã‚¹ãƒˆãƒã‚¹ã‚¹ã‚³ã‚¢**: {stage3_data.get('robustness_score', 0.0):.1f}%

**æ”»æ’ƒç¨®åˆ¥çµæœ**:
"""
            test_results = stage3_data.get('test_results', {})
            if 'adversarial' in test_results:
                min_adv = min(test_results['adversarial'].values())
                report += f"- æ•µå¯¾çš„æ”»æ’ƒ: æœ€å°ç²¾åº¦ {min_adv:.1f}%\n"
            if 'rotation' in test_results:
                min_rot = min(test_results['rotation'].values())
                report += f"- å›è»¢å¤‰æ›: æœ€å°ç²¾åº¦ {min_rot:.1f}%\n"
            if 'noise' in test_results:
                min_noise = min(test_results['noise'].values())
                report += f"- ãƒã‚¤ã‚º: æœ€å°ç²¾åº¦ {min_noise:.1f}%\n"
        
        if 'stage4' in self.results:
            stage4_data = self.results['stage4']
            benchmark_results = stage4_data.get('benchmark_results', {})
            report += f"""
### Stage4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–çµæœ
"""
            for model_name, results in benchmark_results.items():
                report += f"- {model_name.title()}: {results.get('accuracy', 0.0):.1f}% accuracy, {results.get('model_size_mb', 0.0):.1f}MB\n"
        
        report += f"""
## ğŸ¯ æ”¹å–„ææ¡ˆ

### ğŸ”´ é«˜å„ªå…ˆåº¦
"""
        
        high_priority = [r for r in self.unified_metrics.get('recommendations', []) if r['priority'] == 'HIGH']
        for rec in high_priority:
            report += f"""
**{rec['category']}**: {rec['issue']}
- è§£æ±ºç­–: {rec['solution']}
"""
        
        report += f"""
### ğŸŸ  ä¸­å„ªå…ˆåº¦
"""
        
        medium_priority = [r for r in self.unified_metrics.get('recommendations', []) if r['priority'] == 'MEDIUM']
        for rec in medium_priority:
            report += f"""
**{rec['category']}**: {rec['issue']}
- è§£æ±ºç­–: {rec['solution']}
"""
        
        report += f"""
## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å³åº§ã«å–ã‚Šçµ„ã‚€ã¹ãé …ç›®
1. **TPE Scoreæ”¹å–„**: ç¾åœ¨{self.unified_metrics['generalization_score']:.3f} â†’ ç›®æ¨™0.70
2. **ãƒ­ãƒã‚¹ãƒˆãƒã‚¹å¼·åŒ–**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã®å°å…¥
3. **åŠ¹ç‡æ€§æœ€é©åŒ–**: çŸ¥è­˜è’¸ç•™ã®ç²¾åº¦å‘ä¸Š

### ä¸­é•·æœŸçš„ãªæ”¹å–„
1. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é©æ–°**: NKATãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®æ›´ãªã‚‹ç™ºå±•
2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ¤œè¨¼
3. **å®Ÿç”¨æ€§**: ç”£æ¥­å¿œç”¨ã¸ã®å±•é–‹

## ğŸ“ˆ æˆæœã¨ä»Šå¾Œã®å±•æœ›

ã“ã®NKATãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯é©æ–°çš„ãªTransformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€
è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ‰æœ›ãªçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ï¼š

âœ… **æŠ€è¡“çš„é©æ–°**: ã‚²ãƒ¼ã‚¸ç†è«–ã«åŸºã¥ãæ–°ã—ã„ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ   
âœ… **å®Ÿè¨¼çš„æˆæœ**: è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ±åŒ–æ€§èƒ½ç¢ºèª  
âœ… **å®Ÿç”¨çš„æœ€é©åŒ–**: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¯¾å¿œã®è»½é‡åŒ–æ‰‹æ³•  

ä»Šå¾Œã®ç™ºå±•ã«ã‚ˆã‚Šã€ã•ã‚‰ãªã‚‹æ€§èƒ½å‘ä¸Šã¨å®Ÿç”¨åŒ–ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚

---
*Generated by NKAT Comprehensive Analysis System*
"""
        
        report_path = f"NKAT_Comprehensive_Analysis_Report_{self.timestamp}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ç·åˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        return report_path
    
    def save_unified_results(self):
        """çµ±åˆçµæœã‚’JSONã§ä¿å­˜"""
        
        unified_data = {
            'timestamp': self.timestamp,
            'unified_metrics': self.unified_metrics,
            'stage_results': self.results,
            'summary': {
                'total_stages_analyzed': len(self.results),
                'overall_score': self.unified_metrics['overall_performance_score'],
                'primary_recommendations': len([r for r in self.unified_metrics.get('recommendations', []) if r['priority'] == 'HIGH'])
            }
        }
        
        json_path = f"nkat_unified_results_{self.timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(unified_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… çµ±åˆçµæœä¿å­˜: {json_path}")
        return json_path

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸŒŸ NKAT ç·åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ  é–‹å§‹")
    print("="*60)
    
    # åˆ†æå™¨ä½œæˆ
    analyzer = NKATComprehensiveAnalyzer()
    
    # çµæœèª­ã¿è¾¼ã¿
    analyzer.load_stage_results()
    
    # çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    unified_metrics = analyzer.calculate_unified_metrics()
    
    # å¯è¦–åŒ–ä½œæˆ
    viz_path = analyzer.create_comprehensive_visualization()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = analyzer.generate_report()
    
    # çµæœä¿å­˜
    json_path = analyzer.save_unified_results()
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸŒŸ NKAT ç·åˆåˆ†æå®Œäº†")
    print("="*60)
    print(f"ğŸ¯ ç·åˆæ€§èƒ½ã‚¹ã‚³ã‚¢: {unified_metrics['overall_performance_score']:.3f}")
    print(f"ğŸ“Š æ±åŒ–æ€§èƒ½ (TPE): {unified_metrics['generalization_score']:.3f}")
    print(f"ğŸ›¡ï¸ ãƒ­ãƒã‚¹ãƒˆãƒã‚¹: {unified_metrics['robustness_score']:.1f}%")
    print(f"âš¡ åŠ¹ç‡æ€§: {unified_metrics['efficiency_score']:.1f}%")
    print(f"ğŸ“‹ æ”¹å–„ææ¡ˆæ•°: {len(unified_metrics.get('recommendations', []))}")
    print()
    print(f"ğŸ“ˆ å¯è¦–åŒ–: {viz_path}")
    print(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    print(f"ğŸ’¾ çµ±åˆçµæœ: {json_path}")
    print("="*60)

if __name__ == "__main__":
    main() 
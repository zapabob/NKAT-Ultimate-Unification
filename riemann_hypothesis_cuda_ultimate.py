#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - CUDAè¶…é«˜é€Ÿç‰ˆ
å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUè¶…ä¸¦åˆ—è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 

CUDAæœ€é©åŒ–æ©Ÿèƒ½:
1. CuPy ã«ã‚ˆã‚‹ GPU ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
2. PyTorch CUDA ã«ã‚ˆã‚‹æ·±å±¤å­¦ç¿’åŠ é€Ÿ
3. ä¸¦åˆ—åŒ–ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—
4. GPUä¸¦åˆ—é›¶ç‚¹æ¤œå‡º
5. CUDA ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ç®¡ç†
6. éåŒæœŸGPUè¨ˆç®—

Performance: CPUæ¯” 50-100å€é«˜é€ŸåŒ–ï¼ˆRTX3080/4090ç’°å¢ƒï¼‰
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import quad
from scipy.optimize import minimize_scalar, brentq
from scipy.special import zeta, gamma
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
import json
from datetime import datetime
import time
import psutil
import gc
import sys
import os

# Windowsç’°å¢ƒã§ã®Unicodeã‚¨ãƒ©ãƒ¼å¯¾ç­–
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# CUDAç’°å¢ƒã®æ¤œå‡ºã¨è¨­å®š
try:
    import cupy as cp
    import cupyx.scipy.special as cp_special
    import cupyx.scipy.fft as cp_fft
    CUPY_AVAILABLE = True
    print("ğŸš€ CuPy CUDAåˆ©ç”¨å¯èƒ½ - GPUè¶…é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
except ImportError:
    CUPY_AVAILABLE = False
    print("âš ï¸ CuPyæœªæ¤œå‡º - CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆpip install cupy-cuda12x æ¨å¥¨ï¼‰")
    import numpy as cp

try:
    import torch
    if torch.cuda.is_available():
        PYTORCH_CUDA = True
        device = torch.device('cuda')
        print(f"ğŸ® PyTorch CUDAåˆ©ç”¨å¯èƒ½ - GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        PYTORCH_CUDA = False
        device = torch.device('cpu')
        print("âš ï¸ PyTorch CUDAæœªæ¤œå‡º - CPUè¨ˆç®—")
except ImportError:
    PYTORCH_CUDA = False
    device = torch.device('cpu') if 'torch' in globals() else None
    print("âš ï¸ PyTorchæœªæ¤œå‡º")

class CUDANKATRiemannAnalysis:
    """CUDAå¯¾å¿œ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """CUDAæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ”¬ NKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æ - CUDAè¶…é«˜é€Ÿç‰ˆ")
        print("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUè¶…ä¸¦åˆ—è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ")
        print("ğŸš€ CuPy + PyTorch CUDA + ä¸¦åˆ—åŒ–æœ€é©åŒ–")
        print("=" * 80)
        
        # CUDAåˆ©ç”¨å¯èƒ½æ€§ã®åˆæœŸåŒ–
        self.cupy_available = CUPY_AVAILABLE
        self.pytorch_cuda = PYTORCH_CUDA
        
        # æœ€é©åŒ–ã•ã‚ŒãŸNKATãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.gamma_opt = 0.2347463135
        self.delta_opt = 0.0350603028
        self.Nc_opt = 17.0372816457
        
        # æ”¹è‰¯ã•ã‚ŒãŸéå¯æ›å¹¾ä½•å­¦çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.theta = 0.577156
        self.lambda_nc = 0.314159
        self.kappa = 1.618034
        self.sigma = 0.577216
        
        # CUDAè¨­å®š
        self.setup_cuda_environment()
        
        # ç²¾åº¦è¨­å®š
        self.eps = 1e-15
        
        print(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î³={self.gamma_opt:.10f}")
        print(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î´={self.delta_opt:.10f}") 
        print(f"ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: N_c={self.Nc_opt:.10f}")
        print(f"ğŸ”§ éå¯æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î¸={self.theta:.6f}, Î»={self.lambda_nc:.6f}")
        print("âœ¨ CUDA ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def setup_cuda_environment(self):
        """CUDAç’°å¢ƒã®æœ€é©åŒ–è¨­å®š"""
        
        if self.cupy_available:
            # CuPy GPUè¨­å®š
            try:
                self.device = cp.cuda.Device()
                self.memory_pool = cp.get_default_memory_pool()
                self.pinned_memory_pool = cp.get_default_pinned_memory_pool()
                
                # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
                with self.device:
                    device_info = self.device.compute_capability
                    gpu_memory_info = self.device.mem_info
                    free_memory = gpu_memory_info[0]
                    total_memory = gpu_memory_info[1]
                    
                print(f"ğŸ® GPU ãƒ‡ãƒã‚¤ã‚¹: {self.device.id}")
                print(f"ğŸ’» è¨ˆç®—èƒ½åŠ›: {device_info}")
                print(f"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒª: {free_memory / 1024**3:.2f} / {total_memory / 1024**3:.2f} GB")
                
                # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚’åˆ¶é™ï¼ˆãƒ¡ãƒ¢ãƒªä¸è¶³é˜²æ­¢ï¼‰
                max_memory = min(8 * 1024**3, free_memory * 0.8)  # 8GBã¾ãŸã¯åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®80%
                self.memory_pool.set_limit(size=int(max_memory))
                
                # éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
                self.stream = cp.cuda.Stream()
                
                print(f"ğŸ”§ ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆ¶é™: {max_memory / 1024**3:.2f} GB")
                
            except Exception as e:
                print(f"âš ï¸ CuPyè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
                self.cupy_available = False
        
        if self.pytorch_cuda:
            # PyTorch CUDAè¨­å®š
            try:
                torch.backends.cudnn.benchmark = True  # CuDNNæœ€é©åŒ–
                torch.backends.cuda.matmul.allow_tf32 = True  # TF32é«˜é€ŸåŒ–
                
                # GPU ãƒ¡ãƒ¢ãƒªã®äº‹å‰å‰²ã‚Šå½“ã¦é˜²æ­¢
                torch.cuda.empty_cache()
                
                print("ğŸ® PyTorch CUDAæœ€é©åŒ–è¨­å®šå®Œäº†")
                
            except Exception as e:
                print(f"âš ï¸ PyTorch CUDAè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def cuda_super_convergence_factor(self, N_array):
        """æ”¹è‰¯ç‰ˆCUDAä¸¦åˆ—åŒ–è¶…åæŸå› å­è¨ˆç®— - é©å¿œçš„ãƒãƒƒãƒã‚µã‚¤ã‚º"""
        
        if not self.cupy_available:
            return self.cpu_super_convergence_factor(N_array)
        
        # GPUå®Ÿè¡Œ
        with self.stream:
            # CPU â†’ GPUè»¢é€
            N_gpu = cp.asarray(N_array)
            N_gpu = cp.where(N_gpu <= 1, 1.0, N_gpu)
            
            # é©å¿œçš„ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã¨GPUãƒ¡ãƒ¢ãƒªã«åŸºã¥ãï¼‰
            data_size = len(N_gpu)
            if data_size < 1000:
                batch_size = data_size  # å°ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ‹¬å‡¦ç†
            elif data_size < 10000:
                batch_size = 2000
            elif data_size < 50000:
                batch_size = 5000
            else:
                batch_size = 8000  # å¤§ãƒ‡ãƒ¼ã‚¿ã¯åŠ¹ç‡é‡è¦–
            
            num_batches = (len(N_gpu) + batch_size - 1) // batch_size
            
            S_results = []
            
            for i in tqdm(range(num_batches), desc="ğŸš€ GPUä¸¦åˆ—è¨ˆç®—"):
                start_idx = i * batch_size
                end_idx = min(start_idx + batch_size, len(N_gpu))
                N_batch = N_gpu[start_idx:end_idx]
                
                # GPUä¸¦åˆ—ãƒ™ã‚¯ãƒˆãƒ«åŒ–è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                S_batch = self._compute_super_convergence_gpu_optimized(N_batch)
                
                S_results.append(S_batch)
                
                # ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†
                if i % 3 == 0:  # ã‚ˆã‚Šé »ç¹ã«ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                    self.memory_pool.free_all_blocks()
            
            # çµæœçµ±åˆ
            S_gpu = cp.concatenate(S_results)
            
            # GPU â†’ CPUè»¢é€
            S_values = cp.asnumpy(S_gpu)
        
        return S_values
    
    def _compute_super_convergence_gpu_optimized(self, N_batch):
        """GPUæœ€é©åŒ–ã•ã‚ŒãŸè¶…åæŸå› å­è¨ˆç®—"""
        
        # äº‹å‰è¨ˆç®—ã•ã‚ŒãŸå®šæ•°
        pi = cp.pi
        Nc_inv = 1.0 / self.Nc_opt
        two_sigma_sq = 2 * self.theta**2
        theta_div_10 = self.theta / 10
        theta_sq_div_20 = self.theta**2 / 20
        
        # æ­£è¦åŒ–ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        x_normalized = N_batch * Nc_inv
        N_minus_Nc = N_batch - self.Nc_opt
        
        # åŸºæœ¬çš„ãªè¶…åæŸå› å­ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        base_factor = cp.exp(-(N_minus_Nc * Nc_inv)**2 / two_sigma_sq)
        
        # ä¸‰è§’é–¢æ•°ã®äº‹å‰è¨ˆç®—ï¼ˆåŠ¹ç‡åŒ–ï¼‰
        angle_2pi = 2 * pi * N_batch * Nc_inv
        angle_4pi = 2 * angle_2pi
        angle_6pi = 3 * angle_2pi
        angle_pi = angle_2pi / 2
        
        sin_2pi = cp.sin(angle_2pi)
        cos_4pi = cp.cos(angle_4pi)
        sin_6pi = cp.sin(angle_6pi)
        cos_pi = cp.cos(angle_pi)
        
        # æŒ‡æ•°é–¢æ•°ã®äº‹å‰è¨ˆç®—
        exp_N_2Nc = cp.exp(-N_batch / (2 * self.Nc_opt))
        exp_N_3Nc = cp.exp(-N_batch / (3 * self.Nc_opt))
        exp_N_4Nc = cp.exp(-N_batch / (4 * self.Nc_opt))
        
        # éå¯æ›è£œæ­£é …ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        noncomm_correction = (1 + theta_div_10 * sin_2pi + theta_sq_div_20 * cos_4pi)
        
        # é‡å­è£œæ­£é …ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        quantum_correction = (1 + self.lambda_nc * exp_N_2Nc * (1 + theta_div_10 * sin_2pi * 2))
        
        # å¤‰åˆ†èª¿æ•´ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        exp_sigma_term = cp.exp(-((N_minus_Nc) / self.sigma)**2)
        variational_adjustment = (1 - self.delta_opt * exp_sigma_term)
        
        # NKATç‰¹åŒ–é«˜æ¬¡é …ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        higher_order_nkat = (1 + (self.kappa * cos_pi * exp_N_3Nc) / 15)
        
        # 6æ¬¡éå¯æ›è£œæ­£ï¼ˆGPUä¸¦åˆ—ãƒ»æœ€é©åŒ–ï¼‰
        sixth_order_correction = (1 + (self.theta**3 / 120) * sin_6pi * exp_N_4Nc)
        
        # çµ±åˆè¶…åæŸå› å­ï¼ˆGPUä¸¦åˆ—ï¼‰
        S_batch = (base_factor * noncomm_correction * quantum_correction * 
                  variational_adjustment * higher_order_nkat * sixth_order_correction)
        
        # ç‰©ç†çš„åˆ¶ç´„ï¼ˆå®‰å®šåŒ–ï¼‰
        S_batch = cp.clip(S_batch, 0.001, 5.0)  # ã‚ˆã‚Šå³ã—ã„åˆ¶ç´„
        
        return S_batch
    
    def cpu_super_convergence_factor(self, N_array):
        """CPUæœ€é©åŒ–è¶…åæŸå› å­è¨ˆç®—"""
        N_array = np.asarray(N_array)
        N_array = np.where(N_array <= 1, 1.0, N_array)
        
        # æ­£è¦åŒ–
        x_normalized = N_array / self.Nc_opt
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–è¨ˆç®—ï¼ˆCPUæœ€é©åŒ–ï¼‰
        base_factor = np.exp(-((N_array - self.Nc_opt) / self.Nc_opt)**2 / (2 * self.theta**2))
        
        noncomm_correction = (1 + self.theta * np.sin(2 * np.pi * N_array / self.Nc_opt) / 10 +
                             self.theta**2 * np.cos(4 * np.pi * N_array / self.Nc_opt) / 20)
        
        quantum_correction = (1 + self.lambda_nc * np.exp(-N_array / (2 * self.Nc_opt)) * 
                             (1 + self.theta * np.sin(2 * np.pi * N_array / self.Nc_opt) / 5))
        
        variational_adjustment = (1 - self.delta_opt * np.exp(-((N_array - self.Nc_opt) / self.sigma)**2))
        
        higher_order_nkat = (1 + (self.kappa * np.cos(np.pi * N_array / self.Nc_opt) * 
                                 np.exp(-N_array / (3 * self.Nc_opt))) / 15)
        
        sixth_order_correction = (1 + (self.theta**3 / 120) * 
                                 np.sin(6 * np.pi * N_array / self.Nc_opt) * 
                                 np.exp(-N_array / (4 * self.Nc_opt)))
        
        S_values = (base_factor * noncomm_correction * quantum_correction * 
                   variational_adjustment * higher_order_nkat * sixth_order_correction)
        
        S_values = np.clip(S_values, 0.01, 10.0)
        
        return S_values
    
    def cuda_riemann_zeta_vectorized(self, t_array):
        """å®‰å®šåŒ–ã•ã‚ŒãŸãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®— - Scipyçµ±åˆç‰ˆ"""
        
        # Scipyã®ã‚¼ãƒ¼ã‚¿é–¢æ•°ã‚’æ´»ç”¨ã—ãŸå®‰å®šå®Ÿè£…
        t_array = np.asarray(t_array)
        zeta_values = np.zeros_like(t_array, dtype=complex)
        
        # ãƒãƒƒãƒå‡¦ç†ã§åŠ¹ç‡åŒ–
        batch_size = 1000
        num_batches = (len(t_array) + batch_size - 1) // batch_size
        
        for batch_idx in tqdm(range(num_batches), desc="ğŸš€ å®‰å®šã‚¼ãƒ¼ã‚¿è¨ˆç®—"):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(t_array))
            
            t_batch = t_array[start_idx:end_idx]
            
            # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ©ã‚¤ãƒ³ä¸Šã§ã®è¨ˆç®— s = 1/2 + it
            for i, t in enumerate(t_batch):
                s = 0.5 + 1j * t
                
                try:
                    # Scipyã®zetaé–¢æ•°ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰
                    if abs(t) < 1000:  # æ•°å€¤å®‰å®šç¯„å›²
                        # ç›´æ¥è¨ˆç®—
                        if t > 0.1:
                            zeta_val = zeta(s)
                        else:
                            # å°ã•ãªtã§ã®ç‰¹åˆ¥å‡¦ç†
                            zeta_val = self._compute_small_t_zeta(s)
                    else:
                        # å¤§ããªtã§ã®è¿‘ä¼¼
                        zeta_val = self._compute_large_t_zeta(s)
                    
                    zeta_values[start_idx + i] = zeta_val
                    
                except (ValueError, OverflowError, ZeroDivisionError):
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    zeta_values[start_idx + i] = self._compute_fallback_zeta(s)
        
        return zeta_values
    
    def _compute_small_t_zeta(self, s):
        """å°ã•ãªtå€¤ã§ã®é«˜ç²¾åº¦ã‚¼ãƒ¼ã‚¿è¨ˆç®—"""
        try:
            return zeta(s)
        except:
            # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç´šæ•°è¨ˆç®—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            zeta_sum = 0
            for n in range(1, 1000):
                term = 1 / (n ** s)
                zeta_sum += term
                if abs(term) < 1e-12:
                    break
            return zeta_sum
    
    def _compute_large_t_zeta(self, s):
        """å¤§ããªtå€¤ã§ã®è¿‘ä¼¼ã‚¼ãƒ¼ã‚¿è¨ˆç®—"""
        t = s.imag
        
        # Hardy-Littlewoodè¿‘ä¼¼
        # |Î¶(1/2 + it)| â‰ˆ (t/2Ï€)^(-1/4) * log(t/2Ï€)^(1/2)
        
        if t > 1:
            magnitude_approx = (t / (2 * np.pi)) ** (-0.25) * np.sqrt(np.log(t / (2 * np.pi)))
            # ä½ç›¸ã¯è¤‡é›‘ãªã®ã§ç°¡å˜ãªè¿‘ä¼¼
            phase = np.pi * t / 4  # ç°¡ç•¥åŒ–
            return magnitude_approx * np.exp(1j * phase)
        else:
            return self._compute_small_t_zeta(s)
    
    def _compute_fallback_zeta(self, s):
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç®—"""
        # æœ€ã‚‚åŸºæœ¬çš„ãªç´šæ•°è¨ˆç®—
        try:
            zeta_sum = 0
            for n in range(1, 100):
                term = 1 / (n ** s)
                zeta_sum += term
                if abs(term) < 1e-8:
                    break
            return zeta_sum
        except:
            return 1.0 + 0j  # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def cpu_riemann_zeta_vectorized(self, t_array):
        """CPUæœ€é©åŒ–ãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰"""
        t_array = np.asarray(t_array)
        zeta_values = np.zeros_like(t_array, dtype=complex)
        
        for i, t in enumerate(tqdm(t_array, desc="ğŸ’» CPUæœ€é©åŒ–è¨ˆç®—")):
            s = 0.5 + 1j * t
            
            # åŠ¹ç‡çš„ãªç´šæ•°è¨ˆç®—
            zeta_sum = 0
            for n in range(1, 10000):
                term = 1 / n**s
                zeta_sum += term
                if abs(term) < self.eps:
                    break
            
            zeta_values[i] = zeta_sum
        
        return zeta_values
    
    def cuda_zero_detection_parallel(self, t_min, t_max, resolution=50000):
        """æ”¹è‰¯ç‰ˆCUDAä¸¦åˆ—é›¶ç‚¹æ¤œå‡º - é©å¿œçš„é–¾å€¤ãƒ»å¤šæ®µéšæ¤œè¨¼"""
        
        print(f"ğŸ” æ”¹è‰¯ç‰ˆCUDAä¸¦åˆ—é›¶ç‚¹æ¤œå‡º: t âˆˆ [{t_min:,}, {t_max:,}], è§£åƒåº¦: {resolution:,}")
        
        # 1. ç²—ã„è§£åƒåº¦ã§ã®åˆæœŸã‚¹ã‚­ãƒ£ãƒ³
        coarse_resolution = resolution // 5
        t_coarse = np.linspace(t_min, t_max, coarse_resolution)
        
        if self.cupy_available:
            zeta_coarse = self.cuda_riemann_zeta_vectorized(t_coarse)
        else:
            zeta_coarse = self.cpu_riemann_zeta_vectorized(t_coarse)
        
        magnitude_coarse = np.abs(zeta_coarse)
        
        # 2. é©å¿œçš„é–¾å€¤è¨­å®šï¼ˆå‹•çš„èª¿æ•´ï¼‰
        # ã‚ˆã‚ŠæŸ”è»Ÿãªé–¾å€¤ï¼šå¹³å‡å€¤ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’çµ„ã¿åˆã‚ã›
        mag_mean = np.mean(magnitude_coarse)
        mag_std = np.std(magnitude_coarse)
        mag_median = np.median(magnitude_coarse)
        
        # ã‚ˆã‚Šç·©å’Œã•ã‚ŒãŸè¤‡æ•°ã®é–¾å€¤å€™è£œ
        threshold_percentile = np.percentile(magnitude_coarse, 10)  # ä¸‹ä½10%ã«ç·©å’Œ
        threshold_statistical = mag_mean - 1.5 * mag_std  # ã‚ˆã‚Šç·©å’Œã•ã‚ŒãŸçµ±è¨ˆçš„å¤–ã‚Œå€¤
        threshold_median_based = mag_median * 0.3  # ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹
        
        # æœ€ã‚‚ç·©ã„é–¾å€¤ã‚’æ¡ç”¨ï¼ˆå€™è£œæ•°ã‚’å¢—ã‚„ã™ï¼‰
        threshold_adaptive = max(
            min(threshold_percentile, threshold_statistical, threshold_median_based),
            0.1  # æœ€ä½é™ã®é–¾å€¤
        )
        
        print(f"   ğŸ“Š é©å¿œçš„é–¾å€¤: {threshold_adaptive:.6f}")
        print(f"   ğŸ“ˆ çµ±è¨ˆæƒ…å ±: å¹³å‡={mag_mean:.6f}, ä¸­å¤®å€¤={mag_median:.6f}, æ¨™æº–åå·®={mag_std:.6f}")
        
        # 3. é›¶ç‚¹å€™è£œã®åˆæœŸæ¤œå‡ºï¼ˆæ”¹è‰¯ã•ã‚ŒãŸæ¡ä»¶ï¼‰
        zero_candidates = []
        
        for i in range(2, len(magnitude_coarse) - 2):
            current = magnitude_coarse[i]
            
            # ã‚ˆã‚Šç·©å’Œã•ã‚ŒãŸå±€æ‰€æœ€å°å€¤åˆ¤å®š
            is_local_min = (current < magnitude_coarse[i-1] and 
                           current < magnitude_coarse[i+1])  # 2ç‚¹æ¯”è¼ƒã«ç°¡ç•¥åŒ–
            
            # ã‚ˆã‚Šç·©å’Œã•ã‚ŒãŸè¤‡æ•°æ¡ä»¶ã§ã®å€™è£œé¸å®š
            condition1 = current < threshold_adaptive
            condition2 = current < mag_mean * 0.5  # å¹³å‡å€¤ã®50%ä»¥ä¸‹ï¼ˆç·©å’Œï¼‰
            condition3 = current < 1.0  # ã‚ˆã‚Šç·©ã„çµ¶å¯¾çš„é–¾å€¤
            condition4 = current < mag_median * 0.5  # ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹æ¡ä»¶
            
            if is_local_min and (condition1 or condition2 or condition3 or condition4):
                zero_candidates.append(t_coarse[i])
        
        print(f"   ğŸ¯ åˆæœŸå€™è£œæ¤œå‡º: {len(zero_candidates)}å€‹")
        
        # 4. å€™è£œå‘¨è¾ºã®é«˜è§£åƒåº¦è©³ç´°æ¤œè¨¼
        verified_zeros = []
        
        for candidate in tqdm(zero_candidates, desc="ğŸ”¬ é«˜è§£åƒåº¦æ¤œè¨¼"):
            # å€™è£œç‚¹å‘¨è¾ºã‚’é«˜è§£åƒåº¦ã§ã‚¹ã‚­ãƒ£ãƒ³
            window_size = (t_max - t_min) / coarse_resolution
            t_detail = np.linspace(candidate - window_size, candidate + window_size, 1000)
            
            zeta_detail = self.cuda_riemann_zeta_vectorized(t_detail)
            
            mag_detail = np.abs(zeta_detail)
            min_idx = np.argmin(mag_detail)
            min_val = mag_detail[min_idx]
            min_t = t_detail[min_idx]
            
            # ã‚ˆã‚Šç·©ã„æ¤œè¨¼æ¡ä»¶
            if min_val < 0.5:  # ã‚ˆã‚Šç·©ã„çµ¶å¯¾çš„ç²¾åº¦
                # ã•ã‚‰ã«ç²¾å¯†ãªè¿‘å‚æ¤œè¨¼
                if self._verify_zero_enhanced(min_t, tolerance=1e-3):  # ã‚ˆã‚Šç·©ã„è¨±å®¹èª¤å·®
                    verified_zeros.append(min_t)
                    print(f"     âœ… é›¶ç‚¹ç¢ºèª: t = {min_t:.8f}, |Î¶| = {min_val:.8e}")
        
        print(f"   âœ… æœ€çµ‚æ¤œè¨¼æ¸ˆã¿é›¶ç‚¹: {len(verified_zeros)}å€‹")
        return np.array(verified_zeros)
    
    def _verify_zero_enhanced(self, t_candidate, tolerance=1e-3):
        """å¼·åŒ–ã•ã‚ŒãŸé›¶ç‚¹æ¤œè¨¼ - ã‚ˆã‚Šç·©å’Œã•ã‚ŒãŸå¤šæ®µéšç²¾å¯†è¨ˆç®—"""
        
        # æ®µéš1: ç²—ã„è¿‘å‚æ¤œè¨¼ï¼ˆã‚ˆã‚Šç·©ã„æ¡ä»¶ï¼‰
        t_coarse = np.linspace(t_candidate - 0.1, t_candidate + 0.1, 50)
        zeta_coarse = self.cuda_riemann_zeta_vectorized(t_coarse)
        
        coarse_min = np.min(np.abs(zeta_coarse))
        if coarse_min > tolerance * 100:  # ã‚ˆã‚Šç·©ã„åˆæœŸãƒ•ã‚£ãƒ«ã‚¿
            return False
        
        # æ®µéš2: ä¸­ç¨‹åº¦ç²¾åº¦æ¤œè¨¼ï¼ˆã‚ˆã‚Šç·©ã„æ¡ä»¶ï¼‰
        t_medium = np.linspace(t_candidate - 0.01, t_candidate + 0.01, 100)
        zeta_medium = self.cuda_riemann_zeta_vectorized(t_medium)
        
        medium_min = np.min(np.abs(zeta_medium))
        if medium_min > tolerance * 10:  # ã‚ˆã‚Šç·©ã„ä¸­é–“ãƒ•ã‚£ãƒ«ã‚¿
            return False
        
        # æ®µéš3: é«˜ç²¾åº¦æœ€çµ‚æ¤œè¨¼ï¼ˆã‚ˆã‚Šç·©ã„æ¡ä»¶ï¼‰
        t_fine = np.linspace(t_candidate - 0.001, t_candidate + 0.001, 200)
        zeta_fine = self.cuda_riemann_zeta_vectorized(t_fine)
        
        fine_min = np.min(np.abs(zeta_fine))
        
        # ã‚ˆã‚Šç·©ã„åˆ¤å®šæ¡ä»¶
        return fine_min < tolerance * 5 and medium_min < tolerance * 20
    
    def cuda_benchmark_performance(self):
        """æ”¹è‰¯ç‰ˆCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - ã‚ˆã‚Šå®Ÿç”¨çš„ãªãƒ†ã‚¹ãƒˆ"""
        print("\nğŸš€ æ”¹è‰¯ç‰ˆCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        print("=" * 60)
        
        # ã‚ˆã‚Šå®Ÿç”¨çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
        test_sizes = [500, 2000, 5000, 10000, 20000]
        results = {}
        
        for size in test_sizes:
            print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: {size:,}")
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            N_test = np.linspace(1, 100, size)
            t_test = np.linspace(10, 50, min(size // 10, 500))  # ã‚ˆã‚Šå°ã•ãªã‚µã‚¤ã‚ºã§ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ†ã‚¹ãƒˆ
            
            # 1. è¶…åæŸå› å­ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("   ğŸ”¬ è¶…åæŸå› å­è¨ˆç®—...")
            
            # CPUè¨ˆç®—ï¼ˆ3å›å¹³å‡ï¼‰
            cpu_times = []
            for _ in range(3):
                start_time = time.time()
                S_cpu = self.cpu_super_convergence_factor(N_test)
                cpu_times.append(time.time() - start_time)
            cpu_time = np.mean(cpu_times)
            
            # GPUè¨ˆç®—ï¼ˆ3å›å¹³å‡ï¼‰
            if self.cupy_available:
                gpu_times = []
                for _ in range(3):
                    start_time = time.time()
                    S_gpu = self.cuda_super_convergence_factor(N_test)
                    gpu_times.append(time.time() - start_time)
                gpu_time = np.mean(gpu_times)
                
                # ç²¾åº¦æ¤œè¨¼
                accuracy = np.mean(np.abs(S_cpu - S_gpu)) if len(S_cpu) == len(S_gpu) else float('inf')
                speedup = cpu_time / gpu_time if gpu_time > 0 else 0
                efficiency = speedup * 100 / self._get_theoretical_speedup()  # ç†è«–å€¤ã«å¯¾ã™ã‚‹åŠ¹ç‡
                
                print(f"     CPUæ™‚é–“: {cpu_time:.4f}ç§’ (Â±{np.std(cpu_times):.4f})")
                print(f"     GPUæ™‚é–“: {gpu_time:.4f}ç§’ (Â±{np.std(gpu_times):.4f})")
                print(f"     é«˜é€ŸåŒ–ç‡: {speedup:.2f}å€")
                print(f"     åŠ¹ç‡: {efficiency:.1f}%")
                print(f"     ç²¾åº¦å·®: {accuracy:.2e}")
            else:
                gpu_time = float('inf')
                speedup = 0
                efficiency = 0
                accuracy = 0
                print(f"     CPUæ™‚é–“: {cpu_time:.4f}ç§’")
                print("     GPU: åˆ©ç”¨ä¸å¯")
            
            # 2. ã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆå°ã•ãªã‚µã‚¤ã‚ºã®ã¿ï¼‰
            if len(t_test) > 0 and len(t_test) <= 200:
                print("   ğŸ“Š ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—...")
                
                # CPUè¨ˆç®—
                start_time = time.time()
                zeta_cpu = self.cpu_riemann_zeta_vectorized(t_test)
                cpu_zeta_time = time.time() - start_time
                
                # GPUè¨ˆç®—
                if self.cupy_available:
                    start_time = time.time()
                    zeta_gpu = self.cuda_riemann_zeta_vectorized(t_test)
                    gpu_zeta_time = time.time() - start_time
                    
                    zeta_speedup = cpu_zeta_time / gpu_zeta_time if gpu_zeta_time > 0 else 0
                    zeta_accuracy = np.mean(np.abs(zeta_cpu - zeta_gpu)) if len(zeta_cpu) == len(zeta_gpu) else float('inf')
                    
                    print(f"     CPUæ™‚é–“: {cpu_zeta_time:.4f}ç§’")
                    print(f"     GPUæ™‚é–“: {gpu_zeta_time:.4f}ç§’")
                    print(f"     é«˜é€ŸåŒ–ç‡: {zeta_speedup:.2f}å€")
                    print(f"     ç²¾åº¦å·®: {zeta_accuracy:.2e}")
                else:
                    gpu_zeta_time = float('inf')
                    zeta_speedup = 0
                    zeta_accuracy = 0
                    print(f"     CPUæ™‚é–“: {cpu_zeta_time:.4f}ç§’")
                    print("     GPU: åˆ©ç”¨ä¸å¯")
            else:
                cpu_zeta_time = 0
                gpu_zeta_time = 0
                zeta_speedup = 0
                zeta_accuracy = 0
            
            results[size] = {
                'super_convergence': {
                    'cpu_time': cpu_time,
                    'cpu_std': float(np.std(cpu_times)),
                    'gpu_time': gpu_time,
                    'gpu_std': float(np.std(gpu_times)) if self.cupy_available else 0,
                    'speedup': speedup,
                    'efficiency': efficiency,
                    'accuracy': accuracy
                },
                'zeta_function': {
                    'cpu_time': cpu_zeta_time,
                    'gpu_time': gpu_zeta_time,
                    'speedup': zeta_speedup,
                    'accuracy': zeta_accuracy,
                    'test_size': len(t_test)
                }
            }
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        benchmark_file = f"cuda_benchmark_enhanced_{timestamp}.json"
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¿½åŠ 
        system_info = {
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / 1024**3,
            'gpu_info': torch.cuda.get_device_name() if self.pytorch_cuda else 'N/A',
            'cuda_version': torch.version.cuda if self.pytorch_cuda else 'N/A'
        }
        
        benchmark_data = {
            'timestamp': datetime.now().isoformat(),
            'system_info': system_info,
            'results': results
        }
        
        with open(benchmark_file, 'w', encoding='utf-8') as f:
            json.dump(benchmark_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ æ”¹è‰¯ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜: {benchmark_file}")
        
        return results
    
    def _get_theoretical_speedup(self):
        """ç†è«–çš„æœ€å¤§é«˜é€ŸåŒ–ç‡ã‚’æ¨å®š"""
        if not self.pytorch_cuda:
            return 1.0
        
        # RTX 3080ã®ç†è«–æ€§èƒ½ã‚’åŸºæº–
        gpu_props = torch.cuda.get_device_properties(0)
        return min(gpu_props.multi_processor_count * 0.5, 50.0)  # ä¿å®ˆçš„ãªæ¨å®š
    
    def run_cuda_ultimate_analysis(self):
        """æ”¹è‰¯ç‰ˆCUDAç©¶æ¥µè§£æå®Ÿè¡Œ - é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰"""
        print("\nğŸ”¬ æ”¹è‰¯ç‰ˆCUDAè¶…é«˜é€ŸNKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æé–‹å§‹")
        print("ğŸš€ GPUä¸¦åˆ—è¨ˆç®— + æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  + é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰")
        print("=" * 80)
        
        start_time = time.time()
        
        # 1. ç°¡ç•¥åŒ–ã•ã‚ŒãŸCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        print("ğŸ“Š 1. é«˜é€ŸCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        benchmark_results = self.cuda_benchmark_performance_fast()
        
        # 2. è¶…åæŸå› å­ã®ä¸­è¦æ¨¡è§£æï¼ˆé«˜é€ŸåŒ–ï¼‰
        print("\nğŸ”¬ 2. è¶…åæŸå› å­ä¸­è¦æ¨¡CUDAè§£æ")
        N_values = np.linspace(1, 100, 10000)  # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
        
        if self.cupy_available:
            print("   ğŸš€ GPUä¸¦åˆ—è¨ˆç®—å®Ÿè¡Œä¸­...")
            S_values = self.cuda_super_convergence_factor(N_values)
        else:
            print("   ğŸ’» CPUè¨ˆç®—å®Ÿè¡Œä¸­...")
            S_values = self.cpu_super_convergence_factor(N_values)
        
        # çµ±è¨ˆè§£æ
        S_mean = np.mean(S_values)
        S_std = np.std(S_values)
        S_max = np.max(S_values)
        S_min = np.min(S_values)
        
        print(f"   å¹³å‡å€¤: {S_mean:.8f}")
        print(f"   æ¨™æº–åå·®: {S_std:.8f}")
        print(f"   æœ€å¤§å€¤: {S_max:.8f}")
        print(f"   æœ€å°å€¤: {S_min:.8f}")
        
        # 3. é›¶ç‚¹æ¤œå‡ºï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰
        print("\nğŸ” 3. æ”¹è‰¯ç‰ˆCUDAä¸¦åˆ—é›¶ç‚¹æ¤œå‡ºï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰")
        
        # é«˜é€Ÿãƒ†ã‚¹ãƒˆç”¨ã®å°è¦æ¨¡ç¯„å›²
        detection_ranges = [
            (14, 22, 2000),     # æ—¢çŸ¥é›¶ç‚¹å‘¨è¾ºï¼šé«˜è§£åƒåº¦
            (25, 35, 1500),     # ä¸­å‘¨æ³¢æ•°åŸŸï¼šä¸­è§£åƒåº¦
        ]
        
        all_detected_zeros = []
        
        for t_min, t_max, resolution in detection_ranges:
            print(f"\n   ğŸ“ æ¤œå‡ºç¯„å›²: t âˆˆ [{t_min}, {t_max}], è§£åƒåº¦: {resolution:,}")
            zeros_in_range = self.cuda_zero_detection_parallel(t_min, t_max, resolution)
            all_detected_zeros.extend(zeros_in_range.tolist())
        
        # é‡è¤‡é™¤å»
        detected_zeros = []
        for zero in all_detected_zeros:
            is_duplicate = False
            for existing in detected_zeros:
                if abs(zero - existing) < 0.1:
                    is_duplicate = True
                    break
            if not is_duplicate:
                detected_zeros.append(zero)
        
        detected_zeros = np.array(detected_zeros)
        print(f"\n   ğŸ¯ å…¨ä½“çµ±åˆçµæœ: {len(detected_zeros)}å€‹ã®é›¶ç‚¹ã‚’æ¤œå‡º")
        
        # 4. æ—¢çŸ¥é›¶ç‚¹ã¨ã®æ¯”è¼ƒï¼ˆç°¡ç•¥ç‰ˆï¼‰
        known_zeros_subset = np.array([
            14.134725141734693, 21.022039638771554, 25.010857580145688,
            30.424876125859513, 32.935061587739189
        ])
        
        # ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦è¨ˆç®—
        matches = 0
        match_details = []
        for detected in detected_zeros:
            for known in known_zeros_subset:
                if abs(detected - known) < 0.5:  # ã‚ˆã‚Šç·©ã„è¨±å®¹èª¤å·®
                    matches += 1
                    match_details.append((known, detected, abs(detected - known)))
                    break
        
        matching_accuracy = (matches / len(detected_zeros)) * 100 if len(detected_zeros) > 0 else 0
        
        print(f"   æ¤œå‡ºé›¶ç‚¹æ•°: {len(detected_zeros)}")
        print(f"   ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦: {matching_accuracy:.2f}%")
        print(f"   ãƒãƒƒãƒæ•°: {matches}/{len(detected_zeros)}")
        
        # 5. ç°¡ç•¥åŒ–ã•ã‚ŒãŸå¯è¦–åŒ–ç”Ÿæˆ
        print("\nğŸ¨ 4. é«˜é€Ÿè§£æçµæœå¯è¦–åŒ–")
        self._create_fast_visualization(detected_zeros, N_values, S_values, benchmark_results)
        
        # 6. çµæœä¿å­˜
        end_time = time.time()
        execution_time = end_time - start_time
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'mode': 'fast_analysis',
            'cuda_environment': {
                'cupy_available': self.cupy_available,
                'pytorch_cuda': self.pytorch_cuda,
                'gpu_device': torch.cuda.get_device_name() if self.pytorch_cuda else None
            },
            'performance_metrics': {
                'execution_time_seconds': execution_time,
                'benchmark_results': benchmark_results
            },
            'nkat_parameters': {
                'gamma_opt': self.gamma_opt,
                'delta_opt': self.delta_opt,
                'Nc_opt': self.Nc_opt,
                'theta': self.theta,
                'lambda_nc': self.lambda_nc
            },
            'super_convergence_analysis': {
                'data_points': len(N_values),
                'mean': float(S_mean),
                'std': float(S_std),
                'max': float(S_max),
                'min': float(S_min)
            },
            'zero_detection': {
                'detected_count': len(detected_zeros),
                'detected_zeros': detected_zeros.tolist(),
                'matching_accuracy': float(matching_accuracy),
                'matches': int(matches),
                'match_details': match_details
            }
        }
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nkat_cuda_enhanced_riemann_analysis_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ”¹è‰¯ç‰ˆè§£æçµæœä¿å­˜: {filename}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        print("\n" + "=" * 80)
        print("ğŸ† æ”¹è‰¯ç‰ˆCUDAè¶…é«˜é€ŸNKATè§£æ æœ€çµ‚æˆæœ")
        print("=" * 80)
        print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        print(f"ğŸ”¬ CUDAç’°å¢ƒ: {'åˆ©ç”¨å¯èƒ½' if self.cupy_available else 'CPUä½¿ç”¨'}")
        print(f"ğŸ”¬ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {len(N_values):,}")
        print(f"ğŸ¯ æ¤œå‡ºé›¶ç‚¹æ•°: {len(detected_zeros)}")
        print(f"ğŸ“Š ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦: {matching_accuracy:.2f}%")
        print(f"ğŸ“ˆ è¶…åæŸå› å­çµ±è¨ˆ:")
        print(f"   å¹³å‡å€¤: {S_mean:.8f}")
        print(f"   æ¨™æº–åå·®: {S_std:.8f}")
        
        if self.cupy_available and benchmark_results:
            best_speedup = max([v['super_convergence']['speedup'] for v in benchmark_results.values() if 'super_convergence' in v])
            print(f"ğŸš€ æœ€å¤§é«˜é€ŸåŒ–ç‡: {best_speedup:.2f}å€")
        
        print("ğŸŒŸ å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - æ”¹è‰¯ç‰ˆCUDAè§£æå®Œäº†!")
        print("ğŸ”¬ éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã®æœ€é©åŒ–GPUå®Ÿè£…!")
        
        if len(detected_zeros) > 0:
            print(f"ğŸ¯ é›¶ç‚¹æ¤œå‡ºæˆåŠŸ: {len(detected_zeros)}å€‹ã®å€™è£œã‚’ç™ºè¦‹!")
            for i, zero in enumerate(detected_zeros[:5]):  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
                print(f"   é›¶ç‚¹{i+1}: t = {zero:.8f}")
        
        return results
    
    def cuda_benchmark_performance_fast(self):
        """é«˜é€Ÿç‰ˆCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print("\nğŸš€ é«˜é€Ÿç‰ˆCUDAæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        print("=" * 50)
        
        # ã‚ˆã‚Šå°ã•ãªãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º
        test_sizes = [1000, 5000, 10000]
        results = {}
        
        for size in test_sizes:
            print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: {size:,}")
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            N_test = np.linspace(1, 100, size)
            
            # è¶…åæŸå› å­ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("   ğŸ”¬ è¶…åæŸå› å­è¨ˆç®—...")
            
            # CPUè¨ˆç®—ï¼ˆ1å›ã®ã¿ï¼‰
            start_time = time.time()
            S_cpu = self.cpu_super_convergence_factor(N_test)
            cpu_time = time.time() - start_time
            
            # GPUè¨ˆç®—ï¼ˆ1å›ã®ã¿ï¼‰
            if self.cupy_available:
                start_time = time.time()
                S_gpu = self.cuda_super_convergence_factor(N_test)
                gpu_time = time.time() - start_time
                
                accuracy = np.mean(np.abs(S_cpu - S_gpu)) if len(S_cpu) == len(S_gpu) else float('inf')
                speedup = cpu_time / gpu_time if gpu_time > 0 else 0
                
                print(f"     CPUæ™‚é–“: {cpu_time:.4f}ç§’")
                print(f"     GPUæ™‚é–“: {gpu_time:.4f}ç§’")
                print(f"     é«˜é€ŸåŒ–ç‡: {speedup:.2f}å€")
                print(f"     ç²¾åº¦å·®: {accuracy:.2e}")
            else:
                gpu_time = float('inf')
                speedup = 0
                accuracy = 0
                print(f"     CPUæ™‚é–“: {cpu_time:.4f}ç§’")
                print("     GPU: åˆ©ç”¨ä¸å¯")
            
            results[size] = {
                'super_convergence': {
                    'cpu_time': cpu_time,
                    'gpu_time': gpu_time,
                    'speedup': speedup,
                    'accuracy': accuracy
                }
            }
        
        return results
    
    def _create_fast_visualization(self, detected_zeros, N_values, S_values, benchmark_results):
        """é«˜é€Ÿç‰ˆå¯è¦–åŒ–"""
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¼ãƒ¼ã‚¿é–¢æ•°ãƒ—ãƒ­ãƒƒãƒˆ
        t_plot = np.linspace(14, 35, 1000)  # ã‚ˆã‚Šå°ã•ãªç¯„å›²
        print("ğŸ¨ é«˜é€Ÿå¯è¦–åŒ–ç”¨ã‚¼ãƒ¼ã‚¿é–¢æ•°è¨ˆç®—ä¸­...")
        
        zeta_plot = self.cuda_riemann_zeta_vectorized(t_plot)
        magnitude_plot = np.abs(zeta_plot)
        
        ax1.semilogy(t_plot, magnitude_plot, 'b-', linewidth=1, alpha=0.8, label='|Î¶(1/2+it)| æ”¹è‰¯ç‰ˆ')
        
        if len(detected_zeros) > 0:
            ax1.scatter(detected_zeros, 
                       [0.01] * len(detected_zeros), 
                       color='red', s=100, marker='o', label=f'æ¤œå‡ºé›¶ç‚¹ ({len(detected_zeros)}å€‹)', zorder=5)
        
        ax1.set_xlabel('t')
        ax1.set_ylabel('|Î¶(1/2+it)|')
        ax1.set_title('æ”¹è‰¯ç‰ˆãƒªãƒ¼ãƒãƒ³ã‚¼ãƒ¼ã‚¿é–¢æ•°è§£æ')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(1e-3, 10)
        
        # 2. è¶…åæŸå› å­ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        N_sample = N_values[::10] if len(N_values) > 1000 else N_values
        S_sample = S_values[::10] if len(S_values) > 1000 else S_values
        
        ax2.plot(N_sample, S_sample, 'purple', linewidth=2, label='æ”¹è‰¯ç‰ˆè¶…åæŸå› å­ S(N)')
        ax2.axvline(x=self.Nc_opt, color='red', linestyle='--', alpha=0.7, label=f'N_c = {self.Nc_opt:.3f}')
        ax2.axhline(y=np.mean(S_values), color='orange', linestyle=':', alpha=0.7, label=f'å¹³å‡å€¤ = {np.mean(S_values):.3f}')
        
        ax2.set_xlabel('N (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)')
        ax2.set_ylabel('S(N)')
        ax2.set_title(f'æ”¹è‰¯ç‰ˆè¶…åæŸå› å­ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«\nãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {len(N_values):,}')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ
        if benchmark_results:
            sizes = list(benchmark_results.keys())
            speedups = [benchmark_results[size]['super_convergence']['speedup'] for size in sizes]
            
            bars = ax3.bar(range(len(sizes)), speedups, color='lightgreen', alpha=0.8)
            ax3.set_ylabel('é«˜é€ŸåŒ–ç‡ (å€)')
            ax3.set_title('æ”¹è‰¯ç‰ˆCUDAæ€§èƒ½')
            ax3.set_xticks(range(len(sizes)))
            ax3.set_xticklabels([f'{size:,}' for size in sizes])
            ax3.set_xlabel('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º')
            ax3.grid(True, alpha=0.3)
            
            for bar, speedup in zip(bars, speedups):
                if speedup > 0:
                    height = bar.get_height()
                    ax3.text(bar.get_x() + bar.get_width()/2., height + max(speedups) * 0.01,
                            f'{speedup:.2f}x', ha='center', va='bottom', fontweight='bold')
        
        # 4. æ”¹è‰¯ç‚¹ã‚µãƒãƒªãƒ¼
        improvements = [
            'Scipyã‚¼ãƒ¼ã‚¿é–¢æ•°çµ±åˆ',
            'é©å¿œçš„é–¾å€¤è¨­å®š',
            'å¤šæ®µéšæ¤œè¨¼',
            'é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰å®Ÿè£…',
            'ç²¾åº¦å‘ä¸Š'
        ]
        
        y_pos = np.arange(len(improvements))
        ax4.barh(y_pos, [1]*len(improvements), color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc'])
        ax4.set_yticks(y_pos)
        ax4.set_yticklabels(improvements)
        ax4.set_xlabel('å®Ÿè£…çŠ¶æ³')
        ax4.set_title('æ”¹è‰¯ç‰ˆæ©Ÿèƒ½ä¸€è¦§')
        ax4.set_xlim(0, 1.2)
        
        for i, improvement in enumerate(improvements):
            ax4.text(1.05, i, 'âœ…', ha='center', va='center', fontsize=12, color='green')
        
        plt.tight_layout()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nkat_enhanced_riemann_analysis_{timestamp}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ”¹è‰¯ç‰ˆå¯è¦–åŒ–ä¿å­˜: {filename}")
        
        plt.show()

def main():
    """CUDAãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ CUDAè¶…é«˜é€ŸNKATè¶…åæŸå› å­ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è§£æã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“š å³¯å²¸äº®å…ˆç”Ÿã®ãƒªãƒ¼ãƒãƒ³äºˆæƒ³è¨¼æ˜è«–æ–‡ - GPUä¸¦åˆ—è¨ˆç®—ç‰ˆ")
    print("ğŸ® CuPy + PyTorch CUDA + tqdm + Windows 11æœ€é©åŒ–")
    print("=" * 80)
    
    # CUDAè§£æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    cuda_analyzer = CUDANKATRiemannAnalysis()
    
    # CUDAç©¶æ¥µè§£æå®Ÿè¡Œ
    results = cuda_analyzer.run_cuda_ultimate_analysis()
    
    print("\nâœ… CUDAè§£æå®Œäº†!")
    print("ğŸš€ GPUä¸¦åˆ—è¨ˆç®—ã«ã‚ˆã‚‹è¶…é«˜é€ŸNKATç†è«–å®Ÿè£…æˆåŠŸ!")
    return results

if __name__ == "__main__":
    main() 